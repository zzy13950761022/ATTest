=== Run Tests ===
F                                                                        [100%]
=================================== FAILURES ===================================
_ TestQuantizeG2.test_custom_mapping_parameter[simple_linear-False-custom-simple_calibration] _

self = <test_torch_ao_quantization_quantize_g2.TestQuantizeG2 object at 0x14f97e4a0>
model_type = 'simple_linear', inplace = False, mapping = 'custom'
run_fn_type = 'simple_calibration'
simple_linear_model = SimpleLinear(
  (linear1): Linear(in_features=10, out_features=20, bias=True)
  (relu): ReLU()
  (linear2): Linear(in_features=20, out_features=5, bias=True)
)
simple_calibration_fn = <function TestQuantizeG2.simple_calibration_fn.<locals>.calibration_fn at 0x14f9a9a20>

    @pytest.mark.parametrize("model_type,inplace,mapping,run_fn_type", [
        ("simple_linear", False, "custom", "simple_calibration"),
    ])
    def test_custom_mapping_parameter(self, model_type, inplace, mapping, run_fn_type,
                                     simple_linear_model, simple_calibration_fn):
        """TC-03: 自定义映射参数验证"""
        # Arrange
        import torch.ao.quantization as tq
    
        if model_type == "simple_linear":
            model = simple_linear_model
        else:
            pytest.skip(f"Model type {model_type} not implemented")
    
        if run_fn_type == "simple_calibration":
            run_fn = simple_calibration_fn
        else:
            pytest.skip(f"Run function type {run_fn_type} not implemented")
    
        run_args = ()
    
        # Define custom mapping
        custom_mapping = {
            "nn.Linear": "custom.quantized.Linear",
            "nn.ReLU": "custom.quantized.ReLU",
            "nn.Conv2d": "custom.quantized.Conv2d"
        }
    
        # Mock external dependencies
        with patch('torch._C._log_api_usage_once') as mock_log_api, \
             patch('torch.ao.quantization.prepare') as mock_prepare, \
             patch('torch.ao.quantization.convert') as mock_convert:
    
            # Setup mock returns for prepare and convert
            prepared_model = copy.deepcopy(model)
            mock_prepare.return_value = prepared_model
            mock_convert.return_value = prepared_model  # convert returns the same model
    
            # Keep track of original model state
            original_model_state = copy.deepcopy(model.state_dict())
            original_model_id = id(model)
    
            # Act
            result = tq.quantize(
                model=model,
                run_fn=run_fn,
                run_args=run_args,
                mapping=custom_mapping,
                inplace=inplace
            )
    
            # Assert (weak assertions)
            # 1. Returns a model
            assert result is not None, "quantize should return a model"
    
            # 2. Model structure preserved (same type)
            assert isinstance(result, type(model)), "Returned model should be same type as input"
    
            # 3. Custom mapping should be applied
            # Verify convert was called with custom mapping
>           mock_convert.assert_called_once()

tests/test_torch_ao_quantization_quantize_g2.py:136: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock name='convert' id='5630666272'>

    def assert_called_once(self):
        """assert that the mock was called only once.
        """
        if not self.call_count == 1:
            msg = ("Expected '%s' to have been called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
>           raise AssertionError(msg)
E           AssertionError: Expected 'convert' to have been called once. Called 0 times.

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/unittest/mock.py:908: AssertionError
=============================== warnings summary ===============================
exam/torch_group/ao.quantization.quantize/tests/test_torch_ao_quantization_quantize_g2.py::TestQuantizeG2::test_custom_mapping_parameter[simple_linear-False-custom-simple_calibration]
  /opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/ao/quantization/quantize.py:294: UserWarning: None of the submodule got qconfig applied. Make sure you passed correct configuration through `qconfig_dict` or by assigning the `.qconfig` attribute directly on submodules
    warnings.warn("None of the submodule got qconfig applied. Make sure you "

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================================ tests coverage ================================
______________ coverage: platform darwin, python 3.10.19-final-0 _______________

Name                                              Stmts   Miss Branch BrPart  Cover   Missing
---------------------------------------------------------------------------------------------
tests/test_torch_ao_quantization_quantize_g2.py      91     39     10      3    54%   24-27, 36-46, 60, 65, 70-72, 88, 93, 137-172, 192
---------------------------------------------------------------------------------------------
TOTAL                                                91     39     10      3    54%
Coverage XML written to file coverage.xml
=========================== short test summary info ============================
FAILED tests/test_torch_ao_quantization_quantize_g2.py::TestQuantizeG2::test_custom_mapping_parameter[simple_linear-False-custom-simple_calibration]
1 failed, 1 warning in 0.75s

Error: exit 1