=== Run Tests ===
...FFF....                                                               [100%]
=================================== FAILURES ===================================
___________ TestLossFunctionsG2.test_invalid_reduction_parameter_g2 ____________

self = <test_torch_nn_modules_loss_g2.TestLossFunctionsG2 object at 0x1277a15a0>

    def test_invalid_reduction_parameter_g2(self):
        """测试G2组损失函数的无效reduction参数"""
>       with pytest.raises(ValueError, match=".*reduction.*"):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/test_torch_nn_modules_loss_g2.py:290: Failed
______________ TestLossFunctionsG2.test_shape_mismatch_errors_g2 _______________

self = <test_torch_nn_modules_loss_g2.TestLossFunctionsG2 object at 0x1277a1870>

    def test_shape_mismatch_errors_g2(self):
        """测试G2组损失函数的形状不匹配错误"""
        # BCELoss形状不匹配
        loss_fn = nn.BCELoss()
        input_tensor = torch.rand(2, 3, 4)
        target_tensor = torch.rand(2, 3, 5)  # 形状不匹配
    
        with pytest.raises(RuntimeError):
>           loss_fn(input_tensor, target_tensor)

tests/test_torch_nn_modules_loss_g2.py:307: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/modules/module.py:1190: in _call_impl
    return forward_call(*input, **kwargs)
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/modules/loss.py:619: in forward
    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[0.1568, 0.2083, 0.3289, 0.1054],
         [0.9192, 0.4008, 0.9302, 0.6558],
         [0.0766, 0.8460, 0.3624....0850, 0.0029, 0.6431, 0.3908],
         [0.6947, 0.0897, 0.8712, 0.1330],
         [0.4137, 0.6044, 0.7581, 0.9037]]])
target = tensor([[[0.9555, 0.1035, 0.6258, 0.2849, 0.4452],
         [0.1258, 0.9554, 0.1330, 0.7672, 0.6757],
         [0.6625....2709, 0.9295],
         [0.6115, 0.2234, 0.2469, 0.4761, 0.7792],
         [0.3722, 0.2147, 0.3288, 0.1265, 0.6783]]])
weight = None, size_average = None, reduce = None, reduction = 'mean'

    def binary_cross_entropy(
        input: Tensor,
        target: Tensor,
        weight: Optional[Tensor] = None,
        size_average: Optional[bool] = None,
        reduce: Optional[bool] = None,
        reduction: str = "mean",
    ) -> Tensor:
        r"""Function that measures the Binary Cross Entropy between the target and input
        probabilities.
    
        See :class:`~torch.nn.BCELoss` for details.
    
        Args:
            input: Tensor of arbitrary shape as probabilities.
            target: Tensor of the same shape as input with values between 0 and 1.
            weight (Tensor, optional): a manual rescaling weight
                    if provided it's repeated to match input tensor shape
            size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
                the losses are averaged over each loss element in the batch. Note that for
                some losses, there multiple elements per sample. If the field :attr:`size_average`
                is set to ``False``, the losses are instead summed for each minibatch. Ignored
                when reduce is ``False``. Default: ``True``
            reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
                losses are averaged or summed over observations for each minibatch depending
                on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
                batch element instead and ignores :attr:`size_average`. Default: ``True``
            reduction (str, optional): Specifies the reduction to apply to the output:
                ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
                ``'mean'``: the sum of the output will be divided by the number of
                elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
                and :attr:`reduce` are in the process of being deprecated, and in the meantime,
                specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``
    
        Examples::
    
            >>> input = torch.randn(3, 2, requires_grad=True)
            >>> target = torch.rand(3, 2, requires_grad=False)
            >>> loss = F.binary_cross_entropy(torch.sigmoid(input), target)
            >>> loss.backward()
        """
        if has_torch_function_variadic(input, target, weight):
            return handle_torch_function(
                binary_cross_entropy,
                (input, target, weight),
                input,
                target,
                weight=weight,
                size_average=size_average,
                reduce=reduce,
                reduction=reduction,
            )
        if size_average is not None or reduce is not None:
            reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)
        else:
            reduction_enum = _Reduction.get_enum(reduction)
        if target.size() != input.size():
>           raise ValueError(
                "Using a target size ({}) that is different to the input size ({}) is deprecated. "
                "Please ensure they have the same size.".format(target.size(), input.size())
            )
E           ValueError: Using a target size (torch.Size([2, 3, 5])) that is different to the input size (torch.Size([2, 3, 4])) is deprecated. Please ensure they have the same size.

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/functional.py:3086: ValueError
__________ TestLossFunctionsG2.test_bceloss_invalid_probability_range __________

self = <test_torch_nn_modules_loss_g2.TestLossFunctionsG2 object at 0x1277a1b40>

    def test_bceloss_invalid_probability_range(self):
        """测试BCELoss输入概率范围验证"""
        loss_fn = nn.BCELoss()
    
        # 输入超出[0,1]范围 - BCELoss应该能处理（内部会clamp）
        input_tensor = torch.tensor([[1.5, -0.5], [0.3, 0.7]])
        target_tensor = torch.tensor([[1.0, 0.0], [0.0, 1.0]])
    
        # BCELoss应该能处理超出范围的输入（内部会clamp到[eps, 1-eps]）
>       loss = loss_fn(input_tensor, target_tensor)

tests/test_torch_nn_modules_loss_g2.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/modules/module.py:1190: in _call_impl
    return forward_call(*input, **kwargs)
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/modules/loss.py:619: in forward
    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[ 1.5000, -0.5000],
        [ 0.3000,  0.7000]])
target = tensor([[1., 0.],
        [0., 1.]]), weight = None
size_average = None, reduce = None, reduction = 'mean'

    def binary_cross_entropy(
        input: Tensor,
        target: Tensor,
        weight: Optional[Tensor] = None,
        size_average: Optional[bool] = None,
        reduce: Optional[bool] = None,
        reduction: str = "mean",
    ) -> Tensor:
        r"""Function that measures the Binary Cross Entropy between the target and input
        probabilities.
    
        See :class:`~torch.nn.BCELoss` for details.
    
        Args:
            input: Tensor of arbitrary shape as probabilities.
            target: Tensor of the same shape as input with values between 0 and 1.
            weight (Tensor, optional): a manual rescaling weight
                    if provided it's repeated to match input tensor shape
            size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
                the losses are averaged over each loss element in the batch. Note that for
                some losses, there multiple elements per sample. If the field :attr:`size_average`
                is set to ``False``, the losses are instead summed for each minibatch. Ignored
                when reduce is ``False``. Default: ``True``
            reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
                losses are averaged or summed over observations for each minibatch depending
                on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
                batch element instead and ignores :attr:`size_average`. Default: ``True``
            reduction (str, optional): Specifies the reduction to apply to the output:
                ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
                ``'mean'``: the sum of the output will be divided by the number of
                elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
                and :attr:`reduce` are in the process of being deprecated, and in the meantime,
                specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``
    
        Examples::
    
            >>> input = torch.randn(3, 2, requires_grad=True)
            >>> target = torch.rand(3, 2, requires_grad=False)
            >>> loss = F.binary_cross_entropy(torch.sigmoid(input), target)
            >>> loss.backward()
        """
        if has_torch_function_variadic(input, target, weight):
            return handle_torch_function(
                binary_cross_entropy,
                (input, target, weight),
                input,
                target,
                weight=weight,
                size_average=size_average,
                reduce=reduce,
                reduction=reduction,
            )
        if size_average is not None or reduce is not None:
            reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)
        else:
            reduction_enum = _Reduction.get_enum(reduction)
        if target.size() != input.size():
            raise ValueError(
                "Using a target size ({}) that is different to the input size ({}) is deprecated. "
                "Please ensure they have the same size.".format(target.size(), input.size())
            )
    
        if weight is not None:
            new_size = _infer_size(target.size(), weight.size())
            weight = weight.expand(new_size)
    
>       return torch._C._nn.binary_cross_entropy(input, target, weight, reduction_enum)
E       RuntimeError: all elements of input should be between 0 and 1

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/functional.py:3095: RuntimeError
=============================== warnings summary ===============================
exam/torch_group/nn.modules.loss/tests/test_torch_nn_modules_loss_g2.py::TestLossFunctionsG2::test_kldivloss_log_target_parameter
exam/torch_group/nn.modules.loss/tests/test_torch_nn_modules_loss_g2.py::TestLossFunctionsG2::test_loss_functions_are_callable_g2
  /opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/functional.py:2916: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
    warnings.warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================================ tests coverage ================================
______________ coverage: platform darwin, python 3.10.19-final-0 _______________

Name                                     Stmts   Miss Branch BrPart  Cover   Missing
------------------------------------------------------------------------------------
tests/test_torch_nn_modules_loss_g2.py     196     50     60     16    68%   33, 39, 49, 52-55, 60-80, 112, 124, 125->129, 134, 154-158, 165->exit, 202-205, 233, 251-252, 259-264, 268->exit, 293-297, 310-315, 327, 408
------------------------------------------------------------------------------------
TOTAL                                      196     50     60     16    68%
Coverage XML written to file coverage.xml
=========================== short test summary info ============================
FAILED tests/test_torch_nn_modules_loss_g2.py::TestLossFunctionsG2::test_invalid_reduction_parameter_g2
FAILED tests/test_torch_nn_modules_loss_g2.py::TestLossFunctionsG2::test_shape_mismatch_errors_g2
FAILED tests/test_torch_nn_modules_loss_g2.py::TestLossFunctionsG2::test_bceloss_invalid_probability_range
3 failed, 7 passed, 2 warnings in 0.88s

Error: exit 1