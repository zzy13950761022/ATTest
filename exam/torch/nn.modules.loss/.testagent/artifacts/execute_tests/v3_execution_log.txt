=== Run Tests ===
........FF.....FFF....                                                   [100%]
=================================== FAILURES ===================================
_____________ TestLossFunctionsG1.test_invalid_reduction_parameter _____________

self = <test_torch_nn_modules_loss_g1.TestLossFunctionsG1 object at 0x12e795ed0>

    def test_invalid_reduction_parameter(self):
        """测试无效reduction参数"""
>       with pytest.raises(ValueError, match=".*reduction.*"):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/test_torch_nn_modules_loss_g1.py:260: Failed
________________ TestLossFunctionsG1.test_shape_mismatch_errors ________________

self = <test_torch_nn_modules_loss_g1.TestLossFunctionsG1 object at 0x12e7961a0>

    def test_shape_mismatch_errors(self):
        """测试形状不匹配错误"""
        # L1Loss形状不匹配
        loss_fn = nn.L1Loss()
        input_tensor = torch.randn(2, 3, 4)
        target_tensor = torch.randn(2, 3, 5)  # 形状不匹配
    
        with pytest.raises(RuntimeError, match=".*shape.*"):
>           loss_fn(input_tensor, target_tensor)

tests/test_torch_nn_modules_loss_g1.py:277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/modules/module.py:1190: in _call_impl
    return forward_call(*input, **kwargs)
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/modules/loss.py:101: in forward
    return F.l1_loss(input, target, reduction=self.reduction)
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/functional.py:3260: in l1_loss
    expanded_input, expanded_target = torch.broadcast_tensors(input, target)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = (tensor([[[ 0.8108,  1.4974,  0.8258, -1.7190],
         [ 0.9627, -1.0615, -1.4342,  0.7780],
         [-0.1037,  0.1...47],
         [ 0.2750, -1.6155, -0.8580,  1.6777,  0.3595],
         [ 0.5210,  0.6501, -0.1174,  1.0570, -0.6588]]]))

    def broadcast_tensors(*tensors):
        r"""broadcast_tensors(*tensors) -> List of Tensors
    
        Broadcasts the given tensors according to :ref:`broadcasting-semantics`.
    
        Args:
            *tensors: any number of tensors of the same type
    
        .. warning::
    
            More than one element of a broadcasted tensor may refer to a single
            memory location. As a result, in-place operations (especially ones that
            are vectorized) may result in incorrect behavior. If you need to write
            to the tensors, please clone them first.
    
        Example::
    
            >>> x = torch.arange(3).view(1, 3)
            >>> y = torch.arange(2).view(2, 1)
            >>> a, b = torch.broadcast_tensors(x, y)
            >>> a.size()
            torch.Size([2, 3])
            >>> a
            tensor([[0, 1, 2],
                    [0, 1, 2]])
        """
        # This wrapper exists to support variadic args.
        if has_torch_function(tensors):
            return handle_torch_function(broadcast_tensors, tensors, *tensors)
>       return _VF.broadcast_tensors(tensors)  # type: ignore[attr-defined]
E       RuntimeError: The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 2

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/functional.py:74: RuntimeError

During handling of the above exception, another exception occurred:

self = <test_torch_nn_modules_loss_g1.TestLossFunctionsG1 object at 0x12e7961a0>

    def test_shape_mismatch_errors(self):
        """测试形状不匹配错误"""
        # L1Loss形状不匹配
        loss_fn = nn.L1Loss()
        input_tensor = torch.randn(2, 3, 4)
        target_tensor = torch.randn(2, 3, 5)  # 形状不匹配
    
>       with pytest.raises(RuntimeError, match=".*shape.*"):
E       AssertionError: Regex pattern did not match.
E         Expected regex: '.*shape.*'
E         Actual message: 'The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 2'

tests/test_torch_nn_modules_loss_g1.py:276: AssertionError
___________ TestLossFunctionsG2.test_invalid_reduction_parameter_g2 ____________

self = <test_torch_nn_modules_loss_g2.TestLossFunctionsG2 object at 0x12e868a60>

    def test_invalid_reduction_parameter_g2(self):
        """测试G2组损失函数的无效reduction参数"""
        # 根据PyTorch的_Reduction.get_enum函数，无效的reduction参数会抛出ValueError
>       with pytest.raises(ValueError, match=".*is not a valid value for reduction.*"):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/test_torch_nn_modules_loss_g2.py:291: Failed
______________ TestLossFunctionsG2.test_shape_mismatch_errors_g2 _______________

self = <test_torch_nn_modules_loss_g2.TestLossFunctionsG2 object at 0x12e868d00>

    def test_shape_mismatch_errors_g2(self):
        """测试G2组损失函数的形状不匹配错误"""
        # 根据PyTorch的binary_cross_entropy函数，形状不匹配会抛出ValueError
        # BCELoss形状不匹配
        loss_fn = nn.BCELoss()
        input_tensor = torch.rand(2, 3, 4)
        target_tensor = torch.rand(2, 3, 5)  # 形状不匹配
    
        # 根据binary_cross_entropy源码，形状不匹配会抛出ValueError
        with pytest.raises(ValueError, match=".*target size.*different to the input size.*"):
            loss_fn(input_tensor, target_tensor)
    
        # NLLLoss形状不匹配
        loss_fn = nn.NLLLoss()
        input_tensor = torch.randn(2, 5, 3, 4)  # log probabilities
        target_tensor = torch.randint(0, 5, (2, 3, 5))  # 形状不匹配
    
        # NLLLoss也会检查形状兼容性
        with pytest.raises(ValueError):
>           loss_fn(input_tensor, target_tensor)

tests/test_torch_nn_modules_loss_g2.py:329: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/modules/module.py:1190: in _call_impl
    return forward_call(*input, **kwargs)
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/modules/loss.py:216: in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[ 0.7533,  0.6854, -1.6265,  0.6743],
          [ 0.4078,  0.4140, -0.6160,  0.8298],
          [-1.1798, -0..., -0.9886, -1.0438],
          [ 0.9788, -0.1790,  1.0783,  0.3031],
          [-1.2037, -1.1211, -0.3624,  0.3752]]]])
target = tensor([[[1, 1, 3, 1, 3],
         [3, 1, 3, 4, 2],
         [4, 1, 4, 1, 3]],

        [[4, 2, 3, 2, 1],
         [1, 3, 3, 1, 4],
         [3, 2, 1, 4, 4]]])
weight = None, size_average = None, ignore_index = -100, reduce = None
reduction = 'mean'

    def nll_loss(
        input: Tensor,
        target: Tensor,
        weight: Optional[Tensor] = None,
        size_average: Optional[bool] = None,
        ignore_index: int = -100,
        reduce: Optional[bool] = None,
        reduction: str = "mean",
    ) -> Tensor:
        r"""The negative log likelihood loss.
    
        See :class:`~torch.nn.NLLLoss` for details.
    
        Args:
            input: :math:`(N, C)` where `C = number of classes` or :math:`(N, C, H, W)`
                in case of 2D Loss, or :math:`(N, C, d_1, d_2, ..., d_K)` where :math:`K \geq 1`
                in the case of K-dimensional loss. `input` is expected to be log-probabilities.
            target: :math:`(N)` where each value is :math:`0 \leq \text{targets}[i] \leq C-1`,
                or :math:`(N, d_1, d_2, ..., d_K)` where :math:`K \geq 1` for
                K-dimensional loss.
            weight (Tensor, optional): a manual rescaling weight given to each
                class. If given, has to be a Tensor of size `C`
            size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
                the losses are averaged over each loss element in the batch. Note that for
                some losses, there multiple elements per sample. If the field :attr:`size_average`
                is set to ``False``, the losses are instead summed for each minibatch. Ignored
                when reduce is ``False``. Default: ``True``
            ignore_index (int, optional): Specifies a target value that is ignored
                and does not contribute to the input gradient. When :attr:`size_average` is
                ``True``, the loss is averaged over non-ignored targets. Default: -100
            reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
                losses are averaged or summed over observations for each minibatch depending
                on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
                batch element instead and ignores :attr:`size_average`. Default: ``True``
            reduction (str, optional): Specifies the reduction to apply to the output:
                ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
                ``'mean'``: the sum of the output will be divided by the number of
                elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
                and :attr:`reduce` are in the process of being deprecated, and in the meantime,
                specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``
    
        Example::
    
            >>> # input is of size N x C = 3 x 5
            >>> input = torch.randn(3, 5, requires_grad=True)
            >>> # each element in target has to have 0 <= value < C
            >>> target = torch.tensor([1, 0, 4])
            >>> output = F.nll_loss(F.log_softmax(input, dim=1), target)
            >>> output.backward()
        """
        if has_torch_function_variadic(input, target, weight):
            return handle_torch_function(
                nll_loss,
                (input, target, weight),
                input,
                target,
                weight=weight,
                size_average=size_average,
                ignore_index=ignore_index,
                reduce=reduce,
                reduction=reduction,
            )
        if size_average is not None or reduce is not None:
            reduction = _Reduction.legacy_get_string(size_average, reduce)
>       return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
E       RuntimeError: size mismatch (got input: [2, 5, 3, 4] , target: [2, 3, 5]

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/functional.py:2701: RuntimeError
__________ TestLossFunctionsG2.test_bceloss_invalid_probability_range __________

self = <test_torch_nn_modules_loss_g2.TestLossFunctionsG2 object at 0x12e8696f0>

    def test_bceloss_invalid_probability_range(self):
        """测试BCELoss输入概率范围验证"""
        loss_fn = nn.BCELoss()
    
        # 输入超出[0,1]范围 - BCELoss应该能处理（内部会clamp到有效范围）
        # 根据PyTorch实现，BCELoss内部使用binary_cross_entropy，它会处理超出范围的输入
        input_tensor = torch.tensor([[1.5, -0.5], [0.3, 0.7]])
        target_tensor = torch.tensor([[1.0, 0.0], [0.0, 1.0]])
    
        # BCELoss应该能处理超出范围的输入（内部会clamp到[eps, 1-eps]）
>       loss = loss_fn(input_tensor, target_tensor)

tests/test_torch_nn_modules_loss_g2.py:349: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/modules/module.py:1190: in _call_impl
    return forward_call(*input, **kwargs)
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/modules/loss.py:619: in forward
    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[ 1.5000, -0.5000],
        [ 0.3000,  0.7000]])
target = tensor([[1., 0.],
        [0., 1.]]), weight = None
size_average = None, reduce = None, reduction = 'mean'

    def binary_cross_entropy(
        input: Tensor,
        target: Tensor,
        weight: Optional[Tensor] = None,
        size_average: Optional[bool] = None,
        reduce: Optional[bool] = None,
        reduction: str = "mean",
    ) -> Tensor:
        r"""Function that measures the Binary Cross Entropy between the target and input
        probabilities.
    
        See :class:`~torch.nn.BCELoss` for details.
    
        Args:
            input: Tensor of arbitrary shape as probabilities.
            target: Tensor of the same shape as input with values between 0 and 1.
            weight (Tensor, optional): a manual rescaling weight
                    if provided it's repeated to match input tensor shape
            size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,
                the losses are averaged over each loss element in the batch. Note that for
                some losses, there multiple elements per sample. If the field :attr:`size_average`
                is set to ``False``, the losses are instead summed for each minibatch. Ignored
                when reduce is ``False``. Default: ``True``
            reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the
                losses are averaged or summed over observations for each minibatch depending
                on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per
                batch element instead and ignores :attr:`size_average`. Default: ``True``
            reduction (str, optional): Specifies the reduction to apply to the output:
                ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,
                ``'mean'``: the sum of the output will be divided by the number of
                elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`
                and :attr:`reduce` are in the process of being deprecated, and in the meantime,
                specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``
    
        Examples::
    
            >>> input = torch.randn(3, 2, requires_grad=True)
            >>> target = torch.rand(3, 2, requires_grad=False)
            >>> loss = F.binary_cross_entropy(torch.sigmoid(input), target)
            >>> loss.backward()
        """
        if has_torch_function_variadic(input, target, weight):
            return handle_torch_function(
                binary_cross_entropy,
                (input, target, weight),
                input,
                target,
                weight=weight,
                size_average=size_average,
                reduce=reduce,
                reduction=reduction,
            )
        if size_average is not None or reduce is not None:
            reduction_enum = _Reduction.legacy_get_enum(size_average, reduce)
        else:
            reduction_enum = _Reduction.get_enum(reduction)
        if target.size() != input.size():
            raise ValueError(
                "Using a target size ({}) that is different to the input size ({}) is deprecated. "
                "Please ensure they have the same size.".format(target.size(), input.size())
            )
    
        if weight is not None:
            new_size = _infer_size(target.size(), weight.size())
            weight = weight.expand(new_size)
    
>       return torch._C._nn.binary_cross_entropy(input, target, weight, reduction_enum)
E       RuntimeError: all elements of input should be between 0 and 1

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/functional.py:3095: RuntimeError
=============================== warnings summary ===============================
exam/torch_group/nn.modules.loss/tests/test_torch_nn_modules_loss_g1.py::TestLossFunctionsG1::test_shape_mismatch_errors
  /opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([2, 3, 5])) that is different to the input size (torch.Size([2, 3, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
    return F.l1_loss(input, target, reduction=self.reduction)

exam/torch_group/nn.modules.loss/tests/test_torch_nn_modules_loss_g2.py::TestLossFunctionsG2::test_kldivloss_log_target_parameter
exam/torch_group/nn.modules.loss/tests/test_torch_nn_modules_loss_g2.py::TestLossFunctionsG2::test_loss_functions_are_callable_g2
exam/torch_group/nn.modules.loss/tests/test_torch_nn_modules_loss_g2.py::TestLossFunctionsG2::test_batchmean_reduction_kldivloss
  /opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/functional.py:2916: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
    warnings.warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================================ tests coverage ================================
______________ coverage: platform darwin, python 3.10.19-final-0 _______________

Name                                     Stmts   Miss Branch BrPart  Cover   Missing
------------------------------------------------------------------------------------
tests/test_torch_nn_modules_loss_g1.py     147     18     52     10    84%   32, 46, 57, 60-63, 91->95, 143->147, 179->exit, 213-216, 233, 263-267, 280-283, 322
tests/test_torch_nn_modules_loss_g2.py     238     63     60     16    68%   33, 39, 49, 52-55, 60-80, 112, 124, 125->129, 134, 154-158, 165->exit, 202-205, 233, 251-252, 259-264, 268->exit, 294-308, 332-337, 350-368, 497
------------------------------------------------------------------------------------
TOTAL                                      385     81    112     26    74%
Coverage XML written to file coverage.xml
=========================== short test summary info ============================
FAILED tests/test_torch_nn_modules_loss_g1.py::TestLossFunctionsG1::test_invalid_reduction_parameter
FAILED tests/test_torch_nn_modules_loss_g1.py::TestLossFunctionsG1::test_shape_mismatch_errors
FAILED tests/test_torch_nn_modules_loss_g2.py::TestLossFunctionsG2::test_invalid_reduction_parameter_g2
FAILED tests/test_torch_nn_modules_loss_g2.py::TestLossFunctionsG2::test_shape_mismatch_errors_g2
FAILED tests/test_torch_nn_modules_loss_g2.py::TestLossFunctionsG2::test_bceloss_invalid_probability_range
5 failed, 17 passed, 4 warnings in 0.79s

Error: exit 1