=== Run Tests ===
.F...                                                                    [100%]
=================================== FAILURES ===================================
_____________ test_linear_no_bias[10-5-False-dtype0-input_shape0] ______________

in_features = 10, out_features = 5, bias = False, dtype = torch.float32
input_shape = (64, 10)

    @pytest.mark.parametrize("in_features,out_features,bias,dtype,input_shape", [
        (10, 5, False, torch.float32, (64, 10)),  # No bias case from test plan
    ])
    def test_linear_no_bias(in_features, out_features, bias, dtype, input_shape):
        """Test Linear layer without bias."""
        # Create Linear layer without bias
        linear = nn.Linear(
            in_features=in_features,
            out_features=out_features,
            bias=bias,
            dtype=dtype
        )
    
        # Verify bias is None
        assert linear.bias is None, f"Bias should be None when bias=False, got {linear.bias}"
    
        # Create test input
        x = create_test_input(input_shape, dtype=dtype)
    
        # Forward pass
        y = linear(x)
    
        # Check output shape
        expected_shape = (*input_shape[:-1], out_features)
        assert y.shape == expected_shape, f"Output shape mismatch: {y.shape} != {expected_shape}"
    
        # Check output dtype
        assert y.dtype == dtype, f"Output dtype mismatch: {y.dtype} != {dtype}"
    
        # Check finite values
        check_finite(y, "Linear output (no bias)")
    
        # Verify no bias in computation by comparing with functional.linear without bias
        with torch.no_grad():
            weight = linear.weight
            # Compute expected output using functional linear without bias
            y_expected = F.linear(x, weight, bias=None)
    
            # Compare with tolerance
            assert_tensors_close(y, y_expected, rtol=1e-5, atol=1e-8,
                               msg="Linear output doesn't match functional.linear (no bias)")
    
        # Additional check: verify that adding a constant to input changes output linearly
        # This helps confirm there's no hidden bias term
        x2 = x + 1.0
        y2 = linear(x2)
        y_expected_from_x2 = y + linear.weight.sum(dim=1)  # For no bias: y2 = y + sum(weight)
    
        # This is a linearity check specific to no-bias case
>       assert_tensors_close(y2, y_expected_from_x2, rtol=1e-5, atol=1e-8,
                           msg="Linearity property violated for no-bias case")

tests/test_torch_nn_modules_linear_g1.py:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

actual = tensor([[-2.3693e-01,  1.0268e+00, -1.3224e+00,  5.2367e-01, -2.8220e-02],
        [ 5.7882e-01,  4.4990e-01, -3.1978e... 4.8053e-01],
        [-7.0914e-01,  8.2437e-01, -4.6915e-02, -9.4068e-01, -3.0783e-01]],
       grad_fn=<MmBackward0>)
expected = tensor([[-2.3693e-01,  1.0268e+00, -1.3224e+00,  5.2367e-01, -2.8220e-02],
        [ 5.7882e-01,  4.4990e-01, -3.1978e...4.8053e-01],
        [-7.0914e-01,  8.2437e-01, -4.6915e-02, -9.4068e-01, -3.0783e-01]],
       grad_fn=<AddBackward0>)
rtol = 1e-05, atol = 1e-08, msg = 'Linearity property violated for no-bias case'

    def assert_tensors_close(actual, expected, rtol=1e-5, atol=1e-8, msg=""):
        """Assert two tensors are close within tolerance."""
        assert actual.shape == expected.shape, f"Shape mismatch: {actual.shape} != {expected.shape}"
        assert actual.dtype == expected.dtype, f"Dtype mismatch: {actual.dtype} != {expected.dtype}"
    
        diff = torch.abs(actual - expected)
        max_diff = torch.max(diff).item()
        max_relative_diff = torch.max(diff / (torch.abs(expected) + 1e-8)).item()
    
        if max_diff > atol and max_relative_diff > rtol:
>           pytest.fail(f"{msg} Tensors not close: max_diff={max_diff:.2e}, max_relative_diff={max_relative_diff:.2e}")
E           Failed: Linearity property violated for no-bias case Tensors not close: max_diff=4.77e-07, max_relative_diff=3.72e-05

tests/test_torch_nn_modules_linear_g1.py:35: Failed
================================ tests coverage ================================
______________ coverage: platform darwin, python 3.10.19-final-0 _______________

Name                                       Stmts   Miss Branch BrPart  Cover   Missing
--------------------------------------------------------------------------------------
tests/test_torch_nn_modules_linear_g1.py      88      3      4      1    96%   207, 216-217
--------------------------------------------------------------------------------------
TOTAL                                         88      3      4      1    96%
Coverage XML written to file coverage.xml
=========================== short test summary info ============================
FAILED tests/test_torch_nn_modules_linear_g1.py::test_linear_no_bias[10-5-False-dtype0-input_shape0]
1 failed, 4 passed in 0.76s

Error: exit 1