=== Run Tests ===
............F...................F.....F.                                 [100%]
=================================== FAILURES ===================================
____________________ test_softmax_basic[activation_params2] ____________________

activation_params = {'activation': 'Softmax', 'device': 'cpu', 'dim': 1, 'dtype': torch.float32, ...}

    @pytest.mark.parametrize("activation_params", [
        {
            "activation": "Softmax",
            "dim": 1,
            "dtype": torch.float32,
            "device": "cpu",
            "shape": (2, 3, 4),
            "input_range": "normal"
        },
        # Parameter extension from test_plan.json
        {
            "activation": "Softmax",
            "dim": -1,
            "dtype": torch.float32,
            "device": "cpu",
            "shape": (5,),
            "input_range": "normal"
        },
        # Add extreme input test case
        {
            "activation": "Softmax",
            "dim": 1,
            "dtype": torch.float32,
            "device": "cpu",
            "shape": (2, 3),
            "input_range": "extreme"
        },
        # Add monotonicity test case with specific shape
        {
            "activation": "Softmax",
            "dim": 0,
            "dtype": torch.float32,
            "device": "cpu",
            "shape": (4,),
            "input_range": "mixed"
        }
    ])
    def test_softmax_basic(activation_params):
        """Test basic functionality for Softmax activation function.
    
        Test ID: TC-03
        Block ID: CASE_03
        Group: G2
        Assertion level: weak
        """
        # Extract parameters
        activation = activation_params["activation"]
        dim = activation_params["dim"]
        dtype = activation_params["dtype"]
        device = activation_params["device"]
        shape = activation_params["shape"]
        input_range = activation_params["input_range"]
    
        # Generate input tensor
        x = generate_input(shape, dtype, device, input_range)
    
        # Create activation module
        if activation == "Softmax":
            module = nn.Softmax(dim=dim)
            oracle_func = lambda x: F.softmax(x, dim=dim)
        else:
            raise ValueError(f"Unsupported activation: {activation}")
    
        # Forward pass
        output = module(x)
    
        # Weak assertions
        # 1. Shape match
        assert output.shape == shape, f"Output shape mismatch: {output.shape} != {shape}"
    
        # 2. Dtype match
        assert output.dtype == dtype, f"Output dtype mismatch: {output.dtype} != {dtype}"
    
        # 3. Finite values
        assert torch.all(torch.isfinite(output)), "Output contains non-finite values"
    
        # 4. Non-negative values (Softmax specific)
        assert torch.all(output >= 0), "Softmax output contains negative values"
    
        # 5. Sum to 1 along specified dimension
        sums = torch.sum(output, dim=dim)
        assert torch.allclose(sums, torch.ones_like(sums), rtol=1e-5, atol=1e-8), \
            f"Softmax outputs do not sum to 1 along dim={dim}"
    
        # 6. Compare with oracle (torch.nn.functional.softmax)
        expected = oracle_func(x)
        assert torch.allclose(output, expected, rtol=1e-5, atol=1e-8), \
            f"Output doesn't match {activation} oracle"
    
        # 7. Enhanced monotonicity property test
        # Softmax preserves ordering: if x_i > x_j, then softmax(x)_i > softmax(x)_j
        # Test for 1D tensors
        if len(shape) == 1:
            # Create indices for comparison
            for i in range(shape[0]):
                for j in range(i + 1, shape[0]):
                    if x[i] > x[j]:
                        assert output[i] > output[j], \
                            f"Softmax should preserve ordering: x[{i}]={x[i]} > x[{j}]={x[j]}, but output[{i}]={output[i]} <= output[{j}]={output[j]}"
                    elif x[i] < x[j]:
                        assert output[i] < output[j], \
                            f"Softmax should preserve ordering: x[{i}]={x[i]} < x[{j}]={x[j]}, but output[{i}]={output[i]} >= output[{j}]={output[j]}"
                    # If equal, outputs should be equal (within tolerance)
                    else:
                        assert torch.allclose(output[i], output[j], rtol=1e-5, atol=1e-8), \
                            f"Softmax should give equal outputs for equal inputs: x[{i}]={x[i]} == x[{j}]={x[j]}, but output[{i}]={output[i]} != output[{j}]={output[j]}"
    
        # 8. Enhanced numerical stability for extreme inputs
        if input_range == "extreme":
            # Even with extreme inputs, output should be finite and valid
            assert torch.all(torch.isfinite(output)), "Softmax should handle extreme inputs gracefully"
    
            # Sum should still be 1 (within numerical tolerance)
            sums_extreme = torch.sum(output, dim=dim)
            assert torch.allclose(sums_extreme, torch.ones_like(sums_extreme), rtol=1e-4, atol=1e-6), \
                f"Softmax with extreme inputs should sum to 1 along dim={dim}"
    
            # Check for NaN or inf in output
            assert not torch.any(torch.isnan(output)), "Softmax output should not contain NaN for extreme inputs"
            assert not torch.any(torch.isinf(output)), "Softmax output should not contain inf for extreme inputs"
    
            # Test with specific extreme values
            if shape == (2, 3):  # Our extreme test case shape
                # Verify that very large values don't cause overflow
>               assert torch.all(output > 0), "Softmax output should be positive even for extreme inputs"
E               AssertionError: Softmax output should be positive even for extreme inputs
E               assert tensor(False)
E                +  where tensor(False) = <built-in method all of type object at 0x1072ca320>(tensor([[0.0000e+00, 0.0000e+00, 1.0000e+00],\n        [0.0000e+00, 1.0000e+00, 6.6233e-08]]) > 0)
E                +    where <built-in method all of type object at 0x1072ca320> = torch.all

tests/test_torch_nn_modules_activation_g2.py:284: AssertionError
__________________________ test_prelu_basic[4-shape1] __________________________

num_parameters = 4, shape = (3, 4)
mixed_sign_tensor = tensor([[-1.0000,  2.0000],
        [ 0.5000, -0.5000]])

    @pytest.mark.parametrize("num_parameters,shape", [
        (1, (3, 4)),  # Single parameter for all channels
        (4, (3, 4)),  # One parameter per channel
    ])
    def test_prelu_basic(num_parameters, shape, mixed_sign_tensor):
        """Test PReLU (Parametric Rectified Linear Unit) basic functionality.
    
        PReLU is defined as:
        - f(x) = max(0, x) + a * min(0, x)
        - where 'a' is a learnable parameter
    
        Args:
            num_parameters: Number of learnable parameters
            shape: Input tensor shape
            mixed_sign_tensor: Fixture providing tensor with mixed signs
        """
        # Create PReLU module
        prelu = nn.PReLU(num_parameters=num_parameters)
    
        # Generate test input
        if shape == (3, 4):
            x = mixed_sign_tensor
        else:
            x = torch.randn(*shape)
    
        # Forward pass
>       output = prelu(x)

tests/test_torch_nn_modules_activation_g4.py:107: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/modules/module.py:1190: in _call_impl
    return forward_call(*input, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = PReLU(num_parameters=4)
input = tensor([[-1.0000,  2.0000],
        [ 0.5000, -0.5000]])

    def forward(self, input: Tensor) -> Tensor:
>       return F.prelu(input, self.weight)
E       RuntimeError: Mismatch of parameter numbers and input channel size. Found parameter numbers = 4 and channel size = 2.

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/modules/activation.py:1240: RuntimeError
_________________________ test_g4_parameter_validation _________________________

    def test_g4_parameter_validation():
        """Test parameter validation for G4 group modules."""
        # Test PReLU parameter validation
>       with pytest.raises(ValueError, match="num_parameters"):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/test_torch_nn_modules_activation_g4.py:300: Failed
================================ tests coverage ================================
______________ coverage: platform darwin, python 3.10.19-final-0 _______________

Name                                           Stmts   Miss Branch BrPart  Cover   Missing
------------------------------------------------------------------------------------------
tests/test_torch_nn_modules_activation_g1.py     152     14     30      8    88%   34, 37-40, 45->50, 49, 54-57, 63, 68, 73, 127, 225, 271->276, 277->exit
tests/test_torch_nn_modules_activation_g2.py     216     29     44     14    83%   44, 49->69, 56->69, 59->61, 61->63, 63->65, 65->69, 68, 83-86, 97-104, 110, 115, 120, 125-127, 132-134, 139-141, 146-148, 221, 264, 282->288, 285, 293->308, 308->exit, 327
tests/test_torch_nn_modules_activation_g3.py     277     56     34      4    74%   41, 45-68, 83-86, 99-120, 126, 131, 136, 141-143, 148-150, 155-157, 162-164, 219, 249-255
tests/test_torch_nn_modules_activation_g4.py     128     10     22      9    87%   28, 33, 104, 120->126, 126->145, 140-141, 212->218, 218->226, 246->250, 251->256, 278-279, 310, 339-340
------------------------------------------------------------------------------------------
TOTAL                                            773    109    130     35    82%
Coverage XML written to file coverage.xml
=========================== short test summary info ============================
FAILED tests/test_torch_nn_modules_activation_g2.py::test_softmax_basic[activation_params2]
FAILED tests/test_torch_nn_modules_activation_g4.py::test_prelu_basic[4-shape1]
FAILED tests/test_torch_nn_modules_activation_g4.py::test_g4_parameter_validation
3 failed, 37 passed in 0.84s

Error: exit 1