=== Run Tests ===
.FFFFF                                                                   [100%]
=================================== FAILURES ===================================
_____________ test_affine_false_configuration[False-input_shape1] ______________

track_running_stats = False, input_shape = [2, 8, 16, 16]

    @pytest.mark.parametrize("track_running_stats, input_shape", [
        (True, [2, 8, 16, 16]),  # Base case from test plan
        (False, [2, 8, 16, 16]),  # Extension: track_running_stats=False
    ])
    def test_affine_false_configuration(track_running_stats, input_shape):
        """Test BatchNorm2d with affine=False configuration.
    
        TC-05: affine=False配置
        Priority: High
        Assertion level: weak
        Group: G2
        """
        # Set random seed for reproducibility
        torch.manual_seed(42)
    
        # Create BatchNorm2d instance with affine=False
        bn = BatchNorm2d(
            num_features=8,
            eps=1e-5,
            momentum=0.1,
            affine=False,  # Key parameter: no learnable affine parameters
            track_running_stats=track_running_stats
        )
    
        # Create test input
        input_tensor = torch.randn(*input_shape, dtype=torch.float32)
    
        # Set to training mode
        bn.train()
    
        # Save initial state
        if track_running_stats:
            initial_running_mean = bn.running_mean.clone()
            initial_running_var = bn.running_var.clone()
    
        # Forward pass
        output = bn(input_tensor)
    
        # Weak assertions from test plan
        # 1. no_weight_parameter
        assert bn.weight is None, "weight should be None when affine=False"
    
        # 2. no_bias_parameter
        assert bn.bias is None, "bias should be None when affine=False"
    
        # 3. output_shape_correct
        assert output.shape == input_tensor.shape, \
            f"Output shape {output.shape} != input shape {input_tensor.shape}"
    
        # 4. normalization_applied
        # Check that normalization is applied by verifying output statistics
        # When affine=False, output should be approximately zero-mean and unit variance
        # across batch and spatial dimensions for each feature
    
        # Compute mean and variance per feature
        # For BatchNorm2d: input shape [N, C, H, W]
        # We compute statistics across batch (dim 0) and spatial dimensions (dim 2, 3)
        output_reshaped = output.transpose(0, 1).reshape(8, -1)  # [C, N*H*W]
    
        for c in range(8):
            feature_values = output_reshaped[c]
            feature_mean = feature_values.mean().item()
            feature_std = feature_values.std().item()
    
            # Check approximate zero mean (allow some tolerance due to eps and finite samples)
            assert abs(feature_mean) < 0.5, \
                f"Feature {c}: mean {feature_mean:.4f} is not close to zero"
    
            # Check approximate unit variance (allow some tolerance)
            assert 0.8 < feature_std < 1.2, \
                f"Feature {c}: std {feature_std:.4f} is not close to 1"
    
        # Additional checks
        assert output.dtype == torch.float32, \
            f"Output dtype {output.dtype} != expected float32"
    
        assert torch.isfinite(output).all(), \
            "Output contains non-finite values"
    
        # Check running statistics behavior
        if track_running_stats:
            # In training mode with track_running_stats=True, running stats should be updated
            assert not torch.allclose(bn.running_mean, initial_running_mean), \
                "running_mean should be updated in training mode with track_running_stats=True"
            assert not torch.allclose(bn.running_var, initial_running_var), \
                "running_var should be updated in training mode with track_running_stats=True"
        else:
            # With track_running_stats=False, running stats should not exist or be None
            # Actually, they exist but are not updated
>           assert bn.running_mean is not None, "running_mean should exist"
E           AssertionError: running_mean should exist
E           assert None is not None
E            +  where None = BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False).running_mean

tests/test_torch_nn_modules_batchnorm_g2.py:155: AssertionError
__________________________ test_invalid_num_features ___________________________

    def test_invalid_num_features():
        """Test that num_features <= 0 raises ValueError."""
>       with pytest.raises(ValueError):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/test_torch_nn_modules_batchnorm_g2.py:201: Failed
_______________________________ test_invalid_eps _______________________________

    def test_invalid_eps():
        """Test that eps <= 0 raises ValueError."""
>       with pytest.raises(ValueError):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/test_torch_nn_modules_batchnorm_g2.py:210: Failed
____________________________ test_invalid_momentum _____________________________

    def test_invalid_momentum():
        """Test that momentum outside [0, 1] raises ValueError."""
>       with pytest.raises(ValueError):
E       Failed: DID NOT RAISE <class 'ValueError'>

tests/test_torch_nn_modules_batchnorm_g2.py:219: Failed
_______________________ test_input_dimension_validation ________________________

    def test_input_dimension_validation():
        """Test that input dimensions are validated."""
        bn1d = BatchNorm1d(num_features=10)
        bn2d = BatchNorm2d(num_features=10)
        bn3d = BatchNorm3d(num_features=10)
    
        # BatchNorm1d should accept 2D or 3D input
        input_2d = torch.randn(4, 10)
        input_3d = torch.randn(4, 10, 32)
        output_2d = bn1d(input_2d)
        output_3d = bn1d(input_3d)
        assert output_2d.shape == input_2d.shape
        assert output_3d.shape == input_3d.shape
    
        # BatchNorm2d should reject 2D input
        with pytest.raises(RuntimeError):
>           bn2d(input_2d)

tests/test_torch_nn_modules_batchnorm_g2.py:242: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/modules/module.py:1190: in _call_impl
    return forward_call(*input, **kwargs)
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:138: in forward
    self._check_input_dim(input)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
input = tensor([[-0.5197,  1.8524,  1.8365,  2.0741, -0.7373, -0.7687, -0.0512,  1.5986,
          0.2123,  1.1060],
        [...-0.2296],
        [ 1.7335, -1.1168,  0.1869,  1.0334, -1.2218, -0.4378,  1.4290,  0.2306,
         -1.8913,  0.7457]])

    def _check_input_dim(self, input):
        if input.dim() != 4:
>           raise ValueError("expected 4D input (got {}D input)".format(input.dim()))
E           ValueError: expected 4D input (got 2D input)

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:410: ValueError
================================ tests coverage ================================
______________ coverage: platform darwin, python 3.10.19-final-0 _______________

Name                                          Stmts   Miss Branch BrPart  Cover   Missing
-----------------------------------------------------------------------------------------
tests/test_torch_nn_modules_batchnorm_g2.py      84     21     10      1    74%   19-20, 25-26, 31-33, 38-52, 156-160, 173->exit, 204-205, 213-214, 222-223, 245-246
-----------------------------------------------------------------------------------------
TOTAL                                            84     21     10      1    74%
Coverage XML written to file coverage.xml
=========================== short test summary info ============================
FAILED tests/test_torch_nn_modules_batchnorm_g2.py::test_affine_false_configuration[False-input_shape1]
FAILED tests/test_torch_nn_modules_batchnorm_g2.py::test_invalid_num_features
FAILED tests/test_torch_nn_modules_batchnorm_g2.py::test_invalid_eps - Failed...
FAILED tests/test_torch_nn_modules_batchnorm_g2.py::test_invalid_momentum - F...
FAILED tests/test_torch_nn_modules_batchnorm_g2.py::test_input_dimension_validation
5 failed, 1 passed in 0.78s

Error: exit 1