import math
import pytest
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.nn.modules.batchnorm import (
    BatchNorm1d, BatchNorm2d, BatchNorm3d,
    LazyBatchNorm1d, LazyBatchNorm2d, LazyBatchNorm3d,
    SyncBatchNorm
)


# ==== BLOCK:HEADER START ====
# Fixtures and helper functions for batch normalization tests

@pytest.fixture(scope="function")
def set_random_seed():
    """Set random seed for reproducibility."""
    torch.manual_seed(42)
    return 42


def create_test_input(shape, dtype=torch.float32, device="cpu"):
    """Create test input tensor with fixed random values."""
    torch.manual_seed(42)
    return torch.randn(*shape, dtype=dtype, device=device)


def assert_tensor_properties(tensor, expected_shape, expected_dtype, test_name=""):
    """Assert basic tensor properties."""
    assert tensor.shape == expected_shape, f"{test_name}: shape mismatch"
    assert tensor.dtype == expected_dtype, f"{test_name}: dtype mismatch"
    assert torch.isfinite(tensor).all(), f"{test_name}: tensor contains non-finite values"


def get_oracle_batch_norm(input_tensor, bn_module):
    """Get oracle output using F.batch_norm for comparison."""
    if bn_module.training:
        # In training mode, use batch statistics
        return F.batch_norm(
            input_tensor,
            running_mean=None,
            running_var=None,
            weight=bn_module.weight,
            bias=bn_module.bias,
            training=True,
            momentum=bn_module.momentum,
            eps=bn_module.eps
        )
    else:
        # In eval mode, use running statistics
        return F.batch_norm(
            input_tensor,
            running_mean=bn_module.running_mean,
            running_var=bn_module.running_var,
            weight=bn_module.weight,
            bias=bn_module.bias,
            training=False,
            momentum=bn_module.momentum,
            eps=bn_module.eps
        )
# ==== BLOCK:HEADER END ====


# ==== BLOCK:CASE_01 START ====
@pytest.mark.parametrize("input_shape, dtype_str, device_str", [
    ([4, 10], "float32", "cpu"),  # Base case from test plan
    ([4, 10, 32], "float32", "cpu"),  # 3D input extension
    ([4, 10], "float64", "cpu"),  # float64 extension
])
def test_batchnorm1d_basic_forward(input_shape, dtype_str, device_str):
    """Test basic forward propagation for BatchNorm1d.
    
    TC-01: BatchNorm1d基础前向传播
    Priority: High
    Assertion level: weak
    """
    # Convert string parameters
    dtype = getattr(torch, dtype_str)
    device = torch.device(device_str)
    
    # Set random seed for reproducibility
    torch.manual_seed(42)
    
    # Create BatchNorm1d instance with parameters from test plan
    bn = BatchNorm1d(
        num_features=10,
        eps=1e-5,
        momentum=0.1,
        affine=True,
        track_running_stats=True
    )
    bn.to(device=device, dtype=dtype)
    
    # Create test input
    input_tensor = torch.randn(*input_shape, dtype=dtype, device=device)
    
    # Set to training mode (default)
    bn.train()
    
    # Forward pass
    output = bn(input_tensor)
    
    # Weak assertions from test plan
    # 1. output_shape
    assert output.shape == input_tensor.shape, \
        f"Output shape {output.shape} != input shape {input_tensor.shape}"
    
    # 2. output_dtype
    assert output.dtype == dtype, \
        f"Output dtype {output.dtype} != expected dtype {dtype}"
    
    # 3. output_finite
    assert torch.isfinite(output).all(), \
        "Output contains non-finite values"
    
    # 4. running_mean_updated
    if bn.track_running_stats:
        # Check that running_mean has been updated (not all zeros)
        assert not torch.allclose(bn.running_mean, torch.zeros_like(bn.running_mean)), \
            "running_mean should be updated in training mode"
        
        # Check that running_var has been updated (not all ones)
        assert not torch.allclose(bn.running_var, torch.ones_like(bn.running_var)), \
            "running_var should be updated in training mode"
    
    # Additional basic checks
    # Check that weight and bias exist when affine=True
    assert bn.weight is not None, "weight should exist when affine=True"
    assert bn.bias is not None, "bias should exist when affine=True"
    
    # Check weight and bias shapes
    assert bn.weight.shape == (10,), f"weight shape {bn.weight.shape} != (10,)"
    assert bn.bias.shape == (10,), f"bias shape {bn.bias.shape} != (10,)"
    
    # Check that output is on correct device
    assert output.device == device, \
        f"Output device {output.device} != expected device {device}"
# ==== BLOCK:CASE_01 END ====


# ==== BLOCK:CASE_02 START ====
@pytest.mark.parametrize("mode, input_shape", [
    ("train", [2, 8, 16, 16]),  # Base case from test plan
    ("eval", [2, 8, 16, 16]),   # Eval mode extension
])
def test_train_eval_mode_switching(mode, input_shape):
    """Test training/evaluation mode switching for BatchNorm2d.
    
    TC-02: 训练评估模式切换
    Priority: High
    Assertion level: weak
    """
    # Set random seed for reproducibility
    torch.manual_seed(42)
    
    # Create BatchNorm2d instance with parameters from test plan
    bn = BatchNorm2d(
        num_features=8,
        eps=1e-5,
        momentum=0.1,
        affine=True,
        track_running_stats=True
    )
    
    # Create test input
    input_tensor = torch.randn(*input_shape, dtype=torch.float32)
    
    # Set mode
    if mode == "train":
        bn.train()
        expected_training = True
    else:
        bn.eval()
        expected_training = False
    
    # Verify mode is set correctly
    assert bn.training == expected_training, \
        f"Module training mode {bn.training} != expected {expected_training}"
    
    # Save initial running statistics
    if bn.track_running_stats:
        initial_running_mean = bn.running_mean.clone()
        initial_running_var = bn.running_var.clone()
    
    # Forward pass
    output = bn(input_tensor)
    
    # Weak assertions from test plan
    # 1. mode_switch_works
    assert bn.training == expected_training, \
        f"Mode switch failed: training={bn.training}, expected={expected_training}"
    
    # 2. running_stats_used_in_eval
    if mode == "eval" and bn.track_running_stats:
        # In eval mode, running stats should be used but not updated
        assert torch.allclose(bn.running_mean, initial_running_mean), \
            "running_mean should not be updated in eval mode"
        assert torch.allclose(bn.running_var, initial_running_var), \
            "running_var should not be updated in eval mode"
    
    # 3. output_shape_consistent
    assert output.shape == input_tensor.shape, \
        f"Output shape {output.shape} != input shape {input_tensor.shape}"
    
    # Additional checks
    assert output.dtype == torch.float32, \
        f"Output dtype {output.dtype} != expected float32"
    
    assert torch.isfinite(output).all(), \
        "Output contains non-finite values"
    
    # Check that output values are reasonable
    output_mean = output.mean().item()
    output_std = output.std().item()
    assert abs(output_mean) < 5.0, f"Output mean {output_mean} is too large"
    assert 0.1 < output_std < 5.0, f"Output std {output_std} is out of expected range"
# ==== BLOCK:CASE_02 END ====


# ==== BLOCK:CASE_03 START ====
# Placeholder for CASE_03: BatchNorm3d基础功能
# TC-03: BatchNorm3d基础功能
# Priority: High (deferred)
# Assertion level: weak
# ==== BLOCK:CASE_03 END ====


# ==== BLOCK:CASE_04 START ====
# Placeholder for CASE_04: 懒加载类延迟初始化
# TC-04: 懒加载类延迟初始化
# Priority: Medium (deferred)
# Assertion level: weak
# ==== BLOCK:CASE_04 END ====


# ==== BLOCK:CASE_05 START ====
@pytest.mark.parametrize("affine,track_running_stats,input_shape", [
    (False, True, [2, 8, 16, 16]),  # Base case from test plan: affine=False, track_running_stats=True
    (False, False, [2, 8, 16, 16]), # Extension: affine=False, track_running_stats=False
])
def test_affine_false_configuration(affine, track_running_stats, input_shape):
    """Test BatchNorm2d with affine=False configuration.
    
    TC-05: affine=False配置
    Priority: High
    Assertion level: weak
    """
    # Set random seed for reproducibility
    torch.manual_seed(42)
    
    # Create BatchNorm2d instance with specified parameters
    bn = BatchNorm2d(
        num_features=8,
        eps=1e-5,
        momentum=0.1,
        affine=affine,
        track_running_stats=track_running_stats
    )
    
    # Create test input
    input_tensor = torch.randn(*input_shape, dtype=torch.float32)
    
    # Set to training mode
    bn.train()
    
    # Save initial state for comparison
    if track_running_stats:
        initial_running_mean = bn.running_mean.clone()
        initial_running_var = bn.running_var.clone()
    
    # Forward pass
    output = bn(input_tensor)
    
    # Weak assertions from test plan
    # 1. no_weight_parameter
    if not affine:
        assert bn.weight is None, "weight should be None when affine=False"
    else:
        assert bn.weight is not None, "weight should exist when affine=True"
    
    # 2. no_bias_parameter
    if not affine:
        assert bn.bias is None, "bias should be None when affine=False"
    else:
        assert bn.bias is not None, "bias should exist when affine=True"
    
    # 3. output_shape_correct
    assert output.shape == input_tensor.shape, \
        f"Output shape {output.shape} != input shape {input_tensor.shape}"
    
    # 4. normalization_applied
    # Check that output is normalized (mean close to 0, variance close to 1)
    # Note: This is approximate due to batch statistics
    output_mean = output.mean(dim=(0, 2, 3))  # Mean over batch and spatial dimensions
    output_var = output.var(dim=(0, 2, 3), unbiased=False)  # Variance over batch and spatial dimensions
    
    # Allow some tolerance for batch statistics
    assert torch.allclose(output_mean, torch.zeros_like(output_mean), atol=0.5), \
        f"Output mean {output_mean} not close to 0"
    assert torch.allclose(output_var, torch.ones_like(output_var), atol=0.5), \
        f"Output variance {output_var} not close to 1"
    
    # Additional checks
    assert output.dtype == torch.float32, \
        f"Output dtype {output.dtype} != expected float32"
    
    assert torch.isfinite(output).all(), \
        "Output contains non-finite values"
    
    # Check running statistics behavior
    if track_running_stats:
        # In training mode with track_running_stats=True, running stats should be updated
        assert not torch.allclose(bn.running_mean, initial_running_mean), \
            "running_mean should be updated in training mode with track_running_stats=True"
        assert not torch.allclose(bn.running_var, initial_running_var), \
            "running_var should be updated in training mode with track_running_stats=True"
    else:
        # When track_running_stats=False, running_mean and running_var should be None
        assert bn.running_mean is None, \
            "running_mean should be None when track_running_stats=False"
        assert bn.running_var is None, \
            "running_var should be None when track_running_stats=False"
        assert bn.num_batches_tracked is None, \
            "num_batches_tracked should be None when track_running_stats=False"
# ==== BLOCK:CASE_05 END ====


# ==== BLOCK:CASE_06 START ====
# Placeholder for CASE_06: Deferred test case
# ==== BLOCK:CASE_06 END ====


# ==== BLOCK:CASE_07 START ====
# Placeholder for CASE_07: Deferred test case
# ==== BLOCK:CASE_07 END ====


# ==== BLOCK:CASE_08 START ====
# Placeholder for CASE_08: Deferred test case
# ==== BLOCK:CASE_08 END ====


# ==== BLOCK:FOOTER START ====
# Additional test cases and edge case tests

def test_invalid_num_features():
    """Test that num_features <= 0 raises ValueError."""
    with pytest.raises(ValueError):
        BatchNorm1d(num_features=0)
    
    with pytest.raises(ValueError):
        BatchNorm1d(num_features=-1)


def test_invalid_eps():
    """Test that eps <= 0 raises ValueError."""
    with pytest.raises(ValueError):
        BatchNorm1d(num_features=10, eps=0.0)
    
    with pytest.raises(ValueError):
        BatchNorm1d(num_features=10, eps=-1e-5)


def test_invalid_momentum():
    """Test that momentum outside [0, 1] raises ValueError."""
    with pytest.raises(ValueError):
        BatchNorm1d(num_features=10, momentum=1.1)
    
    with pytest.raises(ValueError):
        BatchNorm1d(num_features=10, momentum=-0.1)


def test_input_dimension_validation():
    """Test that input dimensions are validated."""
    bn1d = BatchNorm1d(num_features=10)
    bn2d = BatchNorm2d(num_features=10)
    bn3d = BatchNorm3d(num_features=10)
    
    # BatchNorm1d should accept 2D or 3D input
    input_2d = torch.randn(4, 10)
    input_3d = torch.randn(4, 10, 32)
    output_2d = bn1d(input_2d)
    output_3d = bn1d(input_3d)
    assert output_2d.shape == input_2d.shape
    assert output_3d.shape == input_3d.shape
    
    # BatchNorm2d should reject 2D input
    with pytest.raises(RuntimeError):
        bn2d(input_2d)
    
    # BatchNorm3d should reject 2D input
    with pytest.raises(RuntimeError):
        bn3d(input_2d)
# ==== BLOCK:FOOTER END ====