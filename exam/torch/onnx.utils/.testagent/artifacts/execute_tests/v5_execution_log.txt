=== Run Tests ===
FFFFFF...FFF...                                                          [100%]
=================================== FAILURES ===================================
______ test_export_basic_model_to_file[nn.Module-tuple-file-13-True-True] ______

model_type = 'nn.Module', args_format = 'tuple', output_target = 'file'
opset_version = 13, export_params = True, do_constant_folding = True
simple_linear_model = SimpleLinearModel(
  (linear): Linear(in_features=3, out_features=2, bias=True)
)
simple_conv_model = SimpleConvModel(
  (conv): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)
sample_input_tensor = tensor([[ 0.4485,  0.0330,  1.4503],
        [-0.6936,  0.9967,  0.6131]])
sample_input_tensor_2d = tensor([[[[-9.5632e-01, -1.2476e+00, -7.4994e-01, -5.9219e-01,  1.7744e+00,
           -9.2155e-01,  9.6245e-01, -3.37...  7.4018e-01,  1.4162e+00,  6.8340e-01,
           -1.3825e-01,  9.8639e-01, -3.8926e-01,  6.1381e-01, -2.7863e-01]]]])
temp_onnx_file = '/var/folders/fc/ny_p_wjs10xfzq7xns_lfdc40000gn/T/tmpgy17c1bo.onnx'

    @pytest.mark.parametrize(
        "model_type,args_format,output_target,opset_version,export_params,do_constant_folding",
        [
            # Base case from test plan
            ("nn.Module", "tuple", "file", 13, True, True),
            # Parameter extensions from test plan
            ("nn.Module", "named_tuple", "file", 13, True, False),
            ("nn.Module", "tuple", "file", 7, True, True),
            ("nn.Module", "tuple", "file", 16, False, True),
        ]
    )
    def test_export_basic_model_to_file(
        model_type,
        args_format,
        output_target,
        opset_version,
        export_params,
        do_constant_folding,
        simple_linear_model,
        simple_conv_model,
        sample_input_tensor,
        sample_input_tensor_2d,
        temp_onnx_file,
    ):
        """
        Test basic model export to file with various configurations.
    
        This test covers the core export functionality with different:
        - Model types (nn.Module)
        - Args formats (tuple, named_tuple)
        - Opset versions (7, 13, 16)
        - Export parameters (True/False)
        - Constant folding (True/False)
    
        Weak assertions: file exists, file not empty, no exception.
        """
        # Select model based on type
        if model_type == "nn.Module":
            # Use linear model for 1D input, conv model for 2D input
            if args_format == "tuple":
                model = simple_linear_model
                args = (sample_input_tensor,)
            else:  # named_tuple
                model = simple_conv_model
                args = (sample_input_tensor_2d,)
    
        # Prepare args based on format
        if args_format == "named_tuple":
            # Create args with named parameters
            args = (args[0], {"dummy_param": torch.tensor([1.0])})
    
        # Mock dependencies - we need to mock the entire export chain
        # to avoid C++ type issues
        with mock.patch('torch.jit._get_trace_graph') as mock_get_trace_graph, \
             mock.patch('torch.onnx.utils._model_to_graph') as mock_model_to_graph, \
             mock.patch('torch.onnx.utils._export') as mock_export, \
             mock.patch('io.open', mock.mock_open()) as mock_file:
    
            # Setup mock returns for _get_trace_graph
            mock_graph = mock.MagicMock()
            mock_torch_out = torch.tensor([[1.0, 2.0], [3.0, 4.0]])
            mock_inputs_states = mock.MagicMock()
            mock_get_trace_graph.return_value = (mock_graph, mock_torch_out, mock_inputs_states)
    
            # Create a proper mock for _model_to_graph that returns appropriate types
            mock_params_dict = {}
            mock_model_to_graph.return_value = (mock_graph, mock_params_dict, mock_torch_out)
    
            # Mock _export to do nothing (just track calls)
            mock_export.return_value = None
    
            # Call export
            try:
                onnx_utils.export(
                    model=model,
                    args=args,
                    f=temp_onnx_file,
                    export_params=export_params,
                    opset_version=opset_version,
                    do_constant_folding=do_constant_folding,
                    verbose=False,
                )
    
                # Weak assertion 1: No exception raised
                # (implicitly passed if we reach here)
    
                # Weak assertion 2: File was opened for writing
                # Since we're mocking io.open, check that it was called
>               assert mock_file.called, "File was not opened for writing"
E               AssertionError: File was not opened for writing
E               assert False
E                +  where False = <MagicMock name='open' spec='builtin_function_or_method' id='5169808528'>.called

tests/test_torch_onnx_utils.py:239: AssertionError

During handling of the above exception, another exception occurred:

model_type = 'nn.Module', args_format = 'tuple', output_target = 'file'
opset_version = 13, export_params = True, do_constant_folding = True
simple_linear_model = SimpleLinearModel(
  (linear): Linear(in_features=3, out_features=2, bias=True)
)
simple_conv_model = SimpleConvModel(
  (conv): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)
sample_input_tensor = tensor([[ 0.4485,  0.0330,  1.4503],
        [-0.6936,  0.9967,  0.6131]])
sample_input_tensor_2d = tensor([[[[-9.5632e-01, -1.2476e+00, -7.4994e-01, -5.9219e-01,  1.7744e+00,
           -9.2155e-01,  9.6245e-01, -3.37...  7.4018e-01,  1.4162e+00,  6.8340e-01,
           -1.3825e-01,  9.8639e-01, -3.8926e-01,  6.1381e-01, -2.7863e-01]]]])
temp_onnx_file = '/var/folders/fc/ny_p_wjs10xfzq7xns_lfdc40000gn/T/tmpgy17c1bo.onnx'

    @pytest.mark.parametrize(
        "model_type,args_format,output_target,opset_version,export_params,do_constant_folding",
        [
            # Base case from test plan
            ("nn.Module", "tuple", "file", 13, True, True),
            # Parameter extensions from test plan
            ("nn.Module", "named_tuple", "file", 13, True, False),
            ("nn.Module", "tuple", "file", 7, True, True),
            ("nn.Module", "tuple", "file", 16, False, True),
        ]
    )
    def test_export_basic_model_to_file(
        model_type,
        args_format,
        output_target,
        opset_version,
        export_params,
        do_constant_folding,
        simple_linear_model,
        simple_conv_model,
        sample_input_tensor,
        sample_input_tensor_2d,
        temp_onnx_file,
    ):
        """
        Test basic model export to file with various configurations.
    
        This test covers the core export functionality with different:
        - Model types (nn.Module)
        - Args formats (tuple, named_tuple)
        - Opset versions (7, 13, 16)
        - Export parameters (True/False)
        - Constant folding (True/False)
    
        Weak assertions: file exists, file not empty, no exception.
        """
        # Select model based on type
        if model_type == "nn.Module":
            # Use linear model for 1D input, conv model for 2D input
            if args_format == "tuple":
                model = simple_linear_model
                args = (sample_input_tensor,)
            else:  # named_tuple
                model = simple_conv_model
                args = (sample_input_tensor_2d,)
    
        # Prepare args based on format
        if args_format == "named_tuple":
            # Create args with named parameters
            args = (args[0], {"dummy_param": torch.tensor([1.0])})
    
        # Mock dependencies - we need to mock the entire export chain
        # to avoid C++ type issues
        with mock.patch('torch.jit._get_trace_graph') as mock_get_trace_graph, \
             mock.patch('torch.onnx.utils._model_to_graph') as mock_model_to_graph, \
             mock.patch('torch.onnx.utils._export') as mock_export, \
             mock.patch('io.open', mock.mock_open()) as mock_file:
    
            # Setup mock returns for _get_trace_graph
            mock_graph = mock.MagicMock()
            mock_torch_out = torch.tensor([[1.0, 2.0], [3.0, 4.0]])
            mock_inputs_states = mock.MagicMock()
            mock_get_trace_graph.return_value = (mock_graph, mock_torch_out, mock_inputs_states)
    
            # Create a proper mock for _model_to_graph that returns appropriate types
            mock_params_dict = {}
            mock_model_to_graph.return_value = (mock_graph, mock_params_dict, mock_torch_out)
    
            # Mock _export to do nothing (just track calls)
            mock_export.return_value = None
    
            # Call export
            try:
                onnx_utils.export(
                    model=model,
                    args=args,
                    f=temp_onnx_file,
                    export_params=export_params,
                    opset_version=opset_version,
                    do_constant_folding=do_constant_folding,
                    verbose=False,
                )
    
                # Weak assertion 1: No exception raised
                # (implicitly passed if we reach here)
    
                # Weak assertion 2: File was opened for writing
                # Since we're mocking io.open, check that it was called
                assert mock_file.called, "File was not opened for writing"
    
                # Check that write was called (indicating content was written)
                write_calls = [call for call in mock_file.mock_calls if call[0] == '().write']
                assert len(write_calls) > 0, "No data was written to file"
    
                # Weak assertion 3: _get_trace_graph was called for nn.Module
                if model_type == "nn.Module":
                    assert mock_get_trace_graph.called, "torch.jit._get_trace_graph should be called for nn.Module"
    
                # Weak assertion 4: _model_to_graph was called
                assert mock_model_to_graph.called, "_model_to_graph should be called"
    
                # Weak assertion 5: _export was called
                assert mock_export.called, "_export should be called"
    
                # Additional weak checks
                assert opset_version >= 7 and opset_version <= 16, \
                    f"Opset version {opset_version} should be in range 7-16"
    
                # Check that export was called with correct parameters
                mock_export.assert_called_once()
                call_args = mock_export.call_args
    
                # Verify key parameters
                assert call_args[0][0] == model, "Model parameter should match"
                assert call_args[0][1] == args, "Args parameter should match"
                assert call_args[0][2] == temp_onnx_file, "File parameter should match"
                assert call_args[1]['export_params'] == export_params, "export_params should match"
                assert call_args[1]['opset_version'] == opset_version, "opset_version should match"
                assert call_args[1]['do_constant_folding'] == do_constant_folding, "do_constant_folding should match"
    
            except Exception as e:
>               pytest.fail(f"Export raised unexpected exception: {e}")
E               Failed: Export raised unexpected exception: File was not opened for writing
E               assert False
E                +  where False = <MagicMock name='open' spec='builtin_function_or_method' id='5169808528'>.called

tests/test_torch_onnx_utils.py:272: Failed
__ test_export_basic_model_to_file[nn.Module-named_tuple-file-13-True-False] ___

model_type = 'nn.Module', args_format = 'named_tuple', output_target = 'file'
opset_version = 13, export_params = True, do_constant_folding = False
simple_linear_model = SimpleLinearModel(
  (linear): Linear(in_features=3, out_features=2, bias=True)
)
simple_conv_model = SimpleConvModel(
  (conv): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)
sample_input_tensor = tensor([[ 0.1005,  0.2325,  0.7064],
        [ 0.3693, -0.8368, -1.2204]])
sample_input_tensor_2d = tensor([[[[-1.3386e-01, -5.8557e-02,  1.2574e-01, -5.5258e-01,  7.4480e-02,
           -1.4929e-01, -5.5225e-01, -9.34...  4.5689e-01, -6.0341e-01,  4.6268e-01,
            2.4934e-01, -1.7062e-01, -6.1410e-01,  5.3551e-01, -1.6644e+00]]]])
temp_onnx_file = '/var/folders/fc/ny_p_wjs10xfzq7xns_lfdc40000gn/T/tmpslgxnvn2.onnx'

    @pytest.mark.parametrize(
        "model_type,args_format,output_target,opset_version,export_params,do_constant_folding",
        [
            # Base case from test plan
            ("nn.Module", "tuple", "file", 13, True, True),
            # Parameter extensions from test plan
            ("nn.Module", "named_tuple", "file", 13, True, False),
            ("nn.Module", "tuple", "file", 7, True, True),
            ("nn.Module", "tuple", "file", 16, False, True),
        ]
    )
    def test_export_basic_model_to_file(
        model_type,
        args_format,
        output_target,
        opset_version,
        export_params,
        do_constant_folding,
        simple_linear_model,
        simple_conv_model,
        sample_input_tensor,
        sample_input_tensor_2d,
        temp_onnx_file,
    ):
        """
        Test basic model export to file with various configurations.
    
        This test covers the core export functionality with different:
        - Model types (nn.Module)
        - Args formats (tuple, named_tuple)
        - Opset versions (7, 13, 16)
        - Export parameters (True/False)
        - Constant folding (True/False)
    
        Weak assertions: file exists, file not empty, no exception.
        """
        # Select model based on type
        if model_type == "nn.Module":
            # Use linear model for 1D input, conv model for 2D input
            if args_format == "tuple":
                model = simple_linear_model
                args = (sample_input_tensor,)
            else:  # named_tuple
                model = simple_conv_model
                args = (sample_input_tensor_2d,)
    
        # Prepare args based on format
        if args_format == "named_tuple":
            # Create args with named parameters
            args = (args[0], {"dummy_param": torch.tensor([1.0])})
    
        # Mock dependencies - we need to mock the entire export chain
        # to avoid C++ type issues
        with mock.patch('torch.jit._get_trace_graph') as mock_get_trace_graph, \
             mock.patch('torch.onnx.utils._model_to_graph') as mock_model_to_graph, \
             mock.patch('torch.onnx.utils._export') as mock_export, \
             mock.patch('io.open', mock.mock_open()) as mock_file:
    
            # Setup mock returns for _get_trace_graph
            mock_graph = mock.MagicMock()
            mock_torch_out = torch.tensor([[1.0, 2.0], [3.0, 4.0]])
            mock_inputs_states = mock.MagicMock()
            mock_get_trace_graph.return_value = (mock_graph, mock_torch_out, mock_inputs_states)
    
            # Create a proper mock for _model_to_graph that returns appropriate types
            mock_params_dict = {}
            mock_model_to_graph.return_value = (mock_graph, mock_params_dict, mock_torch_out)
    
            # Mock _export to do nothing (just track calls)
            mock_export.return_value = None
    
            # Call export
            try:
                onnx_utils.export(
                    model=model,
                    args=args,
                    f=temp_onnx_file,
                    export_params=export_params,
                    opset_version=opset_version,
                    do_constant_folding=do_constant_folding,
                    verbose=False,
                )
    
                # Weak assertion 1: No exception raised
                # (implicitly passed if we reach here)
    
                # Weak assertion 2: File was opened for writing
                # Since we're mocking io.open, check that it was called
>               assert mock_file.called, "File was not opened for writing"
E               AssertionError: File was not opened for writing
E               assert False
E                +  where False = <MagicMock name='open' spec='builtin_function_or_method' id='5170301104'>.called

tests/test_torch_onnx_utils.py:239: AssertionError

During handling of the above exception, another exception occurred:

model_type = 'nn.Module', args_format = 'named_tuple', output_target = 'file'
opset_version = 13, export_params = True, do_constant_folding = False
simple_linear_model = SimpleLinearModel(
  (linear): Linear(in_features=3, out_features=2, bias=True)
)
simple_conv_model = SimpleConvModel(
  (conv): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)
sample_input_tensor = tensor([[ 0.1005,  0.2325,  0.7064],
        [ 0.3693, -0.8368, -1.2204]])
sample_input_tensor_2d = tensor([[[[-1.3386e-01, -5.8557e-02,  1.2574e-01, -5.5258e-01,  7.4480e-02,
           -1.4929e-01, -5.5225e-01, -9.34...  4.5689e-01, -6.0341e-01,  4.6268e-01,
            2.4934e-01, -1.7062e-01, -6.1410e-01,  5.3551e-01, -1.6644e+00]]]])
temp_onnx_file = '/var/folders/fc/ny_p_wjs10xfzq7xns_lfdc40000gn/T/tmpslgxnvn2.onnx'

    @pytest.mark.parametrize(
        "model_type,args_format,output_target,opset_version,export_params,do_constant_folding",
        [
            # Base case from test plan
            ("nn.Module", "tuple", "file", 13, True, True),
            # Parameter extensions from test plan
            ("nn.Module", "named_tuple", "file", 13, True, False),
            ("nn.Module", "tuple", "file", 7, True, True),
            ("nn.Module", "tuple", "file", 16, False, True),
        ]
    )
    def test_export_basic_model_to_file(
        model_type,
        args_format,
        output_target,
        opset_version,
        export_params,
        do_constant_folding,
        simple_linear_model,
        simple_conv_model,
        sample_input_tensor,
        sample_input_tensor_2d,
        temp_onnx_file,
    ):
        """
        Test basic model export to file with various configurations.
    
        This test covers the core export functionality with different:
        - Model types (nn.Module)
        - Args formats (tuple, named_tuple)
        - Opset versions (7, 13, 16)
        - Export parameters (True/False)
        - Constant folding (True/False)
    
        Weak assertions: file exists, file not empty, no exception.
        """
        # Select model based on type
        if model_type == "nn.Module":
            # Use linear model for 1D input, conv model for 2D input
            if args_format == "tuple":
                model = simple_linear_model
                args = (sample_input_tensor,)
            else:  # named_tuple
                model = simple_conv_model
                args = (sample_input_tensor_2d,)
    
        # Prepare args based on format
        if args_format == "named_tuple":
            # Create args with named parameters
            args = (args[0], {"dummy_param": torch.tensor([1.0])})
    
        # Mock dependencies - we need to mock the entire export chain
        # to avoid C++ type issues
        with mock.patch('torch.jit._get_trace_graph') as mock_get_trace_graph, \
             mock.patch('torch.onnx.utils._model_to_graph') as mock_model_to_graph, \
             mock.patch('torch.onnx.utils._export') as mock_export, \
             mock.patch('io.open', mock.mock_open()) as mock_file:
    
            # Setup mock returns for _get_trace_graph
            mock_graph = mock.MagicMock()
            mock_torch_out = torch.tensor([[1.0, 2.0], [3.0, 4.0]])
            mock_inputs_states = mock.MagicMock()
            mock_get_trace_graph.return_value = (mock_graph, mock_torch_out, mock_inputs_states)
    
            # Create a proper mock for _model_to_graph that returns appropriate types
            mock_params_dict = {}
            mock_model_to_graph.return_value = (mock_graph, mock_params_dict, mock_torch_out)
    
            # Mock _export to do nothing (just track calls)
            mock_export.return_value = None
    
            # Call export
            try:
                onnx_utils.export(
                    model=model,
                    args=args,
                    f=temp_onnx_file,
                    export_params=export_params,
                    opset_version=opset_version,
                    do_constant_folding=do_constant_folding,
                    verbose=False,
                )
    
                # Weak assertion 1: No exception raised
                # (implicitly passed if we reach here)
    
                # Weak assertion 2: File was opened for writing
                # Since we're mocking io.open, check that it was called
                assert mock_file.called, "File was not opened for writing"
    
                # Check that write was called (indicating content was written)
                write_calls = [call for call in mock_file.mock_calls if call[0] == '().write']
                assert len(write_calls) > 0, "No data was written to file"
    
                # Weak assertion 3: _get_trace_graph was called for nn.Module
                if model_type == "nn.Module":
                    assert mock_get_trace_graph.called, "torch.jit._get_trace_graph should be called for nn.Module"
    
                # Weak assertion 4: _model_to_graph was called
                assert mock_model_to_graph.called, "_model_to_graph should be called"
    
                # Weak assertion 5: _export was called
                assert mock_export.called, "_export should be called"
    
                # Additional weak checks
                assert opset_version >= 7 and opset_version <= 16, \
                    f"Opset version {opset_version} should be in range 7-16"
    
                # Check that export was called with correct parameters
                mock_export.assert_called_once()
                call_args = mock_export.call_args
    
                # Verify key parameters
                assert call_args[0][0] == model, "Model parameter should match"
                assert call_args[0][1] == args, "Args parameter should match"
                assert call_args[0][2] == temp_onnx_file, "File parameter should match"
                assert call_args[1]['export_params'] == export_params, "export_params should match"
                assert call_args[1]['opset_version'] == opset_version, "opset_version should match"
                assert call_args[1]['do_constant_folding'] == do_constant_folding, "do_constant_folding should match"
    
            except Exception as e:
>               pytest.fail(f"Export raised unexpected exception: {e}")
E               Failed: Export raised unexpected exception: File was not opened for writing
E               assert False
E                +  where False = <MagicMock name='open' spec='builtin_function_or_method' id='5170301104'>.called

tests/test_torch_onnx_utils.py:272: Failed
______ test_export_basic_model_to_file[nn.Module-tuple-file-7-True-True] _______

model_type = 'nn.Module', args_format = 'tuple', output_target = 'file'
opset_version = 7, export_params = True, do_constant_folding = True
simple_linear_model = SimpleLinearModel(
  (linear): Linear(in_features=3, out_features=2, bias=True)
)
simple_conv_model = SimpleConvModel(
  (conv): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)
sample_input_tensor = tensor([[-0.2662,  1.0295,  0.1327],
        [ 1.8114, -1.0315,  1.1471]])
sample_input_tensor_2d = tensor([[[[-0.8443, -0.3292, -0.1140, -0.8452,  0.5263,  0.1255, -1.7527,
            0.7752,  0.2892,  0.3520],
     ...9],
          [ 0.1342, -1.1246, -1.8830,  1.6258, -0.7038,  0.5581,  0.2723,
           -0.4286,  0.8240, -1.3990]]]])
temp_onnx_file = '/var/folders/fc/ny_p_wjs10xfzq7xns_lfdc40000gn/T/tmph7zx_b55.onnx'

    @pytest.mark.parametrize(
        "model_type,args_format,output_target,opset_version,export_params,do_constant_folding",
        [
            # Base case from test plan
            ("nn.Module", "tuple", "file", 13, True, True),
            # Parameter extensions from test plan
            ("nn.Module", "named_tuple", "file", 13, True, False),
            ("nn.Module", "tuple", "file", 7, True, True),
            ("nn.Module", "tuple", "file", 16, False, True),
        ]
    )
    def test_export_basic_model_to_file(
        model_type,
        args_format,
        output_target,
        opset_version,
        export_params,
        do_constant_folding,
        simple_linear_model,
        simple_conv_model,
        sample_input_tensor,
        sample_input_tensor_2d,
        temp_onnx_file,
    ):
        """
        Test basic model export to file with various configurations.
    
        This test covers the core export functionality with different:
        - Model types (nn.Module)
        - Args formats (tuple, named_tuple)
        - Opset versions (7, 13, 16)
        - Export parameters (True/False)
        - Constant folding (True/False)
    
        Weak assertions: file exists, file not empty, no exception.
        """
        # Select model based on type
        if model_type == "nn.Module":
            # Use linear model for 1D input, conv model for 2D input
            if args_format == "tuple":
                model = simple_linear_model
                args = (sample_input_tensor,)
            else:  # named_tuple
                model = simple_conv_model
                args = (sample_input_tensor_2d,)
    
        # Prepare args based on format
        if args_format == "named_tuple":
            # Create args with named parameters
            args = (args[0], {"dummy_param": torch.tensor([1.0])})
    
        # Mock dependencies - we need to mock the entire export chain
        # to avoid C++ type issues
        with mock.patch('torch.jit._get_trace_graph') as mock_get_trace_graph, \
             mock.patch('torch.onnx.utils._model_to_graph') as mock_model_to_graph, \
             mock.patch('torch.onnx.utils._export') as mock_export, \
             mock.patch('io.open', mock.mock_open()) as mock_file:
    
            # Setup mock returns for _get_trace_graph
            mock_graph = mock.MagicMock()
            mock_torch_out = torch.tensor([[1.0, 2.0], [3.0, 4.0]])
            mock_inputs_states = mock.MagicMock()
            mock_get_trace_graph.return_value = (mock_graph, mock_torch_out, mock_inputs_states)
    
            # Create a proper mock for _model_to_graph that returns appropriate types
            mock_params_dict = {}
            mock_model_to_graph.return_value = (mock_graph, mock_params_dict, mock_torch_out)
    
            # Mock _export to do nothing (just track calls)
            mock_export.return_value = None
    
            # Call export
            try:
                onnx_utils.export(
                    model=model,
                    args=args,
                    f=temp_onnx_file,
                    export_params=export_params,
                    opset_version=opset_version,
                    do_constant_folding=do_constant_folding,
                    verbose=False,
                )
    
                # Weak assertion 1: No exception raised
                # (implicitly passed if we reach here)
    
                # Weak assertion 2: File was opened for writing
                # Since we're mocking io.open, check that it was called
>               assert mock_file.called, "File was not opened for writing"
E               AssertionError: File was not opened for writing
E               assert False
E                +  where False = <MagicMock name='open' spec='builtin_function_or_method' id='5170655104'>.called

tests/test_torch_onnx_utils.py:239: AssertionError

During handling of the above exception, another exception occurred:

model_type = 'nn.Module', args_format = 'tuple', output_target = 'file'
opset_version = 7, export_params = True, do_constant_folding = True
simple_linear_model = SimpleLinearModel(
  (linear): Linear(in_features=3, out_features=2, bias=True)
)
simple_conv_model = SimpleConvModel(
  (conv): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)
sample_input_tensor = tensor([[-0.2662,  1.0295,  0.1327],
        [ 1.8114, -1.0315,  1.1471]])
sample_input_tensor_2d = tensor([[[[-0.8443, -0.3292, -0.1140, -0.8452,  0.5263,  0.1255, -1.7527,
            0.7752,  0.2892,  0.3520],
     ...9],
          [ 0.1342, -1.1246, -1.8830,  1.6258, -0.7038,  0.5581,  0.2723,
           -0.4286,  0.8240, -1.3990]]]])
temp_onnx_file = '/var/folders/fc/ny_p_wjs10xfzq7xns_lfdc40000gn/T/tmph7zx_b55.onnx'

    @pytest.mark.parametrize(
        "model_type,args_format,output_target,opset_version,export_params,do_constant_folding",
        [
            # Base case from test plan
            ("nn.Module", "tuple", "file", 13, True, True),
            # Parameter extensions from test plan
            ("nn.Module", "named_tuple", "file", 13, True, False),
            ("nn.Module", "tuple", "file", 7, True, True),
            ("nn.Module", "tuple", "file", 16, False, True),
        ]
    )
    def test_export_basic_model_to_file(
        model_type,
        args_format,
        output_target,
        opset_version,
        export_params,
        do_constant_folding,
        simple_linear_model,
        simple_conv_model,
        sample_input_tensor,
        sample_input_tensor_2d,
        temp_onnx_file,
    ):
        """
        Test basic model export to file with various configurations.
    
        This test covers the core export functionality with different:
        - Model types (nn.Module)
        - Args formats (tuple, named_tuple)
        - Opset versions (7, 13, 16)
        - Export parameters (True/False)
        - Constant folding (True/False)
    
        Weak assertions: file exists, file not empty, no exception.
        """
        # Select model based on type
        if model_type == "nn.Module":
            # Use linear model for 1D input, conv model for 2D input
            if args_format == "tuple":
                model = simple_linear_model
                args = (sample_input_tensor,)
            else:  # named_tuple
                model = simple_conv_model
                args = (sample_input_tensor_2d,)
    
        # Prepare args based on format
        if args_format == "named_tuple":
            # Create args with named parameters
            args = (args[0], {"dummy_param": torch.tensor([1.0])})
    
        # Mock dependencies - we need to mock the entire export chain
        # to avoid C++ type issues
        with mock.patch('torch.jit._get_trace_graph') as mock_get_trace_graph, \
             mock.patch('torch.onnx.utils._model_to_graph') as mock_model_to_graph, \
             mock.patch('torch.onnx.utils._export') as mock_export, \
             mock.patch('io.open', mock.mock_open()) as mock_file:
    
            # Setup mock returns for _get_trace_graph
            mock_graph = mock.MagicMock()
            mock_torch_out = torch.tensor([[1.0, 2.0], [3.0, 4.0]])
            mock_inputs_states = mock.MagicMock()
            mock_get_trace_graph.return_value = (mock_graph, mock_torch_out, mock_inputs_states)
    
            # Create a proper mock for _model_to_graph that returns appropriate types
            mock_params_dict = {}
            mock_model_to_graph.return_value = (mock_graph, mock_params_dict, mock_torch_out)
    
            # Mock _export to do nothing (just track calls)
            mock_export.return_value = None
    
            # Call export
            try:
                onnx_utils.export(
                    model=model,
                    args=args,
                    f=temp_onnx_file,
                    export_params=export_params,
                    opset_version=opset_version,
                    do_constant_folding=do_constant_folding,
                    verbose=False,
                )
    
                # Weak assertion 1: No exception raised
                # (implicitly passed if we reach here)
    
                # Weak assertion 2: File was opened for writing
                # Since we're mocking io.open, check that it was called
                assert mock_file.called, "File was not opened for writing"
    
                # Check that write was called (indicating content was written)
                write_calls = [call for call in mock_file.mock_calls if call[0] == '().write']
                assert len(write_calls) > 0, "No data was written to file"
    
                # Weak assertion 3: _get_trace_graph was called for nn.Module
                if model_type == "nn.Module":
                    assert mock_get_trace_graph.called, "torch.jit._get_trace_graph should be called for nn.Module"
    
                # Weak assertion 4: _model_to_graph was called
                assert mock_model_to_graph.called, "_model_to_graph should be called"
    
                # Weak assertion 5: _export was called
                assert mock_export.called, "_export should be called"
    
                # Additional weak checks
                assert opset_version >= 7 and opset_version <= 16, \
                    f"Opset version {opset_version} should be in range 7-16"
    
                # Check that export was called with correct parameters
                mock_export.assert_called_once()
                call_args = mock_export.call_args
    
                # Verify key parameters
                assert call_args[0][0] == model, "Model parameter should match"
                assert call_args[0][1] == args, "Args parameter should match"
                assert call_args[0][2] == temp_onnx_file, "File parameter should match"
                assert call_args[1]['export_params'] == export_params, "export_params should match"
                assert call_args[1]['opset_version'] == opset_version, "opset_version should match"
                assert call_args[1]['do_constant_folding'] == do_constant_folding, "do_constant_folding should match"
    
            except Exception as e:
>               pytest.fail(f"Export raised unexpected exception: {e}")
E               Failed: Export raised unexpected exception: File was not opened for writing
E               assert False
E                +  where False = <MagicMock name='open' spec='builtin_function_or_method' id='5170655104'>.called

tests/test_torch_onnx_utils.py:272: Failed
_____ test_export_basic_model_to_file[nn.Module-tuple-file-16-False-True] ______

model_type = 'nn.Module', args_format = 'tuple', output_target = 'file'
opset_version = 16, export_params = False, do_constant_folding = True
simple_linear_model = SimpleLinearModel(
  (linear): Linear(in_features=3, out_features=2, bias=True)
)
simple_conv_model = SimpleConvModel(
  (conv): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)
sample_input_tensor = tensor([[-1.7534, -1.3003,  0.5800],
        [ 0.0158, -1.6756,  1.0759]])
sample_input_tensor_2d = tensor([[[[-0.4210, -0.6637,  1.4599, -1.9324,  0.2951,  1.9531,  0.0623,
           -1.1079, -0.0518,  0.4115],
     ...7],
          [ 1.5941,  2.5384, -0.4962,  1.5591, -1.2024, -0.6351,  0.2057,
            1.2085, -1.2975, -1.7842]]]])
temp_onnx_file = '/var/folders/fc/ny_p_wjs10xfzq7xns_lfdc40000gn/T/tmpovw0zqvw.onnx'

    @pytest.mark.parametrize(
        "model_type,args_format,output_target,opset_version,export_params,do_constant_folding",
        [
            # Base case from test plan
            ("nn.Module", "tuple", "file", 13, True, True),
            # Parameter extensions from test plan
            ("nn.Module", "named_tuple", "file", 13, True, False),
            ("nn.Module", "tuple", "file", 7, True, True),
            ("nn.Module", "tuple", "file", 16, False, True),
        ]
    )
    def test_export_basic_model_to_file(
        model_type,
        args_format,
        output_target,
        opset_version,
        export_params,
        do_constant_folding,
        simple_linear_model,
        simple_conv_model,
        sample_input_tensor,
        sample_input_tensor_2d,
        temp_onnx_file,
    ):
        """
        Test basic model export to file with various configurations.
    
        This test covers the core export functionality with different:
        - Model types (nn.Module)
        - Args formats (tuple, named_tuple)
        - Opset versions (7, 13, 16)
        - Export parameters (True/False)
        - Constant folding (True/False)
    
        Weak assertions: file exists, file not empty, no exception.
        """
        # Select model based on type
        if model_type == "nn.Module":
            # Use linear model for 1D input, conv model for 2D input
            if args_format == "tuple":
                model = simple_linear_model
                args = (sample_input_tensor,)
            else:  # named_tuple
                model = simple_conv_model
                args = (sample_input_tensor_2d,)
    
        # Prepare args based on format
        if args_format == "named_tuple":
            # Create args with named parameters
            args = (args[0], {"dummy_param": torch.tensor([1.0])})
    
        # Mock dependencies - we need to mock the entire export chain
        # to avoid C++ type issues
        with mock.patch('torch.jit._get_trace_graph') as mock_get_trace_graph, \
             mock.patch('torch.onnx.utils._model_to_graph') as mock_model_to_graph, \
             mock.patch('torch.onnx.utils._export') as mock_export, \
             mock.patch('io.open', mock.mock_open()) as mock_file:
    
            # Setup mock returns for _get_trace_graph
            mock_graph = mock.MagicMock()
            mock_torch_out = torch.tensor([[1.0, 2.0], [3.0, 4.0]])
            mock_inputs_states = mock.MagicMock()
            mock_get_trace_graph.return_value = (mock_graph, mock_torch_out, mock_inputs_states)
    
            # Create a proper mock for _model_to_graph that returns appropriate types
            mock_params_dict = {}
            mock_model_to_graph.return_value = (mock_graph, mock_params_dict, mock_torch_out)
    
            # Mock _export to do nothing (just track calls)
            mock_export.return_value = None
    
            # Call export
            try:
                onnx_utils.export(
                    model=model,
                    args=args,
                    f=temp_onnx_file,
                    export_params=export_params,
                    opset_version=opset_version,
                    do_constant_folding=do_constant_folding,
                    verbose=False,
                )
    
                # Weak assertion 1: No exception raised
                # (implicitly passed if we reach here)
    
                # Weak assertion 2: File was opened for writing
                # Since we're mocking io.open, check that it was called
>               assert mock_file.called, "File was not opened for writing"
E               AssertionError: File was not opened for writing
E               assert False
E                +  where False = <MagicMock name='open' spec='builtin_function_or_method' id='5170852816'>.called

tests/test_torch_onnx_utils.py:239: AssertionError

During handling of the above exception, another exception occurred:

model_type = 'nn.Module', args_format = 'tuple', output_target = 'file'
opset_version = 16, export_params = False, do_constant_folding = True
simple_linear_model = SimpleLinearModel(
  (linear): Linear(in_features=3, out_features=2, bias=True)
)
simple_conv_model = SimpleConvModel(
  (conv): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
)
sample_input_tensor = tensor([[-1.7534, -1.3003,  0.5800],
        [ 0.0158, -1.6756,  1.0759]])
sample_input_tensor_2d = tensor([[[[-0.4210, -0.6637,  1.4599, -1.9324,  0.2951,  1.9531,  0.0623,
           -1.1079, -0.0518,  0.4115],
     ...7],
          [ 1.5941,  2.5384, -0.4962,  1.5591, -1.2024, -0.6351,  0.2057,
            1.2085, -1.2975, -1.7842]]]])
temp_onnx_file = '/var/folders/fc/ny_p_wjs10xfzq7xns_lfdc40000gn/T/tmpovw0zqvw.onnx'

    @pytest.mark.parametrize(
        "model_type,args_format,output_target,opset_version,export_params,do_constant_folding",
        [
            # Base case from test plan
            ("nn.Module", "tuple", "file", 13, True, True),
            # Parameter extensions from test plan
            ("nn.Module", "named_tuple", "file", 13, True, False),
            ("nn.Module", "tuple", "file", 7, True, True),
            ("nn.Module", "tuple", "file", 16, False, True),
        ]
    )
    def test_export_basic_model_to_file(
        model_type,
        args_format,
        output_target,
        opset_version,
        export_params,
        do_constant_folding,
        simple_linear_model,
        simple_conv_model,
        sample_input_tensor,
        sample_input_tensor_2d,
        temp_onnx_file,
    ):
        """
        Test basic model export to file with various configurations.
    
        This test covers the core export functionality with different:
        - Model types (nn.Module)
        - Args formats (tuple, named_tuple)
        - Opset versions (7, 13, 16)
        - Export parameters (True/False)
        - Constant folding (True/False)
    
        Weak assertions: file exists, file not empty, no exception.
        """
        # Select model based on type
        if model_type == "nn.Module":
            # Use linear model for 1D input, conv model for 2D input
            if args_format == "tuple":
                model = simple_linear_model
                args = (sample_input_tensor,)
            else:  # named_tuple
                model = simple_conv_model
                args = (sample_input_tensor_2d,)
    
        # Prepare args based on format
        if args_format == "named_tuple":
            # Create args with named parameters
            args = (args[0], {"dummy_param": torch.tensor([1.0])})
    
        # Mock dependencies - we need to mock the entire export chain
        # to avoid C++ type issues
        with mock.patch('torch.jit._get_trace_graph') as mock_get_trace_graph, \
             mock.patch('torch.onnx.utils._model_to_graph') as mock_model_to_graph, \
             mock.patch('torch.onnx.utils._export') as mock_export, \
             mock.patch('io.open', mock.mock_open()) as mock_file:
    
            # Setup mock returns for _get_trace_graph
            mock_graph = mock.MagicMock()
            mock_torch_out = torch.tensor([[1.0, 2.0], [3.0, 4.0]])
            mock_inputs_states = mock.MagicMock()
            mock_get_trace_graph.return_value = (mock_graph, mock_torch_out, mock_inputs_states)
    
            # Create a proper mock for _model_to_graph that returns appropriate types
            mock_params_dict = {}
            mock_model_to_graph.return_value = (mock_graph, mock_params_dict, mock_torch_out)
    
            # Mock _export to do nothing (just track calls)
            mock_export.return_value = None
    
            # Call export
            try:
                onnx_utils.export(
                    model=model,
                    args=args,
                    f=temp_onnx_file,
                    export_params=export_params,
                    opset_version=opset_version,
                    do_constant_folding=do_constant_folding,
                    verbose=False,
                )
    
                # Weak assertion 1: No exception raised
                # (implicitly passed if we reach here)
    
                # Weak assertion 2: File was opened for writing
                # Since we're mocking io.open, check that it was called
                assert mock_file.called, "File was not opened for writing"
    
                # Check that write was called (indicating content was written)
                write_calls = [call for call in mock_file.mock_calls if call[0] == '().write']
                assert len(write_calls) > 0, "No data was written to file"
    
                # Weak assertion 3: _get_trace_graph was called for nn.Module
                if model_type == "nn.Module":
                    assert mock_get_trace_graph.called, "torch.jit._get_trace_graph should be called for nn.Module"
    
                # Weak assertion 4: _model_to_graph was called
                assert mock_model_to_graph.called, "_model_to_graph should be called"
    
                # Weak assertion 5: _export was called
                assert mock_export.called, "_export should be called"
    
                # Additional weak checks
                assert opset_version >= 7 and opset_version <= 16, \
                    f"Opset version {opset_version} should be in range 7-16"
    
                # Check that export was called with correct parameters
                mock_export.assert_called_once()
                call_args = mock_export.call_args
    
                # Verify key parameters
                assert call_args[0][0] == model, "Model parameter should match"
                assert call_args[0][1] == args, "Args parameter should match"
                assert call_args[0][2] == temp_onnx_file, "File parameter should match"
                assert call_args[1]['export_params'] == export_params, "export_params should match"
                assert call_args[1]['opset_version'] == opset_version, "opset_version should match"
                assert call_args[1]['do_constant_folding'] == do_constant_folding, "do_constant_folding should match"
    
            except Exception as e:
>               pytest.fail(f"Export raised unexpected exception: {e}")
E               Failed: Export raised unexpected exception: File was not opened for writing
E               assert False
E                +  where False = <MagicMock name='open' spec='builtin_function_or_method' id='5170852816'>.called

tests/test_torch_onnx_utils.py:272: Failed
_____ test_export_model_to_bytesio[nn.Module-tensor-bytesio-13-True-True] ______

model_type = 'nn.Module', args_format = 'tensor', output_target = 'bytesio'
opset_version = 13, export_params = True, do_constant_folding = True
simple_linear_model = SimpleLinearModel(
  (linear): Linear(in_features=3, out_features=2, bias=True)
)
sample_input_tensor = tensor([[-0.7328,  0.0113,  0.4797],
        [-0.0365,  1.0878, -0.0177]])

    @pytest.mark.parametrize(
        "model_type,args_format,output_target,opset_version,export_params,do_constant_folding",
        [
            # Base case from test plan
            ("nn.Module", "tensor", "bytesio", 13, True, True),
            # Parameter extension from test plan
            ("ScriptFunction", "tensor", "bytesio", 13, True, True),
        ]
    )
    def test_export_model_to_bytesio(
        model_type,
        args_format,
        output_target,
        opset_version,
        export_params,
        do_constant_folding,
        simple_linear_model,
        sample_input_tensor,
    ):
        """
        Test model export to BytesIO buffer with various configurations.
    
        This test covers:
        - Export to in-memory buffer (BytesIO)
        - Tensor args format
        - Different model types (nn.Module, ScriptFunction)
    
        Weak assertions: buffer not empty, buffer position changed, no exception.
        """
        # Prepare model based on type
        if model_type == "nn.Module":
            model = simple_linear_model
        else:  # ScriptFunction
            # Create a mock ScriptFunction
            model = mock.MagicMock(spec=torch.jit.ScriptFunction)
    
        # Prepare args based on format
        if args_format == "tensor":
            args = sample_input_tensor
    
        # Create BytesIO buffer
        buffer = io.BytesIO()
    
        # Track initial buffer state
        initial_position = buffer.tell()
    
        # Mock dependencies
        with mock.patch('torch.jit._get_trace_graph') as mock_get_trace_graph, \
             mock.patch('torch.onnx.utils._model_to_graph') as mock_model_to_graph, \
             mock.patch('torch.onnx.utils._export') as mock_export:
    
            # Setup mock returns for _get_trace_graph
            mock_graph = mock.MagicMock()
            mock_torch_out = torch.tensor([[1.0, 2.0], [3.0, 4.0]])
            mock_inputs_states = mock.MagicMock()
            mock_get_trace_graph.return_value = (mock_graph, mock_torch_out, mock_inputs_states)
    
            # Create a proper mock for _model_to_graph
            mock_params_dict = {}
            mock_model_to_graph.return_value = (mock_graph, mock_params_dict, mock_torch_out)
    
            # Mock _export to write some dummy data to buffer
            def mock_export_side_effect(*args, **kwargs):
                f = args[2]
                if hasattr(f, 'write'):
                    # Write dummy ONNX-like data
                    f.write(b'dummy_onnx_protobuf_data')
                return None
    
            mock_export.side_effect = mock_export_side_effect
    
            # Call export
            try:
                onnx_utils.export(
                    model=model,
                    args=args,
                    f=buffer,
                    export_params=export_params,
                    opset_version=opset_version,
                    do_constant_folding=do_constant_folding,
                    verbose=False,
                )
    
                # Weak assertion 1: No exception raised
                # (implicitly passed if we reach here)
    
                # Weak assertion 2: Buffer is not empty
                buffer_size = buffer.getbuffer().nbytes
                assert buffer_size > 0, f"Buffer should not be empty, got size: {buffer_size}"
    
                # Weak assertion 3: Buffer position changed
                final_position = buffer.tell()
                assert final_position > initial_position, \
                    f"Buffer position should change. Initial: {initial_position}, Final: {final_position}"
    
                # Weak assertion 4: _get_trace_graph called appropriately
                if model_type == "nn.Module":
>                   assert mock_get_trace_graph.called, "torch.jit._get_trace_graph should be called for nn.Module"
E                   AssertionError: torch.jit._get_trace_graph should be called for nn.Module
E                   assert False
E                    +  where False = <MagicMock name='_get_trace_graph' id='5171129424'>.called

tests/test_torch_onnx_utils.py:375: AssertionError

During handling of the above exception, another exception occurred:

model_type = 'nn.Module', args_format = 'tensor', output_target = 'bytesio'
opset_version = 13, export_params = True, do_constant_folding = True
simple_linear_model = SimpleLinearModel(
  (linear): Linear(in_features=3, out_features=2, bias=True)
)
sample_input_tensor = tensor([[-0.7328,  0.0113,  0.4797],
        [-0.0365,  1.0878, -0.0177]])

    @pytest.mark.parametrize(
        "model_type,args_format,output_target,opset_version,export_params,do_constant_folding",
        [
            # Base case from test plan
            ("nn.Module", "tensor", "bytesio", 13, True, True),
            # Parameter extension from test plan
            ("ScriptFunction", "tensor", "bytesio", 13, True, True),
        ]
    )
    def test_export_model_to_bytesio(
        model_type,
        args_format,
        output_target,
        opset_version,
        export_params,
        do_constant_folding,
        simple_linear_model,
        sample_input_tensor,
    ):
        """
        Test model export to BytesIO buffer with various configurations.
    
        This test covers:
        - Export to in-memory buffer (BytesIO)
        - Tensor args format
        - Different model types (nn.Module, ScriptFunction)
    
        Weak assertions: buffer not empty, buffer position changed, no exception.
        """
        # Prepare model based on type
        if model_type == "nn.Module":
            model = simple_linear_model
        else:  # ScriptFunction
            # Create a mock ScriptFunction
            model = mock.MagicMock(spec=torch.jit.ScriptFunction)
    
        # Prepare args based on format
        if args_format == "tensor":
            args = sample_input_tensor
    
        # Create BytesIO buffer
        buffer = io.BytesIO()
    
        # Track initial buffer state
        initial_position = buffer.tell()
    
        # Mock dependencies
        with mock.patch('torch.jit._get_trace_graph') as mock_get_trace_graph, \
             mock.patch('torch.onnx.utils._model_to_graph') as mock_model_to_graph, \
             mock.patch('torch.onnx.utils._export') as mock_export:
    
            # Setup mock returns for _get_trace_graph
            mock_graph = mock.MagicMock()
            mock_torch_out = torch.tensor([[1.0, 2.0], [3.0, 4.0]])
            mock_inputs_states = mock.MagicMock()
            mock_get_trace_graph.return_value = (mock_graph, mock_torch_out, mock_inputs_states)
    
            # Create a proper mock for _model_to_graph
            mock_params_dict = {}
            mock_model_to_graph.return_value = (mock_graph, mock_params_dict, mock_torch_out)
    
            # Mock _export to write some dummy data to buffer
            def mock_export_side_effect(*args, **kwargs):
                f = args[2]
                if hasattr(f, 'write'):
                    # Write dummy ONNX-like data
                    f.write(b'dummy_onnx_protobuf_data')
                return None
    
            mock_export.side_effect = mock_export_side_effect
    
            # Call export
            try:
                onnx_utils.export(
                    model=model,
                    args=args,
                    f=buffer,
                    export_params=export_params,
                    opset_version=opset_version,
                    do_constant_folding=do_constant_folding,
                    verbose=False,
                )
    
                # Weak assertion 1: No exception raised
                # (implicitly passed if we reach here)
    
                # Weak assertion 2: Buffer is not empty
                buffer_size = buffer.getbuffer().nbytes
                assert buffer_size > 0, f"Buffer should not be empty, got size: {buffer_size}"
    
                # Weak assertion 3: Buffer position changed
                final_position = buffer.tell()
                assert final_position > initial_position, \
                    f"Buffer position should change. Initial: {initial_position}, Final: {final_position}"
    
                # Weak assertion 4: _get_trace_graph called appropriately
                if model_type == "nn.Module":
                    assert mock_get_trace_graph.called, "torch.jit._get_trace_graph should be called for nn.Module"
                else:  # ScriptFunction
                    # For ScriptFunction, _get_trace_graph should not be called
                    # Instead, it should use the existing graph
                    assert not mock_get_trace_graph.called, "torch.jit._get_trace_graph should not be called for ScriptFunction"
    
                # Weak assertion 5: _model_to_graph was called
                assert mock_model_to_graph.called, "_model_to_graph should be called"
    
                # Weak assertion 6: _export was called
                assert mock_export.called, "_export should be called"
    
                # Additional weak check for opset version
                assert opset_version >= 7 and opset_version <= 16, \
                    f"Opset version {opset_version} should be in range 7-16"
    
                # Check buffer content (basic validation)
                buffer_content = buffer.getvalue()
                assert isinstance(buffer_content, bytes), "Buffer content should be bytes"
                assert len(buffer_content) > 0, "Buffer content should have non-zero length"
    
                # Verify that the dummy data was written
                assert buffer_content == b'dummy_onnx_protobuf_data', \
                    "Buffer should contain the dummy data written by mock_export"
    
                # Check that export was called with correct parameters
                mock_export.assert_called_once()
                call_args = mock_export.call_args
    
                # Verify key parameters
                assert call_args[0][0] == model, "Model parameter should match"
                assert call_args[0][1] == args, "Args parameter should match"
                assert call_args[0][2] == buffer, "Buffer parameter should match"
                assert call_args[1]['export_params'] == export_params, "export_params should match"
                assert call_args[1]['opset_version'] == opset_version, "opset_version should match"
                assert call_args[1]['do_constant_folding'] == do_constant_folding, "do_constant_folding should match"
    
            except Exception as e:
>               pytest.fail(f"Export to BytesIO raised unexpected exception: {e}")
E               Failed: Export to BytesIO raised unexpected exception: torch.jit._get_trace_graph should be called for nn.Module
E               assert False
E                +  where False = <MagicMock name='_get_trace_graph' id='5171129424'>.called

tests/test_torch_onnx_utils.py:413: Failed
___ test_export_model_to_bytesio[ScriptFunction-tensor-bytesio-13-True-True] ___

model_type = 'ScriptFunction', args_format = 'tensor', output_target = 'bytesio'
opset_version = 13, export_params = True, do_constant_folding = True
simple_linear_model = SimpleLinearModel(
  (linear): Linear(in_features=3, out_features=2, bias=True)
)
sample_input_tensor = tensor([[-0.6039, -0.3514,  0.5235],
        [ 0.0675, -0.9669, -0.0743]])

    @pytest.mark.parametrize(
        "model_type,args_format,output_target,opset_version,export_params,do_constant_folding",
        [
            # Base case from test plan
            ("nn.Module", "tensor", "bytesio", 13, True, True),
            # Parameter extension from test plan
            ("ScriptFunction", "tensor", "bytesio", 13, True, True),
        ]
    )
    def test_export_model_to_bytesio(
        model_type,
        args_format,
        output_target,
        opset_version,
        export_params,
        do_constant_folding,
        simple_linear_model,
        sample_input_tensor,
    ):
        """
        Test model export to BytesIO buffer with various configurations.
    
        This test covers:
        - Export to in-memory buffer (BytesIO)
        - Tensor args format
        - Different model types (nn.Module, ScriptFunction)
    
        Weak assertions: buffer not empty, buffer position changed, no exception.
        """
        # Prepare model based on type
        if model_type == "nn.Module":
            model = simple_linear_model
        else:  # ScriptFunction
            # Create a mock ScriptFunction
            model = mock.MagicMock(spec=torch.jit.ScriptFunction)
    
        # Prepare args based on format
        if args_format == "tensor":
            args = sample_input_tensor
    
        # Create BytesIO buffer
        buffer = io.BytesIO()
    
        # Track initial buffer state
        initial_position = buffer.tell()
    
        # Mock dependencies
        with mock.patch('torch.jit._get_trace_graph') as mock_get_trace_graph, \
             mock.patch('torch.onnx.utils._model_to_graph') as mock_model_to_graph, \
             mock.patch('torch.onnx.utils._export') as mock_export:
    
            # Setup mock returns for _get_trace_graph
            mock_graph = mock.MagicMock()
            mock_torch_out = torch.tensor([[1.0, 2.0], [3.0, 4.0]])
            mock_inputs_states = mock.MagicMock()
            mock_get_trace_graph.return_value = (mock_graph, mock_torch_out, mock_inputs_states)
    
            # Create a proper mock for _model_to_graph
            mock_params_dict = {}
            mock_model_to_graph.return_value = (mock_graph, mock_params_dict, mock_torch_out)
    
            # Mock _export to write some dummy data to buffer
            def mock_export_side_effect(*args, **kwargs):
                f = args[2]
                if hasattr(f, 'write'):
                    # Write dummy ONNX-like data
                    f.write(b'dummy_onnx_protobuf_data')
                return None
    
            mock_export.side_effect = mock_export_side_effect
    
            # Call export
            try:
                onnx_utils.export(
                    model=model,
                    args=args,
                    f=buffer,
                    export_params=export_params,
                    opset_version=opset_version,
                    do_constant_folding=do_constant_folding,
                    verbose=False,
                )
    
                # Weak assertion 1: No exception raised
                # (implicitly passed if we reach here)
    
                # Weak assertion 2: Buffer is not empty
                buffer_size = buffer.getbuffer().nbytes
                assert buffer_size > 0, f"Buffer should not be empty, got size: {buffer_size}"
    
                # Weak assertion 3: Buffer position changed
                final_position = buffer.tell()
                assert final_position > initial_position, \
                    f"Buffer position should change. Initial: {initial_position}, Final: {final_position}"
    
                # Weak assertion 4: _get_trace_graph called appropriately
                if model_type == "nn.Module":
                    assert mock_get_trace_graph.called, "torch.jit._get_trace_graph should be called for nn.Module"
                else:  # ScriptFunction
                    # For ScriptFunction, _get_trace_graph should not be called
                    # Instead, it should use the existing graph
                    assert not mock_get_trace_graph.called, "torch.jit._get_trace_graph should not be called for ScriptFunction"
    
                # Weak assertion 5: _model_to_graph was called
>               assert mock_model_to_graph.called, "_model_to_graph should be called"
E               AssertionError: _model_to_graph should be called
E               assert False
E                +  where False = <MagicMock name='_model_to_graph' id='5171205440'>.called

tests/test_torch_onnx_utils.py:382: AssertionError

During handling of the above exception, another exception occurred:

model_type = 'ScriptFunction', args_format = 'tensor', output_target = 'bytesio'
opset_version = 13, export_params = True, do_constant_folding = True
simple_linear_model = SimpleLinearModel(
  (linear): Linear(in_features=3, out_features=2, bias=True)
)
sample_input_tensor = tensor([[-0.6039, -0.3514,  0.5235],
        [ 0.0675, -0.9669, -0.0743]])

    @pytest.mark.parametrize(
        "model_type,args_format,output_target,opset_version,export_params,do_constant_folding",
        [
            # Base case from test plan
            ("nn.Module", "tensor", "bytesio", 13, True, True),
            # Parameter extension from test plan
            ("ScriptFunction", "tensor", "bytesio", 13, True, True),
        ]
    )
    def test_export_model_to_bytesio(
        model_type,
        args_format,
        output_target,
        opset_version,
        export_params,
        do_constant_folding,
        simple_linear_model,
        sample_input_tensor,
    ):
        """
        Test model export to BytesIO buffer with various configurations.
    
        This test covers:
        - Export to in-memory buffer (BytesIO)
        - Tensor args format
        - Different model types (nn.Module, ScriptFunction)
    
        Weak assertions: buffer not empty, buffer position changed, no exception.
        """
        # Prepare model based on type
        if model_type == "nn.Module":
            model = simple_linear_model
        else:  # ScriptFunction
            # Create a mock ScriptFunction
            model = mock.MagicMock(spec=torch.jit.ScriptFunction)
    
        # Prepare args based on format
        if args_format == "tensor":
            args = sample_input_tensor
    
        # Create BytesIO buffer
        buffer = io.BytesIO()
    
        # Track initial buffer state
        initial_position = buffer.tell()
    
        # Mock dependencies
        with mock.patch('torch.jit._get_trace_graph') as mock_get_trace_graph, \
             mock.patch('torch.onnx.utils._model_to_graph') as mock_model_to_graph, \
             mock.patch('torch.onnx.utils._export') as mock_export:
    
            # Setup mock returns for _get_trace_graph
            mock_graph = mock.MagicMock()
            mock_torch_out = torch.tensor([[1.0, 2.0], [3.0, 4.0]])
            mock_inputs_states = mock.MagicMock()
            mock_get_trace_graph.return_value = (mock_graph, mock_torch_out, mock_inputs_states)
    
            # Create a proper mock for _model_to_graph
            mock_params_dict = {}
            mock_model_to_graph.return_value = (mock_graph, mock_params_dict, mock_torch_out)
    
            # Mock _export to write some dummy data to buffer
            def mock_export_side_effect(*args, **kwargs):
                f = args[2]
                if hasattr(f, 'write'):
                    # Write dummy ONNX-like data
                    f.write(b'dummy_onnx_protobuf_data')
                return None
    
            mock_export.side_effect = mock_export_side_effect
    
            # Call export
            try:
                onnx_utils.export(
                    model=model,
                    args=args,
                    f=buffer,
                    export_params=export_params,
                    opset_version=opset_version,
                    do_constant_folding=do_constant_folding,
                    verbose=False,
                )
    
                # Weak assertion 1: No exception raised
                # (implicitly passed if we reach here)
    
                # Weak assertion 2: Buffer is not empty
                buffer_size = buffer.getbuffer().nbytes
                assert buffer_size > 0, f"Buffer should not be empty, got size: {buffer_size}"
    
                # Weak assertion 3: Buffer position changed
                final_position = buffer.tell()
                assert final_position > initial_position, \
                    f"Buffer position should change. Initial: {initial_position}, Final: {final_position}"
    
                # Weak assertion 4: _get_trace_graph called appropriately
                if model_type == "nn.Module":
                    assert mock_get_trace_graph.called, "torch.jit._get_trace_graph should be called for nn.Module"
                else:  # ScriptFunction
                    # For ScriptFunction, _get_trace_graph should not be called
                    # Instead, it should use the existing graph
                    assert not mock_get_trace_graph.called, "torch.jit._get_trace_graph should not be called for ScriptFunction"
    
                # Weak assertion 5: _model_to_graph was called
                assert mock_model_to_graph.called, "_model_to_graph should be called"
    
                # Weak assertion 6: _export was called
                assert mock_export.called, "_export should be called"
    
                # Additional weak check for opset version
                assert opset_version >= 7 and opset_version <= 16, \
                    f"Opset version {opset_version} should be in range 7-16"
    
                # Check buffer content (basic validation)
                buffer_content = buffer.getvalue()
                assert isinstance(buffer_content, bytes), "Buffer content should be bytes"
                assert len(buffer_content) > 0, "Buffer content should have non-zero length"
    
                # Verify that the dummy data was written
                assert buffer_content == b'dummy_onnx_protobuf_data', \
                    "Buffer should contain the dummy data written by mock_export"
    
                # Check that export was called with correct parameters
                mock_export.assert_called_once()
                call_args = mock_export.call_args
    
                # Verify key parameters
                assert call_args[0][0] == model, "Model parameter should match"
                assert call_args[0][1] == args, "Args parameter should match"
                assert call_args[0][2] == buffer, "Buffer parameter should match"
                assert call_args[1]['export_params'] == export_params, "export_params should match"
                assert call_args[1]['opset_version'] == opset_version, "opset_version should match"
                assert call_args[1]['do_constant_folding'] == do_constant_folding, "do_constant_folding should match"
    
            except Exception as e:
>               pytest.fail(f"Export to BytesIO raised unexpected exception: {e}")
E               Failed: Export to BytesIO raised unexpected exception: _model_to_graph should be called
E               assert False
E                +  where False = <MagicMock name='_model_to_graph' id='5171205440'>.called

tests/test_torch_onnx_utils.py:413: Failed
___________ TestONNXUtilsExport.test_export_with_default_parameters ____________

self = <test_torch_onnx_utils.TestONNXUtilsExport object at 0x134206230>
simple_linear_model = SimpleLinearModel(
  (linear): Linear(in_features=3, out_features=2, bias=True)
)
sample_input_tensor = tensor([[-0.0280, -0.4115,  0.8032],
        [-0.9688,  0.1715, -0.5394]])
temp_onnx_file = '/var/folders/fc/ny_p_wjs10xfzq7xns_lfdc40000gn/T/tmp02z51gue.onnx'

    def test_export_with_default_parameters(self, simple_linear_model, sample_input_tensor, temp_onnx_file):
        """Test export with minimal required parameters."""
        with mock.patch('torch.jit._get_trace_graph') as mock_get_trace_graph, \
             mock.patch('torch.onnx.utils._model_to_graph') as mock_model_to_graph, \
             mock.patch('torch.onnx.utils._export') as mock_export, \
             mock.patch('io.open', mock.mock_open()) as mock_file:
    
            # Setup mocks
            mock_graph = mock.MagicMock()
            mock_torch_out = torch.tensor([[1.0, 2.0], [3.0, 4.0]])
            mock_inputs_states = mock.MagicMock()
            mock_get_trace_graph.return_value = (mock_graph, mock_torch_out, mock_inputs_states)
    
            mock_params_dict = {}
            mock_model_to_graph.return_value = (mock_graph, mock_params_dict, mock_torch_out)
            mock_export.return_value = None
    
            # Should not raise any exception
            onnx_utils.export(
                model=simple_linear_model,
                args=(sample_input_tensor,),
                f=temp_onnx_file,
            )
    
            # Verify mocks were called
>           assert mock_get_trace_graph.called, "torch.jit._get_trace_graph should be called"
E           AssertionError: torch.jit._get_trace_graph should be called
E           assert False
E            +  where False = <MagicMock name='_get_trace_graph' id='5170630320'>.called

tests/test_torch_onnx_utils.py:587: AssertionError
________ TestONNXUtilsExport.test_export_with_custom_input_output_names ________

self = <test_torch_onnx_utils.TestONNXUtilsExport object at 0x134206560>
simple_linear_model = SimpleLinearModel(
  (linear): Linear(in_features=3, out_features=2, bias=True)
)
sample_input_tensor = tensor([[ 0.4123, -0.2202, -1.7519],
        [-0.2982, -1.6451, -0.6181]])
temp_onnx_file = '/var/folders/fc/ny_p_wjs10xfzq7xns_lfdc40000gn/T/tmp05g13p2p.onnx'

    def test_export_with_custom_input_output_names(self, simple_linear_model, sample_input_tensor, temp_onnx_file):
        """Test export with custom input and output names."""
        with mock.patch('torch.jit._get_trace_graph') as mock_get_trace_graph, \
             mock.patch('torch.onnx.utils._model_to_graph') as mock_model_to_graph, \
             mock.patch('torch.onnx.utils._export') as mock_export, \
             mock.patch('io.open', mock.mock_open()) as mock_file:
    
            # Setup mocks
            mock_graph = mock.MagicMock()
            mock_torch_out = torch.tensor([[1.0, 2.0], [3.0, 4.0]])
            mock_inputs_states = mock.MagicMock()
            mock_get_trace_graph.return_value = (mock_graph, mock_torch_out, mock_inputs_states)
    
            mock_params_dict = {}
            mock_model_to_graph.return_value = (mock_graph, mock_params_dict, mock_torch_out)
            mock_export.return_value = None
    
            onnx_utils.export(
                model=simple_linear_model,
                args=(sample_input_tensor,),
                f=temp_onnx_file,
                input_names=["input_tensor"],
                output_names=["output_tensor"],
            )
    
            # Verify mocks were called with correct parameters
            mock_export.assert_called_once()
            call_args = mock_export.call_args
>           assert call_args[1]['input_names'] == ["input_tensor"], "input_names should match"
E           KeyError: 'input_names'

tests/test_torch_onnx_utils.py:620: KeyError
______________ TestONNXUtilsExport.test_export_with_verbose_mode _______________

self = <test_torch_onnx_utils.TestONNXUtilsExport object at 0x134206890>
simple_linear_model = SimpleLinearModel(
  (linear): Linear(in_features=3, out_features=2, bias=True)
)
sample_input_tensor = tensor([[ 0.7818, -1.0138, -2.0971],
        [ 0.1009,  0.6100,  1.4594]])
temp_onnx_file = '/var/folders/fc/ny_p_wjs10xfzq7xns_lfdc40000gn/T/tmp1_4javll.onnx'

    def test_export_with_verbose_mode(self, simple_linear_model, sample_input_tensor, temp_onnx_file):
        """Test export with verbose mode enabled."""
        with mock.patch('torch.jit._get_trace_graph') as mock_get_trace_graph, \
             mock.patch('torch.onnx.utils._model_to_graph') as mock_model_to_graph, \
             mock.patch('torch.onnx.utils._export') as mock_export, \
             mock.patch('io.open', mock.mock_open()) as mock_file:
    
            # Setup mocks
            mock_graph = mock.MagicMock()
            mock_torch_out = torch.tensor([[1.0, 2.0], [3.0, 4.0]])
            mock_inputs_states = mock.MagicMock()
            mock_get_trace_graph.return_value = (mock_graph, mock_torch_out, mock_inputs_states)
    
            mock_params_dict = {}
            mock_model_to_graph.return_value = (mock_graph, mock_params_dict, mock_torch_out)
            mock_export.return_value = None
    
            # Capture warnings/prints if needed
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                onnx_utils.export(
                    model=simple_linear_model,
                    args=(sample_input_tensor,),
                    f=temp_onnx_file,
                    verbose=True,
                )
    
            # Verify verbose parameter was passed
            mock_export.assert_called_once()
            call_args = mock_export.call_args
>           assert call_args[1]['verbose'] is True, "verbose should be True"
E           KeyError: 'verbose'

tests/test_torch_onnx_utils.py:653: KeyError
================================ tests coverage ================================
______________ coverage: platform darwin, python 3.10.19-final-0 _______________

Name                             Stmts   Miss Branch BrPart  Cover   Missing
----------------------------------------------------------------------------
tests/test_torch_onnx_utils.py     322    101     34      5    67%   30, 41-43, 77->exit, 83-96, 108-135, 140-141, 146-147, 188->198, 242-269, 315->319, 342->345, 385-410, 416-420, 487-488, 588-590, 621, 697-699, 724, 740, 748-759, 764-772, 778-784
----------------------------------------------------------------------------
TOTAL                              322    101     34      5    67%
Coverage XML written to file coverage.xml
=========================== short test summary info ============================
FAILED tests/test_torch_onnx_utils.py::test_export_basic_model_to_file[nn.Module-tuple-file-13-True-True]
FAILED tests/test_torch_onnx_utils.py::test_export_basic_model_to_file[nn.Module-named_tuple-file-13-True-False]
FAILED tests/test_torch_onnx_utils.py::test_export_basic_model_to_file[nn.Module-tuple-file-7-True-True]
FAILED tests/test_torch_onnx_utils.py::test_export_basic_model_to_file[nn.Module-tuple-file-16-False-True]
FAILED tests/test_torch_onnx_utils.py::test_export_model_to_bytesio[nn.Module-tensor-bytesio-13-True-True]
FAILED tests/test_torch_onnx_utils.py::test_export_model_to_bytesio[ScriptFunction-tensor-bytesio-13-True-True]
FAILED tests/test_torch_onnx_utils.py::TestONNXUtilsExport::test_export_with_default_parameters
FAILED tests/test_torch_onnx_utils.py::TestONNXUtilsExport::test_export_with_custom_input_output_names
FAILED tests/test_torch_onnx_utils.py::TestONNXUtilsExport::test_export_with_verbose_mode
9 failed, 6 passed in 0.68s

Error: exit 1