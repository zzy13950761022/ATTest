=== Run Tests ===
.F...F.                                                                  [100%]
=================================== FAILURES ===================================
_____________ TestPruneBasic.test_l1_unstructured_validation[5-5] ______________

self = <test_torch_nn_utils_prune.TestPruneBasic object at 0x1274089a0>
conv2d_module = Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))
set_random_seed = 42, amount = 5, expected_pruned = 5

    @pytest.mark.parametrize("amount,expected_pruned", [
        (5, 5),  # 绝对数量5个参数
    ])
    def test_l1_unstructured_validation(self, conv2d_module, set_random_seed, amount, expected_pruned):
        """Test L1 unstructured pruning with absolute amount."""
        # Arrange
        module = conv2d_module
        param_name = "weight"
        original_weight = module.weight.clone()
    
        # We need to set weights with predictable absolute values
        # L1剪枝基于绝对值，所以我们需要确保绝对值有明确的顺序
        # 注意：我们使用循环值0.0-0.9，这会导致重复值
        # 当有重复值时，torch.topk选择哪些索引是不确定的
        with torch.no_grad():
            # Create weights with predictable absolute values
            # We'll use positive values only to avoid sign confusion
            flat_weights = original_weight.view(-1)
            for i in range(len(flat_weights)):
                # Use values from 0.0 to 0.9 in order (循环)
                # 这会产生重复值：0.0, 0.1, ..., 0.9, 0.0, 0.1, ...
                flat_weights[i] = (i % 10) * 0.1  # Values: 0.0, 0.1, 0.2, ..., 0.9, 0.0, 0.1, ...
    
        # Act
        pruned_module = prune.l1_unstructured(module, param_name, amount)
    
        # Assert - weak assertions
        # 1. mask_shape: 掩码形状正确
        mask_name = f"{param_name}_mask"
        assert hasattr(pruned_module, mask_name), f"Mask buffer {mask_name} should exist"
        mask = getattr(pruned_module, mask_name)
        assert mask.shape == original_weight.shape, f"Mask shape {mask.shape} should match weight shape {original_weight.shape}"
    
        # 2. mask_dtype: 掩码数据类型正确
        assert mask.dtype == torch.float32, f"Mask dtype should be float32, got {mask.dtype}"
    
        # 3. prune_count_correct: 剪枝数量正确
        pruned_count = torch.sum(mask == 0).item()
        assert pruned_count == expected_pruned, \
            f"Pruned count {pruned_count} should equal expected {expected_pruned}"
    
        # 4. module_modified: 模块被修改
        assert pruned_module is module, "Function should return the modified module"
    
        # 5. l1_order: 检查L1顺序 - 修改断言以适应实际实现
        # L1剪枝应该剪掉绝对值最小的参数
        # 在我们的设置中，绝对值就是值本身（因为都是正数）
        # 注意：由于我们的值有重复（0.0, 0.1, ..., 0.9, 0.0, ...），
        # 当有重复值时，torch.topk选择哪些索引是不确定的
        # 所以我们只检查被剪枝的数量正确，不检查具体索引
        mask_flat = mask.view(-1)
        zero_indices = torch.where(mask_flat == 0)[0]
        # 只检查剪枝数量，不检查具体索引
        # 这是弱断言，符合test_plan的要求
    
        # 6. Check original parameter is stored
        orig_name = f"{param_name}_orig"
        assert hasattr(pruned_module, orig_name), f"Original parameter {orig_name} should be stored"
        orig_param = getattr(pruned_module, orig_name)
>       assert torch.allclose(orig_param, original_weight), "Original parameter should be preserved"
E       AssertionError: Original parameter should be preserved
E       assert False
E        +  where False = <built-in method allclose of type object at 0x1121aa320>(Parameter containing:\ntensor([[[[-0.0272,  0.1484,  0.0284],\n          [-0.0898,  0.0491, -0.0887],\n          [-0.0226... 0.0233, -0.0582],\n          [ 0.1399, -0.0050,  0.1502],\n          [ 0.1850, -0.0938, -0.1404]]]], requires_grad=True), tensor([[[[0.0000, 0.1000, 0.2000],\n          [0.3000, 0.4000, 0.5000],\n          [0.6000, 0.7000, 0.8000]],\n\n        ..., 0.4000, 0.5000],\n          [0.6000, 0.7000, 0.8000],\n          [0.9000, 0.0000, 0.1000]]]], grad_fn=<CloneBackward0>))
E        +    where <built-in method allclose of type object at 0x1121aa320> = torch.allclose

tests/test_torch_nn_utils_prune.py:159: AssertionError
______________ TestPruneBasic.test_l2_structured_pruning[3-1-2-3] ______________

self = <test_torch_nn_utils_prune.TestPruneBasic object at 0x127409510>
amount = 3, dim = 1, n = 2, expected_pruned_channels = 3

    @pytest.mark.parametrize("amount,dim,n,expected_pruned_channels", [
        (3, 1, 2, 3),  # 在dim=1上剪枝3个通道，使用L2范数
    ])
    def test_l2_structured_pruning(self, amount, dim, n, expected_pruned_channels):
        """Test L2 structured pruning (ln_structured with n=2)."""
        # Arrange
        module = nn.Conv2d(4, 8, kernel_size=3)  # shape: [8, 4, 3, 3]
        param_name = "weight"
        original_weight = module.weight.clone()
    
        # Mock torch.norm to control norm calculation
        with patch('torch.norm') as mock_norm:
            # Create deterministic norm values for channel selection
            # We'll make the first 'expected_pruned_channels' channels have smallest norm
            if dim == 0:
                n_channels = original_weight.shape[0]  # 8 output channels
            else:
                n_channels = original_weight.shape[1]  # 4 input channels
    
            # Create mock norm values in increasing order
            # The first channels will have smallest norm and be pruned
            mock_norm_values = torch.linspace(0.1, 1.0, n_channels)
    
            def norm_side_effect(tensor, p, dim, keepdim):
                # Return pre-defined norm values based on channel index
                # This is a simplified mock that returns deterministic values
                channel_idx = dim[0] if isinstance(dim, tuple) else dim
                if channel_idx == dim:
                    # Return our mock values
                    result = torch.zeros(tensor.shape[dim])
                    for i in range(n_channels):
                        result[i] = mock_norm_values[i]
                    if keepdim:
                        # Add dimension back
                        result = result.unsqueeze(dim)
                    return result
                else:
                    # For other dims, compute actual norm
                    return torch.norm(tensor, p=p, dim=dim, keepdim=keepdim)
    
            mock_norm.side_effect = norm_side_effect
    
            # Act
>           pruned_module = prune.ln_structured(
                module, param_name, amount=amount, n=n, dim=dim
            )

tests/test_torch_nn_utils_prune.py:410: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/utils/prune.py:1010: in ln_structured
    LnStructured.apply(
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/utils/prune.py:786: in apply
    return super(LnStructured, cls).apply(
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/utils/prune.py:205: in apply
    raise e
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/utils/prune.py:191: in apply
    mask = method.compute_mask(importance_scores, default_mask=default_mask)
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/utils/prune.py:732: in compute_mask
    norm = _compute_norm(t, self.n, self.dim)
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/utils/prune.py:1363: in _compute_norm
    norm = torch.norm(t, p=n, dim=dims)
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/unittest/mock.py:1114: in __call__
    return self._mock_call(*args, **kwargs)
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/unittest/mock.py:1118: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock name='norm' id='4953514304'>
args = (Parameter containing:
tensor([[[[-0.1650, -0.0644, -0.1278],
          [ 0.1368,  0.0480,  0.0690],
          [ 0.052....1125,  0.0279],
          [-0.1268, -0.1337,  0.0829],
          [-0.1240, -0.0205,  0.0800]]]], requires_grad=True),)
kwargs = {'dim': [0, 2, 3], 'p': 2}
effect = <function TestPruneBasic.test_l2_structured_pruning.<locals>.norm_side_effect at 0x12747e710>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
                result = next(effect)
                if _is_exception(result):
                    raise result
            else:
>               result = effect(*args, **kwargs)
E               TypeError: TestPruneBasic.test_l2_structured_pruning.<locals>.norm_side_effect() missing 1 required positional argument: 'keepdim'

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/unittest/mock.py:1179: TypeError
================================ tests coverage ================================
______________ coverage: platform darwin, python 3.10.19-final-0 _______________

Name                                 Stmts   Miss Branch BrPart  Cover   Missing
--------------------------------------------------------------------------------
test_debug.py                            0      0      0      0   100%
tests/test_torch_nn_utils_prune.py     271     52     70     15    73%   92->96, 93->92, 162-174, 195, 219-221, 229, 252->256, 253->252, 300->304, 301->300, 350->354, 351->350, 382, 393-405, 416-481, 560->564, 561->560, 599
--------------------------------------------------------------------------------
TOTAL                                  271     52     70     15    73%
Coverage XML written to file coverage.xml
=========================== short test summary info ============================
FAILED tests/test_torch_nn_utils_prune.py::TestPruneBasic::test_l1_unstructured_validation[5-5]
FAILED tests/test_torch_nn_utils_prune.py::TestPruneBasic::test_l2_structured_pruning[3-1-2-3]
2 failed, 5 passed in 0.82s

Error: exit 1