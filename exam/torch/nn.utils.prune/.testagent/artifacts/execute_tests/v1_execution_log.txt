=== Run Tests ===
FF                                                                       [100%]
=================================== FAILURES ===================================
_____________ TestPruneBasic.test_random_unstructured_basic[0.3-4] _____________

self = <test_torch_nn_utils_prune.TestPruneBasic object at 0x11fb001c0>
linear_module = Linear(in_features=5, out_features=3, bias=True)
set_random_seed = 42, amount = 0.3, expected_pruned = 4

    @pytest.mark.parametrize("amount,expected_pruned", [
        (0.3, 4),  # 5*3=15个参数，30%约4.5个，向下取整为4
    ])
    def test_random_unstructured_basic(self, linear_module, set_random_seed, amount, expected_pruned):
        """Test basic random unstructured pruning with float amount."""
        # Arrange
        module = linear_module
        param_name = "weight"
        original_weight = module.weight.clone()
    
        # Mock torch.rand to control randomness
        with patch('torch.rand') as mock_rand:
            # Create deterministic random values for mask selection
            # We'll make the first 'expected_pruned' values be the smallest
            mock_values = torch.linspace(0.1, 0.9, original_weight.numel())
            mock_rand.return_value = mock_values
    
            # Act
            pruned_module = prune.random_unstructured(module, param_name, amount)
    
            # Assert - weak assertions
            # 1. mask_shape: 掩码形状正确
            mask_name = f"{param_name}_mask"
            assert hasattr(pruned_module, mask_name), f"Mask buffer {mask_name} should exist"
            mask = getattr(pruned_module, mask_name)
            assert mask.shape == original_weight.shape, f"Mask shape {mask.shape} should match weight shape {original_weight.shape}"
    
            # 2. mask_dtype: 掩码数据类型正确
            assert mask.dtype == torch.float32, f"Mask dtype should be float32, got {mask.dtype}"
    
            # 3. mask_values: 掩码值为0或1
            assert torch.all((mask == 0) | (mask == 1)), "Mask values should be either 0 or 1"
    
            # 4. module_modified: 模块被修改
            assert pruned_module is module, "Function should return the modified module"
    
            # 5. buffer_added: 缓冲区已添加
            assert mask_name in dict(pruned_module.named_buffers()), f"Buffer {mask_name} should be in module buffers"
    
            # 6. Check original parameter is stored
            orig_name = f"{param_name}_orig"
            assert hasattr(pruned_module, orig_name), f"Original parameter {orig_name} should be stored"
            orig_param = getattr(pruned_module, orig_name)
            assert torch.allclose(orig_param, original_weight), "Original parameter should be preserved"
    
            # 7. Check pruned count is approximately correct
            pruned_count = torch.sum(mask == 0).item()
            total_params = original_weight.numel()
            expected_min = math.floor(total_params * amount) if amount < 1.0 else amount
            # Allow small tolerance for float rounding
            assert abs(pruned_count - expected_pruned) <= 1, \
                f"Pruned count {pruned_count} should be close to expected {expected_pruned}"
    
            # 8. Check forward hook is registered
            hook_name = f"{param_name}_mask"
>           assert any(hook_name in key for key in pruned_module._forward_pre_hooks.keys()), \
                "Forward pre-hook should be registered for mask application"

tests/test_torch_nn_utils_prune.py:91: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <odict_iterator object at 0x11fb09580>

>   assert any(hook_name in key for key in pruned_module._forward_pre_hooks.keys()), \
        "Forward pre-hook should be registered for mask application"
E   TypeError: argument of type 'int' is not iterable

tests/test_torch_nn_utils_prune.py:91: TypeError
_____________ TestPruneBasic.test_l1_unstructured_validation[5-5] ______________

self = <test_torch_nn_utils_prune.TestPruneBasic object at 0x11fb004f0>
conv2d_module = Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))
set_random_seed = 42, amount = 5, expected_pruned = 5

    @pytest.mark.parametrize("amount,expected_pruned", [
        (5, 5),  # 绝对数量5个参数
    ])
    def test_l1_unstructured_validation(self, conv2d_module, set_random_seed, amount, expected_pruned):
        """Test L1 unstructured pruning with absolute amount."""
        # Arrange
        module = conv2d_module
        param_name = "weight"
        original_weight = module.weight.clone()
    
        # We don't need to mock torch.abs since it's deterministic
        # Just ensure the weights have deterministic absolute values
        with torch.no_grad():
            # Create weights with predictable absolute values
            # This ensures deterministic pruning
            flat_weights = original_weight.view(-1)
            for i in range(len(flat_weights)):
                flat_weights[i] = (i % 10) * 0.1  # Values from 0.0 to 0.9
    
        # Act
        pruned_module = prune.l1_unstructured(module, param_name, amount)
    
        # Assert - weak assertions
        # 1. mask_shape: 掩码形状正确
        mask_name = f"{param_name}_mask"
        assert hasattr(pruned_module, mask_name), f"Mask buffer {mask_name} should exist"
        mask = getattr(pruned_module, mask_name)
        assert mask.shape == original_weight.shape, f"Mask shape {mask.shape} should match weight shape {original_weight.shape}"
    
        # 2. mask_dtype: 掩码数据类型正确
        assert mask.dtype == torch.float32, f"Mask dtype should be float32, got {mask.dtype}"
    
        # 3. prune_count_correct: 剪枝数量正确
        pruned_count = torch.sum(mask == 0).item()
        assert pruned_count == expected_pruned, \
            f"Pruned count {pruned_count} should equal expected {expected_pruned}"
    
        # 4. module_modified: 模块被修改
        assert pruned_module is module, "Function should return the modified module"
    
        # 5. l1_order: 检查L1顺序
        # The smallest absolute values should be pruned
        # Since we set weights with values 0.0, 0.1, 0.2, ..., the smallest ones should be pruned
        mask_flat = mask.view(-1)
        # Check that at least some of the zero values correspond to small absolute values
        zero_indices = torch.where(mask_flat == 0)[0]
        if len(zero_indices) > 0:
            # The pruned indices should be among the smallest values
            # In our setup, values are (i % 10) * 0.1, so indices 0, 1, 2, 3, 4 should be pruned
            expected_pruned_indices = torch.arange(expected_pruned)
>           assert torch.all(zero_indices[:expected_pruned] == expected_pruned_indices), \
                "Smallest absolute values should be pruned first"
E           AssertionError: Smallest absolute values should be pruned first
E           assert tensor(False)
E            +  where tensor(False) = <built-in method all of type object at 0x108baa320>(tensor([105, ...21, 252, 369]) == tensor([0, 1, 2, 3, 4])
E            +    where <built-in method all of type object at 0x108baa320> = torch.all
E               
E               Use -v to get more diff)

tests/test_torch_nn_utils_prune.py:146: AssertionError
================================ tests coverage ================================
______________ coverage: platform darwin, python 3.10.19-final-0 _______________

Name                                 Stmts   Miss Branch BrPart  Cover   Missing
--------------------------------------------------------------------------------
tests/test_torch_nn_utils_prune.py      77      9      6      2    87%   150-163, 226
--------------------------------------------------------------------------------
TOTAL                                   77      9      6      2    87%
Coverage XML written to file coverage.xml
=========================== short test summary info ============================
FAILED tests/test_torch_nn_utils_prune.py::TestPruneBasic::test_random_unstructured_basic[0.3-4]
FAILED tests/test_torch_nn_utils_prune.py::TestPruneBasic::test_l1_unstructured_validation[5-5]
2 failed in 0.57s

Error: exit 1