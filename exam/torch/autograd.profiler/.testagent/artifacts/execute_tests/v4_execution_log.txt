=== Run Tests ===
ssssssFFF                                                                [100%]
=================================== FAILURES ===================================
__________________________ test_record_function_basic __________________________

fixed_seed = 42
simple_tensor_ops = (tensor([[ 0.3367,  0.1288,  0.2345],
        [ 0.2303, -1.1229, -0.1863]], requires_grad=True), tensor([[ 2.2082, -0....674],
        [ 0.5349,  0.8094,  1.1103, -1.6898],
        [-0.9890,  0.9580,  1.3221,  0.8172]], requires_grad=True))

    def test_record_function_basic(fixed_seed, simple_tensor_ops):
        """G3-01: record_function 基本功能测试
    
        测试 record_function 上下文管理器在性能分析中的标签功能。
        """
        x, y = simple_tensor_ops
    
        # 使用性能分析器
        with torch.autograd.profiler.profile(
            enabled=True,
            use_cuda=False,
            record_shapes=False,
            with_flops=False,
            profile_memory=False,
            with_stack=False,
            with_modules=False,
            use_kineto=False,
            use_cpu=True,
            experimental_config=None
        ) as prof:
            # 执行一些张量操作
            z = torch.matmul(x, y)
    
            # 使用 record_function 添加标签
            with torch.autograd.profiler.record_function("custom_label"):
                w = torch.randn(4, 2, requires_grad=True)
                v = torch.matmul(z, w)
    
            loss = v.sum()
            loss.backward()
    
        # 基本断言
        assert prof is not None, "Profiler should be created"
    
        # 检查事件列表
>       events = prof.events()
E       AttributeError: 'profile' object has no attribute 'events'

tests/test_torch_autograd_profiler_edge.py:115: AttributeError
----------------------------- Captured stderr call -----------------------------
STAGE:2026-01-17 16:44:10 58961:35502817 ActivityProfilerController.cpp:294] Completed Stage: Warm Up
STAGE:2026-01-17 16:44:10 58961:35502817 ActivityProfilerController.cpp:300] Completed Stage: Collection
____________________ test_record_function_disabled_profiler ____________________

fixed_seed = 42
simple_tensor_ops = (tensor([[ 0.3367,  0.1288,  0.2345],
        [ 0.2303, -1.1229, -0.1863]], requires_grad=True), tensor([[ 2.2082, -0....674],
        [ 0.5349,  0.8094,  1.1103, -1.6898],
        [-0.9890,  0.9580,  1.3221,  0.8172]], requires_grad=True))

    def test_record_function_disabled_profiler(fixed_seed, simple_tensor_ops):
        """G3-02: 禁用分析器时的 record_function
    
        测试当性能分析器禁用时，record_function 是否正常工作（应无异常）。
        """
        x, y = simple_tensor_ops
    
        # 使用禁用的性能分析器
        with torch.autograd.profiler.profile(
            enabled=False,  # 禁用分析器
            use_cuda=False,
            record_shapes=False,
            with_flops=False,
            profile_memory=False,
            with_stack=False,
            with_modules=False,
            use_kineto=False,
            use_cpu=True,
            experimental_config=None
        ) as prof:
            # 执行一些张量操作
            z = torch.matmul(x, y)
    
            # 即使分析器禁用，record_function 也应该正常工作
            with torch.autograd.profiler.record_function("disabled_profiler_label"):
                w = torch.randn(4, 2, requires_grad=True)
                v = torch.matmul(z, w)
    
            loss = v.sum()
            loss.backward()
    
        # 基本断言 - 即使分析器禁用，也不应抛出异常
>       assert prof is not None, "Profiler should be created even when disabled"
E       AssertionError: Profiler should be created even when disabled
E       assert None is not None

tests/test_torch_autograd_profiler_edge.py:169: AssertionError
_____________________________ test_emit_nvtx_basic _____________________________

mock_cuda_unavailable = None, fixed_seed = 42
simple_tensor_ops = (tensor([[ 0.3367,  0.1288,  0.2345],
        [ 0.2303, -1.1229, -0.1863]], requires_grad=True), tensor([[ 2.2082, -0....674],
        [ 0.5349,  0.8094,  1.1103, -1.6898],
        [-0.9890,  0.9580,  1.3221,  0.8172]], requires_grad=True))

    def test_emit_nvtx_basic(mock_cuda_unavailable, fixed_seed, simple_tensor_ops):
        """G3-03: emit_nvtx 基本功能测试
    
        测试 emit_nvtx 上下文管理器的基本功能。
        注意：由于测试环境通常没有CUDA，我们主要测试它不会崩溃。
        """
        x, y = simple_tensor_ops
    
        # 使用 emit_nvtx（通常用于CUDA分析，但在CPU上也不应崩溃）
>       with torch.autograd.profiler.emit_nvtx(enabled=True, record_shapes=False):

tests/test_torch_autograd_profiler_edge.py:188: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/autograd/profiler.py:684: in __enter__
    torch.cuda.synchronize()
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/cuda/__init__.py:564: in synchronize
    _lazy_init()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _lazy_init():
        global _initialized, _queued_calls
        if is_initialized() or hasattr(_tls, 'is_initializing'):
            return
        with _initialization_lock:
            # We be double-checked locking, boys!  This is OK because
            # the above test was GIL protected anyway.  The inner test
            # is for when a thread blocked on some other thread which was
            # doing the initialization; when they get the lock, they will
            # find there is nothing left to do.
            if is_initialized():
                return
            # It is important to prevent other threads from entering _lazy_init
            # immediately, while we are still guaranteed to have the GIL, because some
            # of the C calls we make below will release the GIL
            if _is_in_bad_fork():
                raise RuntimeError(
                    "Cannot re-initialize CUDA in forked subprocess. To use CUDA with "
                    "multiprocessing, you must use the 'spawn' start method")
            if not hasattr(torch._C, '_cuda_getDeviceCount'):
>               raise AssertionError("Torch not compiled with CUDA enabled")
E               AssertionError: Torch not compiled with CUDA enabled

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/cuda/__init__.py:221: AssertionError
================================ tests coverage ================================
______________ coverage: platform darwin, python 3.10.19-final-0 _______________

Name                                             Stmts   Miss Branch BrPart  Cover   Missing
--------------------------------------------------------------------------------------------
tests/test_torch_autograd_profiler_advanced.py      59     14      4      1    73%   51-52, 57-59, 64-66, 71-76, 105
tests/test_torch_autograd_profiler_basic.py         59     14      4      1    73%   51-52, 57-59, 64-66, 71-76, 106
tests/test_torch_autograd_profiler_edge.py         101     30      6      1    67%   71-76, 116-133, 172-175, 190-211, 217
--------------------------------------------------------------------------------------------
TOTAL                                              219     58     14      3    70%
Coverage XML written to file coverage.xml
=========================== short test summary info ============================
FAILED tests/test_torch_autograd_profiler_edge.py::test_record_function_basic
FAILED tests/test_torch_autograd_profiler_edge.py::test_record_function_disabled_profiler
FAILED tests/test_torch_autograd_profiler_edge.py::test_emit_nvtx_basic - Ass...
3 failed, 6 skipped in 0.61s

Error: exit 1