=== Run Tests ===
.......F.ss........F.....FF.FFFFFFF                                      [100%]
=================================== FAILURES ===================================
___________________ test_groupnorm_device_dtype[dtype0-cpu] ____________________

dtype = torch.float32, device = 'cpu', set_random_seed = 42

    @pytest.mark.parametrize("dtype,device", [
        # Test different data types on CPU
        (torch.float32, "cpu"),
        (torch.float64, "cpu"),
        # Test CUDA if available
        pytest.param(torch.float32, "cuda", marks=pytest.mark.skipif(not torch.cuda.is_available(), reason="CUDA not available")),
        pytest.param(torch.float64, "cuda", marks=pytest.mark.skipif(not torch.cuda.is_available(), reason="CUDA not available")),
    ])
    def test_groupnorm_device_dtype(dtype, device, set_random_seed):
        """Test GroupNorm with different devices and data types"""
        # Common parameters
        num_groups = 2
        num_channels = 8
        eps = 1e-5
        affine = True
        shape = (2, 8, 16, 16)
    
        # Create input tensor
        torch.manual_seed(42)
        input_tensor = torch.randn(*shape, dtype=dtype, device=device)
    
        # Create GroupNorm layer
        gn = GroupNorm(
            num_groups=num_groups,
            num_channels=num_channels,
            eps=eps,
            affine=affine
        ).to(device=device, dtype=dtype)
    
        # Forward pass
        output = gn(input_tensor)
    
        # Weak assertions
        # 1. Shape assertion
        assert output.shape == input_tensor.shape, \
            f"Output shape {output.shape} != input shape {input_tensor.shape}"
    
        # 2. Dtype assertion
        assert output.dtype == dtype, \
            f"Output dtype {output.dtype} != expected {dtype}"
    
        # 3. Device assertion
        assert output.device.type == device, \
            f"Output device {output.device.type} != expected {device}"
    
        # 4. Finite values assertion
        assert torch.all(torch.isfinite(output)), \
            "Output contains NaN or infinite values"
    
        # 5. Basic normalization property
        batch_size = shape[0]
        channels_per_group = num_channels // num_groups
        spatial_dims = shape[2:]
    
        # Reshape for group-wise statistics
        output_reshaped = output.view(batch_size, num_groups, channels_per_group, *spatial_dims)
    
        # Check that each group is normalized
        for b in range(batch_size):
            for g in range(num_groups):
                group_output = output_reshaped[b, g].flatten()
    
                # Mean should be close to 0
                mean_abs = torch.abs(torch.mean(group_output))
                assert mean_abs < 0.2, f"Group mean too large: {mean_abs}"
    
                # Std should be close to 1
                std = torch.std(group_output)
                assert 0.8 < std < 1.2, f"Group std out of range: {std}"
    
        # 6. Test parameter device/dtype consistency
        if affine:
            # Weight and bias should be on correct device and dtype
            assert gn.weight.device.type == device, \
                f"Weight device {gn.weight.device.type} != expected {device}"
            assert gn.weight.dtype == dtype, \
                f"Weight dtype {gn.weight.dtype} != expected {dtype}"
    
            assert gn.bias.device.type == device, \
                f"Bias device {gn.bias.device.type} != expected {device}"
            assert gn.bias.dtype == dtype, \
                f"Bias dtype {gn.bias.dtype} != expected {dtype}"
    
        # 7. Test with mixed precision - FIXED: PyTorch doesn't support automatic dtype conversion
        # between input and layer parameters. We'll skip this test or handle it differently.
        # Instead, we'll test that creating a layer with one dtype and using input with another
        # dtype either works (with casting) or fails gracefully.
    
        # Create a new layer for mixed precision test
        gn_mixed = GroupNorm(
            num_groups=num_groups,
            num_channels=num_channels,
            eps=eps,
            affine=affine
        ).to(device=device, dtype=dtype)
    
        # Create input with different dtype
        if dtype == torch.float32:
            mixed_dtype = torch.float64
        else:
            mixed_dtype = torch.float32
    
        mixed_input = torch.randn(*shape, dtype=mixed_dtype, device=device)
    
        # Try the mixed precision forward pass
        # PyTorch may or may not support this automatically
        try:
            mixed_output = gn_mixed(mixed_input)
            # If it works, check basic properties
            assert mixed_output.shape == shape
            assert mixed_output.device.type == device
    
            # Output dtype should match layer dtype, not input dtype
            # This is PyTorch's behavior: it casts to layer's dtype
            assert mixed_output.dtype == dtype, \
                f"Mixed precision output dtype {mixed_output.dtype} != layer dtype {dtype}"
    
            print(f"Mixed precision test passed: input {mixed_dtype}, layer {dtype}, output {mixed_output.dtype}")
    
        except RuntimeError as e:
            # If PyTorch doesn't support mixed precision, that's OK
            # Check if it's the expected "expected scalar type" error
            error_msg = str(e).lower()
            if 'expected scalar type' in error_msg or 'dtype' in error_msg:
                print(f"Mixed precision not supported (expected): {e}")
                # This is acceptable - PyTorch requires matching dtypes
            else:
                # Some other error - re-raise
                raise
    
        # 8. Test device transfer
        if device == "cpu":
            # Test moving to CPU (already there)
            gn_cpu = gn.cpu()
            assert gn_cpu.weight.device.type == "cpu"
    
            # Test with CPU input
            cpu_input = torch.randn(*shape, dtype=dtype, device="cpu")
            cpu_output = gn_cpu(cpu_input)
            assert cpu_output.device.type == "cpu"
    
        # 9. Test dtype conversion
        if dtype == torch.float32:
            # Convert to float64
            gn_fp64 = gn.double()
            assert gn_fp64.weight.dtype == torch.float64
    
            fp64_input = torch.randn(*shape, dtype=torch.float64, device=device)
            fp64_output = gn_fp64(fp64_input)
            assert fp64_output.dtype == torch.float64
    
        # 10. Test with requires_grad
        input_tensor.requires_grad_(True)
>       output = gn(input_tensor)

tests/test_torch_nn_modules_normalization_g1.py:506: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/modules/module.py:1190: in _call_impl
    return forward_call(*input, **kwargs)
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/modules/normalization.py:273: in forward
    return F.group_norm(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[ 1.9269e+00,  1.4873e+00,  9.0072e-01,  ..., -5.5943e-01,
           -7.6884e-01,  7.6245e-01],
          [...[ 5.6279e-01, -2.5226e-01,  1.4472e+00,  ..., -1.4031e-01,
            9.4162e-01, -1.1843e-02]]]], requires_grad=True)
num_groups = 2
weight = Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64,
       requires_grad=True)
bias = Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64,
       requires_grad=True)
eps = 1e-05

    def group_norm(
        input: Tensor, num_groups: int, weight: Optional[Tensor] = None, bias: Optional[Tensor] = None, eps: float = 1e-5
    ) -> Tensor:
        r"""Applies Group Normalization for last certain number of dimensions.
    
        See :class:`~torch.nn.GroupNorm` for details.
        """
        if has_torch_function_variadic(input, weight, bias):
            return handle_torch_function(group_norm, (input, weight, bias,), input, num_groups, weight=weight, bias=bias, eps=eps)
        _verify_batch_size([input.size(0) * input.size(1) // num_groups, num_groups] + list(input.size()[2:]))
>       return torch.group_norm(input, num_groups, weight, bias, eps, torch.backends.cudnn.enabled)
E       RuntimeError: expected scalar type Float but found Double

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/functional.py:2528: RuntimeError
----------------------------- Captured stdout call -----------------------------
Mixed precision not supported (expected): expected scalar type Double but found Float
_______________________ test_layernorm_exception_shapes ________________________

    def test_layernorm_exception_shapes():
        """Test LayerNorm with invalid shapes and parameters"""
        # Test 1: normalized_shape doesn't match input shape
        normalized_shape = [8, 8]
        eps = 1e-5
        elementwise_affine = True
    
        # Create LayerNorm layer
        ln = LayerNorm(
            normalized_shape=normalized_shape,
            eps=eps,
            elementwise_affine=elementwise_affine
        )
    
        # Test with input that has wrong last dimensions
        # LayerNorm expects last 2 dimensions to be 8x8, but we give 4x4
        wrong_shape_input = torch.randn(2, 4, 4, 4)
    
        # This should raise a RuntimeError during forward pass
        # LayerNorm checks that input shape ends with normalized_shape
        with pytest.raises(RuntimeError) as exc_info:
            ln(wrong_shape_input)
    
        error_msg = str(exc_info.value).lower()
        assert any(keyword in error_msg for keyword in
                  ['shape', 'size', 'dimension', 'normalized', 'expected']), \
            f"Error message doesn't mention shape mismatch: {error_msg}"
    
        # Test 2: Input with too few dimensions
        # If normalized_shape has 2 elements, input needs at least 3 dimensions
        input_2d = torch.randn(8, 8)  # Only 2 dimensions
    
>       with pytest.raises(RuntimeError) as exc_info:
E       Failed: DID NOT RAISE <class 'RuntimeError'>

tests/test_torch_nn_modules_normalization_g2.py:370: Failed
_ test_localresponsenorm_boundary_values[3-0.0001-0.75-1.0-dtype1-cpu-shape1-small_size] _

size = 3, alpha = 0.0001, beta = 0.75, k = 1.0, dtype = torch.float32
device = 'cpu', shape = (2, 8, 8, 8), test_type = 'small_size'
set_random_seed = 42

    @pytest.mark.parametrize("size,alpha,beta,k,dtype,device,shape,test_type", [
        # Test boundary values for size
        (1, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 8, 8, 8), "min_size"),
        (3, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 8, 8, 8), "small_size"),
        (15, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_size"),
        # Test boundary values for alpha - avoid alpha=0 which can cause issues
        (5, 1e-10, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "tiny_alpha"),
        (5, 1.0, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_alpha"),
        # Test boundary values for beta - avoid beta=0 which can cause issues
        (5, 1e-4, 0.5, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "small_beta"),
        (5, 1e-4, 2.0, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_beta"),
        # Test boundary values for k - avoid k=0 which can cause division by zero
        (5, 1e-4, 0.75, 0.1, torch.float32, "cpu", (2, 16, 8, 8), "small_k"),
        (5, 1e-4, 0.75, 10.0, torch.float32, "cpu", (2, 16, 8, 8), "large_k"),
        # Test with different data types
        (5, 1e-4, 0.75, 1.0, torch.float64, "cpu", (2, 16, 8, 8), "float64"),
        # Test with small batch size
        (5, 1e-4, 0.75, 1.0, torch.float32, "cpu", (1, 16, 8, 8), "batch_size_1"),
    ])
    def test_localresponsenorm_boundary_values(size, alpha, beta, k, dtype, device, shape, test_type, set_random_seed):
        """Test LocalResponseNorm with boundary values for parameters"""
        # Skip CUDA tests if device not available
        if device == "cuda" and not torch.cuda.is_available():
            pytest.skip("CUDA not available")
    
        # Validate parameters based on test type
        if test_type == "min_size":
            assert size == 1, "Test requires size=1"
        elif test_type == "large_size":
            # Size should be odd and <= number of channels
            assert size % 2 == 1, "Size should be odd"
            assert size <= shape[1], f"Size {size} should not exceed channels {shape[1]}"
    
        # Create input tensor
        torch.manual_seed(42)
        input_tensor = torch.randn(*shape, dtype=dtype, device=device)
    
        # Create LocalResponseNorm layer
        lrn = LocalResponseNorm(
            size=size,
            alpha=alpha,
            beta=beta,
            k=k
        ).to(device=device)
    
        # Forward pass
        output = lrn(input_tensor)
    
        # Basic assertions for all boundary tests
        # 1. Shape assertion
        assert output.shape == input_tensor.shape, \
            f"Output shape {output.shape} != input shape {input_tensor.shape}"
    
        # 2. Dtype assertion
        assert output.dtype == input_tensor.dtype, \
            f"Output dtype {output.dtype} != input dtype {input_tensor.dtype}"
    
        # 3. Finite values assertion
        assert torch.all(torch.isfinite(output)), \
            f"Output contains NaN or infinite values for test_type={test_type}"
    
        # 4. Sign preservation (allow small numerical errors)
        # Check that signs are preserved for most elements
        sign_match = ((input_tensor >= 0) == (output >= 0))
        sign_match_ratio = torch.sum(sign_match).item() / sign_match.numel()
        assert sign_match_ratio > 0.99, \
            f"Sign preservation failed for test_type={test_type}: ratio={sign_match_ratio}"
    
        # Test-specific assertions
        if test_type == "tiny_alpha":
            # With very small alpha, normalization effect is minimal
            # Output should be close to input / (k^beta)
            expected = input_tensor / (k**beta)
            diff = torch.norm(output - expected) / torch.norm(expected)
            assert diff < 0.1, f"Tiny alpha test failed: diff={diff}"
    
        elif test_type == "large_alpha":
            # With large alpha, normalization effect is stronger
            # Output magnitude should be reduced
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
            reduction_ratio = output_norm / input_norm
    
            # With alpha=1.0, reduction should be noticeable
            assert reduction_ratio < 1.0, \
                f"Large alpha should reduce norm: reduction_ratio={reduction_ratio}"
    
        elif test_type == "small_beta":
            # With small beta (0.5), normalization is less aggressive
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
    
            # Compare with beta=0.75 case
            lrn_normal = LocalResponseNorm(size=size, alpha=alpha, beta=0.75, k=k).to(device=device)
            normal_output = lrn_normal(input_tensor)
            normal_norm = torch.norm(normal_output)
    
            # Smaller beta should produce larger output (less reduction)
            assert output_norm > normal_norm * 0.9, \
                f"Small beta should reduce output less: beta={beta} vs 0.75"
    
        elif test_type == "large_beta":
            # With large beta (2.0), normalization is more aggressive
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
    
            # Compare with beta=0.75 case
            lrn_normal = LocalResponseNorm(size=size, alpha=alpha, beta=0.75, k=k).to(device=device)
            normal_output = lrn_normal(input_tensor)
            normal_norm = torch.norm(normal_output)
    
            # Larger beta should produce smaller output
            assert output_norm < normal_norm * 1.1, \
                f"Large beta should reduce output more: beta={beta} vs 0.75"
    
        elif test_type == "min_size":
            # With size=1, only self-channel is considered
            # Output should be approximately input / (k^beta + alpha * input^2)^beta
            # For size=1, the sum over neighbors is just self
            squared = input_tensor ** 2
            denominator = k + alpha * squared
            expected = input_tensor / (denominator ** beta)
            diff = torch.norm(output - expected) / torch.norm(expected)
            assert diff < 0.2, f"Size=1 test failed: diff={diff}"
    
        elif test_type == "small_k":
            # With small k, normalization denominator is small
            # Output magnitude could be large
            assert torch.all(torch.isfinite(output)), "Small k test produced non-finite values"
    
        # Test with all positive input
        positive_input = torch.abs(input_tensor) + 0.1
        positive_output = lrn(positive_input)
        # Check that output is mostly positive (allow small numerical errors)
        positive_ratio = torch.sum(positive_output >= -1e-7).item() / positive_output.numel()
        assert positive_ratio > 0.99, \
            f"Positive input should produce non-negative output for test_type={test_type}: ratio={positive_ratio}"
    
        # Test with all negative input
        negative_input = -torch.abs(input_tensor) - 0.1
        negative_output = lrn(negative_input)
        # Check that output is mostly negative (allow small numerical errors)
        negative_ratio = torch.sum(negative_output <= 1e-7).item() / negative_output.numel()
        assert negative_ratio > 0.99, \
            f"Negative input should produce non-positive output for test_type={test_type}: ratio={negative_ratio}"
    
        # Test with constant input
        constant_value = 5.0
        constant_input = torch.full(shape, constant_value, dtype=dtype, device=device)
        constant_output = lrn(constant_input)
    
        # For constant input, output should be scaled version of input
        # All values should be approximately equal
        output_std = torch.std(constant_output)
>       assert output_std < 1e-5, \
            f"Constant input should produce constant output for test_type={test_type}: std={output_std}"
E       AssertionError: Constant input should produce constant output for test_type=small_size: std=0.0013487441465258598
E       assert tensor(0.0013) < 1e-05

tests/test_torch_nn_modules_normalization_g3.py:440: AssertionError
_ test_localresponsenorm_boundary_values[15-0.0001-0.75-1.0-dtype2-cpu-shape2-large_size] _

size = 15, alpha = 0.0001, beta = 0.75, k = 1.0, dtype = torch.float32
device = 'cpu', shape = (2, 16, 8, 8), test_type = 'large_size'
set_random_seed = 42

    @pytest.mark.parametrize("size,alpha,beta,k,dtype,device,shape,test_type", [
        # Test boundary values for size
        (1, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 8, 8, 8), "min_size"),
        (3, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 8, 8, 8), "small_size"),
        (15, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_size"),
        # Test boundary values for alpha - avoid alpha=0 which can cause issues
        (5, 1e-10, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "tiny_alpha"),
        (5, 1.0, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_alpha"),
        # Test boundary values for beta - avoid beta=0 which can cause issues
        (5, 1e-4, 0.5, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "small_beta"),
        (5, 1e-4, 2.0, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_beta"),
        # Test boundary values for k - avoid k=0 which can cause division by zero
        (5, 1e-4, 0.75, 0.1, torch.float32, "cpu", (2, 16, 8, 8), "small_k"),
        (5, 1e-4, 0.75, 10.0, torch.float32, "cpu", (2, 16, 8, 8), "large_k"),
        # Test with different data types
        (5, 1e-4, 0.75, 1.0, torch.float64, "cpu", (2, 16, 8, 8), "float64"),
        # Test with small batch size
        (5, 1e-4, 0.75, 1.0, torch.float32, "cpu", (1, 16, 8, 8), "batch_size_1"),
    ])
    def test_localresponsenorm_boundary_values(size, alpha, beta, k, dtype, device, shape, test_type, set_random_seed):
        """Test LocalResponseNorm with boundary values for parameters"""
        # Skip CUDA tests if device not available
        if device == "cuda" and not torch.cuda.is_available():
            pytest.skip("CUDA not available")
    
        # Validate parameters based on test type
        if test_type == "min_size":
            assert size == 1, "Test requires size=1"
        elif test_type == "large_size":
            # Size should be odd and <= number of channels
            assert size % 2 == 1, "Size should be odd"
            assert size <= shape[1], f"Size {size} should not exceed channels {shape[1]}"
    
        # Create input tensor
        torch.manual_seed(42)
        input_tensor = torch.randn(*shape, dtype=dtype, device=device)
    
        # Create LocalResponseNorm layer
        lrn = LocalResponseNorm(
            size=size,
            alpha=alpha,
            beta=beta,
            k=k
        ).to(device=device)
    
        # Forward pass
        output = lrn(input_tensor)
    
        # Basic assertions for all boundary tests
        # 1. Shape assertion
        assert output.shape == input_tensor.shape, \
            f"Output shape {output.shape} != input shape {input_tensor.shape}"
    
        # 2. Dtype assertion
        assert output.dtype == input_tensor.dtype, \
            f"Output dtype {output.dtype} != input dtype {input_tensor.dtype}"
    
        # 3. Finite values assertion
        assert torch.all(torch.isfinite(output)), \
            f"Output contains NaN or infinite values for test_type={test_type}"
    
        # 4. Sign preservation (allow small numerical errors)
        # Check that signs are preserved for most elements
        sign_match = ((input_tensor >= 0) == (output >= 0))
        sign_match_ratio = torch.sum(sign_match).item() / sign_match.numel()
        assert sign_match_ratio > 0.99, \
            f"Sign preservation failed for test_type={test_type}: ratio={sign_match_ratio}"
    
        # Test-specific assertions
        if test_type == "tiny_alpha":
            # With very small alpha, normalization effect is minimal
            # Output should be close to input / (k^beta)
            expected = input_tensor / (k**beta)
            diff = torch.norm(output - expected) / torch.norm(expected)
            assert diff < 0.1, f"Tiny alpha test failed: diff={diff}"
    
        elif test_type == "large_alpha":
            # With large alpha, normalization effect is stronger
            # Output magnitude should be reduced
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
            reduction_ratio = output_norm / input_norm
    
            # With alpha=1.0, reduction should be noticeable
            assert reduction_ratio < 1.0, \
                f"Large alpha should reduce norm: reduction_ratio={reduction_ratio}"
    
        elif test_type == "small_beta":
            # With small beta (0.5), normalization is less aggressive
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
    
            # Compare with beta=0.75 case
            lrn_normal = LocalResponseNorm(size=size, alpha=alpha, beta=0.75, k=k).to(device=device)
            normal_output = lrn_normal(input_tensor)
            normal_norm = torch.norm(normal_output)
    
            # Smaller beta should produce larger output (less reduction)
            assert output_norm > normal_norm * 0.9, \
                f"Small beta should reduce output less: beta={beta} vs 0.75"
    
        elif test_type == "large_beta":
            # With large beta (2.0), normalization is more aggressive
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
    
            # Compare with beta=0.75 case
            lrn_normal = LocalResponseNorm(size=size, alpha=alpha, beta=0.75, k=k).to(device=device)
            normal_output = lrn_normal(input_tensor)
            normal_norm = torch.norm(normal_output)
    
            # Larger beta should produce smaller output
            assert output_norm < normal_norm * 1.1, \
                f"Large beta should reduce output more: beta={beta} vs 0.75"
    
        elif test_type == "min_size":
            # With size=1, only self-channel is considered
            # Output should be approximately input / (k^beta + alpha * input^2)^beta
            # For size=1, the sum over neighbors is just self
            squared = input_tensor ** 2
            denominator = k + alpha * squared
            expected = input_tensor / (denominator ** beta)
            diff = torch.norm(output - expected) / torch.norm(expected)
            assert diff < 0.2, f"Size=1 test failed: diff={diff}"
    
        elif test_type == "small_k":
            # With small k, normalization denominator is small
            # Output magnitude could be large
            assert torch.all(torch.isfinite(output)), "Small k test produced non-finite values"
    
        # Test with all positive input
        positive_input = torch.abs(input_tensor) + 0.1
        positive_output = lrn(positive_input)
        # Check that output is mostly positive (allow small numerical errors)
        positive_ratio = torch.sum(positive_output >= -1e-7).item() / positive_output.numel()
        assert positive_ratio > 0.99, \
            f"Positive input should produce non-negative output for test_type={test_type}: ratio={positive_ratio}"
    
        # Test with all negative input
        negative_input = -torch.abs(input_tensor) - 0.1
        negative_output = lrn(negative_input)
        # Check that output is mostly negative (allow small numerical errors)
        negative_ratio = torch.sum(negative_output <= 1e-7).item() / negative_output.numel()
        assert negative_ratio > 0.99, \
            f"Negative input should produce non-positive output for test_type={test_type}: ratio={negative_ratio}"
    
        # Test with constant input
        constant_value = 5.0
        constant_input = torch.full(shape, constant_value, dtype=dtype, device=device)
        constant_output = lrn(constant_input)
    
        # For constant input, output should be scaled version of input
        # All values should be approximately equal
        output_std = torch.std(constant_output)
>       assert output_std < 1e-5, \
            f"Constant input should produce constant output for test_type={test_type}: std={output_std}"
E       AssertionError: Constant input should produce constant output for test_type=large_size: std=0.0014275847934186459
E       assert tensor(0.0014) < 1e-05

tests/test_torch_nn_modules_normalization_g3.py:440: AssertionError
_ test_localresponsenorm_boundary_values[5-1.0-0.75-1.0-dtype4-cpu-shape4-large_alpha] _

size = 5, alpha = 1.0, beta = 0.75, k = 1.0, dtype = torch.float32
device = 'cpu', shape = (2, 16, 8, 8), test_type = 'large_alpha'
set_random_seed = 42

    @pytest.mark.parametrize("size,alpha,beta,k,dtype,device,shape,test_type", [
        # Test boundary values for size
        (1, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 8, 8, 8), "min_size"),
        (3, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 8, 8, 8), "small_size"),
        (15, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_size"),
        # Test boundary values for alpha - avoid alpha=0 which can cause issues
        (5, 1e-10, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "tiny_alpha"),
        (5, 1.0, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_alpha"),
        # Test boundary values for beta - avoid beta=0 which can cause issues
        (5, 1e-4, 0.5, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "small_beta"),
        (5, 1e-4, 2.0, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_beta"),
        # Test boundary values for k - avoid k=0 which can cause division by zero
        (5, 1e-4, 0.75, 0.1, torch.float32, "cpu", (2, 16, 8, 8), "small_k"),
        (5, 1e-4, 0.75, 10.0, torch.float32, "cpu", (2, 16, 8, 8), "large_k"),
        # Test with different data types
        (5, 1e-4, 0.75, 1.0, torch.float64, "cpu", (2, 16, 8, 8), "float64"),
        # Test with small batch size
        (5, 1e-4, 0.75, 1.0, torch.float32, "cpu", (1, 16, 8, 8), "batch_size_1"),
    ])
    def test_localresponsenorm_boundary_values(size, alpha, beta, k, dtype, device, shape, test_type, set_random_seed):
        """Test LocalResponseNorm with boundary values for parameters"""
        # Skip CUDA tests if device not available
        if device == "cuda" and not torch.cuda.is_available():
            pytest.skip("CUDA not available")
    
        # Validate parameters based on test type
        if test_type == "min_size":
            assert size == 1, "Test requires size=1"
        elif test_type == "large_size":
            # Size should be odd and <= number of channels
            assert size % 2 == 1, "Size should be odd"
            assert size <= shape[1], f"Size {size} should not exceed channels {shape[1]}"
    
        # Create input tensor
        torch.manual_seed(42)
        input_tensor = torch.randn(*shape, dtype=dtype, device=device)
    
        # Create LocalResponseNorm layer
        lrn = LocalResponseNorm(
            size=size,
            alpha=alpha,
            beta=beta,
            k=k
        ).to(device=device)
    
        # Forward pass
        output = lrn(input_tensor)
    
        # Basic assertions for all boundary tests
        # 1. Shape assertion
        assert output.shape == input_tensor.shape, \
            f"Output shape {output.shape} != input shape {input_tensor.shape}"
    
        # 2. Dtype assertion
        assert output.dtype == input_tensor.dtype, \
            f"Output dtype {output.dtype} != input dtype {input_tensor.dtype}"
    
        # 3. Finite values assertion
        assert torch.all(torch.isfinite(output)), \
            f"Output contains NaN or infinite values for test_type={test_type}"
    
        # 4. Sign preservation (allow small numerical errors)
        # Check that signs are preserved for most elements
        sign_match = ((input_tensor >= 0) == (output >= 0))
        sign_match_ratio = torch.sum(sign_match).item() / sign_match.numel()
        assert sign_match_ratio > 0.99, \
            f"Sign preservation failed for test_type={test_type}: ratio={sign_match_ratio}"
    
        # Test-specific assertions
        if test_type == "tiny_alpha":
            # With very small alpha, normalization effect is minimal
            # Output should be close to input / (k^beta)
            expected = input_tensor / (k**beta)
            diff = torch.norm(output - expected) / torch.norm(expected)
            assert diff < 0.1, f"Tiny alpha test failed: diff={diff}"
    
        elif test_type == "large_alpha":
            # With large alpha, normalization effect is stronger
            # Output magnitude should be reduced
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
            reduction_ratio = output_norm / input_norm
    
            # With alpha=1.0, reduction should be noticeable
            assert reduction_ratio < 1.0, \
                f"Large alpha should reduce norm: reduction_ratio={reduction_ratio}"
    
        elif test_type == "small_beta":
            # With small beta (0.5), normalization is less aggressive
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
    
            # Compare with beta=0.75 case
            lrn_normal = LocalResponseNorm(size=size, alpha=alpha, beta=0.75, k=k).to(device=device)
            normal_output = lrn_normal(input_tensor)
            normal_norm = torch.norm(normal_output)
    
            # Smaller beta should produce larger output (less reduction)
            assert output_norm > normal_norm * 0.9, \
                f"Small beta should reduce output less: beta={beta} vs 0.75"
    
        elif test_type == "large_beta":
            # With large beta (2.0), normalization is more aggressive
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
    
            # Compare with beta=0.75 case
            lrn_normal = LocalResponseNorm(size=size, alpha=alpha, beta=0.75, k=k).to(device=device)
            normal_output = lrn_normal(input_tensor)
            normal_norm = torch.norm(normal_output)
    
            # Larger beta should produce smaller output
            assert output_norm < normal_norm * 1.1, \
                f"Large beta should reduce output more: beta={beta} vs 0.75"
    
        elif test_type == "min_size":
            # With size=1, only self-channel is considered
            # Output should be approximately input / (k^beta + alpha * input^2)^beta
            # For size=1, the sum over neighbors is just self
            squared = input_tensor ** 2
            denominator = k + alpha * squared
            expected = input_tensor / (denominator ** beta)
            diff = torch.norm(output - expected) / torch.norm(expected)
            assert diff < 0.2, f"Size=1 test failed: diff={diff}"
    
        elif test_type == "small_k":
            # With small k, normalization denominator is small
            # Output magnitude could be large
            assert torch.all(torch.isfinite(output)), "Small k test produced non-finite values"
    
        # Test with all positive input
        positive_input = torch.abs(input_tensor) + 0.1
        positive_output = lrn(positive_input)
        # Check that output is mostly positive (allow small numerical errors)
        positive_ratio = torch.sum(positive_output >= -1e-7).item() / positive_output.numel()
        assert positive_ratio > 0.99, \
            f"Positive input should produce non-negative output for test_type={test_type}: ratio={positive_ratio}"
    
        # Test with all negative input
        negative_input = -torch.abs(input_tensor) - 0.1
        negative_output = lrn(negative_input)
        # Check that output is mostly negative (allow small numerical errors)
        negative_ratio = torch.sum(negative_output <= 1e-7).item() / negative_output.numel()
        assert negative_ratio > 0.99, \
            f"Negative input should produce non-positive output for test_type={test_type}: ratio={negative_ratio}"
    
        # Test with constant input
        constant_value = 5.0
        constant_input = torch.full(shape, constant_value, dtype=dtype, device=device)
        constant_output = lrn(constant_input)
    
        # For constant input, output should be scaled version of input
        # All values should be approximately equal
        output_std = torch.std(constant_output)
>       assert output_std < 1e-5, \
            f"Constant input should produce constant output for test_type={test_type}: std={output_std}"
E       AssertionError: Constant input should produce constant output for test_type=large_alpha: std=0.06445513665676117
E       assert tensor(0.0645) < 1e-05

tests/test_torch_nn_modules_normalization_g3.py:440: AssertionError
_ test_localresponsenorm_boundary_values[5-0.0001-0.5-1.0-dtype5-cpu-shape5-small_beta] _

size = 5, alpha = 0.0001, beta = 0.5, k = 1.0, dtype = torch.float32
device = 'cpu', shape = (2, 16, 8, 8), test_type = 'small_beta'
set_random_seed = 42

    @pytest.mark.parametrize("size,alpha,beta,k,dtype,device,shape,test_type", [
        # Test boundary values for size
        (1, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 8, 8, 8), "min_size"),
        (3, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 8, 8, 8), "small_size"),
        (15, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_size"),
        # Test boundary values for alpha - avoid alpha=0 which can cause issues
        (5, 1e-10, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "tiny_alpha"),
        (5, 1.0, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_alpha"),
        # Test boundary values for beta - avoid beta=0 which can cause issues
        (5, 1e-4, 0.5, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "small_beta"),
        (5, 1e-4, 2.0, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_beta"),
        # Test boundary values for k - avoid k=0 which can cause division by zero
        (5, 1e-4, 0.75, 0.1, torch.float32, "cpu", (2, 16, 8, 8), "small_k"),
        (5, 1e-4, 0.75, 10.0, torch.float32, "cpu", (2, 16, 8, 8), "large_k"),
        # Test with different data types
        (5, 1e-4, 0.75, 1.0, torch.float64, "cpu", (2, 16, 8, 8), "float64"),
        # Test with small batch size
        (5, 1e-4, 0.75, 1.0, torch.float32, "cpu", (1, 16, 8, 8), "batch_size_1"),
    ])
    def test_localresponsenorm_boundary_values(size, alpha, beta, k, dtype, device, shape, test_type, set_random_seed):
        """Test LocalResponseNorm with boundary values for parameters"""
        # Skip CUDA tests if device not available
        if device == "cuda" and not torch.cuda.is_available():
            pytest.skip("CUDA not available")
    
        # Validate parameters based on test type
        if test_type == "min_size":
            assert size == 1, "Test requires size=1"
        elif test_type == "large_size":
            # Size should be odd and <= number of channels
            assert size % 2 == 1, "Size should be odd"
            assert size <= shape[1], f"Size {size} should not exceed channels {shape[1]}"
    
        # Create input tensor
        torch.manual_seed(42)
        input_tensor = torch.randn(*shape, dtype=dtype, device=device)
    
        # Create LocalResponseNorm layer
        lrn = LocalResponseNorm(
            size=size,
            alpha=alpha,
            beta=beta,
            k=k
        ).to(device=device)
    
        # Forward pass
        output = lrn(input_tensor)
    
        # Basic assertions for all boundary tests
        # 1. Shape assertion
        assert output.shape == input_tensor.shape, \
            f"Output shape {output.shape} != input shape {input_tensor.shape}"
    
        # 2. Dtype assertion
        assert output.dtype == input_tensor.dtype, \
            f"Output dtype {output.dtype} != input dtype {input_tensor.dtype}"
    
        # 3. Finite values assertion
        assert torch.all(torch.isfinite(output)), \
            f"Output contains NaN or infinite values for test_type={test_type}"
    
        # 4. Sign preservation (allow small numerical errors)
        # Check that signs are preserved for most elements
        sign_match = ((input_tensor >= 0) == (output >= 0))
        sign_match_ratio = torch.sum(sign_match).item() / sign_match.numel()
        assert sign_match_ratio > 0.99, \
            f"Sign preservation failed for test_type={test_type}: ratio={sign_match_ratio}"
    
        # Test-specific assertions
        if test_type == "tiny_alpha":
            # With very small alpha, normalization effect is minimal
            # Output should be close to input / (k^beta)
            expected = input_tensor / (k**beta)
            diff = torch.norm(output - expected) / torch.norm(expected)
            assert diff < 0.1, f"Tiny alpha test failed: diff={diff}"
    
        elif test_type == "large_alpha":
            # With large alpha, normalization effect is stronger
            # Output magnitude should be reduced
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
            reduction_ratio = output_norm / input_norm
    
            # With alpha=1.0, reduction should be noticeable
            assert reduction_ratio < 1.0, \
                f"Large alpha should reduce norm: reduction_ratio={reduction_ratio}"
    
        elif test_type == "small_beta":
            # With small beta (0.5), normalization is less aggressive
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
    
            # Compare with beta=0.75 case
            lrn_normal = LocalResponseNorm(size=size, alpha=alpha, beta=0.75, k=k).to(device=device)
            normal_output = lrn_normal(input_tensor)
            normal_norm = torch.norm(normal_output)
    
            # Smaller beta should produce larger output (less reduction)
            assert output_norm > normal_norm * 0.9, \
                f"Small beta should reduce output less: beta={beta} vs 0.75"
    
        elif test_type == "large_beta":
            # With large beta (2.0), normalization is more aggressive
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
    
            # Compare with beta=0.75 case
            lrn_normal = LocalResponseNorm(size=size, alpha=alpha, beta=0.75, k=k).to(device=device)
            normal_output = lrn_normal(input_tensor)
            normal_norm = torch.norm(normal_output)
    
            # Larger beta should produce smaller output
            assert output_norm < normal_norm * 1.1, \
                f"Large beta should reduce output more: beta={beta} vs 0.75"
    
        elif test_type == "min_size":
            # With size=1, only self-channel is considered
            # Output should be approximately input / (k^beta + alpha * input^2)^beta
            # For size=1, the sum over neighbors is just self
            squared = input_tensor ** 2
            denominator = k + alpha * squared
            expected = input_tensor / (denominator ** beta)
            diff = torch.norm(output - expected) / torch.norm(expected)
            assert diff < 0.2, f"Size=1 test failed: diff={diff}"
    
        elif test_type == "small_k":
            # With small k, normalization denominator is small
            # Output magnitude could be large
            assert torch.all(torch.isfinite(output)), "Small k test produced non-finite values"
    
        # Test with all positive input
        positive_input = torch.abs(input_tensor) + 0.1
        positive_output = lrn(positive_input)
        # Check that output is mostly positive (allow small numerical errors)
        positive_ratio = torch.sum(positive_output >= -1e-7).item() / positive_output.numel()
        assert positive_ratio > 0.99, \
            f"Positive input should produce non-negative output for test_type={test_type}: ratio={positive_ratio}"
    
        # Test with all negative input
        negative_input = -torch.abs(input_tensor) - 0.1
        negative_output = lrn(negative_input)
        # Check that output is mostly negative (allow small numerical errors)
        negative_ratio = torch.sum(negative_output <= 1e-7).item() / negative_output.numel()
        assert negative_ratio > 0.99, \
            f"Negative input should produce non-positive output for test_type={test_type}: ratio={negative_ratio}"
    
        # Test with constant input
        constant_value = 5.0
        constant_input = torch.full(shape, constant_value, dtype=dtype, device=device)
        constant_output = lrn(constant_input)
    
        # For constant input, output should be scaled version of input
        # All values should be approximately equal
        output_std = torch.std(constant_output)
>       assert output_std < 1e-5, \
            f"Constant input should produce constant output for test_type={test_type}: std={output_std}"
E       AssertionError: Constant input should produce constant output for test_type=small_beta: std=0.0008674598066136241
E       assert tensor(0.0009) < 1e-05

tests/test_torch_nn_modules_normalization_g3.py:440: AssertionError
_ test_localresponsenorm_boundary_values[5-0.0001-2.0-1.0-dtype6-cpu-shape6-large_beta] _

size = 5, alpha = 0.0001, beta = 2.0, k = 1.0, dtype = torch.float32
device = 'cpu', shape = (2, 16, 8, 8), test_type = 'large_beta'
set_random_seed = 42

    @pytest.mark.parametrize("size,alpha,beta,k,dtype,device,shape,test_type", [
        # Test boundary values for size
        (1, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 8, 8, 8), "min_size"),
        (3, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 8, 8, 8), "small_size"),
        (15, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_size"),
        # Test boundary values for alpha - avoid alpha=0 which can cause issues
        (5, 1e-10, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "tiny_alpha"),
        (5, 1.0, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_alpha"),
        # Test boundary values for beta - avoid beta=0 which can cause issues
        (5, 1e-4, 0.5, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "small_beta"),
        (5, 1e-4, 2.0, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_beta"),
        # Test boundary values for k - avoid k=0 which can cause division by zero
        (5, 1e-4, 0.75, 0.1, torch.float32, "cpu", (2, 16, 8, 8), "small_k"),
        (5, 1e-4, 0.75, 10.0, torch.float32, "cpu", (2, 16, 8, 8), "large_k"),
        # Test with different data types
        (5, 1e-4, 0.75, 1.0, torch.float64, "cpu", (2, 16, 8, 8), "float64"),
        # Test with small batch size
        (5, 1e-4, 0.75, 1.0, torch.float32, "cpu", (1, 16, 8, 8), "batch_size_1"),
    ])
    def test_localresponsenorm_boundary_values(size, alpha, beta, k, dtype, device, shape, test_type, set_random_seed):
        """Test LocalResponseNorm with boundary values for parameters"""
        # Skip CUDA tests if device not available
        if device == "cuda" and not torch.cuda.is_available():
            pytest.skip("CUDA not available")
    
        # Validate parameters based on test type
        if test_type == "min_size":
            assert size == 1, "Test requires size=1"
        elif test_type == "large_size":
            # Size should be odd and <= number of channels
            assert size % 2 == 1, "Size should be odd"
            assert size <= shape[1], f"Size {size} should not exceed channels {shape[1]}"
    
        # Create input tensor
        torch.manual_seed(42)
        input_tensor = torch.randn(*shape, dtype=dtype, device=device)
    
        # Create LocalResponseNorm layer
        lrn = LocalResponseNorm(
            size=size,
            alpha=alpha,
            beta=beta,
            k=k
        ).to(device=device)
    
        # Forward pass
        output = lrn(input_tensor)
    
        # Basic assertions for all boundary tests
        # 1. Shape assertion
        assert output.shape == input_tensor.shape, \
            f"Output shape {output.shape} != input shape {input_tensor.shape}"
    
        # 2. Dtype assertion
        assert output.dtype == input_tensor.dtype, \
            f"Output dtype {output.dtype} != input dtype {input_tensor.dtype}"
    
        # 3. Finite values assertion
        assert torch.all(torch.isfinite(output)), \
            f"Output contains NaN or infinite values for test_type={test_type}"
    
        # 4. Sign preservation (allow small numerical errors)
        # Check that signs are preserved for most elements
        sign_match = ((input_tensor >= 0) == (output >= 0))
        sign_match_ratio = torch.sum(sign_match).item() / sign_match.numel()
        assert sign_match_ratio > 0.99, \
            f"Sign preservation failed for test_type={test_type}: ratio={sign_match_ratio}"
    
        # Test-specific assertions
        if test_type == "tiny_alpha":
            # With very small alpha, normalization effect is minimal
            # Output should be close to input / (k^beta)
            expected = input_tensor / (k**beta)
            diff = torch.norm(output - expected) / torch.norm(expected)
            assert diff < 0.1, f"Tiny alpha test failed: diff={diff}"
    
        elif test_type == "large_alpha":
            # With large alpha, normalization effect is stronger
            # Output magnitude should be reduced
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
            reduction_ratio = output_norm / input_norm
    
            # With alpha=1.0, reduction should be noticeable
            assert reduction_ratio < 1.0, \
                f"Large alpha should reduce norm: reduction_ratio={reduction_ratio}"
    
        elif test_type == "small_beta":
            # With small beta (0.5), normalization is less aggressive
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
    
            # Compare with beta=0.75 case
            lrn_normal = LocalResponseNorm(size=size, alpha=alpha, beta=0.75, k=k).to(device=device)
            normal_output = lrn_normal(input_tensor)
            normal_norm = torch.norm(normal_output)
    
            # Smaller beta should produce larger output (less reduction)
            assert output_norm > normal_norm * 0.9, \
                f"Small beta should reduce output less: beta={beta} vs 0.75"
    
        elif test_type == "large_beta":
            # With large beta (2.0), normalization is more aggressive
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
    
            # Compare with beta=0.75 case
            lrn_normal = LocalResponseNorm(size=size, alpha=alpha, beta=0.75, k=k).to(device=device)
            normal_output = lrn_normal(input_tensor)
            normal_norm = torch.norm(normal_output)
    
            # Larger beta should produce smaller output
            assert output_norm < normal_norm * 1.1, \
                f"Large beta should reduce output more: beta={beta} vs 0.75"
    
        elif test_type == "min_size":
            # With size=1, only self-channel is considered
            # Output should be approximately input / (k^beta + alpha * input^2)^beta
            # For size=1, the sum over neighbors is just self
            squared = input_tensor ** 2
            denominator = k + alpha * squared
            expected = input_tensor / (denominator ** beta)
            diff = torch.norm(output - expected) / torch.norm(expected)
            assert diff < 0.2, f"Size=1 test failed: diff={diff}"
    
        elif test_type == "small_k":
            # With small k, normalization denominator is small
            # Output magnitude could be large
            assert torch.all(torch.isfinite(output)), "Small k test produced non-finite values"
    
        # Test with all positive input
        positive_input = torch.abs(input_tensor) + 0.1
        positive_output = lrn(positive_input)
        # Check that output is mostly positive (allow small numerical errors)
        positive_ratio = torch.sum(positive_output >= -1e-7).item() / positive_output.numel()
        assert positive_ratio > 0.99, \
            f"Positive input should produce non-negative output for test_type={test_type}: ratio={positive_ratio}"
    
        # Test with all negative input
        negative_input = -torch.abs(input_tensor) - 0.1
        negative_output = lrn(negative_input)
        # Check that output is mostly negative (allow small numerical errors)
        negative_ratio = torch.sum(negative_output <= 1e-7).item() / negative_output.numel()
        assert negative_ratio > 0.99, \
            f"Negative input should produce non-positive output for test_type={test_type}: ratio={negative_ratio}"
    
        # Test with constant input
        constant_value = 5.0
        constant_input = torch.full(shape, constant_value, dtype=dtype, device=device)
        constant_output = lrn(constant_input)
    
        # For constant input, output should be scaled version of input
        # All values should be approximately equal
        output_std = torch.std(constant_output)
>       assert output_std < 1e-5, \
            f"Constant input should produce constant output for test_type={test_type}: std={output_std}"
E       AssertionError: Constant input should produce constant output for test_type=large_beta: std=0.0034596342593431473
E       assert tensor(0.0035) < 1e-05

tests/test_torch_nn_modules_normalization_g3.py:440: AssertionError
_ test_localresponsenorm_boundary_values[5-0.0001-0.75-0.1-dtype7-cpu-shape7-small_k] _

size = 5, alpha = 0.0001, beta = 0.75, k = 0.1, dtype = torch.float32
device = 'cpu', shape = (2, 16, 8, 8), test_type = 'small_k'
set_random_seed = 42

    @pytest.mark.parametrize("size,alpha,beta,k,dtype,device,shape,test_type", [
        # Test boundary values for size
        (1, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 8, 8, 8), "min_size"),
        (3, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 8, 8, 8), "small_size"),
        (15, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_size"),
        # Test boundary values for alpha - avoid alpha=0 which can cause issues
        (5, 1e-10, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "tiny_alpha"),
        (5, 1.0, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_alpha"),
        # Test boundary values for beta - avoid beta=0 which can cause issues
        (5, 1e-4, 0.5, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "small_beta"),
        (5, 1e-4, 2.0, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_beta"),
        # Test boundary values for k - avoid k=0 which can cause division by zero
        (5, 1e-4, 0.75, 0.1, torch.float32, "cpu", (2, 16, 8, 8), "small_k"),
        (5, 1e-4, 0.75, 10.0, torch.float32, "cpu", (2, 16, 8, 8), "large_k"),
        # Test with different data types
        (5, 1e-4, 0.75, 1.0, torch.float64, "cpu", (2, 16, 8, 8), "float64"),
        # Test with small batch size
        (5, 1e-4, 0.75, 1.0, torch.float32, "cpu", (1, 16, 8, 8), "batch_size_1"),
    ])
    def test_localresponsenorm_boundary_values(size, alpha, beta, k, dtype, device, shape, test_type, set_random_seed):
        """Test LocalResponseNorm with boundary values for parameters"""
        # Skip CUDA tests if device not available
        if device == "cuda" and not torch.cuda.is_available():
            pytest.skip("CUDA not available")
    
        # Validate parameters based on test type
        if test_type == "min_size":
            assert size == 1, "Test requires size=1"
        elif test_type == "large_size":
            # Size should be odd and <= number of channels
            assert size % 2 == 1, "Size should be odd"
            assert size <= shape[1], f"Size {size} should not exceed channels {shape[1]}"
    
        # Create input tensor
        torch.manual_seed(42)
        input_tensor = torch.randn(*shape, dtype=dtype, device=device)
    
        # Create LocalResponseNorm layer
        lrn = LocalResponseNorm(
            size=size,
            alpha=alpha,
            beta=beta,
            k=k
        ).to(device=device)
    
        # Forward pass
        output = lrn(input_tensor)
    
        # Basic assertions for all boundary tests
        # 1. Shape assertion
        assert output.shape == input_tensor.shape, \
            f"Output shape {output.shape} != input shape {input_tensor.shape}"
    
        # 2. Dtype assertion
        assert output.dtype == input_tensor.dtype, \
            f"Output dtype {output.dtype} != input dtype {input_tensor.dtype}"
    
        # 3. Finite values assertion
        assert torch.all(torch.isfinite(output)), \
            f"Output contains NaN or infinite values for test_type={test_type}"
    
        # 4. Sign preservation (allow small numerical errors)
        # Check that signs are preserved for most elements
        sign_match = ((input_tensor >= 0) == (output >= 0))
        sign_match_ratio = torch.sum(sign_match).item() / sign_match.numel()
        assert sign_match_ratio > 0.99, \
            f"Sign preservation failed for test_type={test_type}: ratio={sign_match_ratio}"
    
        # Test-specific assertions
        if test_type == "tiny_alpha":
            # With very small alpha, normalization effect is minimal
            # Output should be close to input / (k^beta)
            expected = input_tensor / (k**beta)
            diff = torch.norm(output - expected) / torch.norm(expected)
            assert diff < 0.1, f"Tiny alpha test failed: diff={diff}"
    
        elif test_type == "large_alpha":
            # With large alpha, normalization effect is stronger
            # Output magnitude should be reduced
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
            reduction_ratio = output_norm / input_norm
    
            # With alpha=1.0, reduction should be noticeable
            assert reduction_ratio < 1.0, \
                f"Large alpha should reduce norm: reduction_ratio={reduction_ratio}"
    
        elif test_type == "small_beta":
            # With small beta (0.5), normalization is less aggressive
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
    
            # Compare with beta=0.75 case
            lrn_normal = LocalResponseNorm(size=size, alpha=alpha, beta=0.75, k=k).to(device=device)
            normal_output = lrn_normal(input_tensor)
            normal_norm = torch.norm(normal_output)
    
            # Smaller beta should produce larger output (less reduction)
            assert output_norm > normal_norm * 0.9, \
                f"Small beta should reduce output less: beta={beta} vs 0.75"
    
        elif test_type == "large_beta":
            # With large beta (2.0), normalization is more aggressive
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
    
            # Compare with beta=0.75 case
            lrn_normal = LocalResponseNorm(size=size, alpha=alpha, beta=0.75, k=k).to(device=device)
            normal_output = lrn_normal(input_tensor)
            normal_norm = torch.norm(normal_output)
    
            # Larger beta should produce smaller output
            assert output_norm < normal_norm * 1.1, \
                f"Large beta should reduce output more: beta={beta} vs 0.75"
    
        elif test_type == "min_size":
            # With size=1, only self-channel is considered
            # Output should be approximately input / (k^beta + alpha * input^2)^beta
            # For size=1, the sum over neighbors is just self
            squared = input_tensor ** 2
            denominator = k + alpha * squared
            expected = input_tensor / (denominator ** beta)
            diff = torch.norm(output - expected) / torch.norm(expected)
            assert diff < 0.2, f"Size=1 test failed: diff={diff}"
    
        elif test_type == "small_k":
            # With small k, normalization denominator is small
            # Output magnitude could be large
            assert torch.all(torch.isfinite(output)), "Small k test produced non-finite values"
    
        # Test with all positive input
        positive_input = torch.abs(input_tensor) + 0.1
        positive_output = lrn(positive_input)
        # Check that output is mostly positive (allow small numerical errors)
        positive_ratio = torch.sum(positive_output >= -1e-7).item() / positive_output.numel()
        assert positive_ratio > 0.99, \
            f"Positive input should produce non-negative output for test_type={test_type}: ratio={positive_ratio}"
    
        # Test with all negative input
        negative_input = -torch.abs(input_tensor) - 0.1
        negative_output = lrn(negative_input)
        # Check that output is mostly negative (allow small numerical errors)
        negative_ratio = torch.sum(negative_output <= 1e-7).item() / negative_output.numel()
        assert negative_ratio > 0.99, \
            f"Negative input should produce non-positive output for test_type={test_type}: ratio={negative_ratio}"
    
        # Test with constant input
        constant_value = 5.0
        constant_input = torch.full(shape, constant_value, dtype=dtype, device=device)
        constant_output = lrn(constant_input)
    
        # For constant input, output should be scaled version of input
        # All values should be approximately equal
        output_std = torch.std(constant_output)
>       assert output_std < 1e-5, \
            f"Constant input should produce constant output for test_type={test_type}: std={output_std}"
E       AssertionError: Constant input should produce constant output for test_type=small_k: std=0.07085202634334564
E       assert tensor(0.0709) < 1e-05

tests/test_torch_nn_modules_normalization_g3.py:440: AssertionError
_ test_localresponsenorm_boundary_values[5-0.0001-0.75-10.0-dtype8-cpu-shape8-large_k] _

size = 5, alpha = 0.0001, beta = 0.75, k = 10.0, dtype = torch.float32
device = 'cpu', shape = (2, 16, 8, 8), test_type = 'large_k'
set_random_seed = 42

    @pytest.mark.parametrize("size,alpha,beta,k,dtype,device,shape,test_type", [
        # Test boundary values for size
        (1, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 8, 8, 8), "min_size"),
        (3, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 8, 8, 8), "small_size"),
        (15, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_size"),
        # Test boundary values for alpha - avoid alpha=0 which can cause issues
        (5, 1e-10, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "tiny_alpha"),
        (5, 1.0, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_alpha"),
        # Test boundary values for beta - avoid beta=0 which can cause issues
        (5, 1e-4, 0.5, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "small_beta"),
        (5, 1e-4, 2.0, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_beta"),
        # Test boundary values for k - avoid k=0 which can cause division by zero
        (5, 1e-4, 0.75, 0.1, torch.float32, "cpu", (2, 16, 8, 8), "small_k"),
        (5, 1e-4, 0.75, 10.0, torch.float32, "cpu", (2, 16, 8, 8), "large_k"),
        # Test with different data types
        (5, 1e-4, 0.75, 1.0, torch.float64, "cpu", (2, 16, 8, 8), "float64"),
        # Test with small batch size
        (5, 1e-4, 0.75, 1.0, torch.float32, "cpu", (1, 16, 8, 8), "batch_size_1"),
    ])
    def test_localresponsenorm_boundary_values(size, alpha, beta, k, dtype, device, shape, test_type, set_random_seed):
        """Test LocalResponseNorm with boundary values for parameters"""
        # Skip CUDA tests if device not available
        if device == "cuda" and not torch.cuda.is_available():
            pytest.skip("CUDA not available")
    
        # Validate parameters based on test type
        if test_type == "min_size":
            assert size == 1, "Test requires size=1"
        elif test_type == "large_size":
            # Size should be odd and <= number of channels
            assert size % 2 == 1, "Size should be odd"
            assert size <= shape[1], f"Size {size} should not exceed channels {shape[1]}"
    
        # Create input tensor
        torch.manual_seed(42)
        input_tensor = torch.randn(*shape, dtype=dtype, device=device)
    
        # Create LocalResponseNorm layer
        lrn = LocalResponseNorm(
            size=size,
            alpha=alpha,
            beta=beta,
            k=k
        ).to(device=device)
    
        # Forward pass
        output = lrn(input_tensor)
    
        # Basic assertions for all boundary tests
        # 1. Shape assertion
        assert output.shape == input_tensor.shape, \
            f"Output shape {output.shape} != input shape {input_tensor.shape}"
    
        # 2. Dtype assertion
        assert output.dtype == input_tensor.dtype, \
            f"Output dtype {output.dtype} != input dtype {input_tensor.dtype}"
    
        # 3. Finite values assertion
        assert torch.all(torch.isfinite(output)), \
            f"Output contains NaN or infinite values for test_type={test_type}"
    
        # 4. Sign preservation (allow small numerical errors)
        # Check that signs are preserved for most elements
        sign_match = ((input_tensor >= 0) == (output >= 0))
        sign_match_ratio = torch.sum(sign_match).item() / sign_match.numel()
        assert sign_match_ratio > 0.99, \
            f"Sign preservation failed for test_type={test_type}: ratio={sign_match_ratio}"
    
        # Test-specific assertions
        if test_type == "tiny_alpha":
            # With very small alpha, normalization effect is minimal
            # Output should be close to input / (k^beta)
            expected = input_tensor / (k**beta)
            diff = torch.norm(output - expected) / torch.norm(expected)
            assert diff < 0.1, f"Tiny alpha test failed: diff={diff}"
    
        elif test_type == "large_alpha":
            # With large alpha, normalization effect is stronger
            # Output magnitude should be reduced
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
            reduction_ratio = output_norm / input_norm
    
            # With alpha=1.0, reduction should be noticeable
            assert reduction_ratio < 1.0, \
                f"Large alpha should reduce norm: reduction_ratio={reduction_ratio}"
    
        elif test_type == "small_beta":
            # With small beta (0.5), normalization is less aggressive
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
    
            # Compare with beta=0.75 case
            lrn_normal = LocalResponseNorm(size=size, alpha=alpha, beta=0.75, k=k).to(device=device)
            normal_output = lrn_normal(input_tensor)
            normal_norm = torch.norm(normal_output)
    
            # Smaller beta should produce larger output (less reduction)
            assert output_norm > normal_norm * 0.9, \
                f"Small beta should reduce output less: beta={beta} vs 0.75"
    
        elif test_type == "large_beta":
            # With large beta (2.0), normalization is more aggressive
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
    
            # Compare with beta=0.75 case
            lrn_normal = LocalResponseNorm(size=size, alpha=alpha, beta=0.75, k=k).to(device=device)
            normal_output = lrn_normal(input_tensor)
            normal_norm = torch.norm(normal_output)
    
            # Larger beta should produce smaller output
            assert output_norm < normal_norm * 1.1, \
                f"Large beta should reduce output more: beta={beta} vs 0.75"
    
        elif test_type == "min_size":
            # With size=1, only self-channel is considered
            # Output should be approximately input / (k^beta + alpha * input^2)^beta
            # For size=1, the sum over neighbors is just self
            squared = input_tensor ** 2
            denominator = k + alpha * squared
            expected = input_tensor / (denominator ** beta)
            diff = torch.norm(output - expected) / torch.norm(expected)
            assert diff < 0.2, f"Size=1 test failed: diff={diff}"
    
        elif test_type == "small_k":
            # With small k, normalization denominator is small
            # Output magnitude could be large
            assert torch.all(torch.isfinite(output)), "Small k test produced non-finite values"
    
        # Test with all positive input
        positive_input = torch.abs(input_tensor) + 0.1
        positive_output = lrn(positive_input)
        # Check that output is mostly positive (allow small numerical errors)
        positive_ratio = torch.sum(positive_output >= -1e-7).item() / positive_output.numel()
        assert positive_ratio > 0.99, \
            f"Positive input should produce non-negative output for test_type={test_type}: ratio={positive_ratio}"
    
        # Test with all negative input
        negative_input = -torch.abs(input_tensor) - 0.1
        negative_output = lrn(negative_input)
        # Check that output is mostly negative (allow small numerical errors)
        negative_ratio = torch.sum(negative_output <= 1e-7).item() / negative_output.numel()
        assert negative_ratio > 0.99, \
            f"Negative input should produce non-positive output for test_type={test_type}: ratio={negative_ratio}"
    
        # Test with constant input
        constant_value = 5.0
        constant_input = torch.full(shape, constant_value, dtype=dtype, device=device)
        constant_output = lrn(constant_input)
    
        # For constant input, output should be scaled version of input
        # All values should be approximately equal
        output_std = torch.std(constant_output)
>       assert output_std < 1e-5, \
            f"Constant input should produce constant output for test_type={test_type}: std={output_std}"
E       AssertionError: Constant input should produce constant output for test_type=large_k: std=2.31948488362832e-05
E       assert tensor(2.3195e-05) < 1e-05

tests/test_torch_nn_modules_normalization_g3.py:440: AssertionError
_ test_localresponsenorm_boundary_values[5-0.0001-0.75-1.0-dtype9-cpu-shape9-float64] _

size = 5, alpha = 0.0001, beta = 0.75, k = 1.0, dtype = torch.float64
device = 'cpu', shape = (2, 16, 8, 8), test_type = 'float64'
set_random_seed = 42

    @pytest.mark.parametrize("size,alpha,beta,k,dtype,device,shape,test_type", [
        # Test boundary values for size
        (1, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 8, 8, 8), "min_size"),
        (3, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 8, 8, 8), "small_size"),
        (15, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_size"),
        # Test boundary values for alpha - avoid alpha=0 which can cause issues
        (5, 1e-10, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "tiny_alpha"),
        (5, 1.0, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_alpha"),
        # Test boundary values for beta - avoid beta=0 which can cause issues
        (5, 1e-4, 0.5, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "small_beta"),
        (5, 1e-4, 2.0, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_beta"),
        # Test boundary values for k - avoid k=0 which can cause division by zero
        (5, 1e-4, 0.75, 0.1, torch.float32, "cpu", (2, 16, 8, 8), "small_k"),
        (5, 1e-4, 0.75, 10.0, torch.float32, "cpu", (2, 16, 8, 8), "large_k"),
        # Test with different data types
        (5, 1e-4, 0.75, 1.0, torch.float64, "cpu", (2, 16, 8, 8), "float64"),
        # Test with small batch size
        (5, 1e-4, 0.75, 1.0, torch.float32, "cpu", (1, 16, 8, 8), "batch_size_1"),
    ])
    def test_localresponsenorm_boundary_values(size, alpha, beta, k, dtype, device, shape, test_type, set_random_seed):
        """Test LocalResponseNorm with boundary values for parameters"""
        # Skip CUDA tests if device not available
        if device == "cuda" and not torch.cuda.is_available():
            pytest.skip("CUDA not available")
    
        # Validate parameters based on test type
        if test_type == "min_size":
            assert size == 1, "Test requires size=1"
        elif test_type == "large_size":
            # Size should be odd and <= number of channels
            assert size % 2 == 1, "Size should be odd"
            assert size <= shape[1], f"Size {size} should not exceed channels {shape[1]}"
    
        # Create input tensor
        torch.manual_seed(42)
        input_tensor = torch.randn(*shape, dtype=dtype, device=device)
    
        # Create LocalResponseNorm layer
        lrn = LocalResponseNorm(
            size=size,
            alpha=alpha,
            beta=beta,
            k=k
        ).to(device=device)
    
        # Forward pass
        output = lrn(input_tensor)
    
        # Basic assertions for all boundary tests
        # 1. Shape assertion
        assert output.shape == input_tensor.shape, \
            f"Output shape {output.shape} != input shape {input_tensor.shape}"
    
        # 2. Dtype assertion
        assert output.dtype == input_tensor.dtype, \
            f"Output dtype {output.dtype} != input dtype {input_tensor.dtype}"
    
        # 3. Finite values assertion
        assert torch.all(torch.isfinite(output)), \
            f"Output contains NaN or infinite values for test_type={test_type}"
    
        # 4. Sign preservation (allow small numerical errors)
        # Check that signs are preserved for most elements
        sign_match = ((input_tensor >= 0) == (output >= 0))
        sign_match_ratio = torch.sum(sign_match).item() / sign_match.numel()
        assert sign_match_ratio > 0.99, \
            f"Sign preservation failed for test_type={test_type}: ratio={sign_match_ratio}"
    
        # Test-specific assertions
        if test_type == "tiny_alpha":
            # With very small alpha, normalization effect is minimal
            # Output should be close to input / (k^beta)
            expected = input_tensor / (k**beta)
            diff = torch.norm(output - expected) / torch.norm(expected)
            assert diff < 0.1, f"Tiny alpha test failed: diff={diff}"
    
        elif test_type == "large_alpha":
            # With large alpha, normalization effect is stronger
            # Output magnitude should be reduced
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
            reduction_ratio = output_norm / input_norm
    
            # With alpha=1.0, reduction should be noticeable
            assert reduction_ratio < 1.0, \
                f"Large alpha should reduce norm: reduction_ratio={reduction_ratio}"
    
        elif test_type == "small_beta":
            # With small beta (0.5), normalization is less aggressive
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
    
            # Compare with beta=0.75 case
            lrn_normal = LocalResponseNorm(size=size, alpha=alpha, beta=0.75, k=k).to(device=device)
            normal_output = lrn_normal(input_tensor)
            normal_norm = torch.norm(normal_output)
    
            # Smaller beta should produce larger output (less reduction)
            assert output_norm > normal_norm * 0.9, \
                f"Small beta should reduce output less: beta={beta} vs 0.75"
    
        elif test_type == "large_beta":
            # With large beta (2.0), normalization is more aggressive
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
    
            # Compare with beta=0.75 case
            lrn_normal = LocalResponseNorm(size=size, alpha=alpha, beta=0.75, k=k).to(device=device)
            normal_output = lrn_normal(input_tensor)
            normal_norm = torch.norm(normal_output)
    
            # Larger beta should produce smaller output
            assert output_norm < normal_norm * 1.1, \
                f"Large beta should reduce output more: beta={beta} vs 0.75"
    
        elif test_type == "min_size":
            # With size=1, only self-channel is considered
            # Output should be approximately input / (k^beta + alpha * input^2)^beta
            # For size=1, the sum over neighbors is just self
            squared = input_tensor ** 2
            denominator = k + alpha * squared
            expected = input_tensor / (denominator ** beta)
            diff = torch.norm(output - expected) / torch.norm(expected)
            assert diff < 0.2, f"Size=1 test failed: diff={diff}"
    
        elif test_type == "small_k":
            # With small k, normalization denominator is small
            # Output magnitude could be large
            assert torch.all(torch.isfinite(output)), "Small k test produced non-finite values"
    
        # Test with all positive input
        positive_input = torch.abs(input_tensor) + 0.1
        positive_output = lrn(positive_input)
        # Check that output is mostly positive (allow small numerical errors)
        positive_ratio = torch.sum(positive_output >= -1e-7).item() / positive_output.numel()
        assert positive_ratio > 0.99, \
            f"Positive input should produce non-negative output for test_type={test_type}: ratio={positive_ratio}"
    
        # Test with all negative input
        negative_input = -torch.abs(input_tensor) - 0.1
        negative_output = lrn(negative_input)
        # Check that output is mostly negative (allow small numerical errors)
        negative_ratio = torch.sum(negative_output <= 1e-7).item() / negative_output.numel()
        assert negative_ratio > 0.99, \
            f"Negative input should produce non-positive output for test_type={test_type}: ratio={negative_ratio}"
    
        # Test with constant input
        constant_value = 5.0
        constant_input = torch.full(shape, constant_value, dtype=dtype, device=device)
        constant_output = lrn(constant_input)
    
        # For constant input, output should be scaled version of input
        # All values should be approximately equal
        output_std = torch.std(constant_output)
>       assert output_std < 1e-5, \
            f"Constant input should produce constant output for test_type={test_type}: std={output_std}"
E       AssertionError: Constant input should produce constant output for test_type=float64: std=0.0013006162728712114
E       assert tensor(0.0013, dtype=torch.float64) < 1e-05

tests/test_torch_nn_modules_normalization_g3.py:440: AssertionError
_ test_localresponsenorm_boundary_values[5-0.0001-0.75-1.0-dtype10-cpu-shape10-batch_size_1] _

size = 5, alpha = 0.0001, beta = 0.75, k = 1.0, dtype = torch.float32
device = 'cpu', shape = (1, 16, 8, 8), test_type = 'batch_size_1'
set_random_seed = 42

    @pytest.mark.parametrize("size,alpha,beta,k,dtype,device,shape,test_type", [
        # Test boundary values for size
        (1, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 8, 8, 8), "min_size"),
        (3, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 8, 8, 8), "small_size"),
        (15, 1e-4, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_size"),
        # Test boundary values for alpha - avoid alpha=0 which can cause issues
        (5, 1e-10, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "tiny_alpha"),
        (5, 1.0, 0.75, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_alpha"),
        # Test boundary values for beta - avoid beta=0 which can cause issues
        (5, 1e-4, 0.5, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "small_beta"),
        (5, 1e-4, 2.0, 1.0, torch.float32, "cpu", (2, 16, 8, 8), "large_beta"),
        # Test boundary values for k - avoid k=0 which can cause division by zero
        (5, 1e-4, 0.75, 0.1, torch.float32, "cpu", (2, 16, 8, 8), "small_k"),
        (5, 1e-4, 0.75, 10.0, torch.float32, "cpu", (2, 16, 8, 8), "large_k"),
        # Test with different data types
        (5, 1e-4, 0.75, 1.0, torch.float64, "cpu", (2, 16, 8, 8), "float64"),
        # Test with small batch size
        (5, 1e-4, 0.75, 1.0, torch.float32, "cpu", (1, 16, 8, 8), "batch_size_1"),
    ])
    def test_localresponsenorm_boundary_values(size, alpha, beta, k, dtype, device, shape, test_type, set_random_seed):
        """Test LocalResponseNorm with boundary values for parameters"""
        # Skip CUDA tests if device not available
        if device == "cuda" and not torch.cuda.is_available():
            pytest.skip("CUDA not available")
    
        # Validate parameters based on test type
        if test_type == "min_size":
            assert size == 1, "Test requires size=1"
        elif test_type == "large_size":
            # Size should be odd and <= number of channels
            assert size % 2 == 1, "Size should be odd"
            assert size <= shape[1], f"Size {size} should not exceed channels {shape[1]}"
    
        # Create input tensor
        torch.manual_seed(42)
        input_tensor = torch.randn(*shape, dtype=dtype, device=device)
    
        # Create LocalResponseNorm layer
        lrn = LocalResponseNorm(
            size=size,
            alpha=alpha,
            beta=beta,
            k=k
        ).to(device=device)
    
        # Forward pass
        output = lrn(input_tensor)
    
        # Basic assertions for all boundary tests
        # 1. Shape assertion
        assert output.shape == input_tensor.shape, \
            f"Output shape {output.shape} != input shape {input_tensor.shape}"
    
        # 2. Dtype assertion
        assert output.dtype == input_tensor.dtype, \
            f"Output dtype {output.dtype} != input dtype {input_tensor.dtype}"
    
        # 3. Finite values assertion
        assert torch.all(torch.isfinite(output)), \
            f"Output contains NaN or infinite values for test_type={test_type}"
    
        # 4. Sign preservation (allow small numerical errors)
        # Check that signs are preserved for most elements
        sign_match = ((input_tensor >= 0) == (output >= 0))
        sign_match_ratio = torch.sum(sign_match).item() / sign_match.numel()
        assert sign_match_ratio > 0.99, \
            f"Sign preservation failed for test_type={test_type}: ratio={sign_match_ratio}"
    
        # Test-specific assertions
        if test_type == "tiny_alpha":
            # With very small alpha, normalization effect is minimal
            # Output should be close to input / (k^beta)
            expected = input_tensor / (k**beta)
            diff = torch.norm(output - expected) / torch.norm(expected)
            assert diff < 0.1, f"Tiny alpha test failed: diff={diff}"
    
        elif test_type == "large_alpha":
            # With large alpha, normalization effect is stronger
            # Output magnitude should be reduced
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
            reduction_ratio = output_norm / input_norm
    
            # With alpha=1.0, reduction should be noticeable
            assert reduction_ratio < 1.0, \
                f"Large alpha should reduce norm: reduction_ratio={reduction_ratio}"
    
        elif test_type == "small_beta":
            # With small beta (0.5), normalization is less aggressive
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
    
            # Compare with beta=0.75 case
            lrn_normal = LocalResponseNorm(size=size, alpha=alpha, beta=0.75, k=k).to(device=device)
            normal_output = lrn_normal(input_tensor)
            normal_norm = torch.norm(normal_output)
    
            # Smaller beta should produce larger output (less reduction)
            assert output_norm > normal_norm * 0.9, \
                f"Small beta should reduce output less: beta={beta} vs 0.75"
    
        elif test_type == "large_beta":
            # With large beta (2.0), normalization is more aggressive
            input_norm = torch.norm(input_tensor)
            output_norm = torch.norm(output)
    
            # Compare with beta=0.75 case
            lrn_normal = LocalResponseNorm(size=size, alpha=alpha, beta=0.75, k=k).to(device=device)
            normal_output = lrn_normal(input_tensor)
            normal_norm = torch.norm(normal_output)
    
            # Larger beta should produce smaller output
            assert output_norm < normal_norm * 1.1, \
                f"Large beta should reduce output more: beta={beta} vs 0.75"
    
        elif test_type == "min_size":
            # With size=1, only self-channel is considered
            # Output should be approximately input / (k^beta + alpha * input^2)^beta
            # For size=1, the sum over neighbors is just self
            squared = input_tensor ** 2
            denominator = k + alpha * squared
            expected = input_tensor / (denominator ** beta)
            diff = torch.norm(output - expected) / torch.norm(expected)
            assert diff < 0.2, f"Size=1 test failed: diff={diff}"
    
        elif test_type == "small_k":
            # With small k, normalization denominator is small
            # Output magnitude could be large
            assert torch.all(torch.isfinite(output)), "Small k test produced non-finite values"
    
        # Test with all positive input
        positive_input = torch.abs(input_tensor) + 0.1
        positive_output = lrn(positive_input)
        # Check that output is mostly positive (allow small numerical errors)
        positive_ratio = torch.sum(positive_output >= -1e-7).item() / positive_output.numel()
        assert positive_ratio > 0.99, \
            f"Positive input should produce non-negative output for test_type={test_type}: ratio={positive_ratio}"
    
        # Test with all negative input
        negative_input = -torch.abs(input_tensor) - 0.1
        negative_output = lrn(negative_input)
        # Check that output is mostly negative (allow small numerical errors)
        negative_ratio = torch.sum(negative_output <= 1e-7).item() / negative_output.numel()
        assert negative_ratio > 0.99, \
            f"Negative input should produce non-positive output for test_type={test_type}: ratio={negative_ratio}"
    
        # Test with constant input
        constant_value = 5.0
        constant_input = torch.full(shape, constant_value, dtype=dtype, device=device)
        constant_output = lrn(constant_input)
    
        # For constant input, output should be scaled version of input
        # All values should be approximately equal
        output_std = torch.std(constant_output)
>       assert output_std < 1e-5, \
            f"Constant input should produce constant output for test_type={test_type}: std={output_std}"
E       AssertionError: Constant input should produce constant output for test_type=batch_size_1: std=0.0013009667163714767
E       assert tensor(0.0013) < 1e-05

tests/test_torch_nn_modules_normalization_g3.py:440: AssertionError
================================ tests coverage ================================
______________ coverage: platform darwin, python 3.10.19-final-0 _______________

Name                                              Stmts   Miss Branch BrPart  Cover   Missing
---------------------------------------------------------------------------------------------
tests/test_torch_nn_modules_normalization_g1.py     216     25     48      9    85%   24-39, 54, 101->96, 129-130, 181->186, 199-200, 212-213, 225-226, 256, 424->442, 462-470, 481, 484->495, 513->518, 525
tests/test_torch_nn_modules_normalization_g2.py     234     87     42      3    64%   24-39, 54, 143-144, 190, 373-538, 544
tests/test_torch_nn_modules_normalization_g3.py     205     17     46      6    88%   24-39, 52, 117-118, 128->143, 177, 239->254, 309, 468-471, 484
---------------------------------------------------------------------------------------------
TOTAL                                               655    129    136     18    79%
Coverage XML written to file coverage.xml
=========================== short test summary info ============================
FAILED tests/test_torch_nn_modules_normalization_g1.py::test_groupnorm_device_dtype[dtype0-cpu]
FAILED tests/test_torch_nn_modules_normalization_g2.py::test_layernorm_exception_shapes
FAILED tests/test_torch_nn_modules_normalization_g3.py::test_localresponsenorm_boundary_values[3-0.0001-0.75-1.0-dtype1-cpu-shape1-small_size]
FAILED tests/test_torch_nn_modules_normalization_g3.py::test_localresponsenorm_boundary_values[15-0.0001-0.75-1.0-dtype2-cpu-shape2-large_size]
FAILED tests/test_torch_nn_modules_normalization_g3.py::test_localresponsenorm_boundary_values[5-1.0-0.75-1.0-dtype4-cpu-shape4-large_alpha]
FAILED tests/test_torch_nn_modules_normalization_g3.py::test_localresponsenorm_boundary_values[5-0.0001-0.5-1.0-dtype5-cpu-shape5-small_beta]
FAILED tests/test_torch_nn_modules_normalization_g3.py::test_localresponsenorm_boundary_values[5-0.0001-2.0-1.0-dtype6-cpu-shape6-large_beta]
FAILED tests/test_torch_nn_modules_normalization_g3.py::test_localresponsenorm_boundary_values[5-0.0001-0.75-0.1-dtype7-cpu-shape7-small_k]
FAILED tests/test_torch_nn_modules_normalization_g3.py::test_localresponsenorm_boundary_values[5-0.0001-0.75-10.0-dtype8-cpu-shape8-large_k]
FAILED tests/test_torch_nn_modules_normalization_g3.py::test_localresponsenorm_boundary_values[5-0.0001-0.75-1.0-dtype9-cpu-shape9-float64]
FAILED tests/test_torch_nn_modules_normalization_g3.py::test_localresponsenorm_boundary_values[5-0.0001-0.75-1.0-dtype10-cpu-shape10-batch_size_1]
11 failed, 22 passed, 2 skipped in 1.11s

Error: exit 1