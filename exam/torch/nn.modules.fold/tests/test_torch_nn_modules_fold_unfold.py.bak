import math
import pytest
import torch
import torch.nn as nn
from torch.nn.modules.fold import Fold, Unfold

# ==== BLOCK:HEADER START ====
"""
Test module for torch.nn.modules.fold.Unfold
G2: Unfold类核心功能
"""
import math
import pytest
import torch
import torch.nn as nn
from torch.nn.modules.fold import Fold, Unfold

# Set random seed for reproducibility
torch.manual_seed(42)
# ==== BLOCK:HEADER END ====

# ==== BLOCK:CASE_05 START ====
@pytest.mark.parametrize(
    "kernel_size,stride,padding,dilation,batch_size,channels,input_height,input_width,dtype,device",
    [
        # Base case from test plan
        (2, 1, 0, 1, 1, 3, 4, 5, torch.float32, 'cpu'),
        # Parameter extensions
        (2, 1, 0, 1, 4, 8, 4, 5, torch.float64, 'cpu'),
    ]
)
def test_unfold_basic_int_params(kernel_size, stride, padding, dilation, batch_size, channels, input_height, input_width, dtype, device):
    """
    TC-05: Unfold基本功能_int参数
    Test Unfold with integer parameters (scalar values applied to all dimensions)
    """
    # Create Unfold module
    unfold = Unfold(
        kernel_size=kernel_size,
        stride=stride,
        padding=padding,
        dilation=dilation
    )
    
    # Create valid input tensor
    input_tensor = create_unfold_input(
        batch_size=batch_size,
        channels=channels,
        input_height=input_height,
        input_width=input_width,
        dtype=dtype,
        device=device
    )
    
    # Forward pass
    output = unfold(input_tensor)
    
    # Weak assertions
    # 1. Shape match
    expected_shape = compute_unfold_output_shape(
        batch_size, channels, input_height, input_width, kernel_size, stride, padding, dilation
    )
    assert output.shape == expected_shape, f"Expected shape {expected_shape}, got {output.shape}"
    
    # 2. Dtype match
    assert output.dtype == dtype, f"Expected dtype {dtype}, got {output.dtype}"
    
    # 3. Finite values
    assert torch.isfinite(output).all(), "Output contains non-finite values (inf or nan)"
    
    # 4. No NaN/Inf
    assert not torch.isnan(output).any(), "Output contains NaN values"
    assert not torch.isinf(output).any(), "Output contains Inf values"
    
    # Additional basic checks
    assert output.device.type == device, f"Expected device {device}, got {output.device.type}"
    
    # Verify output channels calculation
    if isinstance(kernel_size, int):
        expected_channels = channels * kernel_size * kernel_size
    else:
        expected_channels = channels * kernel_size[0] * kernel_size[1]
    assert output.size(1) == expected_channels, \
        f"Expected channels {expected_channels}, got {output.size(1)}"
# ==== BLOCK:CASE_05 END ====

# ==== BLOCK:CASE_06 START ====
@pytest.mark.parametrize(
    "kernel_size,stride,padding,dilation,batch_size,channels,input_height,input_width,dtype,device",
    [
        # Base case from test plan
        ([2, 3], [1, 1], [0, 0], [1, 1], 2, 3, 4, 6, torch.float32, 'cpu'),
        # Parameter extensions
        ([2, 3], [2, 2], [1, 1], [2, 2], 2, 3, 4, 6, torch.float32, 'cpu'),
    ]
)
def test_unfold_basic_tuple_params(kernel_size, stride, padding, dilation, batch_size, channels, input_height, input_width, dtype, device):
    """
    TC-06: Unfold基本功能_tuple参数
    Test Unfold with tuple parameters (different values for height and width dimensions)
    """
    # Create Unfold module
    unfold = Unfold(
        kernel_size=kernel_size,
        stride=stride,
        padding=padding,
        dilation=dilation
    )
    
    # Create valid input tensor
    input_tensor = create_unfold_input(
        batch_size=batch_size,
        channels=channels,
        input_height=input_height,
        input_width=input_width,
        dtype=dtype,
        device=device
    )
    
    # Forward pass
    output = unfold(input_tensor)
    
    # Weak assertions
    # 1. Shape match
    expected_shape = compute_unfold_output_shape(
        batch_size, channels, input_height, input_width, kernel_size, stride, padding, dilation
    )
    assert output.shape == expected_shape, f"Expected shape {expected_shape}, got {output.shape}"
    
    # 2. Dtype match
    assert output.dtype == dtype, f"Expected dtype {dtype}, got {output.dtype}"
    
    # 3. Finite values
    assert torch.isfinite(output).all(), "Output contains non-finite values (inf or nan)"
    
    # 4. No NaN/Inf
    assert not torch.isnan(output).any(), "Output contains NaN values"
    assert not torch.isinf(output).any(), "Output contains Inf values"
    
    # Additional basic checks
    assert output.device.type == device, f"Expected device {device}, got {output.device.type}"
    
    # Verify parameter handling
    # Check that module stores parameters correctly
    # Note: Unfold may store parameters as lists or tuples internally
    # We need to check equality regardless of container type
    assert list(unfold.kernel_size) == list(kernel_size), \
        f"Module kernel_size mismatch: expected {kernel_size}, got {unfold.kernel_size}"
    assert list(unfold.stride) == list(stride), \
        f"Module stride mismatch: expected {stride}, got {unfold.stride}"
    assert list(unfold.padding) == list(padding), \
        f"Module padding mismatch: expected {padding}, got {unfold.padding}"
    assert list(unfold.dilation) == list(dilation), \
        f"Module dilation mismatch: expected {dilation}, got {unfold.dilation}"
    
    # Verify output channels calculation
    expected_channels = channels * kernel_size[0] * kernel_size[1]
    assert output.size(1) == expected_channels, \
        f"Expected channels {expected_channels}, got {output.size(1)}"
# ==== BLOCK:CASE_06 END ====

# ==== BLOCK:CASE_07 START ====
@pytest.mark.parametrize(
    "kernel_size,stride,padding,dilation,batch_size,channels,input_height,input_width,dtype,device",
    [
        # Base case from test plan - minimal valid configuration
        ([2, 2], [1, 1], [0, 0], [1, 1], 1, 1, 2, 2, torch.float32, 'cpu'),
    ]
)
def test_unfold_edge_conditions(kernel_size, stride, padding, dilation, batch_size, channels, input_height, input_width, dtype, device):
    """
    TC-07: Unfold边界条件
    Test Unfold with edge/boundary conditions (minimal valid input size)
    """
    # Create Unfold module
    unfold = Unfold(
        kernel_size=kernel_size,
        stride=stride,
        padding=padding,
        dilation=dilation
    )
    
    # Create valid input tensor with minimal size
    input_tensor = create_unfold_input(
        batch_size=batch_size,
        channels=channels,
        input_height=input_height,
        input_width=input_width,
        dtype=dtype,
        device=device
    )
    
    # Forward pass
    output = unfold(input_tensor)
    
    # Weak assertions
    # 1. Shape match
    expected_shape = compute_unfold_output_shape(
        batch_size, channels, input_height, input_width, kernel_size, stride, padding, dilation
    )
    assert output.shape == expected_shape, f"Expected shape {expected_shape}, got {output.shape}"
    
    # 2. Dtype match
    assert output.dtype == dtype, f"Expected dtype {dtype}, got {output.dtype}"
    
    # 3. Finite values
    assert torch.isfinite(output).all(), "Output contains non-finite values (inf or nan)"
    
    # 4. No NaN/Inf
    assert not torch.isnan(output).any(), "Output contains NaN values"
    assert not torch.isinf(output).any(), "Output contains Inf values"
    
    # Additional basic checks
    assert output.device.type == device, f"Expected device {device}, got {output.device.type}"
    
    # Verify parameter handling
    # Check that module stores parameters correctly
    # Compare as lists to handle both list and tuple storage
    assert list(unfold.kernel_size) == list(kernel_size), \
        f"Module kernel_size mismatch: expected {kernel_size}, got {unfold.kernel_size}"
    assert list(unfold.stride) == list(stride), \
        f"Module stride mismatch: expected {stride}, got {unfold.stride}"
    assert list(unfold.padding) == list(padding), \
        f"Module padding mismatch: expected {padding}, got {unfold.padding}"
    assert list(unfold.dilation) == list(dilation), \
        f"Module dilation mismatch: expected {dilation}, got {unfold.dilation}"
    
    # Verify output channels calculation
    expected_channels = channels * kernel_size[0] * kernel_size[1]
    assert output.size(1) == expected_channels, \
        f"Expected channels {expected_channels}, got {output.size(1)}"
    
    # Verify output blocks calculation
    # For 2x2 input with 2x2 kernel, stride 1, padding 0, dilation 1:
    # output_h = floor((2 + 2*0 - 1*(2-1) - 1)/1 + 1) = floor((2 - 1 - 1)/1 + 1) = floor(0 + 1) = 1
    # output_w = same = 1
    # total_blocks = 1 * 1 = 1
    expected_blocks = 1
    assert output.size(2) == expected_blocks, \
        f"Expected {expected_blocks} blocks, got {output.size(2)}"
    
    # Verify that output has correct values (should extract the single 2x2 block)
    # The output should be a 3D tensor of shape (1, 4, 1) for 1 batch, 1*2*2=4 channels, 1 block
    assert output.shape == (batch_size, expected_channels, expected_blocks), \
        f"Expected shape ({batch_size}, {expected_channels}, {expected_blocks}), got {output.shape}"
# ==== BLOCK:CASE_07 END ====

# ==== BLOCK:CASE_08 START ====
@pytest.mark.parametrize(
    "kernel_size,stride,padding,dilation,batch_size,channels,input_height,input_width,dtype,device,expect_error",
    [
        # Error case from test plan - kernel_size = 0 should raise an error
        (0, 1, 0, 1, 1, 1, 2, 2, torch.float32, 'cpu', True),
        # Additional valid case to cover else branch
        (2, 1, 0, 1, 1, 1, 4, 4, torch.float32, 'cpu', False),
    ]
)
def test_unfold_error_handling(kernel_size, stride, padding, dilation, batch_size, channels, input_height, input_width, dtype, device, expect_error):
    """
    TC-08: Unfold错误处理
    Test Unfold error handling for invalid parameters
    """
    if expect_error:
        # Test that invalid parameters raise appropriate exceptions
        with pytest.raises((ValueError, RuntimeError)) as exc_info:
            # Create Unfold module with invalid parameters
            unfold = Unfold(
                kernel_size=kernel_size,
                stride=stride,
                padding=padding,
                dilation=dilation
            )
            
            # Try to create input tensor (might fail earlier)
            input_tensor = create_unfold_input(
                batch_size=batch_size,
                channels=channels,
                input_height=input_height,
                input_width=input_width,
                dtype=dtype,
                device=device
            )
            
            # Try forward pass (should fail if module creation succeeded)
            output = unfold(input_tensor)
        
        # Verify error message contains relevant information
        error_msg = str(exc_info.value).lower()
        # Check for kernel size related error
        assert any(keyword in error_msg for keyword in ['kernel', 'size', 'positive', 'zero', 'invalid']), \
            f"Error message should mention kernel/size issue, got: {error_msg}"
    else:
        # This branch is for future extensions if needed
        # Create Unfold module with valid parameters
        unfold = Unfold(
            kernel_size=kernel_size,
            stride=stride,
            padding=padding,
            dilation=dilation
        )
        
        # Create valid input tensor
        input_tensor = create_unfold_input(
            batch_size=batch_size,
            channels=channels,
            input_height=input_height,
            input_width=input_width,
            dtype=dtype,
            device=device
        )
        
        # Forward pass
        output = unfold(input_tensor)
        
        # Basic assertions
        assert output.shape[0] == batch_size
        assert output.dtype == dtype
        assert output.device.type == device
        
        # Additional weak assertions
        assert torch.isfinite(output).all(), "Output contains non-finite values"
        assert not torch.isnan(output).any(), "Output contains NaN values"
        assert not torch.isinf(output).any(), "Output contains Inf values"
        
        # Shape check
        expected_shape = compute_unfold_output_shape(
            batch_size, channels, input_height, input_width, kernel_size, stride, padding, dilation
        )
        assert output.shape == expected_shape, f"Expected shape {expected_shape}, got {output.shape}"
# ==== BLOCK:CASE_08 END ====

# ==== BLOCK:FOOTER START ====
# Helper functions for Unfold tests
def compute_unfold_output_shape(batch_size, channels, input_height, input_width, kernel_size, stride, padding, dilation):
    """Compute expected output shape for Unfold operation"""
    if isinstance(kernel_size, int):
        kernel_size = (kernel_size, kernel_size)
    if isinstance(stride, int):
        stride = (stride, stride)
    if isinstance(padding, int):
        padding = (padding, padding)
    if isinstance(dilation, int):
        dilation = (dilation, dilation)
    
    # Compute output spatial dimensions
    # Formula: L = ∏_{i=1}^2 ⌊(input_size[i] + 2*padding[i] - dilation[i]*(kernel_size[i]-1) - 1)/stride[i] + 1⌋
    output_h = math.floor((input_height + 2*padding[0] - dilation[0]*(kernel_size[0]-1) - 1) / stride[0] + 1)
    output_w = math.floor((input_width + 2*padding[1] - dilation[1]*(kernel_size[1]-1) - 1) / stride[1] + 1)
    total_blocks = output_h * output_w
    
    # Unfold output shape: (N, C × ∏(kernel_size), L)
    output_channels = channels * kernel_size[0] * kernel_size[1]
    return (batch_size, output_channels, total_blocks)

def create_unfold_input(batch_size, channels, input_height, input_width, dtype=torch.float32, device='cpu'):
    """Create valid input tensor for Unfold operation"""
    input_tensor = torch.randn(batch_size, channels, input_height, input_width, dtype=dtype, device=device)
    return input_tensor
# ==== BLOCK:FOOTER END ====