=== Run Tests ===
.F...............................ssssssssF....FF.........ssssss.......   [100%]
=================================== FAILURES ===================================
__ TestTorchCudaRandomCudaUnavailable.test_get_rng_state_all_cuda_unavailable __

self = <test_torch_cuda_random_cuda_unavailable.TestTorchCudaRandomCudaUnavailable object at 0x14028bd90>

    def test_get_rng_state_all_cuda_unavailable(self):
        """Test get_rng_state_all when CUDA is not available.
    
        This function calls get_rng_state() for each device, which will
        raise AssertionError when torch is not compiled with CUDA enabled.
        """
        with patch('torch.cuda.is_available', return_value=False):
>           with pytest.raises(AssertionError) as exc_info:
E           Failed: DID NOT RAISE <class 'AssertionError'>

tests/test_torch_cuda_random_cuda_unavailable.py:36: Failed
_ TestTorchCudaRandomG2CudaUnavailable.test_get_rng_state_all_cuda_unavailable _

self = <test_torch_cuda_random_g2_cuda_unavailable.TestTorchCudaRandomG2CudaUnavailable object at 0x140322e00>

    def test_get_rng_state_all_cuda_unavailable(self):
        """Test get_rng_state_all when CUDA is not available.
    
        This function calls get_rng_state() for each device, which will
        raise AssertionError when torch is not compiled with CUDA enabled.
        """
        with patch('torch.cuda.is_available', return_value=False):
>           with pytest.raises(AssertionError) as exc_info:
E           Failed: DID NOT RAISE <class 'AssertionError'>

tests/test_torch_cuda_random_g2_cuda_unavailable.py:22: Failed
_ TestTorchCudaRandomG2CudaUnavailable.test_invalid_device_index_cuda_unavailable _

self = <test_torch_cuda_random_g2_cuda_unavailable.TestTorchCudaRandomG2CudaUnavailable object at 0x140321690>

    def test_invalid_device_index_cuda_unavailable(self):
        """Test invalid device index when CUDA is not available."""
        with patch('torch.cuda.is_available', return_value=False):
            # Test with invalid device index for get_rng_state
            with pytest.raises(AssertionError) as exc_info:
                torch.cuda.get_rng_state(device=-1)
    
            error_msg = str(exc_info.value).lower()
            assert "torch not compiled with cuda enabled" in error_msg, \
                f"Error message should be 'Torch not compiled with CUDA enabled', got: {error_msg}"
    
            # Test with invalid device index for set_rng_state
            valid_state = torch.ByteTensor(100).random_(0, 256)
            # Should not raise any exception (uses _lazy_call)
>           torch.cuda.set_rng_state(valid_state, device=-1)

tests/test_torch_cuda_random_g2_cuda_unavailable.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

new_state = tensor([ 32, 117,  64, 145, 223, 238, 176,  10,  84,  25,  62, 216,  85,  58,
         26, 176, 204, 160,  97, 104,  9...50,
        206, 228,  84, 141,  65,  74, 178, 102, 165, 191, 251, 225,  37,  49,
         97,  81], dtype=torch.uint8)
device = -1

    def set_rng_state(new_state: Tensor, device: Union[int, str, torch.device] = 'cuda') -> None:
        r"""Sets the random number generator state of the specified GPU.
    
        Args:
            new_state (torch.ByteTensor): The desired state
            device (torch.device or int, optional): The device to set the RNG state.
                Default: ``'cuda'`` (i.e., ``torch.device('cuda')``, the current CUDA device).
        """
        new_state_copy = new_state.clone(memory_format=torch.contiguous_format)
        if isinstance(device, str):
            device = torch.device(device)
        elif isinstance(device, int):
>           device = torch.device('cuda', device)
E           RuntimeError: Device index must not be negative

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/cuda/random.py:55: RuntimeError
_ TestTorchCudaRandomG2CudaUnavailable.test_multi_device_batch_management_cuda_unavailable _

self = <test_torch_cuda_random_g2_cuda_unavailable.TestTorchCudaRandomG2CudaUnavailable object at 0x140321cf0>

    def test_multi_device_batch_management_cuda_unavailable(self):
        """Test multi-device batch management when CUDA is not available."""
        with patch('torch.cuda.is_available', return_value=False):
            # Test all G2 functions in CUDA unavailable scenario
    
            # get_rng_state_all should raise AssertionError
>           with pytest.raises(AssertionError):
E           Failed: DID NOT RAISE <class 'AssertionError'>

tests/test_torch_cuda_random_g2_cuda_unavailable.py:95: Failed
================================ tests coverage ================================
______________ coverage: platform darwin, python 3.10.19-final-0 _______________

Name                                                  Stmts   Miss Branch BrPart  Cover   Missing
-------------------------------------------------------------------------------------------------
tests/test_torch_cuda_random_cuda_unavailable.py         79      2      2      0    98%   39-40
tests/test_torch_cuda_random_g1.py                      177    136     28      0    20%   37-42, 47-48, 53-54, 59-60, 84-144, 169-251, 277, 302, 325-367, 391-448, 480-483, 494, 505-515, 526-534, 541-555, 566-572
tests/test_torch_cuda_random_g1_cuda_unavailable.py      76      0      2      0   100%
tests/test_torch_cuda_random_g2.py                      239    170     62      8    27%   34, 38, 47-48, 53-60, 96-188, 226-281, 311-313, 317-386, 416-418, 422-493, 528-530, 533-551, 561->exit, 566-567
tests/test_torch_cuda_random_g2_cuda_unavailable.py      72     10      2      0    86%   25-26, 99-115
tests/test_torch_cuda_random_g2_temp.py                 149    123     40      0    14%   31-36, 45-46, 51-58, 81-177, 202-261, 278, 286-299, 305-323, 333-364
-------------------------------------------------------------------------------------------------
TOTAL                                                   792    441    136      8    40%
Coverage XML written to file coverage.xml
=========================== short test summary info ============================
FAILED tests/test_torch_cuda_random_cuda_unavailable.py::TestTorchCudaRandomCudaUnavailable::test_get_rng_state_all_cuda_unavailable
FAILED tests/test_torch_cuda_random_g2_cuda_unavailable.py::TestTorchCudaRandomG2CudaUnavailable::test_get_rng_state_all_cuda_unavailable
FAILED tests/test_torch_cuda_random_g2_cuda_unavailable.py::TestTorchCudaRandomG2CudaUnavailable::test_invalid_device_index_cuda_unavailable
FAILED tests/test_torch_cuda_random_g2_cuda_unavailable.py::TestTorchCudaRandomG2CudaUnavailable::test_multi_device_batch_management_cuda_unavailable
4 failed, 52 passed, 14 skipped in 0.88s

Error: exit 1