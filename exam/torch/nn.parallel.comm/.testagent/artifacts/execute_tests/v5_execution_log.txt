=== Run Tests ===
FFFFF.ssFFFFFFFFF                                                        [100%]
=================================== FAILURES ===================================
_ TestBroadcastFunctions.test_broadcast_basic[dtype0-cuda:0-shape0-target_devices0] _

self = <test_torch_nn_parallel_comm_broadcast.TestBroadcastFunctions object at 0x127aaf580>
cuda_devices = [device(type='cpu'), device(type='cpu'), device(type='cpu')]
random_tensor = <function random_tensor.<locals>._create at 0x127aea7a0>
dtype = torch.float32, device = 'cuda:0', shape = (4, 8)
target_devices = ['cuda:0', 'cuda:1']

    @pytest.mark.parametrize("dtype,device,shape,target_devices", [
        (torch.float32, "cuda:0", (4, 8), ["cuda:0", "cuda:1"]),
    ])
    def test_broadcast_basic(self, cuda_devices, random_tensor, dtype, device, shape, target_devices):
        """TC-01: broadcast基本功能
    
        测试单GPU到多GPU的广播功能正确性
        """
        # 跳过如果设备不足
        if len(cuda_devices) < len(target_devices):
            pytest.skip(f"Need {len(target_devices)} CUDA devices, got {len(cuda_devices)}")
    
        # 创建源张量
>       src_tensor = random_tensor(shape, dtype=dtype, device=device)

tests/test_torch_nn_parallel_comm_broadcast.py:66: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/test_torch_nn_parallel_comm_broadcast.py:41: in _create
    tensor = torch.randn(*shape, dtype=dtype, device=device)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _lazy_init():
        global _initialized, _queued_calls
        if is_initialized() or hasattr(_tls, 'is_initializing'):
            return
        with _initialization_lock:
            # We be double-checked locking, boys!  This is OK because
            # the above test was GIL protected anyway.  The inner test
            # is for when a thread blocked on some other thread which was
            # doing the initialization; when they get the lock, they will
            # find there is nothing left to do.
            if is_initialized():
                return
            # It is important to prevent other threads from entering _lazy_init
            # immediately, while we are still guaranteed to have the GIL, because some
            # of the C calls we make below will release the GIL
            if _is_in_bad_fork():
                raise RuntimeError(
                    "Cannot re-initialize CUDA in forked subprocess. To use CUDA with "
                    "multiprocessing, you must use the 'spawn' start method")
            if not hasattr(torch._C, '_cuda_getDeviceCount'):
>               raise AssertionError("Torch not compiled with CUDA enabled")
E               AssertionError: Torch not compiled with CUDA enabled

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/cuda/__init__.py:221: AssertionError
_ TestBroadcastFunctions.test_broadcast_basic_cpu_fallback[dtype0-shape0-target_devices0] _

self = <test_torch_nn_parallel_comm_broadcast.TestBroadcastFunctions object at 0x127aafb20>
random_tensor = <function random_tensor.<locals>._create at 0x127ca8280>
dtype = torch.float32, shape = (4, 8), target_devices = ['cpu', 'cpu']

    @pytest.mark.parametrize("dtype,shape,target_devices", [
        # CPU回退测试用例
        (torch.float32, (4, 8), ["cpu", "cpu"]),
        (torch.float64, (10, 10), ["cpu", "cpu", "cpu"]),
        (torch.complex64, (2, 2), ["cpu", "cpu"]),
    ])
    def test_broadcast_basic_cpu_fallback(self, random_tensor, dtype, shape, target_devices):
        """TC-01 CPU回退版本: broadcast基本功能（CPU设备）
    
        在没有CUDA设备时测试广播功能正确性
        """
        # 创建源张量（在CPU上）
        src_tensor = random_tensor(shape, dtype=dtype, device="cpu")
        src_data = src_tensor.clone()
    
        # 使用mock来模拟CUDA不可用的情况
        # 由于broadcast函数内部调用_get_device_index时没有设置allow_cpu=True
        # 我们需要mock这个函数来支持CPU设备
        with patch('torch.nn.parallel.comm._get_device_index') as mock_get_device_index:
            # 模拟_get_device_index函数，对于CPU设备返回-1
            def mock_get_device_index_func(device, optional=False, allow_cpu=False):
                if isinstance(device, str):
                    device = torch.device(device)
                if isinstance(device, torch.device):
                    if device.type == "cpu":
                        return -1
                    else:
                        # 对于CUDA设备，返回设备索引
                        return device.index if device.index is not None else 0
                elif isinstance(device, int):
                    return device
                else:
                    raise ValueError(f"Unexpected device type: {type(device)}")
    
            mock_get_device_index.side_effect = mock_get_device_index_func
    
            # 执行广播
>           result = comm.broadcast(src_tensor, devices=target_devices)

tests/test_torch_nn_parallel_comm_broadcast.py:140: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = tensor([[ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784, -1.2345, -0.0431, -1.6047],
        [-0.7521,  1.6487, -0.3925, ...-0.7581,  1.0783,  0.8008,  1.6806],
        [ 1.2791,  1.2964,  0.6105,  1.3347, -0.2316,  0.0418, -0.2516,  0.8599]])
devices = [-1, -1]

    def broadcast(tensor, devices=None, *, out=None):
        r"""Broadcasts a tensor to specified GPU devices.
    
        Args:
            tensor (Tensor): tensor to broadcast. Can be on CPU or GPU.
            devices (Iterable[torch.device, str or int], optional): an iterable of
              GPU devices, among which to broadcast.
            out (Sequence[Tensor], optional, keyword-only): the GPU tensors to
              store output results.
    
        .. note::
            Exactly one of :attr:`devices` and :attr:`out` must be specified.
    
        Returns:
            - If :attr:`devices` is specified,
                a tuple containing copies of :attr:`tensor`, placed on
                :attr:`devices`.
            - If :attr:`out` is specified,
                a tuple containing :attr:`out` tensors, each containing a copy of
                :attr:`tensor`.
        """
        tensor = _handle_complex(tensor)
        if not ((devices is None) ^ (out is None)):
            raise RuntimeError(
                "Exactly one of 'devices' and 'out' must be specified, but got "
                "devices={} and out={}".format(devices, out))
        if devices is not None:
            devices = [_get_device_index(d) for d in devices]
>           return torch._C._broadcast(tensor, devices)
E           AttributeError: module 'torch._C' has no attribute '_broadcast'

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/comm.py:36: AttributeError
_ TestBroadcastFunctions.test_broadcast_basic_cpu_fallback[dtype1-shape1-target_devices1] _

self = <test_torch_nn_parallel_comm_broadcast.TestBroadcastFunctions object at 0x127aafca0>
random_tensor = <function random_tensor.<locals>._create at 0x127ca9630>
dtype = torch.float64, shape = (10, 10), target_devices = ['cpu', 'cpu', 'cpu']

    @pytest.mark.parametrize("dtype,shape,target_devices", [
        # CPU回退测试用例
        (torch.float32, (4, 8), ["cpu", "cpu"]),
        (torch.float64, (10, 10), ["cpu", "cpu", "cpu"]),
        (torch.complex64, (2, 2), ["cpu", "cpu"]),
    ])
    def test_broadcast_basic_cpu_fallback(self, random_tensor, dtype, shape, target_devices):
        """TC-01 CPU回退版本: broadcast基本功能（CPU设备）
    
        在没有CUDA设备时测试广播功能正确性
        """
        # 创建源张量（在CPU上）
        src_tensor = random_tensor(shape, dtype=dtype, device="cpu")
        src_data = src_tensor.clone()
    
        # 使用mock来模拟CUDA不可用的情况
        # 由于broadcast函数内部调用_get_device_index时没有设置allow_cpu=True
        # 我们需要mock这个函数来支持CPU设备
        with patch('torch.nn.parallel.comm._get_device_index') as mock_get_device_index:
            # 模拟_get_device_index函数，对于CPU设备返回-1
            def mock_get_device_index_func(device, optional=False, allow_cpu=False):
                if isinstance(device, str):
                    device = torch.device(device)
                if isinstance(device, torch.device):
                    if device.type == "cpu":
                        return -1
                    else:
                        # 对于CUDA设备，返回设备索引
                        return device.index if device.index is not None else 0
                elif isinstance(device, int):
                    return device
                else:
                    raise ValueError(f"Unexpected device type: {type(device)}")
    
            mock_get_device_index.side_effect = mock_get_device_index_func
    
            # 执行广播
>           result = comm.broadcast(src_tensor, devices=target_devices)

tests/test_torch_nn_parallel_comm_broadcast.py:140: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = tensor([[ 0.4212,  1.5046,  1.2716,  0.6187, -0.0372,  1.0352, -0.0101,  0.0895,
          0.0840,  0.3900],
        [....4981,  0.7066, -2.0855, -0.4383,  2.4478, -1.2867,  1.4204,  0.0433,
         -0.6199, -0.6909]], dtype=torch.float64)
devices = [-1, -1, -1]

    def broadcast(tensor, devices=None, *, out=None):
        r"""Broadcasts a tensor to specified GPU devices.
    
        Args:
            tensor (Tensor): tensor to broadcast. Can be on CPU or GPU.
            devices (Iterable[torch.device, str or int], optional): an iterable of
              GPU devices, among which to broadcast.
            out (Sequence[Tensor], optional, keyword-only): the GPU tensors to
              store output results.
    
        .. note::
            Exactly one of :attr:`devices` and :attr:`out` must be specified.
    
        Returns:
            - If :attr:`devices` is specified,
                a tuple containing copies of :attr:`tensor`, placed on
                :attr:`devices`.
            - If :attr:`out` is specified,
                a tuple containing :attr:`out` tensors, each containing a copy of
                :attr:`tensor`.
        """
        tensor = _handle_complex(tensor)
        if not ((devices is None) ^ (out is None)):
            raise RuntimeError(
                "Exactly one of 'devices' and 'out' must be specified, but got "
                "devices={} and out={}".format(devices, out))
        if devices is not None:
            devices = [_get_device_index(d) for d in devices]
>           return torch._C._broadcast(tensor, devices)
E           AttributeError: module 'torch._C' has no attribute '_broadcast'

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/comm.py:36: AttributeError
_ TestBroadcastFunctions.test_broadcast_basic_cpu_fallback[dtype2-shape2-target_devices2] _

self = <test_torch_nn_parallel_comm_broadcast.TestBroadcastFunctions object at 0x127aafe80>
random_tensor = <function random_tensor.<locals>._create at 0x127caa9e0>
dtype = torch.complex64, shape = (2, 2), target_devices = ['cpu', 'cpu']

    @pytest.mark.parametrize("dtype,shape,target_devices", [
        # CPU回退测试用例
        (torch.float32, (4, 8), ["cpu", "cpu"]),
        (torch.float64, (10, 10), ["cpu", "cpu", "cpu"]),
        (torch.complex64, (2, 2), ["cpu", "cpu"]),
    ])
    def test_broadcast_basic_cpu_fallback(self, random_tensor, dtype, shape, target_devices):
        """TC-01 CPU回退版本: broadcast基本功能（CPU设备）
    
        在没有CUDA设备时测试广播功能正确性
        """
        # 创建源张量（在CPU上）
        src_tensor = random_tensor(shape, dtype=dtype, device="cpu")
        src_data = src_tensor.clone()
    
        # 使用mock来模拟CUDA不可用的情况
        # 由于broadcast函数内部调用_get_device_index时没有设置allow_cpu=True
        # 我们需要mock这个函数来支持CPU设备
        with patch('torch.nn.parallel.comm._get_device_index') as mock_get_device_index:
            # 模拟_get_device_index函数，对于CPU设备返回-1
            def mock_get_device_index_func(device, optional=False, allow_cpu=False):
                if isinstance(device, str):
                    device = torch.device(device)
                if isinstance(device, torch.device):
                    if device.type == "cpu":
                        return -1
                    else:
                        # 对于CUDA设备，返回设备索引
                        return device.index if device.index is not None else 0
                elif isinstance(device, int):
                    return device
                else:
                    raise ValueError(f"Unexpected device type: {type(device)}")
    
            mock_get_device_index.side_effect = mock_get_device_index_func
    
            # 执行广播
>           result = comm.broadcast(src_tensor, devices=target_devices)

tests/test_torch_nn_parallel_comm_broadcast.py:140: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = tensor([[[-0.7529,  0.0746],
         [ 1.3957,  0.7568]],

        [[-1.2289,  0.1302],
         [-0.1105, -0.4724]]])
devices = [-1, -1]

    def broadcast(tensor, devices=None, *, out=None):
        r"""Broadcasts a tensor to specified GPU devices.
    
        Args:
            tensor (Tensor): tensor to broadcast. Can be on CPU or GPU.
            devices (Iterable[torch.device, str or int], optional): an iterable of
              GPU devices, among which to broadcast.
            out (Sequence[Tensor], optional, keyword-only): the GPU tensors to
              store output results.
    
        .. note::
            Exactly one of :attr:`devices` and :attr:`out` must be specified.
    
        Returns:
            - If :attr:`devices` is specified,
                a tuple containing copies of :attr:`tensor`, placed on
                :attr:`devices`.
            - If :attr:`out` is specified,
                a tuple containing :attr:`out` tensors, each containing a copy of
                :attr:`tensor`.
        """
        tensor = _handle_complex(tensor)
        if not ((devices is None) ^ (out is None)):
            raise RuntimeError(
                "Exactly one of 'devices' and 'out' must be specified, but got "
                "devices={} and out={}".format(devices, out))
        if devices is not None:
            devices = [_get_device_index(d) for d in devices]
>           return torch._C._broadcast(tensor, devices)
E           AttributeError: module 'torch._C' has no attribute '_broadcast'

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/comm.py:36: AttributeError
___________ TestBroadcastFunctions.test_broadcast_parameter_conflict ___________

self = <test_torch_nn_parallel_comm_broadcast.TestBroadcastFunctions object at 0x127c001c0>
cuda_devices = [device(type='cpu'), device(type='cpu'), device(type='cpu')]
random_tensor = <function random_tensor.<locals>._create at 0x127ca9c60>

    def test_broadcast_parameter_conflict(self, cuda_devices, random_tensor):
        """TC-02: broadcast参数冲突异常
    
        测试devices和out参数同时提供时的异常
        """
        if len(cuda_devices) < 2:
            pytest.skip("Need at least 2 CUDA devices")
    
        # 创建源张量
        shape = (2, 3)
        dtype = torch.float32
>       src_tensor = random_tensor(shape, dtype=dtype, device="cuda:0")

tests/test_torch_nn_parallel_comm_broadcast.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/test_torch_nn_parallel_comm_broadcast.py:41: in _create
    tensor = torch.randn(*shape, dtype=dtype, device=device)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _lazy_init():
        global _initialized, _queued_calls
        if is_initialized() or hasattr(_tls, 'is_initializing'):
            return
        with _initialization_lock:
            # We be double-checked locking, boys!  This is OK because
            # the above test was GIL protected anyway.  The inner test
            # is for when a thread blocked on some other thread which was
            # doing the initialization; when they get the lock, they will
            # find there is nothing left to do.
            if is_initialized():
                return
            # It is important to prevent other threads from entering _lazy_init
            # immediately, while we are still guaranteed to have the GIL, because some
            # of the C calls we make below will release the GIL
            if _is_in_bad_fork():
                raise RuntimeError(
                    "Cannot re-initialize CUDA in forked subprocess. To use CUDA with "
                    "multiprocessing, you must use the 'spawn' start method")
            if not hasattr(torch._C, '_cuda_getDeviceCount'):
>               raise AssertionError("Torch not compiled with CUDA enabled")
E               AssertionError: Torch not compiled with CUDA enabled

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/cuda/__init__.py:221: AssertionError
_______ TestReduceAddFunctions.test_reduce_add_shape_mismatch_exception ________

self = <test_torch_nn_parallel_comm_reduce.TestReduceAddFunctions object at 0x127c03e80>
cuda_devices = [device(type='cpu'), device(type='cpu'), device(type='cpu')]
random_tensor = <function random_tensor.<locals>._create at 0x127cf8160>

    def test_reduce_add_shape_mismatch_exception(self, cuda_devices, random_tensor):
        """TC-06: reduce_add形状不匹配异常
    
        测试当输入张量形状不匹配时抛出RuntimeError异常
        """
        # 检查CUDA可用性，如果不可用则使用CPU回退
        if not torch.cuda.is_available():
            # CPU回退测试
            devices = ["cpu", "cpu"]
            destination = "cpu"
        else:
            # 跳过如果设备不足
            if len(cuda_devices) < 2:
                pytest.skip(f"Need at least 2 CUDA devices, got {len(cuda_devices)}")
            devices = ["cuda:0", "cuda:1"]
            destination = "cuda:0"
    
        # 创建形状不匹配的张量列表
        # 第一个张量形状为 (2, 3)，第二个为 (3, 4)
        inputs = []
    
        # 第一个张量：形状 (2, 3)
        shape1 = (2, 3)
        tensor1 = random_tensor(shape1, dtype=torch.float32, device=devices[0])
        inputs.append(tensor1)
    
        # 第二个张量：形状 (3, 4) - 与第一个不匹配
        shape2 = (3, 4)
        tensor2 = random_tensor(shape2, dtype=torch.float32, device=devices[1])
        inputs.append(tensor2)
    
        # 使用mock来模拟CUDA不可用的情况
        with patch('torch.nn.parallel.comm._get_device_index') as mock_get_device_index:
            # 模拟_get_device_index函数，对于CPU设备返回-1
            def mock_get_device_index_func(device, optional=False, allow_cpu=False):
                if isinstance(device, str):
                    device = torch.device(device)
                if isinstance(device, torch.device):
                    if device.type == "cpu":
                        return -1
                    else:
                        # 对于CUDA设备，返回设备索引
                        return device.index if device.index is not None else 0
                elif isinstance(device, int):
                    return device
                else:
                    raise ValueError(f"Unexpected device type: {type(device)}")
    
            mock_get_device_index.side_effect = mock_get_device_index_func
    
            # 验证当形状不匹配时抛出RuntimeError异常
            with pytest.raises(RuntimeError) as exc_info:
>               comm.reduce_add(inputs, destination=destination)

tests/test_torch_nn_parallel_comm_reduce.py:190: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

inputs = [tensor([[ 0.3367,  0.1288,  0.2345],
        [ 0.2303, -1.1229, -0.1863]]), tensor([[ 2.2082, -0.6380,  0.4617,  0.2674],
        [ 0.5349,  0.8094,  1.1103, -1.6898],
        [-0.9890,  0.9580,  1.3221,  0.8172]])]
destination = -1

    def reduce_add(inputs, destination=None):
        """Sums tensors from multiple GPUs.
    
        All inputs should have matching shapes, dtype, and layout. The output tensor
        will be of the same shape, dtype, and layout.
    
        Args:
            inputs (Iterable[Tensor]): an iterable of tensors to add.
            destination (int, optional): a device on which the output will be
                placed (default: current device).
    
        Returns:
            A tensor containing an elementwise sum of all inputs, placed on the
            :attr:`destination` device.
        """
        destination = _get_device_index(destination, optional=True)
        input_size = inputs[0].size()
        root_index = None  # index of input tensor that already is on the correct device
        for i, inp in enumerate(inputs):
>           assert inp.device.type != "cpu", "reduce_add expects all inputs to be on GPUs"
E           AssertionError: reduce_add expects all inputs to be on GPUs

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/comm.py:80: AssertionError
_ TestScatterGatherFunctions.test_scatter_gather_roundtrip[dtype0-cuda:0-shape0-target_devices0-0] _

self = <test_torch_nn_parallel_comm_scatter_gather.TestScatterGatherFunctions object at 0x133048a30>
cuda_devices = [device(type='cpu'), device(type='cpu'), device(type='cpu')]
random_tensor = <function random_tensor.<locals>._create at 0x127ca8280>
dtype = torch.float32, device = 'cuda:0', shape = (8, 6)
target_devices = ['cuda:0', 'cuda:1'], dim = 0

    @pytest.mark.parametrize("dtype,device,shape,target_devices,dim", [
        # 原始测试用例 (High优先级)
        (torch.float32, "cuda:0", (8, 6), ["cuda:0", "cuda:1"], 0),
        # 参数扩展 (Medium优先级) - 扩展数据类型、设备数量和维度
        (torch.float64, "cuda:0", (12, 8), ["cuda:0", "cuda:1", "cuda:2"], 1),
    ])
    def test_scatter_gather_roundtrip(self, cuda_devices, random_tensor, dtype, device, shape, target_devices, dim):
        """TC-08: scatter_gather往返完整性
    
        测试张量分散-聚集往返数据完整性
        """
        # 跳过如果设备不足
        if len(cuda_devices) < len(target_devices):
            pytest.skip(f"Need {len(target_devices)} CUDA devices, got {len(cuda_devices)}")
    
        # 创建源张量
>       src_tensor = random_tensor(shape, dtype=dtype, device=device)

tests/test_torch_nn_parallel_comm_scatter_gather.py:69: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/test_torch_nn_parallel_comm_scatter_gather.py:41: in _create
    tensor = torch.randn(*shape, dtype=dtype, device=device)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _lazy_init():
        global _initialized, _queued_calls
        if is_initialized() or hasattr(_tls, 'is_initializing'):
            return
        with _initialization_lock:
            # We be double-checked locking, boys!  This is OK because
            # the above test was GIL protected anyway.  The inner test
            # is for when a thread blocked on some other thread which was
            # doing the initialization; when they get the lock, they will
            # find there is nothing left to do.
            if is_initialized():
                return
            # It is important to prevent other threads from entering _lazy_init
            # immediately, while we are still guaranteed to have the GIL, because some
            # of the C calls we make below will release the GIL
            if _is_in_bad_fork():
                raise RuntimeError(
                    "Cannot re-initialize CUDA in forked subprocess. To use CUDA with "
                    "multiprocessing, you must use the 'spawn' start method")
            if not hasattr(torch._C, '_cuda_getDeviceCount'):
>               raise AssertionError("Torch not compiled with CUDA enabled")
E               AssertionError: Torch not compiled with CUDA enabled

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/cuda/__init__.py:221: AssertionError
_ TestScatterGatherFunctions.test_scatter_gather_roundtrip[dtype1-cuda:0-shape1-target_devices1-1] _

self = <test_torch_nn_parallel_comm_scatter_gather.TestScatterGatherFunctions object at 0x133048b80>
cuda_devices = [device(type='cpu'), device(type='cpu'), device(type='cpu')]
random_tensor = <function random_tensor.<locals>._create at 0x127cfbb50>
dtype = torch.float64, device = 'cuda:0', shape = (12, 8)
target_devices = ['cuda:0', 'cuda:1', 'cuda:2'], dim = 1

    @pytest.mark.parametrize("dtype,device,shape,target_devices,dim", [
        # 原始测试用例 (High优先级)
        (torch.float32, "cuda:0", (8, 6), ["cuda:0", "cuda:1"], 0),
        # 参数扩展 (Medium优先级) - 扩展数据类型、设备数量和维度
        (torch.float64, "cuda:0", (12, 8), ["cuda:0", "cuda:1", "cuda:2"], 1),
    ])
    def test_scatter_gather_roundtrip(self, cuda_devices, random_tensor, dtype, device, shape, target_devices, dim):
        """TC-08: scatter_gather往返完整性
    
        测试张量分散-聚集往返数据完整性
        """
        # 跳过如果设备不足
        if len(cuda_devices) < len(target_devices):
            pytest.skip(f"Need {len(target_devices)} CUDA devices, got {len(cuda_devices)}")
    
        # 创建源张量
>       src_tensor = random_tensor(shape, dtype=dtype, device=device)

tests/test_torch_nn_parallel_comm_scatter_gather.py:69: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/test_torch_nn_parallel_comm_scatter_gather.py:41: in _create
    tensor = torch.randn(*shape, dtype=dtype, device=device)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _lazy_init():
        global _initialized, _queued_calls
        if is_initialized() or hasattr(_tls, 'is_initializing'):
            return
        with _initialization_lock:
            # We be double-checked locking, boys!  This is OK because
            # the above test was GIL protected anyway.  The inner test
            # is for when a thread blocked on some other thread which was
            # doing the initialization; when they get the lock, they will
            # find there is nothing left to do.
            if is_initialized():
                return
            # It is important to prevent other threads from entering _lazy_init
            # immediately, while we are still guaranteed to have the GIL, because some
            # of the C calls we make below will release the GIL
            if _is_in_bad_fork():
                raise RuntimeError(
                    "Cannot re-initialize CUDA in forked subprocess. To use CUDA with "
                    "multiprocessing, you must use the 'spawn' start method")
            if not hasattr(torch._C, '_cuda_getDeviceCount'):
>               raise AssertionError("Torch not compiled with CUDA enabled")
E               AssertionError: Torch not compiled with CUDA enabled

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/cuda/__init__.py:221: AssertionError
_ TestScatterGatherFunctions.test_scatter_gather_roundtrip_cpu_fallback[dtype0-shape0-target_devices0-0] _

self = <test_torch_nn_parallel_comm_scatter_gather.TestScatterGatherFunctions object at 0x133049090>
random_tensor = <function random_tensor.<locals>._create at 0x127cfaa70>
dtype = torch.float32, shape = (8, 6), target_devices = ['cpu', 'cpu'], dim = 0

    @pytest.mark.parametrize("dtype,shape,target_devices,dim", [
        # CPU回退测试用例
        (torch.float32, (8, 6), ["cpu", "cpu"], 0),
        (torch.float64, (12, 8), ["cpu", "cpu", "cpu"], 1),
    ])
    def test_scatter_gather_roundtrip_cpu_fallback(self, random_tensor, dtype, shape, target_devices, dim):
        """TC-08 CPU回退版本: scatter_gather往返完整性（CPU设备）
    
        在没有CUDA设备时测试张量分散-聚集往返数据完整性
        """
        # 创建源张量（在CPU上）
        src_tensor = random_tensor(shape, dtype=dtype, device="cpu")
        src_data = src_tensor.clone()
    
        # 使用mock来模拟CUDA不可用的情况
        with patch('torch.nn.parallel.comm._get_device_index') as mock_get_device_index:
            # 模拟_get_device_index函数，对于CPU设备返回-1
            def mock_get_device_index_func(device, optional=False, allow_cpu=False):
                if isinstance(device, str):
                    device = torch.device(device)
                if isinstance(device, torch.device):
                    if device.type == "cpu":
                        return -1
                    else:
                        # 对于CUDA设备，返回设备索引
                        return device.index if device.index is not None else 0
                elif isinstance(device, int):
                    return device
                else:
                    raise ValueError(f"Unexpected device type: {type(device)}")
    
            mock_get_device_index.side_effect = mock_get_device_index_func
    
            # 步骤1: 分散(scatter)到多个CPU设备
>           scattered = comm.scatter(src_tensor, devices=target_devices, dim=dim)

tests/test_torch_nn_parallel_comm_scatter_gather.py:164: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = tensor([[ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784, -1.2345],
        [-0.0431, -1.6047, -0.7521,  1.6487, -0.3925, ... 0.3189, -0.4245,  0.3057, -0.7746, -1.5576,  0.9956],
        [-0.8798, -0.6011, -1.2742,  2.1228, -1.2347, -0.4879]])
devices = [-1, -1], chunk_sizes = None, dim = 0, streams = None

    def scatter(tensor, devices=None, chunk_sizes=None, dim=0, streams=None, *, out=None):
        """Scatters tensor across multiple GPUs.
    
        Args:
            tensor (Tensor): tensor to scatter. Can be on CPU or GPU.
            devices (Iterable[torch.device, str or int], optional): an iterable of
              GPU devices, among which to scatter.
            chunk_sizes (Iterable[int], optional): sizes of chunks to be placed on
              each device. It should match :attr:`devices` in length and sums to
              ``tensor.size(dim)``. If not specified, :attr:`tensor` will be divided
              into equal chunks.
            dim (int, optional): A dimension along which to chunk :attr:`tensor`.
              Default: ``0``.
            streams (Iterable[Stream], optional): an iterable of Streams, among
              which to execute the scatter. If not specified, the default stream will
              be utilized.
            out (Sequence[Tensor], optional, keyword-only): the GPU tensors to
              store output results. Sizes of these tensors must match that of
              :attr:`tensor`, except for :attr:`dim`, where the total size must
              sum to ``tensor.size(dim)``.
    
        .. note::
            Exactly one of :attr:`devices` and :attr:`out` must be specified. When
            :attr:`out` is specified, :attr:`chunk_sizes` must not be specified and
            will be inferred from sizes of :attr:`out`.
    
        Returns:
            - If :attr:`devices` is specified,
                a tuple containing chunks of :attr:`tensor`, placed on
                :attr:`devices`.
            - If :attr:`out` is specified,
                a tuple containing :attr:`out` tensors, each containing a chunk of
                :attr:`tensor`.
        """
        tensor = _handle_complex(tensor)
        if out is None:
            devices = [_get_device_index(d) for d in devices]
>           return tuple(torch._C._scatter(tensor, devices, chunk_sizes, dim, streams))
E           AttributeError: module 'torch._C' has no attribute '_scatter'

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/comm.py:189: AttributeError
_ TestScatterGatherFunctions.test_scatter_gather_roundtrip_cpu_fallback[dtype1-shape1-target_devices1-1] _

self = <test_torch_nn_parallel_comm_scatter_gather.TestScatterGatherFunctions object at 0x133049630>
random_tensor = <function random_tensor.<locals>._create at 0x127cfbd00>
dtype = torch.float64, shape = (12, 8), target_devices = ['cpu', 'cpu', 'cpu']
dim = 1

    @pytest.mark.parametrize("dtype,shape,target_devices,dim", [
        # CPU回退测试用例
        (torch.float32, (8, 6), ["cpu", "cpu"], 0),
        (torch.float64, (12, 8), ["cpu", "cpu", "cpu"], 1),
    ])
    def test_scatter_gather_roundtrip_cpu_fallback(self, random_tensor, dtype, shape, target_devices, dim):
        """TC-08 CPU回退版本: scatter_gather往返完整性（CPU设备）
    
        在没有CUDA设备时测试张量分散-聚集往返数据完整性
        """
        # 创建源张量（在CPU上）
        src_tensor = random_tensor(shape, dtype=dtype, device="cpu")
        src_data = src_tensor.clone()
    
        # 使用mock来模拟CUDA不可用的情况
        with patch('torch.nn.parallel.comm._get_device_index') as mock_get_device_index:
            # 模拟_get_device_index函数，对于CPU设备返回-1
            def mock_get_device_index_func(device, optional=False, allow_cpu=False):
                if isinstance(device, str):
                    device = torch.device(device)
                if isinstance(device, torch.device):
                    if device.type == "cpu":
                        return -1
                    else:
                        # 对于CUDA设备，返回设备索引
                        return device.index if device.index is not None else 0
                elif isinstance(device, int):
                    return device
                else:
                    raise ValueError(f"Unexpected device type: {type(device)}")
    
            mock_get_device_index.side_effect = mock_get_device_index_func
    
            # 步骤1: 分散(scatter)到多个CPU设备
>           scattered = comm.scatter(src_tensor, devices=target_devices, dim=dim)

tests/test_torch_nn_parallel_comm_scatter_gather.py:164: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = tensor([[ 0.0384, -0.1182, -1.7446, -0.4695,  0.4573,  0.5177, -0.2771, -0.6641],
        [ 0.2494,  0.2616, -1.5265, ...0.5671],
        [ 0.2010,  0.2412,  1.0836, -0.9592, -0.6303,  0.8235, -0.2507, -0.2796]],
       dtype=torch.float64)
devices = [-1, -1, -1], chunk_sizes = None, dim = 1, streams = None

    def scatter(tensor, devices=None, chunk_sizes=None, dim=0, streams=None, *, out=None):
        """Scatters tensor across multiple GPUs.
    
        Args:
            tensor (Tensor): tensor to scatter. Can be on CPU or GPU.
            devices (Iterable[torch.device, str or int], optional): an iterable of
              GPU devices, among which to scatter.
            chunk_sizes (Iterable[int], optional): sizes of chunks to be placed on
              each device. It should match :attr:`devices` in length and sums to
              ``tensor.size(dim)``. If not specified, :attr:`tensor` will be divided
              into equal chunks.
            dim (int, optional): A dimension along which to chunk :attr:`tensor`.
              Default: ``0``.
            streams (Iterable[Stream], optional): an iterable of Streams, among
              which to execute the scatter. If not specified, the default stream will
              be utilized.
            out (Sequence[Tensor], optional, keyword-only): the GPU tensors to
              store output results. Sizes of these tensors must match that of
              :attr:`tensor`, except for :attr:`dim`, where the total size must
              sum to ``tensor.size(dim)``.
    
        .. note::
            Exactly one of :attr:`devices` and :attr:`out` must be specified. When
            :attr:`out` is specified, :attr:`chunk_sizes` must not be specified and
            will be inferred from sizes of :attr:`out`.
    
        Returns:
            - If :attr:`devices` is specified,
                a tuple containing chunks of :attr:`tensor`, placed on
                :attr:`devices`.
            - If :attr:`out` is specified,
                a tuple containing :attr:`out` tensors, each containing a chunk of
                :attr:`tensor`.
        """
        tensor = _handle_complex(tensor)
        if out is None:
            devices = [_get_device_index(d) for d in devices]
>           return tuple(torch._C._scatter(tensor, devices, chunk_sizes, dim, streams))
E           AttributeError: module 'torch._C' has no attribute '_scatter'

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/comm.py:189: AttributeError
_____ TestScatterGatherFunctions.test_scatter_parameter_conflict_exception _____

self = <test_torch_nn_parallel_comm_scatter_gather.TestScatterGatherFunctions object at 0x133049120>
cuda_devices = [device(type='cpu'), device(type='cpu'), device(type='cpu')]
random_tensor = <function random_tensor.<locals>._create at 0x127cfaf80>

    def test_scatter_parameter_conflict_exception(self, cuda_devices, random_tensor):
        """TC-09: scatter参数冲突异常
    
        测试当同时提供devices和out参数时抛出RuntimeError异常
        """
        # 跳过如果设备不足
        if len(cuda_devices) < 2:
            pytest.skip(f"Need at least 2 CUDA devices, got {len(cuda_devices)}")
    
        # 测试参数
        dtype = torch.float32
        device = "cuda:0"
        shape = (6, 4)
        target_devices = ["cuda:0", "cuda:1"]
        dim = 0
    
        # 创建源张量
>       src_tensor = random_tensor(shape, dtype=dtype, device=device)

tests/test_torch_nn_parallel_comm_scatter_gather.py:243: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/test_torch_nn_parallel_comm_scatter_gather.py:41: in _create
    tensor = torch.randn(*shape, dtype=dtype, device=device)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _lazy_init():
        global _initialized, _queued_calls
        if is_initialized() or hasattr(_tls, 'is_initializing'):
            return
        with _initialization_lock:
            # We be double-checked locking, boys!  This is OK because
            # the above test was GIL protected anyway.  The inner test
            # is for when a thread blocked on some other thread which was
            # doing the initialization; when they get the lock, they will
            # find there is nothing left to do.
            if is_initialized():
                return
            # It is important to prevent other threads from entering _lazy_init
            # immediately, while we are still guaranteed to have the GIL, because some
            # of the C calls we make below will release the GIL
            if _is_in_bad_fork():
                raise RuntimeError(
                    "Cannot re-initialize CUDA in forked subprocess. To use CUDA with "
                    "multiprocessing, you must use the 'spawn' start method")
            if not hasattr(torch._C, '_cuda_getDeviceCount'):
>               raise AssertionError("Torch not compiled with CUDA enabled")
E               AssertionError: Torch not compiled with CUDA enabled

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/cuda/__init__.py:221: AssertionError
_ TestScatterGatherFunctions.test_scatter_parameter_conflict_exception_cpu_fallback _

self = <test_torch_nn_parallel_comm_scatter_gather.TestScatterGatherFunctions object at 0x133049c60>
random_tensor = <function random_tensor.<locals>._create at 0x127dc7400>

    def test_scatter_parameter_conflict_exception_cpu_fallback(self, random_tensor):
        """TC-09 CPU回退版本: scatter参数冲突异常（CPU设备）
    
        在没有CUDA设备时测试当同时提供devices和out参数时抛出RuntimeError异常
        """
        # 测试参数
        dtype = torch.float32
        device = "cpu"
        shape = (6, 4)
        target_devices = ["cpu", "cpu"]
        dim = 0
    
        # 创建源张量
        src_tensor = random_tensor(shape, dtype=dtype, device=device)
    
        # 创建输出张量列表（用于out参数）
        out_tensors = []
        chunk_size = shape[dim] // len(target_devices)
        for i, target_device in enumerate(target_devices):
            # 创建输出张量，形状与分散后的块匹配
            out_shape = list(shape)
            out_shape[dim] = chunk_size
            out_tensor = torch.empty(out_shape, dtype=dtype, device=target_device)
            out_tensors.append(out_tensor)
    
        # 使用mock来模拟CUDA不可用的情况
        with patch('torch.nn.parallel.comm._get_device_index') as mock_get_device_index:
            # 模拟_get_device_index函数，对于CPU设备返回-1
            def mock_get_device_index_func(device, optional=False, allow_cpu=False):
                if isinstance(device, str):
                    device = torch.device(device)
                if isinstance(device, torch.device):
                    if device.type == "cpu":
                        return -1
                    else:
                        # 对于CUDA设备，返回设备索引
                        return device.index if device.index is not None else 0
                elif isinstance(device, int):
                    return device
                else:
                    raise ValueError(f"Unexpected device type: {type(device)}")
    
            mock_get_device_index.side_effect = mock_get_device_index_func
    
            # weak断言验证 - 当同时提供devices和out参数时应该抛出RuntimeError异常
            with pytest.raises(RuntimeError) as exc_info:
                comm.scatter(src_tensor, devices=target_devices, dim=dim, out=out_tensors)
    
        # 验证异常消息包含关键信息
        exception_msg = str(exc_info.value)
        assert "devices" in exception_msg.lower(), \
            f"Exception message should mention 'devices', got: {exception_msg}"
        assert "out" in exception_msg.lower(), \
            f"Exception message should mention 'out', got: {exception_msg}"
        assert "must not be specified" in exception_msg, \
            f"Exception message should contain 'must not be specified', got: {exception_msg}"
    
        # 验证异常类型（应该是RuntimeError）
        assert exc_info.type == RuntimeError, \
            f"Expected RuntimeError, got {exc_info.type}"
    
        # 额外验证：单独使用devices参数应该正常工作
        with patch('torch.nn.parallel.comm._get_device_index') as mock_get_device_index:
            # 模拟_get_device_index函数，对于CPU设备返回-1
            def mock_get_device_index_func(device, optional=False, allow_cpu=False):
                if isinstance(device, str):
                    device = torch.device(device)
                if isinstance(device, torch.device):
                    if device.type == "cpu":
                        return -1
                    else:
                        # 对于CUDA设备，返回设备索引
                        return device.index if device.index is not None else 0
                elif isinstance(device, int):
                    return device
                else:
                    raise ValueError(f"Unexpected device type: {type(device)}")
    
            mock_get_device_index.side_effect = mock_get_device_index_func
    
>           result_with_devices = comm.scatter(src_tensor, devices=target_devices, dim=dim)

tests/test_torch_nn_parallel_comm_scatter_gather.py:367: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensor = tensor([[-9.2913e-01,  2.7619e-01, -5.3888e-01,  4.6258e-01],
        [-8.7189e-01, -2.7118e-02, -3.5325e-01,  1.4639e...   [-1.4129e+00, -1.8791e+00, -1.7983e-01,  7.9039e-01],
        [ 5.2394e-01, -2.6935e-01, -1.6191e+00,  1.2588e-03]])
devices = [-1, -1], chunk_sizes = None, dim = 0, streams = None

    def scatter(tensor, devices=None, chunk_sizes=None, dim=0, streams=None, *, out=None):
        """Scatters tensor across multiple GPUs.
    
        Args:
            tensor (Tensor): tensor to scatter. Can be on CPU or GPU.
            devices (Iterable[torch.device, str or int], optional): an iterable of
              GPU devices, among which to scatter.
            chunk_sizes (Iterable[int], optional): sizes of chunks to be placed on
              each device. It should match :attr:`devices` in length and sums to
              ``tensor.size(dim)``. If not specified, :attr:`tensor` will be divided
              into equal chunks.
            dim (int, optional): A dimension along which to chunk :attr:`tensor`.
              Default: ``0``.
            streams (Iterable[Stream], optional): an iterable of Streams, among
              which to execute the scatter. If not specified, the default stream will
              be utilized.
            out (Sequence[Tensor], optional, keyword-only): the GPU tensors to
              store output results. Sizes of these tensors must match that of
              :attr:`tensor`, except for :attr:`dim`, where the total size must
              sum to ``tensor.size(dim)``.
    
        .. note::
            Exactly one of :attr:`devices` and :attr:`out` must be specified. When
            :attr:`out` is specified, :attr:`chunk_sizes` must not be specified and
            will be inferred from sizes of :attr:`out`.
    
        Returns:
            - If :attr:`devices` is specified,
                a tuple containing chunks of :attr:`tensor`, placed on
                :attr:`devices`.
            - If :attr:`out` is specified,
                a tuple containing :attr:`out` tensors, each containing a chunk of
                :attr:`tensor`.
        """
        tensor = _handle_complex(tensor)
        if out is None:
            devices = [_get_device_index(d) for d in devices]
>           return tuple(torch._C._scatter(tensor, devices, chunk_sizes, dim, streams))
E           AttributeError: module 'torch._C' has no attribute '_scatter'

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/comm.py:189: AttributeError
__ TestScatterGatherFunctions.test_gather_mutually_exclusive_parameter_check ___

self = <test_torch_nn_parallel_comm_scatter_gather.TestScatterGatherFunctions object at 0x133049a80>
cuda_devices = [device(type='cpu'), device(type='cpu'), device(type='cpu')]
random_tensor = <function random_tensor.<locals>._create at 0x127dc53f0>

    def test_gather_mutually_exclusive_parameter_check(self, cuda_devices, random_tensor):
        """TC-10: gather参数互斥检查
    
        测试当同时提供destination和out参数时抛出RuntimeError异常
        """
        # 跳过如果设备不足
        if len(cuda_devices) < 2:
            pytest.skip(f"Need at least 2 CUDA devices, got {len(cuda_devices)}")
    
        # 测试参数
        dtype = torch.float32
        devices = ["cuda:0", "cuda:1"]
        shape = (3, 4)
        destination = "cuda:0"
        dim = 0
    
        # 创建输入张量列表
        input_tensors = []
        for device in devices:
>           tensor = random_tensor(shape, dtype=dtype, device=device)

tests/test_torch_nn_parallel_comm_scatter_gather.py:401: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/test_torch_nn_parallel_comm_scatter_gather.py:41: in _create
    tensor = torch.randn(*shape, dtype=dtype, device=device)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _lazy_init():
        global _initialized, _queued_calls
        if is_initialized() or hasattr(_tls, 'is_initializing'):
            return
        with _initialization_lock:
            # We be double-checked locking, boys!  This is OK because
            # the above test was GIL protected anyway.  The inner test
            # is for when a thread blocked on some other thread which was
            # doing the initialization; when they get the lock, they will
            # find there is nothing left to do.
            if is_initialized():
                return
            # It is important to prevent other threads from entering _lazy_init
            # immediately, while we are still guaranteed to have the GIL, because some
            # of the C calls we make below will release the GIL
            if _is_in_bad_fork():
                raise RuntimeError(
                    "Cannot re-initialize CUDA in forked subprocess. To use CUDA with "
                    "multiprocessing, you must use the 'spawn' start method")
            if not hasattr(torch._C, '_cuda_getDeviceCount'):
>               raise AssertionError("Torch not compiled with CUDA enabled")
E               AssertionError: Torch not compiled with CUDA enabled

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/cuda/__init__.py:221: AssertionError
_ TestScatterGatherFunctions.test_gather_mutually_exclusive_parameter_check_cpu_fallback _

self = <test_torch_nn_parallel_comm_scatter_gather.TestScatterGatherFunctions object at 0x133049e70>
random_tensor = <function random_tensor.<locals>._create at 0x127dc48b0>

    def test_gather_mutually_exclusive_parameter_check_cpu_fallback(self, random_tensor):
        """TC-10 CPU回退版本: gather参数互斥检查（CPU设备）
    
        在没有CUDA设备时测试当同时提供destination和out参数时抛出RuntimeError异常
        """
        # 测试参数
        dtype = torch.float32
        devices = ["cpu", "cpu"]
        shape = (3, 4)
        destination = "cpu"
        dim = 0
    
        # 创建输入张量列表
        input_tensors = []
        for device in devices:
            tensor = random_tensor(shape, dtype=dtype, device=device)
            input_tensors.append(tensor)
    
        # 创建输出张量（用于out参数）
        # 计算聚集后的总大小
        total_size = sum(tensor.shape[dim] for tensor in input_tensors)
        out_shape = list(shape)
        out_shape[dim] = total_size
        out_tensor = torch.empty(out_shape, dtype=dtype, device=destination)
    
        # weak断言验证 - 当同时提供destination和out参数时应该抛出RuntimeError异常
        with pytest.raises(RuntimeError) as exc_info:
            comm.gather(input_tensors, dim=dim, destination=destination, out=out_tensor)
    
        # 验证异常消息包含关键信息
        exception_msg = str(exc_info.value)
        assert "destination" in exception_msg.lower(), \
            f"Exception message should mention 'destination', got: {exception_msg}"
        assert "out" in exception_msg.lower(), \
            f"Exception message should mention 'out', got: {exception_msg}"
        assert "must not be specified" in exception_msg, \
            f"Exception message should contain 'must not be specified', got: {exception_msg}"
    
        # 验证异常类型（应该是RuntimeError）
        assert exc_info.type == RuntimeError, \
            f"Expected RuntimeError, got {exc_info.type}"
    
        # 额外验证：单独使用destination参数应该正常工作
        # 使用mock来避免调用不存在的torch._C._gather
>       with patch('torch._C._gather') as mock_gather:

tests/test_torch_nn_parallel_comm_scatter_gather.py:497: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/unittest/mock.py:1447: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x127c03250>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'torch._C' from '/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/_C.cpython-310-darwin.so'> does not have the attribute '_gather'

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/unittest/mock.py:1420: AttributeError
================================ tests coverage ================================
______________ coverage: platform darwin, python 3.10.19-final-0 _______________

Name                                                  Stmts   Miss Branch BrPart  Cover   Missing
-------------------------------------------------------------------------------------------------
tests/test_torch_nn_parallel_comm_broadcast.py          115     52     38      9    48%   13, 19, 29-34, 63, 67-100, 124->126, 131-135, 144-168, 179, 187-213, 236-247, 308
tests/test_torch_nn_parallel_comm_reduce.py             104     53     38      9    42%   13, 19, 29-34, 70-133, 150-153, 173->175, 180-184, 194-208, 220
tests/test_torch_nn_parallel_comm_scatter_gather.py     241    128     52     14    45%   13, 19, 29-34, 66, 70-127, 148->150, 155-159, 168-221, 233, 246-284, 316-327, 352->354, 359-363, 368-377, 389, 402-450, 499-516, 522
-------------------------------------------------------------------------------------------------
TOTAL                                                   460    233    128     32    45%
Coverage XML written to file coverage.xml
=========================== short test summary info ============================
FAILED tests/test_torch_nn_parallel_comm_broadcast.py::TestBroadcastFunctions::test_broadcast_basic[dtype0-cuda:0-shape0-target_devices0]
FAILED tests/test_torch_nn_parallel_comm_broadcast.py::TestBroadcastFunctions::test_broadcast_basic_cpu_fallback[dtype0-shape0-target_devices0]
FAILED tests/test_torch_nn_parallel_comm_broadcast.py::TestBroadcastFunctions::test_broadcast_basic_cpu_fallback[dtype1-shape1-target_devices1]
FAILED tests/test_torch_nn_parallel_comm_broadcast.py::TestBroadcastFunctions::test_broadcast_basic_cpu_fallback[dtype2-shape2-target_devices2]
FAILED tests/test_torch_nn_parallel_comm_broadcast.py::TestBroadcastFunctions::test_broadcast_parameter_conflict
FAILED tests/test_torch_nn_parallel_comm_reduce.py::TestReduceAddFunctions::test_reduce_add_shape_mismatch_exception
FAILED tests/test_torch_nn_parallel_comm_scatter_gather.py::TestScatterGatherFunctions::test_scatter_gather_roundtrip[dtype0-cuda:0-shape0-target_devices0-0]
FAILED tests/test_torch_nn_parallel_comm_scatter_gather.py::TestScatterGatherFunctions::test_scatter_gather_roundtrip[dtype1-cuda:0-shape1-target_devices1-1]
FAILED tests/test_torch_nn_parallel_comm_scatter_gather.py::TestScatterGatherFunctions::test_scatter_gather_roundtrip_cpu_fallback[dtype0-shape0-target_devices0-0]
FAILED tests/test_torch_nn_parallel_comm_scatter_gather.py::TestScatterGatherFunctions::test_scatter_gather_roundtrip_cpu_fallback[dtype1-shape1-target_devices1-1]
FAILED tests/test_torch_nn_parallel_comm_scatter_gather.py::TestScatterGatherFunctions::test_scatter_parameter_conflict_exception
FAILED tests/test_torch_nn_parallel_comm_scatter_gather.py::TestScatterGatherFunctions::test_scatter_parameter_conflict_exception_cpu_fallback
FAILED tests/test_torch_nn_parallel_comm_scatter_gather.py::TestScatterGatherFunctions::test_gather_mutually_exclusive_parameter_check
FAILED tests/test_torch_nn_parallel_comm_scatter_gather.py::TestScatterGatherFunctions::test_gather_mutually_exclusive_parameter_check_cpu_fallback
14 failed, 1 passed, 2 skipped in 0.80s

Error: exit 1