=== Run Tests ===
FFFFF.ssFFFFFFFFF                                                        [100%]
=================================== FAILURES ===================================
_ TestBroadcastFunctions.test_broadcast_basic[dtype0-cuda:0-shape0-target_devices0] _

self = <test_torch_nn_parallel_comm_broadcast.TestBroadcastFunctions object at 0x1415af880>
cuda_devices = [device(type='cpu'), device(type='cpu'), device(type='cpu')]
random_tensor = <function random_tensor.<locals>._create at 0x1415e9f30>
dtype = torch.float32, device = 'cuda:0', shape = (4, 8)
target_devices = ['cuda:0', 'cuda:1']

    @pytest.mark.parametrize("dtype,device,shape,target_devices", [
        (torch.float32, "cuda:0", (4, 8), ["cuda:0", "cuda:1"]),
    ])
    def test_broadcast_basic(self, cuda_devices, random_tensor, dtype, device, shape, target_devices):
        """TC-01: broadcast基本功能
    
        测试单GPU到多GPU的广播功能正确性
        """
        # 跳过如果设备不足
        if len(cuda_devices) < len(target_devices):
            pytest.skip(f"Need {len(target_devices)} CUDA devices, got {len(cuda_devices)}")
    
        # 创建源张量
>       src_tensor = random_tensor(shape, dtype=dtype, device=device)

tests/test_torch_nn_parallel_comm_broadcast.py:66: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/test_torch_nn_parallel_comm_broadcast.py:41: in _create
    tensor = torch.randn(*shape, dtype=dtype, device=device)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _lazy_init():
        global _initialized, _queued_calls
        if is_initialized() or hasattr(_tls, 'is_initializing'):
            return
        with _initialization_lock:
            # We be double-checked locking, boys!  This is OK because
            # the above test was GIL protected anyway.  The inner test
            # is for when a thread blocked on some other thread which was
            # doing the initialization; when they get the lock, they will
            # find there is nothing left to do.
            if is_initialized():
                return
            # It is important to prevent other threads from entering _lazy_init
            # immediately, while we are still guaranteed to have the GIL, because some
            # of the C calls we make below will release the GIL
            if _is_in_bad_fork():
                raise RuntimeError(
                    "Cannot re-initialize CUDA in forked subprocess. To use CUDA with "
                    "multiprocessing, you must use the 'spawn' start method")
            if not hasattr(torch._C, '_cuda_getDeviceCount'):
>               raise AssertionError("Torch not compiled with CUDA enabled")
E               AssertionError: Torch not compiled with CUDA enabled

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/cuda/__init__.py:221: AssertionError
_ TestBroadcastFunctions.test_broadcast_basic_cpu_fallback[dtype0-shape0-target_devices0] _

self = <test_torch_nn_parallel_comm_broadcast.TestBroadcastFunctions object at 0x1415afe20>
random_tensor = <function random_tensor.<locals>._create at 0x14f0b3b50>
dtype = torch.float32, shape = (4, 8), target_devices = ['cpu', 'cpu']

    @pytest.mark.parametrize("dtype,shape,target_devices", [
        # CPU回退测试用例
        (torch.float32, (4, 8), ["cpu", "cpu"]),
        (torch.float64, (10, 10), ["cpu", "cpu", "cpu"]),
        (torch.complex64, (2, 2), ["cpu", "cpu"]),
    ])
    def test_broadcast_basic_cpu_fallback(self, random_tensor, dtype, shape, target_devices):
        """TC-01 CPU回退版本: broadcast基本功能（CPU设备）
    
        在没有CUDA设备时测试广播功能正确性
        """
        # 创建源张量（在CPU上）
        src_tensor = random_tensor(shape, dtype=dtype, device="cpu")
        src_data = src_tensor.clone()
    
        # 执行广播
>       result = comm.broadcast(src_tensor, devices=target_devices)

tests/test_torch_nn_parallel_comm_broadcast.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/comm.py:35: in broadcast
    devices = [_get_device_index(d) for d in devices]
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/comm.py:35: in <listcomp>
    devices = [_get_device_index(d) for d in devices]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

device = device(type='cpu'), optional = False, allow_cpu = False

    def _get_device_index(
        device: Any, optional: bool = False, allow_cpu: bool = False
    ) -> int:
        r"""Gets the device index from :attr:`device`, which can be a torch.device
        object, a Python integer, or ``None``.
    
        If :attr:`device` is a torch.device object, returns the device index if it
        has index. Note that for a device without a specified index,
        i.e., ``torch.device('xxx')``, this will return the current default
        device of that type if :attr:`optional` is ``True``. If :attr:`allow_cpu` is ``True``,
        CPU devices will be accepted and ``-1`` will be returned in this case.
    
        If :attr:`device` is a Python integer, it is returned as is.
    
        If :attr:`device` is ``None``, this will return the current default
        device of the supported runtime platform if :attr:`optional` is ``True``.
        i.e., the current default CUDA device will be returned if CUDA runtime is supported.
        """
        if isinstance(device, str):
            device = torch.device(device)
        device_idx: Optional[int] = None
        if isinstance(device, torch.device):
            if not allow_cpu and device.type == "cpu":
>               raise ValueError("Expected a non cpu device, but got: {}".format(device))
E               ValueError: Expected a non cpu device, but got: cpu

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/_utils.py:614: ValueError
_ TestBroadcastFunctions.test_broadcast_basic_cpu_fallback[dtype1-shape1-target_devices1] _

self = <test_torch_nn_parallel_comm_broadcast.TestBroadcastFunctions object at 0x1415affa0>
random_tensor = <function random_tensor.<locals>._create at 0x14efc1750>
dtype = torch.float64, shape = (10, 10), target_devices = ['cpu', 'cpu', 'cpu']

    @pytest.mark.parametrize("dtype,shape,target_devices", [
        # CPU回退测试用例
        (torch.float32, (4, 8), ["cpu", "cpu"]),
        (torch.float64, (10, 10), ["cpu", "cpu", "cpu"]),
        (torch.complex64, (2, 2), ["cpu", "cpu"]),
    ])
    def test_broadcast_basic_cpu_fallback(self, random_tensor, dtype, shape, target_devices):
        """TC-01 CPU回退版本: broadcast基本功能（CPU设备）
    
        在没有CUDA设备时测试广播功能正确性
        """
        # 创建源张量（在CPU上）
        src_tensor = random_tensor(shape, dtype=dtype, device="cpu")
        src_data = src_tensor.clone()
    
        # 执行广播
>       result = comm.broadcast(src_tensor, devices=target_devices)

tests/test_torch_nn_parallel_comm_broadcast.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/comm.py:35: in broadcast
    devices = [_get_device_index(d) for d in devices]
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/comm.py:35: in <listcomp>
    devices = [_get_device_index(d) for d in devices]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

device = device(type='cpu'), optional = False, allow_cpu = False

    def _get_device_index(
        device: Any, optional: bool = False, allow_cpu: bool = False
    ) -> int:
        r"""Gets the device index from :attr:`device`, which can be a torch.device
        object, a Python integer, or ``None``.
    
        If :attr:`device` is a torch.device object, returns the device index if it
        has index. Note that for a device without a specified index,
        i.e., ``torch.device('xxx')``, this will return the current default
        device of that type if :attr:`optional` is ``True``. If :attr:`allow_cpu` is ``True``,
        CPU devices will be accepted and ``-1`` will be returned in this case.
    
        If :attr:`device` is a Python integer, it is returned as is.
    
        If :attr:`device` is ``None``, this will return the current default
        device of the supported runtime platform if :attr:`optional` is ``True``.
        i.e., the current default CUDA device will be returned if CUDA runtime is supported.
        """
        if isinstance(device, str):
            device = torch.device(device)
        device_idx: Optional[int] = None
        if isinstance(device, torch.device):
            if not allow_cpu and device.type == "cpu":
>               raise ValueError("Expected a non cpu device, but got: {}".format(device))
E               ValueError: Expected a non cpu device, but got: cpu

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/_utils.py:614: ValueError
_ TestBroadcastFunctions.test_broadcast_basic_cpu_fallback[dtype2-shape2-target_devices2] _

self = <test_torch_nn_parallel_comm_broadcast.TestBroadcastFunctions object at 0x1415fc1c0>
random_tensor = <function random_tensor.<locals>._create at 0x14efc2f80>
dtype = torch.complex64, shape = (2, 2), target_devices = ['cpu', 'cpu']

    @pytest.mark.parametrize("dtype,shape,target_devices", [
        # CPU回退测试用例
        (torch.float32, (4, 8), ["cpu", "cpu"]),
        (torch.float64, (10, 10), ["cpu", "cpu", "cpu"]),
        (torch.complex64, (2, 2), ["cpu", "cpu"]),
    ])
    def test_broadcast_basic_cpu_fallback(self, random_tensor, dtype, shape, target_devices):
        """TC-01 CPU回退版本: broadcast基本功能（CPU设备）
    
        在没有CUDA设备时测试广播功能正确性
        """
        # 创建源张量（在CPU上）
        src_tensor = random_tensor(shape, dtype=dtype, device="cpu")
        src_data = src_tensor.clone()
    
        # 执行广播
>       result = comm.broadcast(src_tensor, devices=target_devices)

tests/test_torch_nn_parallel_comm_broadcast.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/comm.py:35: in broadcast
    devices = [_get_device_index(d) for d in devices]
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/comm.py:35: in <listcomp>
    devices = [_get_device_index(d) for d in devices]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

device = device(type='cpu'), optional = False, allow_cpu = False

    def _get_device_index(
        device: Any, optional: bool = False, allow_cpu: bool = False
    ) -> int:
        r"""Gets the device index from :attr:`device`, which can be a torch.device
        object, a Python integer, or ``None``.
    
        If :attr:`device` is a torch.device object, returns the device index if it
        has index. Note that for a device without a specified index,
        i.e., ``torch.device('xxx')``, this will return the current default
        device of that type if :attr:`optional` is ``True``. If :attr:`allow_cpu` is ``True``,
        CPU devices will be accepted and ``-1`` will be returned in this case.
    
        If :attr:`device` is a Python integer, it is returned as is.
    
        If :attr:`device` is ``None``, this will return the current default
        device of the supported runtime platform if :attr:`optional` is ``True``.
        i.e., the current default CUDA device will be returned if CUDA runtime is supported.
        """
        if isinstance(device, str):
            device = torch.device(device)
        device_idx: Optional[int] = None
        if isinstance(device, torch.device):
            if not allow_cpu and device.type == "cpu":
>               raise ValueError("Expected a non cpu device, but got: {}".format(device))
E               ValueError: Expected a non cpu device, but got: cpu

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/_utils.py:614: ValueError
___________ TestBroadcastFunctions.test_broadcast_parameter_conflict ___________

self = <test_torch_nn_parallel_comm_broadcast.TestBroadcastFunctions object at 0x1415fc4c0>
cuda_devices = [device(type='cpu'), device(type='cpu'), device(type='cpu')]
random_tensor = <function random_tensor.<locals>._create at 0x14efc36d0>

    def test_broadcast_parameter_conflict(self, cuda_devices, random_tensor):
        """TC-02: broadcast参数冲突异常
    
        测试devices和out参数同时提供时的异常
        """
        if len(cuda_devices) < 2:
            pytest.skip("Need at least 2 CUDA devices")
    
        # 创建源张量
        shape = (2, 3)
        dtype = torch.float32
>       src_tensor = random_tensor(shape, dtype=dtype, device="cuda:0")

tests/test_torch_nn_parallel_comm_broadcast.py:163: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/test_torch_nn_parallel_comm_broadcast.py:41: in _create
    tensor = torch.randn(*shape, dtype=dtype, device=device)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _lazy_init():
        global _initialized, _queued_calls
        if is_initialized() or hasattr(_tls, 'is_initializing'):
            return
        with _initialization_lock:
            # We be double-checked locking, boys!  This is OK because
            # the above test was GIL protected anyway.  The inner test
            # is for when a thread blocked on some other thread which was
            # doing the initialization; when they get the lock, they will
            # find there is nothing left to do.
            if is_initialized():
                return
            # It is important to prevent other threads from entering _lazy_init
            # immediately, while we are still guaranteed to have the GIL, because some
            # of the C calls we make below will release the GIL
            if _is_in_bad_fork():
                raise RuntimeError(
                    "Cannot re-initialize CUDA in forked subprocess. To use CUDA with "
                    "multiprocessing, you must use the 'spawn' start method")
            if not hasattr(torch._C, '_cuda_getDeviceCount'):
>               raise AssertionError("Torch not compiled with CUDA enabled")
E               AssertionError: Torch not compiled with CUDA enabled

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/cuda/__init__.py:221: AssertionError
_______ TestReduceAddFunctions.test_reduce_add_shape_mismatch_exception ________

self = <test_torch_nn_parallel_comm_reduce.TestReduceAddFunctions object at 0x1415fd0f0>
cuda_devices = [device(type='cpu'), device(type='cpu'), device(type='cpu')]
random_tensor = <function random_tensor.<locals>._create at 0x104f55750>

    def test_reduce_add_shape_mismatch_exception(self, cuda_devices, random_tensor):
        """TC-06: reduce_add形状不匹配异常
    
        测试当输入张量形状不匹配时抛出RuntimeError异常
        """
        # 检查CUDA可用性，如果不可用则使用CPU回退
        if not torch.cuda.is_available():
            # CPU回退测试
            devices = ["cpu", "cpu"]
            destination = "cpu"
        else:
            # 跳过如果设备不足
            if len(cuda_devices) < 2:
                pytest.skip(f"Need at least 2 CUDA devices, got {len(cuda_devices)}")
            devices = ["cuda:0", "cuda:1"]
            destination = "cuda:0"
    
        # 创建形状不匹配的张量列表
        # 第一个张量形状为 (2, 3)，第二个为 (3, 4)
        inputs = []
    
        # 第一个张量：形状 (2, 3)
        shape1 = (2, 3)
        tensor1 = random_tensor(shape1, dtype=torch.float32, device=devices[0])
        inputs.append(tensor1)
    
        # 第二个张量：形状 (3, 4) - 与第一个不匹配
        shape2 = (3, 4)
        tensor2 = random_tensor(shape2, dtype=torch.float32, device=devices[1])
        inputs.append(tensor2)
    
        # 验证当形状不匹配时抛出RuntimeError异常
        with pytest.raises(RuntimeError) as exc_info:
>           comm.reduce_add(inputs, destination=destination)

tests/test_torch_nn_parallel_comm_reduce.py:152: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/comm.py:76: in reduce_add
    destination = _get_device_index(destination, optional=True)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

device = device(type='cpu'), optional = True, allow_cpu = False

    def _get_device_index(
        device: Any, optional: bool = False, allow_cpu: bool = False
    ) -> int:
        r"""Gets the device index from :attr:`device`, which can be a torch.device
        object, a Python integer, or ``None``.
    
        If :attr:`device` is a torch.device object, returns the device index if it
        has index. Note that for a device without a specified index,
        i.e., ``torch.device('xxx')``, this will return the current default
        device of that type if :attr:`optional` is ``True``. If :attr:`allow_cpu` is ``True``,
        CPU devices will be accepted and ``-1`` will be returned in this case.
    
        If :attr:`device` is a Python integer, it is returned as is.
    
        If :attr:`device` is ``None``, this will return the current default
        device of the supported runtime platform if :attr:`optional` is ``True``.
        i.e., the current default CUDA device will be returned if CUDA runtime is supported.
        """
        if isinstance(device, str):
            device = torch.device(device)
        device_idx: Optional[int] = None
        if isinstance(device, torch.device):
            if not allow_cpu and device.type == "cpu":
>               raise ValueError("Expected a non cpu device, but got: {}".format(device))
E               ValueError: Expected a non cpu device, but got: cpu

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/_utils.py:614: ValueError
_ TestScatterGatherFunctions.test_scatter_gather_roundtrip[dtype0-cuda:0-shape0-target_devices0-0] _

self = <test_torch_nn_parallel_comm_scatter_gather.TestScatterGatherFunctions object at 0x14160fbb0>
cuda_devices = [device(type='cpu'), device(type='cpu'), device(type='cpu')]
random_tensor = <function random_tensor.<locals>._create at 0x14efc1e10>
dtype = torch.float32, device = 'cuda:0', shape = (8, 6)
target_devices = ['cuda:0', 'cuda:1'], dim = 0

    @pytest.mark.parametrize("dtype,device,shape,target_devices,dim", [
        # 原始测试用例 (High优先级)
        (torch.float32, "cuda:0", (8, 6), ["cuda:0", "cuda:1"], 0),
        # 参数扩展 (Medium优先级) - 扩展数据类型、设备数量和维度
        (torch.float64, "cuda:0", (12, 8), ["cuda:0", "cuda:1", "cuda:2"], 1),
    ])
    def test_scatter_gather_roundtrip(self, cuda_devices, random_tensor, dtype, device, shape, target_devices, dim):
        """TC-08: scatter_gather往返完整性
    
        测试张量分散-聚集往返数据完整性
        """
        # 跳过如果设备不足
        if len(cuda_devices) < len(target_devices):
            pytest.skip(f"Need {len(target_devices)} CUDA devices, got {len(cuda_devices)}")
    
        # 创建源张量
>       src_tensor = random_tensor(shape, dtype=dtype, device=device)

tests/test_torch_nn_parallel_comm_scatter_gather.py:69: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/test_torch_nn_parallel_comm_scatter_gather.py:41: in _create
    tensor = torch.randn(*shape, dtype=dtype, device=device)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _lazy_init():
        global _initialized, _queued_calls
        if is_initialized() or hasattr(_tls, 'is_initializing'):
            return
        with _initialization_lock:
            # We be double-checked locking, boys!  This is OK because
            # the above test was GIL protected anyway.  The inner test
            # is for when a thread blocked on some other thread which was
            # doing the initialization; when they get the lock, they will
            # find there is nothing left to do.
            if is_initialized():
                return
            # It is important to prevent other threads from entering _lazy_init
            # immediately, while we are still guaranteed to have the GIL, because some
            # of the C calls we make below will release the GIL
            if _is_in_bad_fork():
                raise RuntimeError(
                    "Cannot re-initialize CUDA in forked subprocess. To use CUDA with "
                    "multiprocessing, you must use the 'spawn' start method")
            if not hasattr(torch._C, '_cuda_getDeviceCount'):
>               raise AssertionError("Torch not compiled with CUDA enabled")
E               AssertionError: Torch not compiled with CUDA enabled

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/cuda/__init__.py:221: AssertionError
_ TestScatterGatherFunctions.test_scatter_gather_roundtrip[dtype1-cuda:0-shape1-target_devices1-1] _

self = <test_torch_nn_parallel_comm_scatter_gather.TestScatterGatherFunctions object at 0x14160f880>
cuda_devices = [device(type='cpu'), device(type='cpu'), device(type='cpu')]
random_tensor = <function random_tensor.<locals>._create at 0x14effaa70>
dtype = torch.float64, device = 'cuda:0', shape = (12, 8)
target_devices = ['cuda:0', 'cuda:1', 'cuda:2'], dim = 1

    @pytest.mark.parametrize("dtype,device,shape,target_devices,dim", [
        # 原始测试用例 (High优先级)
        (torch.float32, "cuda:0", (8, 6), ["cuda:0", "cuda:1"], 0),
        # 参数扩展 (Medium优先级) - 扩展数据类型、设备数量和维度
        (torch.float64, "cuda:0", (12, 8), ["cuda:0", "cuda:1", "cuda:2"], 1),
    ])
    def test_scatter_gather_roundtrip(self, cuda_devices, random_tensor, dtype, device, shape, target_devices, dim):
        """TC-08: scatter_gather往返完整性
    
        测试张量分散-聚集往返数据完整性
        """
        # 跳过如果设备不足
        if len(cuda_devices) < len(target_devices):
            pytest.skip(f"Need {len(target_devices)} CUDA devices, got {len(cuda_devices)}")
    
        # 创建源张量
>       src_tensor = random_tensor(shape, dtype=dtype, device=device)

tests/test_torch_nn_parallel_comm_scatter_gather.py:69: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/test_torch_nn_parallel_comm_scatter_gather.py:41: in _create
    tensor = torch.randn(*shape, dtype=dtype, device=device)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _lazy_init():
        global _initialized, _queued_calls
        if is_initialized() or hasattr(_tls, 'is_initializing'):
            return
        with _initialization_lock:
            # We be double-checked locking, boys!  This is OK because
            # the above test was GIL protected anyway.  The inner test
            # is for when a thread blocked on some other thread which was
            # doing the initialization; when they get the lock, they will
            # find there is nothing left to do.
            if is_initialized():
                return
            # It is important to prevent other threads from entering _lazy_init
            # immediately, while we are still guaranteed to have the GIL, because some
            # of the C calls we make below will release the GIL
            if _is_in_bad_fork():
                raise RuntimeError(
                    "Cannot re-initialize CUDA in forked subprocess. To use CUDA with "
                    "multiprocessing, you must use the 'spawn' start method")
            if not hasattr(torch._C, '_cuda_getDeviceCount'):
>               raise AssertionError("Torch not compiled with CUDA enabled")
E               AssertionError: Torch not compiled with CUDA enabled

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/cuda/__init__.py:221: AssertionError
_ TestScatterGatherFunctions.test_scatter_gather_roundtrip_cpu_fallback[dtype0-shape0-target_devices0-0] _

self = <test_torch_nn_parallel_comm_scatter_gather.TestScatterGatherFunctions object at 0x14160f490>
random_tensor = <function random_tensor.<locals>._create at 0x14effa8c0>
dtype = torch.float32, shape = (8, 6), target_devices = ['cpu', 'cpu'], dim = 0

    @pytest.mark.parametrize("dtype,shape,target_devices,dim", [
        # CPU回退测试用例
        (torch.float32, (8, 6), ["cpu", "cpu"], 0),
        (torch.float64, (12, 8), ["cpu", "cpu", "cpu"], 1),
    ])
    def test_scatter_gather_roundtrip_cpu_fallback(self, random_tensor, dtype, shape, target_devices, dim):
        """TC-08 CPU回退版本: scatter_gather往返完整性（CPU设备）
    
        在没有CUDA设备时测试张量分散-聚集往返数据完整性
        """
        # 创建源张量（在CPU上）
        src_tensor = random_tensor(shape, dtype=dtype, device="cpu")
        src_data = src_tensor.clone()
    
        # 步骤1: 分散(scatter)到多个CPU设备
>       scattered = comm.scatter(src_tensor, devices=target_devices, dim=dim)

tests/test_torch_nn_parallel_comm_scatter_gather.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/comm.py:188: in scatter
    devices = [_get_device_index(d) for d in devices]
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/comm.py:188: in <listcomp>
    devices = [_get_device_index(d) for d in devices]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

device = device(type='cpu'), optional = False, allow_cpu = False

    def _get_device_index(
        device: Any, optional: bool = False, allow_cpu: bool = False
    ) -> int:
        r"""Gets the device index from :attr:`device`, which can be a torch.device
        object, a Python integer, or ``None``.
    
        If :attr:`device` is a torch.device object, returns the device index if it
        has index. Note that for a device without a specified index,
        i.e., ``torch.device('xxx')``, this will return the current default
        device of that type if :attr:`optional` is ``True``. If :attr:`allow_cpu` is ``True``,
        CPU devices will be accepted and ``-1`` will be returned in this case.
    
        If :attr:`device` is a Python integer, it is returned as is.
    
        If :attr:`device` is ``None``, this will return the current default
        device of the supported runtime platform if :attr:`optional` is ``True``.
        i.e., the current default CUDA device will be returned if CUDA runtime is supported.
        """
        if isinstance(device, str):
            device = torch.device(device)
        device_idx: Optional[int] = None
        if isinstance(device, torch.device):
            if not allow_cpu and device.type == "cpu":
>               raise ValueError("Expected a non cpu device, but got: {}".format(device))
E               ValueError: Expected a non cpu device, but got: cpu

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/_utils.py:614: ValueError
_ TestScatterGatherFunctions.test_scatter_gather_roundtrip_cpu_fallback[dtype1-shape1-target_devices1-1] _

self = <test_torch_nn_parallel_comm_scatter_gather.TestScatterGatherFunctions object at 0x14160f3a0>
random_tensor = <function random_tensor.<locals>._create at 0x14effbb50>
dtype = torch.float64, shape = (12, 8), target_devices = ['cpu', 'cpu', 'cpu']
dim = 1

    @pytest.mark.parametrize("dtype,shape,target_devices,dim", [
        # CPU回退测试用例
        (torch.float32, (8, 6), ["cpu", "cpu"], 0),
        (torch.float64, (12, 8), ["cpu", "cpu", "cpu"], 1),
    ])
    def test_scatter_gather_roundtrip_cpu_fallback(self, random_tensor, dtype, shape, target_devices, dim):
        """TC-08 CPU回退版本: scatter_gather往返完整性（CPU设备）
    
        在没有CUDA设备时测试张量分散-聚集往返数据完整性
        """
        # 创建源张量（在CPU上）
        src_tensor = random_tensor(shape, dtype=dtype, device="cpu")
        src_data = src_tensor.clone()
    
        # 步骤1: 分散(scatter)到多个CPU设备
>       scattered = comm.scatter(src_tensor, devices=target_devices, dim=dim)

tests/test_torch_nn_parallel_comm_scatter_gather.py:145: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/comm.py:188: in scatter
    devices = [_get_device_index(d) for d in devices]
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/comm.py:188: in <listcomp>
    devices = [_get_device_index(d) for d in devices]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

device = device(type='cpu'), optional = False, allow_cpu = False

    def _get_device_index(
        device: Any, optional: bool = False, allow_cpu: bool = False
    ) -> int:
        r"""Gets the device index from :attr:`device`, which can be a torch.device
        object, a Python integer, or ``None``.
    
        If :attr:`device` is a torch.device object, returns the device index if it
        has index. Note that for a device without a specified index,
        i.e., ``torch.device('xxx')``, this will return the current default
        device of that type if :attr:`optional` is ``True``. If :attr:`allow_cpu` is ``True``,
        CPU devices will be accepted and ``-1`` will be returned in this case.
    
        If :attr:`device` is a Python integer, it is returned as is.
    
        If :attr:`device` is ``None``, this will return the current default
        device of the supported runtime platform if :attr:`optional` is ``True``.
        i.e., the current default CUDA device will be returned if CUDA runtime is supported.
        """
        if isinstance(device, str):
            device = torch.device(device)
        device_idx: Optional[int] = None
        if isinstance(device, torch.device):
            if not allow_cpu and device.type == "cpu":
>               raise ValueError("Expected a non cpu device, but got: {}".format(device))
E               ValueError: Expected a non cpu device, but got: cpu

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/_utils.py:614: ValueError
_____ TestScatterGatherFunctions.test_scatter_parameter_conflict_exception _____

self = <test_torch_nn_parallel_comm_scatter_gather.TestScatterGatherFunctions object at 0x14160efe0>
cuda_devices = [device(type='cpu'), device(type='cpu'), device(type='cpu')]
random_tensor = <function random_tensor.<locals>._create at 0x14effbac0>

    def test_scatter_parameter_conflict_exception(self, cuda_devices, random_tensor):
        """TC-09: scatter参数冲突异常
    
        测试当同时提供devices和out参数时抛出RuntimeError异常
        """
        # 跳过如果设备不足
        if len(cuda_devices) < 2:
            pytest.skip(f"Need at least 2 CUDA devices, got {len(cuda_devices)}")
    
        # 测试参数
        dtype = torch.float32
        device = "cuda:0"
        shape = (6, 4)
        target_devices = ["cuda:0", "cuda:1"]
        dim = 0
    
        # 创建源张量
>       src_tensor = random_tensor(shape, dtype=dtype, device=device)

tests/test_torch_nn_parallel_comm_scatter_gather.py:218: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/test_torch_nn_parallel_comm_scatter_gather.py:41: in _create
    tensor = torch.randn(*shape, dtype=dtype, device=device)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _lazy_init():
        global _initialized, _queued_calls
        if is_initialized() or hasattr(_tls, 'is_initializing'):
            return
        with _initialization_lock:
            # We be double-checked locking, boys!  This is OK because
            # the above test was GIL protected anyway.  The inner test
            # is for when a thread blocked on some other thread which was
            # doing the initialization; when they get the lock, they will
            # find there is nothing left to do.
            if is_initialized():
                return
            # It is important to prevent other threads from entering _lazy_init
            # immediately, while we are still guaranteed to have the GIL, because some
            # of the C calls we make below will release the GIL
            if _is_in_bad_fork():
                raise RuntimeError(
                    "Cannot re-initialize CUDA in forked subprocess. To use CUDA with "
                    "multiprocessing, you must use the 'spawn' start method")
            if not hasattr(torch._C, '_cuda_getDeviceCount'):
>               raise AssertionError("Torch not compiled with CUDA enabled")
E               AssertionError: Torch not compiled with CUDA enabled

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/cuda/__init__.py:221: AssertionError
_ TestScatterGatherFunctions.test_scatter_parameter_conflict_exception_cpu_fallback _

self = <test_torch_nn_parallel_comm_scatter_gather.TestScatterGatherFunctions object at 0x14160ead0>
random_tensor = <function random_tensor.<locals>._create at 0x14eff5510>

    def test_scatter_parameter_conflict_exception_cpu_fallback(self, random_tensor):
        """TC-09 CPU回退版本: scatter参数冲突异常（CPU设备）
    
        在没有CUDA设备时测试当同时提供devices和out参数时抛出RuntimeError异常
        """
        # 测试参数
        dtype = torch.float32
        device = "cpu"
        shape = (6, 4)
        target_devices = ["cpu", "cpu"]
        dim = 0
    
        # 创建源张量
        src_tensor = random_tensor(shape, dtype=dtype, device=device)
    
        # 创建输出张量列表（用于out参数）
        out_tensors = []
        chunk_size = shape[dim] // len(target_devices)
        for i, target_device in enumerate(target_devices):
            # 创建输出张量，形状与分散后的块匹配
            out_shape = list(shape)
            out_shape[dim] = chunk_size
            out_tensor = torch.empty(out_shape, dtype=dtype, device=target_device)
            out_tensors.append(out_tensor)
    
        # weak断言验证 - 当同时提供devices和out参数时应该抛出RuntimeError异常
        with pytest.raises(RuntimeError) as exc_info:
            comm.scatter(src_tensor, devices=target_devices, dim=dim, out=out_tensors)
    
        # 验证异常消息包含关键信息
        exception_msg = str(exc_info.value)
        assert "devices" in exception_msg.lower(), \
            f"Exception message should mention 'devices', got: {exception_msg}"
        assert "out" in exception_msg.lower(), \
            f"Exception message should mention 'out', got: {exception_msg}"
        assert "must not be specified" in exception_msg, \
            f"Exception message should contain 'must not be specified', got: {exception_msg}"
    
        # 验证异常类型（应该是RuntimeError）
        assert exc_info.type == RuntimeError, \
            f"Expected RuntimeError, got {exc_info.type}"
    
        # 额外验证：单独使用devices参数应该正常工作
>       result_with_devices = comm.scatter(src_tensor, devices=target_devices, dim=dim)

tests/test_torch_nn_parallel_comm_scatter_gather.py:305: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/comm.py:188: in scatter
    devices = [_get_device_index(d) for d in devices]
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/comm.py:188: in <listcomp>
    devices = [_get_device_index(d) for d in devices]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

device = device(type='cpu'), optional = False, allow_cpu = False

    def _get_device_index(
        device: Any, optional: bool = False, allow_cpu: bool = False
    ) -> int:
        r"""Gets the device index from :attr:`device`, which can be a torch.device
        object, a Python integer, or ``None``.
    
        If :attr:`device` is a torch.device object, returns the device index if it
        has index. Note that for a device without a specified index,
        i.e., ``torch.device('xxx')``, this will return the current default
        device of that type if :attr:`optional` is ``True``. If :attr:`allow_cpu` is ``True``,
        CPU devices will be accepted and ``-1`` will be returned in this case.
    
        If :attr:`device` is a Python integer, it is returned as is.
    
        If :attr:`device` is ``None``, this will return the current default
        device of the supported runtime platform if :attr:`optional` is ``True``.
        i.e., the current default CUDA device will be returned if CUDA runtime is supported.
        """
        if isinstance(device, str):
            device = torch.device(device)
        device_idx: Optional[int] = None
        if isinstance(device, torch.device):
            if not allow_cpu and device.type == "cpu":
>               raise ValueError("Expected a non cpu device, but got: {}".format(device))
E               ValueError: Expected a non cpu device, but got: cpu

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/_utils.py:614: ValueError
__ TestScatterGatherFunctions.test_gather_mutually_exclusive_parameter_check ___

self = <test_torch_nn_parallel_comm_scatter_gather.TestScatterGatherFunctions object at 0x14160e770>
cuda_devices = [device(type='cpu'), device(type='cpu'), device(type='cpu')]
random_tensor = <function random_tensor.<locals>._create at 0x14eff4ca0>

    def test_gather_mutually_exclusive_parameter_check(self, cuda_devices, random_tensor):
        """TC-10: gather参数互斥检查
    
        测试当同时提供destination和out参数时抛出RuntimeError异常
        """
        # 跳过如果设备不足
        if len(cuda_devices) < 2:
            pytest.skip(f"Need at least 2 CUDA devices, got {len(cuda_devices)}")
    
        # 测试参数
        dtype = torch.float32
        devices = ["cuda:0", "cuda:1"]
        shape = (3, 4)
        destination = "cuda:0"
        dim = 0
    
        # 创建输入张量列表
        input_tensors = []
        for device in devices:
>           tensor = random_tensor(shape, dtype=dtype, device=device)

tests/test_torch_nn_parallel_comm_scatter_gather.py:339: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/test_torch_nn_parallel_comm_scatter_gather.py:41: in _create
    tensor = torch.randn(*shape, dtype=dtype, device=device)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _lazy_init():
        global _initialized, _queued_calls
        if is_initialized() or hasattr(_tls, 'is_initializing'):
            return
        with _initialization_lock:
            # We be double-checked locking, boys!  This is OK because
            # the above test was GIL protected anyway.  The inner test
            # is for when a thread blocked on some other thread which was
            # doing the initialization; when they get the lock, they will
            # find there is nothing left to do.
            if is_initialized():
                return
            # It is important to prevent other threads from entering _lazy_init
            # immediately, while we are still guaranteed to have the GIL, because some
            # of the C calls we make below will release the GIL
            if _is_in_bad_fork():
                raise RuntimeError(
                    "Cannot re-initialize CUDA in forked subprocess. To use CUDA with "
                    "multiprocessing, you must use the 'spawn' start method")
            if not hasattr(torch._C, '_cuda_getDeviceCount'):
>               raise AssertionError("Torch not compiled with CUDA enabled")
E               AssertionError: Torch not compiled with CUDA enabled

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/cuda/__init__.py:221: AssertionError
_ TestScatterGatherFunctions.test_gather_mutually_exclusive_parameter_check_cpu_fallback _

self = <test_torch_nn_parallel_comm_scatter_gather.TestScatterGatherFunctions object at 0x14160e320>
random_tensor = <function random_tensor.<locals>._create at 0x14eff6c20>

    def test_gather_mutually_exclusive_parameter_check_cpu_fallback(self, random_tensor):
        """TC-10 CPU回退版本: gather参数互斥检查（CPU设备）
    
        在没有CUDA设备时测试当同时提供destination和out参数时抛出RuntimeError异常
        """
        # 测试参数
        dtype = torch.float32
        devices = ["cpu", "cpu"]
        shape = (3, 4)
        destination = "cpu"
        dim = 0
    
        # 创建输入张量列表
        input_tensors = []
        for device in devices:
            tensor = random_tensor(shape, dtype=dtype, device=device)
            input_tensors.append(tensor)
    
        # 创建输出张量（用于out参数）
        # 计算聚集后的总大小
        total_size = sum(tensor.shape[dim] for tensor in input_tensors)
        out_shape = list(shape)
        out_shape[dim] = total_size
        out_tensor = torch.empty(out_shape, dtype=dtype, device=destination)
    
        # weak断言验证 - 当同时提供destination和out参数时应该抛出RuntimeError异常
        with pytest.raises(RuntimeError) as exc_info:
            comm.gather(input_tensors, dim=dim, destination=destination, out=out_tensor)
    
        # 验证异常消息包含关键信息
        exception_msg = str(exc_info.value)
        assert "destination" in exception_msg.lower(), \
            f"Exception message should mention 'destination', got: {exception_msg}"
        assert "out" in exception_msg.lower(), \
            f"Exception message should mention 'out', got: {exception_msg}"
        assert "must not be specified" in exception_msg, \
            f"Exception message should contain 'must not be specified', got: {exception_msg}"
    
        # 验证异常类型（应该是RuntimeError）
        assert exc_info.type == RuntimeError, \
            f"Expected RuntimeError, got {exc_info.type}"
    
        # 额外验证：单独使用destination参数应该正常工作
>       result_with_destination = comm.gather(input_tensors, dim=dim, destination=destination)

tests/test_torch_nn_parallel_comm_scatter_gather.py:428: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tensors = [tensor([[ 1.2135,  0.7924, -0.4401,  0.4996],
        [-0.7581,  0.9989, -0.8793,  0.7486],
        [-1.3375,  0.6449....0090, -1.2315, -1.0470],
        [-1.7461, -0.3742, -0.4117, -0.8997],
        [ 0.4821,  2.5151, -0.7723,  0.1532]])]
dim = 0, destination = -1

    def gather(tensors, dim=0, destination=None, *, out=None):
        r"""Gathers tensors from multiple GPU devices.
    
        Args:
            tensors (Iterable[Tensor]): an iterable of tensors to gather.
              Tensor sizes in all dimensions other than :attr:`dim` have to match.
            dim (int, optional): a dimension along which the tensors will be
              concatenated. Default: ``0``.
            destination (torch.device, str, or int, optional): the output device.
              Can be CPU or CUDA. Default: the current CUDA device.
            out (Tensor, optional, keyword-only): the tensor to store gather result.
              Its sizes must match those of :attr:`tensors`, except for :attr:`dim`,
              where the size must equal ``sum(tensor.size(dim) for tensor in tensors)``.
              Can be on CPU or CUDA.
    
        .. note::
            :attr:`destination` must not be specified when :attr:`out` is specified.
    
        Returns:
            - If :attr:`destination` is specified,
                a tensor located on :attr:`destination` device, that is a result of
                concatenating :attr:`tensors` along :attr:`dim`.
            - If :attr:`out` is specified,
                the :attr:`out` tensor, now containing results of concatenating
                :attr:`tensors` along :attr:`dim`.
        """
        tensors = [_handle_complex(t) for t in tensors]
        if out is None:
            if destination == -1:
                warnings.warn(
                    'Using -1 to represent CPU tensor is deprecated. Please use a '
                    'device object or string instead, e.g., "cpu".')
            destination = _get_device_index(destination, allow_cpu=True, optional=True)
>           return torch._C._gather(tensors, dim, destination)
E           AttributeError: module 'torch._C' has no attribute '_gather'

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/comm.py:235: AttributeError
================================ tests coverage ================================
______________ coverage: platform darwin, python 3.10.19-final-0 _______________

Name                                                  Stmts   Miss Branch BrPart  Cover   Missing
-------------------------------------------------------------------------------------------------
tests/test_torch_nn_parallel_comm_broadcast.py           91     39     22      6    53%   13, 19, 29-34, 63, 67-100, 123-147, 158, 166-192, 268
tests/test_torch_nn_parallel_comm_reduce.py              80     37     22      6    48%   13, 19, 29-34, 70-114, 131-134, 156-170, 182
tests/test_torch_nn_parallel_comm_scatter_gather.py     194    100     28      8    48%   13, 19, 29-34, 66, 70-127, 149-196, 208, 221-259, 306-315, 327, 340-382, 429-442, 448
-------------------------------------------------------------------------------------------------
TOTAL                                                   365    176     72     20    49%
Coverage XML written to file coverage.xml
=========================== short test summary info ============================
FAILED tests/test_torch_nn_parallel_comm_broadcast.py::TestBroadcastFunctions::test_broadcast_basic[dtype0-cuda:0-shape0-target_devices0]
FAILED tests/test_torch_nn_parallel_comm_broadcast.py::TestBroadcastFunctions::test_broadcast_basic_cpu_fallback[dtype0-shape0-target_devices0]
FAILED tests/test_torch_nn_parallel_comm_broadcast.py::TestBroadcastFunctions::test_broadcast_basic_cpu_fallback[dtype1-shape1-target_devices1]
FAILED tests/test_torch_nn_parallel_comm_broadcast.py::TestBroadcastFunctions::test_broadcast_basic_cpu_fallback[dtype2-shape2-target_devices2]
FAILED tests/test_torch_nn_parallel_comm_broadcast.py::TestBroadcastFunctions::test_broadcast_parameter_conflict
FAILED tests/test_torch_nn_parallel_comm_reduce.py::TestReduceAddFunctions::test_reduce_add_shape_mismatch_exception
FAILED tests/test_torch_nn_parallel_comm_scatter_gather.py::TestScatterGatherFunctions::test_scatter_gather_roundtrip[dtype0-cuda:0-shape0-target_devices0-0]
FAILED tests/test_torch_nn_parallel_comm_scatter_gather.py::TestScatterGatherFunctions::test_scatter_gather_roundtrip[dtype1-cuda:0-shape1-target_devices1-1]
FAILED tests/test_torch_nn_parallel_comm_scatter_gather.py::TestScatterGatherFunctions::test_scatter_gather_roundtrip_cpu_fallback[dtype0-shape0-target_devices0-0]
FAILED tests/test_torch_nn_parallel_comm_scatter_gather.py::TestScatterGatherFunctions::test_scatter_gather_roundtrip_cpu_fallback[dtype1-shape1-target_devices1-1]
FAILED tests/test_torch_nn_parallel_comm_scatter_gather.py::TestScatterGatherFunctions::test_scatter_parameter_conflict_exception
FAILED tests/test_torch_nn_parallel_comm_scatter_gather.py::TestScatterGatherFunctions::test_scatter_parameter_conflict_exception_cpu_fallback
FAILED tests/test_torch_nn_parallel_comm_scatter_gather.py::TestScatterGatherFunctions::test_gather_mutually_exclusive_parameter_check
FAILED tests/test_torch_nn_parallel_comm_scatter_gather.py::TestScatterGatherFunctions::test_gather_mutually_exclusive_parameter_check_cpu_fallback
14 failed, 1 passed, 2 skipped in 0.95s

Error: exit 1