# torch.nn.utils.weight_norm 测试需求

## 1. 目标与范围
- 主要功能与期望行为：对模块参数应用权重归一化，将权重分解为幅度(g)和方向(v)，通过前向钩子动态计算权重
- 不在范围内的内容：权重归一化的移除、自定义范数计算、梯度计算验证

## 2. 输入与约束
- 参数列表：
  - module: PyTorch Module类型，必须包含要归一化的参数
  - name: str类型，默认'weight'，要归一化的参数名称
  - dim: int类型，默认0，计算范数的维度，可接受None值
- 有效取值范围/维度/设备要求：
  - module必须是torch.nn.Module子类
  - name参数必须存在于module中且为Parameter类型
  - dim可为0或None，dim=0时按输出通道独立计算范数
  - 支持CPU和CUDA设备
- 必需与可选组合：
  - module为必需参数
  - name和dim为可选参数，有默认值
- 随机性/全局状态要求：无随机性，但会修改模块内部状态

## 3. 输出与判定
- 期望返回结构及关键字段：
  - 返回原始模块对象（原地修改）
  - 模块新增参数：name_g（幅度）和name_v（方向）
  - 原始name参数被移除
- 容差/误差界（如浮点）：
  - 浮点计算误差在1e-6范围内
  - 权重重构误差：w ≈ g * v/||v||
- 状态变化或副作用检查点：
  - 模块参数列表变化：新增_g和_v参数
  - 前向传播钩子正确注册
  - 每次前向传播前权重被重新计算

## 4. 错误与异常场景
- 非法输入/维度/类型触发的异常或警告：
  - module不是nn.Module类型 → TypeError
  - name参数不存在于module中 → AttributeError
  - name参数不是Parameter类型 → TypeError
  - dim不是int或None类型 → TypeError
- 边界值（空、None、0长度、极端形状/数值）：
  - dim=None时在整个张量上计算范数
  - 权重张量维度为1时dim=0的行为
  - 权重张量包含NaN/Inf值
  - 权重张量全零或极小值

## 5. 依赖与环境
- 外部资源/设备/网络/文件依赖：
  - PyTorch库依赖
  - CUDA设备（可选测试）
- 需要mock/monkeypatch的部分：
  - `torch.nn.utils.weight_norm.WeightNorm.apply`内部实现
  - 前向传播钩子注册机制
  - 参数添加/移除的内部方法

## 6. 覆盖与优先级
- 必测路径（高优先级，最多5条，短句）：
  1. 对Linear层应用默认参数权重归一化
  2. 验证参数分解正确性：w ≈ g * v/||v||
  3. 测试dim=None在整个张量上计算范数
  4. 验证前向传播钩子正确触发权重重计算
  5. 测试不同参数名称（非'weight'）的归一化
- 可选路径（中/低优先级合并为一组列表）：
  - 测试不同模块类型（Conv2d, Conv1d, Conv3d）
  - 测试不同设备（CPU, CUDA）
  - 测试梯度计算和反向传播
  - 测试极端形状权重（1维, 高维）
  - 测试与其他nn.Module方法的兼容性
- 已知风险/缺失信息（仅列条目，不展开）：
  - WeightNorm.apply内部实现细节未知
  - dim参数类型注解与实际接受None值不一致
  - 未明确支持的模块类型范围
  - 缺少移除权重归一化的测试