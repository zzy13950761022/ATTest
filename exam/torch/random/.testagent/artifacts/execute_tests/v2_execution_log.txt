=== Run Tests ===
F...F..                                                                  [100%]
=================================== FAILURES ===================================
_____________ TestTorchRandom.test_manual_seed_basic[42-Generator] _____________

self = <test_torch_random.TestTorchRandom object at 0x128cbf430>, seed = 42
expected_type = <class 'torch._C.Generator'>
mock_cuda_functions = {'bad_fork': <MagicMock name='_is_in_bad_fork' id='4979818064'>, 'device_count': <MagicMock name='device_count' id='49... name='get_rng_state_all' id='4979712032'>, 'manual_seed_all': <MagicMock name='manual_seed_all' id='4979810048'>, ...}

    @pytest.mark.parametrize("seed,expected_type", [
        (42, torch._C.Generator),
    ])
    def test_manual_seed_basic(self, seed, expected_type, mock_cuda_functions):
        """Test basic manual_seed functionality (TC-01)."""
        # Reset mock call count before test
        mock_cuda_functions['manual_seed_all'].reset_mock()
    
        # Call manual_seed
        result = torch.random.manual_seed(seed)
    
        # Weak assertions
        # 1. Return type is correct
        assert isinstance(result, expected_type), \
            f"manual_seed should return {expected_type}, got {type(result)}"
    
        # 2. Seed setting is successful (verify by checking random sequence)
        # Generate two random tensors with the same seed
        torch.random.manual_seed(seed)
        tensor1 = torch.randn(10)
    
        torch.random.manual_seed(seed)
        tensor2 = torch.randn(10)
    
        assert torch.allclose(tensor1, tensor2), \
            "Random sequence should be deterministic with same seed"
    
        # 3. Verify CUDA functions were called exactly once for the first call
        # Note: manual_seed_all should be called when manual_seed is called
        # We reset the mock above, so we only count calls from the first manual_seed
>       mock_cuda_functions['manual_seed_all'].assert_called_once_with(seed)

tests/test_torch_random.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock name='manual_seed_all' id='4979810048'>, args = (42,)
kwargs = {}
msg = "Expected 'manual_seed_all' to be called once. Called 3 times.\nCalls: [call(42), call(42), call(42)]."

    def assert_called_once_with(self, /, *args, **kwargs):
        """assert that the mock was called exactly once and that that call was
        with the specified arguments."""
        if not self.call_count == 1:
            msg = ("Expected '%s' to be called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
>           raise AssertionError(msg)
E           AssertionError: Expected 'manual_seed_all' to be called once. Called 3 times.
E           Calls: [call(42), call(42), call(42)].

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/unittest/mock.py:940: AssertionError
_________ TestTorchRandom.test_fork_rng_basic_context[None-True-basic] _________

self = <test_torch_random.TestTorchRandom object at 0x128d04310>, devices = None
enabled = True, context_type = 'basic'
mock_cuda_functions = {'bad_fork': <MagicMock name='_is_in_bad_fork' id='4980217920'>, 'device_count': <MagicMock name='device_count' id='49... name='get_rng_state_all' id='4981115248'>, 'manual_seed_all': <MagicMock name='manual_seed_all' id='4981831952'>, ...}

    @pytest.mark.parametrize("devices,enabled,context_type", [
        (None, True, "basic"),
    ])
    def test_fork_rng_basic_context(self, devices, enabled, context_type, mock_cuda_functions):
        """Test basic fork_rng context management (TC-04)."""
    
        # Setup mock CUDA state - only if CUDA is available in the mock
        mock_cuda_state = torch.ByteTensor([1, 2, 3, 4, 5])
        mock_cuda_functions['get_state_all'].return_value = [mock_cuda_state] * 2  # 2 devices
    
        # Save original CPU RNG state
        original_cpu_state = torch.random.get_rng_state()
    
        # Generate some random data before context
        before_random = torch.randn(3, 3)
    
        # Enter fork_rng context
>       with torch.random.fork_rng(devices=devices, enabled=enabled):

tests/test_torch_random.py:252: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/random.py:122: in fork_rng
    gpu_rng_states.append(torch.cuda.get_rng_state(device))
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/cuda/random.py:22: in get_rng_state
    _lazy_init()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _lazy_init():
        global _initialized, _queued_calls
        if is_initialized() or hasattr(_tls, 'is_initializing'):
            return
        with _initialization_lock:
            # We be double-checked locking, boys!  This is OK because
            # the above test was GIL protected anyway.  The inner test
            # is for when a thread blocked on some other thread which was
            # doing the initialization; when they get the lock, they will
            # find there is nothing left to do.
            if is_initialized():
                return
            # It is important to prevent other threads from entering _lazy_init
            # immediately, while we are still guaranteed to have the GIL, because some
            # of the C calls we make below will release the GIL
            if _is_in_bad_fork():
                raise RuntimeError(
                    "Cannot re-initialize CUDA in forked subprocess. To use CUDA with "
                    "multiprocessing, you must use the 'spawn' start method")
            if not hasattr(torch._C, '_cuda_getDeviceCount'):
>               raise AssertionError("Torch not compiled with CUDA enabled")
E               AssertionError: Torch not compiled with CUDA enabled

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/cuda/__init__.py:221: AssertionError
=============================== warnings summary ===============================
exam/torch_group/random/tests/test_torch_random.py::TestTorchRandom::test_fork_rng_basic_context[None-True-basic]
  /opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/random.py:99: UserWarning: CUDA reports that you have 2 available devices, and you have used fork_rng without explicitly specifying which devices are being used. For safety, we initialize *every* CUDA device by default, which can be quite slow if you have a lot of GPUs.  If you know that you are only making use of a few CUDA devices, set the environment variable CUDA_VISIBLE_DEVICES or the 'devices' keyword argument of fork_rng with the set of devices you are actually using.  For example, if you are using CPU only, set CUDA_VISIBLE_DEVICES= or devices=[]; if you are using GPU 0 only, set CUDA_VISIBLE_DEVICES=0 or devices=[0].  To initialize all devices and suppress this warning, set the 'devices' keyword argument to `range(torch.cuda.device_count())`.
    warnings.warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================================ tests coverage ================================
______________ coverage: platform darwin, python 3.10.19-final-0 _______________

Name                         Stmts   Miss Branch BrPart  Cover   Missing
------------------------------------------------------------------------
tests/test_torch_random.py     132     38     18      2    65%   74-82, 119->exit, 145, 255-326
------------------------------------------------------------------------
TOTAL                          132     38     18      2    65%
Coverage XML written to file coverage.xml
=========================== short test summary info ============================
FAILED tests/test_torch_random.py::TestTorchRandom::test_manual_seed_basic[42-Generator]
FAILED tests/test_torch_random.py::TestTorchRandom::test_fork_rng_basic_context[None-True-basic]
2 failed, 5 passed, 1 warning in 0.74s

Error: exit 1