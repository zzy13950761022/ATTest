=== Run Tests ===
....F..                                                                  [100%]
=================================== FAILURES ===================================
_________ TestTorchRandom.test_fork_rng_basic_context[None-True-basic] _________

self = <test_torch_random.TestTorchRandom object at 0x159abff10>, devices = None
enabled = True, context_type = 'basic'
mock_cuda_functions = {'bad_fork': <MagicMock name='_is_in_bad_fork' id='5802203968'>, 'device_count': <MagicMock name='device_count' id='58...Mock name='get_rng_state' id='5802146496'>, 'get_state_all': <MagicMock name='get_rng_state_all' id='5802263408'>, ...}

    @pytest.mark.parametrize("devices,enabled,context_type", [
        (None, True, "basic"),
    ])
    def test_fork_rng_basic_context(self, devices, enabled, context_type, mock_cuda_functions):
        """Test basic fork_rng context management (TC-04)."""
    
        # Setup mock CUDA state - only if CUDA is available in the mock
        mock_cuda_state = torch.ByteTensor([1, 2, 3, 4, 5])
        mock_cuda_functions['get_rng_state'].return_value = mock_cuda_state
    
        # Save original CPU RNG state
        original_cpu_state = torch.random.get_rng_state()
    
        # Generate some random data before context
        before_random = torch.randn(3, 3)
    
        # Enter fork_rng context
        with torch.random.fork_rng(devices=devices, enabled=enabled):
            # Inside context, RNG should be forked
            # Generate random data inside context
            inside_random = torch.randn(3, 3)
    
            # Change RNG state inside context
            torch.random.manual_seed(999)
            changed_inside_random = torch.randn(3, 3)
    
            # Verify CUDA functions were called for context entry if enabled
            # Only check if CUDA is mocked as available (device_count > 0)
            if enabled and mock_cuda_functions['device_count'].return_value > 0:
                # fork_rng calls get_rng_state for each device, not get_rng_state_all
                # With 2 mock devices, it should be called twice
                assert mock_cuda_functions['get_rng_state'].call_count == 2, \
                    f"Expected get_rng_state to be called 2 times (once per device), " \
                    f"but called {mock_cuda_functions['get_rng_state'].call_count} times"
    
        # Weak assertions
        # 1. Context manager works (no exceptions)
        # 2. External state is restored after context exit
    
        # Generate random data after context
        after_random = torch.randn(3, 3)
    
        # Save state after context
        after_state = torch.random.get_rng_state()
    
        # Verify external state restoration
        # Reset to original state and generate same sequence
        torch.random.set_rng_state(original_cpu_state)
        # Skip the 'before_random' generation (we already consumed it)
        _ = torch.randn(3, 3)  # This should match before_random
        verification_after = torch.randn(3, 3)  # This should match after_random
    
        assert torch.allclose(after_random, verification_after, rtol=1e-5, atol=1e-5), \
            f"External RNG state should be restored after fork_rng context. " \
            f"Max diff: {(after_random - verification_after).abs().max().item()}"
    
        # 3. Internal isolation was effective
        # The random sequence inside context should be different from outside
        # (This is probabilistic but should hold)
        assert not torch.allclose(before_random, inside_random, rtol=1e-5, atol=1e-5), \
            "Random sequences inside and outside context should differ"
    
        # 4. Verify CUDA state restoration if enabled and CUDA is available
        if enabled and mock_cuda_functions['device_count'].return_value > 0:
            # fork_rng calls set_rng_state for each device, not set_rng_state_all
            # With 2 mock devices, it should be called twice
            assert mock_cuda_functions['set_rng_state'].call_count == 2, \
                f"Expected set_rng_state to be called 2 times (once per device), " \
                f"but called {mock_cuda_functions['set_rng_state'].call_count} times"
    
            # Check the calls were made with correct arguments
            calls = mock_cuda_functions['set_rng_state'].call_args_list
            for i, call in enumerate(calls):
                args, kwargs = call
                # First arg should be the state tensor
                assert isinstance(args[0], torch.Tensor)
                # Second arg should be device index
                assert args[1] == i, f"Expected device index {i}, got {args[1]}"
    
        # 5. Context type verification
        assert context_type == "basic", \
            f"Expected context_type 'basic', got {context_type}"
    
        # 6. Test with enabled=False (should not fork)
        # Reset mocks for the disabled test
        mock_cuda_functions['get_rng_state'].reset_mock()
        mock_cuda_functions['set_rng_state'].reset_mock()
    
        with torch.random.fork_rng(enabled=False):
            # No state saving should occur
            pass
    
        # Verify CUDA calls based on enabled flag and CUDA availability
        if not enabled:
            # If disabled, no CUDA calls should be made
            mock_cuda_functions['get_rng_state'].assert_not_called()
            mock_cuda_functions['set_rng_state'].assert_not_called()
        elif mock_cuda_functions['device_count'].return_value > 0:
            # If enabled and CUDA available, it should have been called
            # fork_rng calls get_rng_state for each device
>           assert mock_cuda_functions['get_rng_state'].call_count == 2, \
                f"Expected get_rng_state to be called 2 times, " \
                f"but called {mock_cuda_functions['get_rng_state'].call_count} times"
E           AssertionError: Expected get_rng_state to be called 2 times, but called 0 times
E           assert 0 == 2
E            +  where 0 = <MagicMock name='get_rng_state' id='5802146496'>.call_count

tests/test_torch_random.py:345: AssertionError
=============================== warnings summary ===============================
exam/torch_group/random/tests/test_torch_random.py::TestTorchRandom::test_fork_rng_basic_context[None-True-basic]
  /opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/random.py:99: UserWarning: CUDA reports that you have 2 available devices, and you have used fork_rng without explicitly specifying which devices are being used. For safety, we initialize *every* CUDA device by default, which can be quite slow if you have a lot of GPUs.  If you know that you are only making use of a few CUDA devices, set the environment variable CUDA_VISIBLE_DEVICES or the 'devices' keyword argument of fork_rng with the set of devices you are actually using.  For example, if you are using CPU only, set CUDA_VISIBLE_DEVICES= or devices=[]; if you are using GPU 0 only, set CUDA_VISIBLE_DEVICES=0 or devices=[0].  To initialize all devices and suppress this warning, set the 'devices' keyword argument to `range(torch.cuda.device_count())`.
    warnings.warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================================ tests coverage ================================
______________ coverage: platform darwin, python 3.10.19-final-0 _______________

Name                         Stmts   Miss Branch BrPart  Cover   Missing
------------------------------------------------------------------------
tests/test_torch_random.py     135     10     18      7    89%   87-92, 129->exit, 155, 273->285, 308->325, 340-341, 349-355
------------------------------------------------------------------------
TOTAL                          135     10     18      7    89%
Coverage XML written to file coverage.xml
=========================== short test summary info ============================
FAILED tests/test_torch_random.py::TestTorchRandom::test_fork_rng_basic_context[None-True-basic]
1 failed, 6 passed, 1 warning in 0.74s

Error: exit 1