=== Run Tests ===
F..FF..                                                                  [100%]
=================================== FAILURES ===================================
_____________ TestTorchRandom.test_manual_seed_basic[42-Generator] _____________

self = <test_torch_random.TestTorchRandom object at 0x10c2bb550>, seed = 42
expected_type = <class 'torch._C.Generator'>
mock_cuda_functions = {'bad_fork': <MagicMock name='_is_in_bad_fork' id='4500619120'>, 'device_count': <MagicMock name='device_count' id='44... name='get_rng_state_all' id='4500513088'>, 'manual_seed_all': <MagicMock name='manual_seed_all' id='4500611104'>, ...}

    @pytest.mark.parametrize("seed,expected_type", [
        (42, torch._C.Generator),
    ])
    def test_manual_seed_basic(self, seed, expected_type, mock_cuda_functions):
        """Test basic manual_seed functionality (TC-01)."""
        # Call manual_seed
        result = torch.random.manual_seed(seed)
    
        # Weak assertions
        # 1. Return type is correct
        assert isinstance(result, expected_type), \
            f"manual_seed should return {expected_type}, got {type(result)}"
    
        # 2. Seed setting is successful (verify by checking random sequence)
        # Generate two random tensors with the same seed
        torch.random.manual_seed(seed)
        tensor1 = torch.randn(10)
    
        torch.random.manual_seed(seed)
        tensor2 = torch.randn(10)
    
        assert torch.allclose(tensor1, tensor2), \
            "Random sequence should be deterministic with same seed"
    
        # 3. Verify CUDA functions were called
>       mock_cuda_functions['manual_seed_all'].assert_called_once_with(seed)

tests/test_torch_random.py:66: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock name='manual_seed_all' id='4500611104'>, args = (42,)
kwargs = {}
msg = "Expected 'manual_seed_all' to be called once. Called 3 times.\nCalls: [call(42), call(42), call(42)]."

    def assert_called_once_with(self, /, *args, **kwargs):
        """assert that the mock was called exactly once and that that call was
        with the specified arguments."""
        if not self.call_count == 1:
            msg = ("Expected '%s' to be called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
>           raise AssertionError(msg)
E           AssertionError: Expected 'manual_seed_all' to be called once. Called 3 times.
E           Calls: [call(42), call(42), call(42)].

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/unittest/mock.py:940: AssertionError
___ TestTorchRandom.test_state_save_restore_basic[valid-operation_sequence0] ___

self = <test_torch_random.TestTorchRandom object at 0x10c2bbfa0>
state_type = 'valid', operation_sequence = ['get', 'set']

    @pytest.mark.parametrize("state_type,operation_sequence", [
        ("valid", ["get", "set"]),
    ])
    def test_state_save_restore_basic(self, state_type, operation_sequence):
        """Test basic state save/restore functionality (TC-03)."""
    
        # Generate some random data to create state
        torch.random.manual_seed(42)
        original_random_data = torch.randn(5, 5)
    
        # Get current RNG state
        state = torch.random.get_rng_state()
    
        # Weak assertions for get_rng_state()
        # 1. Returns ByteTensor
        assert isinstance(state, torch.Tensor), \
            f"get_rng_state() should return Tensor, got {type(state)}"
        assert state.dtype == torch.uint8, \
            f"get_rng_state() should return ByteTensor (uint8), got {state.dtype}"
    
        # 2. State tensor has valid structure
        assert state.dim() == 1, \
            f"RNG state should be 1D tensor, got shape {state.shape}"
        assert state.numel() > 0, \
            "RNG state tensor should not be empty"
    
        # Generate more random data to change state
        changed_random_data = torch.randn(5, 5)
    
        # Verify state changed (random sequences are different)
        assert not torch.allclose(original_random_data, changed_random_data), \
            "Random sequences should differ after state change"
    
        # Restore original state
        torch.random.set_rng_state(state)
    
        # Weak assertions for set_rng_state()
        # 1. set_rng_state returns None (implicitly tested)
        # 2. State restoration is successful
    
        # Generate random data again after restoration
        restored_random_data = torch.randn(5, 5)
    
        # Verify sequence is restored (should match original sequence)
        # Note: We need to reset to the same point in sequence
        torch.random.set_rng_state(state)
        verification_random_data = torch.randn(5, 5)
    
>       assert torch.allclose(original_random_data, verification_random_data), \
            "Random sequence should be restored after set_rng_state"
E       AssertionError: Random sequence should be restored after set_rng_state
E       assert False
E        +  where False = <built-in method allclose of type object at 0x104dee320>(tensor([[ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784],\n        [-1.2345, -0.0431, -1.6047, -0.7521, -0.6866],\n        ...2.3169],\n        [-0.2168, -1.3847, -0.3957,  0.8034, -0.6216],\n        [-0.5920, -0.0631, -0.8286,  0.3309, -1.5576]]), tensor([[ 0.3211,  1.5736, -0.8455,  1.3123,  0.6872],\n        [-1.0892, -0.3553, -0.9138,  0.8963,  2.2181],\n        ...1.2780],\n        [ 0.1453,  0.2311,  0.0566,  0.4263,  0.5750],\n        [-0.6417, -2.2064, -0.7508,  2.8140,  0.3598]]))
E        +    where <built-in method allclose of type object at 0x104dee320> = torch.allclose

tests/test_torch_random.py:198: AssertionError
_________ TestTorchRandom.test_fork_rng_basic_context[None-True-basic] _________

self = <test_torch_random.TestTorchRandom object at 0x10c404430>, devices = None
enabled = True, context_type = 'basic'
mock_cuda_functions = {'bad_fork': <MagicMock name='_is_in_bad_fork' id='4501447648'>, 'device_count': <MagicMock name='device_count' id='45... name='get_rng_state_all' id='4502607216'>, 'manual_seed_all': <MagicMock name='manual_seed_all' id='4501439728'>, ...}

    @pytest.mark.parametrize("devices,enabled,context_type", [
        (None, True, "basic"),
    ])
    def test_fork_rng_basic_context(self, devices, enabled, context_type, mock_cuda_functions):
        """Test basic fork_rng context management (TC-04)."""
    
        # Setup mock CUDA state
        mock_cuda_state = torch.ByteTensor([1, 2, 3, 4, 5])
        mock_cuda_functions['get_state_all'].return_value = [mock_cuda_state] * 2  # 2 devices
    
        # Save original CPU RNG state
        original_cpu_state = torch.random.get_rng_state()
    
        # Generate some random data before context
        before_random = torch.randn(3, 3)
    
        # Enter fork_rng context
>       with torch.random.fork_rng(devices=devices, enabled=enabled):

tests/test_torch_random.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/contextlib.py:135: in __enter__
    return next(self.gen)
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/random.py:122: in fork_rng
    gpu_rng_states.append(torch.cuda.get_rng_state(device))
/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/cuda/random.py:22: in get_rng_state
    _lazy_init()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _lazy_init():
        global _initialized, _queued_calls
        if is_initialized() or hasattr(_tls, 'is_initializing'):
            return
        with _initialization_lock:
            # We be double-checked locking, boys!  This is OK because
            # the above test was GIL protected anyway.  The inner test
            # is for when a thread blocked on some other thread which was
            # doing the initialization; when they get the lock, they will
            # find there is nothing left to do.
            if is_initialized():
                return
            # It is important to prevent other threads from entering _lazy_init
            # immediately, while we are still guaranteed to have the GIL, because some
            # of the C calls we make below will release the GIL
            if _is_in_bad_fork():
                raise RuntimeError(
                    "Cannot re-initialize CUDA in forked subprocess. To use CUDA with "
                    "multiprocessing, you must use the 'spawn' start method")
            if not hasattr(torch._C, '_cuda_getDeviceCount'):
>               raise AssertionError("Torch not compiled with CUDA enabled")
E               AssertionError: Torch not compiled with CUDA enabled

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/cuda/__init__.py:221: AssertionError
=============================== warnings summary ===============================
exam/torch_group/random/tests/test_torch_random.py::TestTorchRandom::test_fork_rng_basic_context[None-True-basic]
  /opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/random.py:99: UserWarning: CUDA reports that you have 2 available devices, and you have used fork_rng without explicitly specifying which devices are being used. For safety, we initialize *every* CUDA device by default, which can be quite slow if you have a lot of GPUs.  If you know that you are only making use of a few CUDA devices, set the environment variable CUDA_VISIBLE_DEVICES or the 'devices' keyword argument of fork_rng with the set of devices you are actually using.  For example, if you are using CPU only, set CUDA_VISIBLE_DEVICES= or devices=[]; if you are using GPU 0 only, set CUDA_VISIBLE_DEVICES=0 or devices=[0].  To initialize all devices and suppress this warning, set the 'devices' keyword argument to `range(torch.cuda.device_count())`.
    warnings.warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================================ tests coverage ================================
______________ coverage: platform darwin, python 3.10.19-final-0 _______________

Name                         Stmts   Miss Branch BrPart  Cover   Missing
------------------------------------------------------------------------
tests/test_torch_random.py     124     39     14      2    64%   69-77, 114->exit, 140, 203-214, 239-299
------------------------------------------------------------------------
TOTAL                          124     39     14      2    64%
Coverage XML written to file coverage.xml
=========================== short test summary info ============================
FAILED tests/test_torch_random.py::TestTorchRandom::test_manual_seed_basic[42-Generator]
FAILED tests/test_torch_random.py::TestTorchRandom::test_state_save_restore_basic[valid-operation_sequence0]
FAILED tests/test_torch_random.py::TestTorchRandom::test_fork_rng_basic_context[None-True-basic]
3 failed, 4 passed, 1 warning in 0.58s

Error: exit 1