=== Run Tests ===
...F....F.....                                                           [100%]
=================================== FAILURES ===================================
____________________ test_complex_module_structure_tracing _____________________

    def test_complex_module_structure_tracing():
        """Test complex module structure tracing (CASE_06)."""
        # Set random seed for reproducibility
        set_random_seed(42)
    
        # Create a complex sequential module with multiple layers
        class ComplexSequentialModule(nn.Module):
            def __init__(self):
                super().__init__()
                # Create a sequential module with multiple layers
                self.features = nn.Sequential(
                    nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),
                    nn.BatchNorm2d(16),
                    nn.ReLU(inplace=True),
                    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),
                    nn.BatchNorm2d(32),
                    nn.ReLU(inplace=True),
                    nn.AdaptiveAvgPool2d((1, 1)),
                    nn.Flatten(),
                    nn.Linear(32, 10)
                )
    
                # Add some additional parallel layers
                self.parallel_branch = nn.Sequential(
                    nn.Conv2d(in_channels=3, out_channels=8, kernel_size=1),
                    nn.ReLU(inplace=True),
                    nn.AdaptiveAvgPool2d((1, 1)),
                    nn.Flatten(),
                    nn.Linear(8, 5)
                )
    
                # Final combination layer
                self.combine = nn.Linear(15, 7)  # 10 + 5 = 15
    
            def forward(self, x: torch.Tensor) -> torch.Tensor:
                # Main branch
                main_out = self.features(x)
    
                # Parallel branch
                parallel_out = self.parallel_branch(x)
    
                # Combine outputs
                combined = torch.cat([main_out, parallel_out], dim=1)
                output = self.combine(combined)
    
                return output
    
        # Create test module
        module = ComplexSequentialModule()
        module.eval()  # Set to eval mode for consistent behavior
    
        # Create test input with shape [2, 3, 32, 32]
        shape = (2, 3, 32, 32)
        x = create_test_tensor(shape, dtype=torch.float32, device='cpu')
    
        # Test the original module
        original_output = module(x)
    
        # Trace the module with strict=True and check_trace=True
        traced_module = torch.jit.trace(
            func=module,
            example_inputs=x,
            strict=True,
            check_trace=True
        )
    
        # Test the traced module
        traced_output = traced_module(x)
    
        # Weak assertions
        # 1. Output shape check
        assert traced_output.shape == original_output.shape, \
            f"Traced output shape {traced_output.shape} != original shape {original_output.shape}"
    
        # 2. Output dtype check
        assert traced_output.dtype == original_output.dtype, \
            f"Traced output dtype {traced_output.dtype} != original dtype {original_output.dtype}"
    
        # 3. Basic equality check (within tolerance)
        tolerance = 1e-5
        assert torch.allclose(traced_output, original_output, rtol=tolerance, atol=tolerance), \
            f"Traced output differs from original output beyond tolerance {tolerance}"
    
        # Additional checks for complex module structure
        # Check that traced module is a ScriptModule
        assert isinstance(traced_module, torch.jit.ScriptModule), \
            f"Traced module should be ScriptModule, got {type(traced_module)}"
    
        # Check submodule preservation
        # Note: When tracing, submodules are flattened into the main module
        # We can check that the traced module has the same parameters
        original_params = dict(module.named_parameters())
        traced_params = dict(traced_module.named_parameters())
    
        # Check that all parameter names are preserved
        original_param_names = set(original_params.keys())
        traced_param_names = set(traced_params.keys())
    
        # The traced module might have slightly different parameter names due to flattening
        # But the number of parameters should be the same
        assert len(original_params) == len(traced_params), \
            f"Number of parameters changed: {len(original_params)} vs {len(traced_params)}"
    
        # Check parameter values match (within tolerance)
        for orig_name, orig_param in original_params.items():
            # Find corresponding parameter in traced module
            # Parameter names might be prefixed in traced module
            found = False
            for traced_name, traced_param in traced_params.items():
                if orig_name in traced_name or traced_name.endswith(orig_name.split('.')[-1]):
>                   assert torch.allclose(orig_param, traced_param, rtol=tolerance, atol=tolerance), \
                        f"Parameter {orig_name} values don't match"
E                   RuntimeError: The size of tensor a (16) must match the size of tensor b (3) at non-singleton dimension 3

tests/test_torch_jit_trace_g2.py:225: RuntimeError
_________________________ test_invalid_input_handling __________________________

    def test_invalid_input_handling():
        """Test exception handling for invalid inputs."""
        set_random_seed(42)
    
        # Define a simple function
        def add_multiply(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:
            """Simple function: (x + y) * 2"""
            return (x + y) * 2
    
        # Create valid test tensors
        shape = (2, 2)
        x = torch.randn(shape, dtype=torch.float32)
        y = torch.randn(shape, dtype=torch.float32)
    
        # Test 1: Non-tensor input should raise an error during tracing
        print("Test 1: Testing with non-tensor input...")
        with pytest.raises((RuntimeError, TypeError)) as exc_info:
            # Try to trace with a non-tensor input
            traced_fn = torch.jit.trace(
                add_multiply,
                (x, 42),  # 42 is not a tensor
                strict=True,
                check_trace=True
            )
    
        # Check error message contains expected keywords
        error_msg = str(exc_info.value).lower()
        assert any(keyword in error_msg for keyword in ['tensor', 'type', 'expected']), \
            f"Expected error about tensor type, got: {error_msg}"
    
        # Test 2: Mismatched shape inputs should work during tracing
        # but might fail during execution with wrong shapes
        print("Test 2: Testing with mismatched shapes during execution...")
    
        # First trace with correct shapes
        traced_fn = torch.jit.trace(
            add_multiply,
            (x, y),
            strict=True,
            check_trace=True
        )
    
        # Now try to call with mismatched shapes
        y_wrong_shape = torch.randn(3, 3, dtype=torch.float32)
    
        # This should raise a runtime error when executing the traced function
        with pytest.raises(RuntimeError) as exc_info:
            traced_fn(x, y_wrong_shape)
    
        error_msg = str(exc_info.value).lower()
        # The error might be about shape mismatch or broadcasting
        assert any(keyword in error_msg for keyword in ['shape', 'size', 'broadcast', 'inconsistent']), \
            f"Expected error about shape mismatch, got: {error_msg}"
    
        # Test 3: None input should raise an error
        print("Test 3: Testing with None input...")
        with pytest.raises((RuntimeError, TypeError)) as exc_info:
            traced_fn = torch.jit.trace(
                add_multiply,
                (x, None),  # None is not a tensor
                strict=True,
                check_trace=True
            )
    
        # Test 4: Wrong dtype input to traced function
        print("Test 4: Testing with wrong dtype...")
        y_wrong_dtype = torch.randn(shape, dtype=torch.float64)
    
        # This might work (dtype conversion) or fail depending on PyTorch version
        try:
            result = traced_fn(x, y_wrong_dtype)
            # If it works, check the result dtype
            assert result.dtype == torch.float32 or result.dtype == torch.float64, \
                f"Unexpected dtype: {result.dtype}"
        except RuntimeError as e:
            # It's also acceptable if it fails with a dtype error
            error_msg = str(e).lower()
            assert any(keyword in error_msg for keyword in ['dtype', 'type', 'scalar type']), \
                f"Expected error about dtype, got: {error_msg}"
    
        # Test 5: Test with invalid function (not callable)
        print("Test 5: Testing with non-callable func...")
        # Based on the execution log, torch.jit.trace raises RuntimeError when
        # trying to get the qualified name of a non-callable object
        with pytest.raises(RuntimeError) as exc_info:
            traced_fn = torch.jit.trace(
                "not a function",  # Not callable
                (x, y),
                strict=True,
                check_trace=True
            )
    
        # Check the error message
        error_msg = str(exc_info.value).lower()
        # The error should be about not being able to get the name
        assert any(keyword in error_msg for keyword in ['name', 'class', 'object', 'qualified']), \
            f"Expected error about getting object name, got: {error_msg}"
    
        # Test 6: Test with empty example_inputs tuple
        print("Test 6: Testing with empty example_inputs...")
        with pytest.raises((RuntimeError, ValueError)) as exc_info:
>           traced_fn = torch.jit.trace(
                add_multiply,
                (),  # Empty tuple
                strict=True,
                check_trace=True
            )

tests/test_torch_jit_trace_g4.py:191: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

func = <function test_invalid_input_handling.<locals>.add_multiply at 0x117c37490>
example_inputs = (), optimize = None, check_trace = True, check_inputs = None
check_tolerance = 1e-05, strict = True, _force_outplace = False
_module_class = None
_compilation_unit = <torch.jit.CompilationUnit object at 0x1030f3330>

    def trace(
        func,
        example_inputs,
        optimize=None,
        check_trace=True,
        check_inputs=None,
        check_tolerance=1e-5,
        strict=True,
        _force_outplace=False,
        _module_class=None,
        _compilation_unit=_python_cu,
    ):
        """
        Trace a function and return an executable  or :class:`ScriptFunction`
        that will be optimized using just-in-time compilation. Tracing is ideal for
        code that operates only on ``Tensor``\\s and lists, dictionaries, and
        tuples of ``Tensor``\\s.
    
        Using `torch.jit.trace` and `torch.jit.trace_module`, you can turn an
        existing module or Python function into a TorchScript
        :class:`ScriptFunction` or :class:`ScriptModule`. You must provide example
        inputs, and we run the function, recording the operations performed on all
        the tensors.
    
        * The resulting recording of a standalone function produces `ScriptFunction`.
        * The resulting recording of `nn.Module.forward` or `nn.Module` produces
          `ScriptModule`.
    
        This module also contains any parameters that the original
        module had as well.
    
        Warning:
            Tracing only correctly records functions and modules which are not data
            dependent (e.g., do not have conditionals on data in tensors) and do not have
            any untracked external dependencies (e.g., perform input/output or
            access global variables). Tracing only records operations done when the given
            function is run on the given tensors. Therefore, the returned
            `ScriptModule` will always run the same traced graph on any input. This
            has some important implications when your module is expected to run
            different sets of operations, depending on the input and/or the module
            state. For example,
    
            * Tracing will not record any control-flow like if-statements or loops.
              When this control-flow is constant across your module, this is fine
              and it often inlines the control-flow decisions. But sometimes the
              control-flow is actually part of the model itself. For instance, a
              recurrent network is a loop over the (possibly dynamic) length of an
              input sequence.
            * In the returned :class:`ScriptModule`, operations that have different
              behaviors in ``training`` and ``eval`` modes will always behave as if
              it is in the mode it was in during tracing, no matter which mode the
              `ScriptModule` is in.
    
            In cases like these, tracing would not be appropriate and
            :func:`scripting <torch.jit.script>` is a better choice. If you trace
            such models, you may silently get incorrect results on subsequent
            invocations of the model. The tracer will try to emit warnings when
            doing something that may cause an incorrect trace to be produced.
    
        Args:
            func (callable or torch.nn.Module):  A Python function or `torch.nn.Module`
                that will be run with `example_inputs`. `func` arguments and return
                values  must be tensors or (possibly nested) tuples that contain
                tensors. When a module is passed `torch.jit.trace`, only the
                ``forward`` method is run and traced (see :func:`torch.jit.trace
                <torch.jit.trace_module>` for details).
            example_inputs (tuple or torch.Tensor):  A tuple of example inputs that
                will be passed to the function while tracing. The resulting trace
                can be run with inputs of different types and shapes assuming the
                traced operations support those types and shapes. `example_inputs`
                may also be a single Tensor in which case it is automatically
                wrapped in a tuple.
    
        Keyword arguments:
            check_trace (``bool``, optional): Check if the same inputs run through
                traced code produce the same outputs. Default: ``True``. You might want
                to disable this if, for example, your network contains non-
                deterministic ops or if you are sure that the network is correct despite
                a checker failure.
    
            check_inputs (list of tuples, optional): A list of tuples of input
                arguments that should be used to check the trace against what is
                expected. Each tuple is equivalent to a set of input arguments that
                would be specified in ``example_inputs``. For best results, pass in
                a set of checking inputs representative of the space of shapes and
                types of inputs you expect the network to see.  If not specified,
                the original ``example_inputs`` are used for checking
            check_tolerance (float, optional): Floating-point comparison tolerance
                to use in the checker procedure.  This can be used to relax the
                checker strictness in the event that results diverge numerically
                for a known reason, such as operator fusion.
            strict (``bool``, optional): run the tracer in a strict mode or not
                (default: ``True``). Only turn this off when you want the tracer to
                record your mutable container types (currently ``list``/``dict``)
                and you are sure that the container you are using in your
                problem is a ``constant`` structure and does not get used as
                control flow (if, for) conditions.
    
        Returns:
            If `func` is `nn.Module` or ``forward`` of `nn.Module`, `trace` returns
            a :class:`ScriptModule` object with a single ``forward`` method
            containing the traced code.  The returned `ScriptModule` will
            have the same set of sub-modules and parameters as the original
            ``nn.Module``.  If ``func`` is a standalone function, ``trace``
            returns `ScriptFunction`.
    
        Example (tracing a function):
    
        .. testcode::
    
            import torch
    
            def foo(x, y):
                return 2 * x + y
    
            # Run `foo` with the provided inputs and record the tensor operations
            traced_foo = torch.jit.trace(foo, (torch.rand(3), torch.rand(3)))
    
            # `traced_foo` can now be run with the TorchScript interpreter or saved
            # and loaded in a Python-free environment
    
        Example (tracing an existing module)::
    
            import torch
            import torch.nn as nn
    
            class Net(nn.Module):
                def __init__(self):
                    super(Net, self).__init__()
                    self.conv = nn.Conv2d(1, 1, 3)
    
                def forward(self, x):
                    return self.conv(x)
    
            n = Net()
            example_weight = torch.rand(1, 1, 3, 3)
            example_forward_input = torch.rand(1, 1, 3, 3)
    
            # Trace a specific method and construct `ScriptModule` with
            # a single `forward` method
            module = torch.jit.trace(n.forward, example_forward_input)
    
            # Trace a module (implicitly traces `forward`) and construct a
            # `ScriptModule` with a single `forward` method
            module = torch.jit.trace(n, example_forward_input)
    
        """
        if not _enabled:
            return func
        if optimize is not None:
            warnings.warn(
                "`optimize` is deprecated and has no effect. Use `with torch.jit.optimized_execution() instead"
            )
    
        if isinstance(func, torch.jit.ScriptModule):
            # it is hard to trace it because the forward method on ScriptModule is already defined, so it
            # would result in an error.
            warnings.warn(
                "The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is."
            )
            return func
    
        if isinstance(func, torch.nn.Module):
            return trace_module(
                func,
                {"forward": example_inputs},
                None,
                check_trace,
                wrap_check_inputs(check_inputs),
                check_tolerance,
                strict,
                _force_outplace,
                _module_class,
            )
    
        if (
            hasattr(func, "__self__")
            and isinstance(func.__self__, torch.nn.Module)
            and func.__name__ == "forward"
        ):
            return trace_module(
                func.__self__,
                {"forward": example_inputs},
                None,
                check_trace,
                wrap_check_inputs(check_inputs),
                check_tolerance,
                strict,
                _force_outplace,
                _module_class,
            )
    
        # Special case for common case of passing a single Tensor
        if isinstance(example_inputs, (torch.Tensor, dict)):
            example_inputs = (example_inputs,)
        # done primarily so that weird iterables fail here and not pybind11 code
        elif not isinstance(example_inputs, tuple):
            example_inputs = tuple(example_inputs)
    
        var_lookup_fn = _create_interpreter_name_lookup_fn(0)
    
        if hasattr(func, "__self__") and isinstance(func.__self__, torch.nn.Module):
            raise AttributeError(
                "trace doesn't support compiling individual module's functions.\n"
                "Please use trace_module"
            )
    
        name = _qualified_name(func)
>       traced = torch._C._create_function_from_trace(
            name,
            func,
            example_inputs,
            var_lookup_fn,
            strict,
            _force_outplace,
            get_callable_argument_names(func)
        )
E       TypeError: test_invalid_input_handling.<locals>.add_multiply() missing 2 required positional arguments: 'x' and 'y'

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/jit/_trace.py:804: TypeError
----------------------------- Captured stdout call -----------------------------
Test 1: Testing with non-tensor input...
Test 2: Testing with mismatched shapes during execution...
Test 3: Testing with None input...
Test 4: Testing with wrong dtype...
Test 5: Testing with non-callable func...
Test 6: Testing with empty example_inputs...
=============================== warnings summary ===============================
exam/torch_group/jit._trace/tests/test_torch_jit_trace_g3.py::test_strict_vs_nonstrict_mode_comparison
  /Users/zzf1sh/Documents/Project/TestAgent-CLI-main/exam/torch_group/jit._trace/tests/test_torch_jit_trace_g3.py:232: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
    if input_tensor[i] > thresholds[i]:

exam/torch_group/jit._trace/tests/test_torch_jit_trace_g3.py::test_tolerance_parameter_adjustment
  /opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/jit/_trace.py:828: TracerWarning: Trace had nondeterministic nodes. Did you forget call .eval() on your model? Nodes:
  	%7 : Float(2, 2, strides=[2, 1], requires_grad=0, device=cpu) = aten::randn_like(%a, %2, %3, %4, %5, %6) # /Users/zzf1sh/Documents/Project/TestAgent-CLI-main/exam/torch_group/jit._trace/tests/test_torch_jit_trace_g3.py:332:0
  This may cause errors in trace checking. To disable trace checking, pass check_trace=False to torch.jit.trace()
    _check_trace(

exam/torch_group/jit._trace/tests/test_torch_jit_trace_g3.py::test_tolerance_parameter_adjustment
  /opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/jit/_trace.py:828: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:
  Tensor-likes are not close!
  
  Mismatched elements: 3 / 4 (75.0%)
  Greatest absolute difference: 0.00010848045349121094 at index (0, 0) (up to 1e-05 allowed)
  Greatest relative difference: 6.899285817775002e-05 at index (0, 0) (up to 1e-05 allowed)
    _check_trace(

exam/torch_group/jit._trace/tests/test_torch_jit_trace_g3.py::test_tolerance_parameter_adjustment
  /opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/jit/_trace.py:828: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:
  Tensor-likes are not close!
  
  Mismatched elements: 3 / 4 (75.0%)
  Greatest absolute difference: 0.00010848045349121094 at index (0, 0) (up to 1e-05 allowed)
  Greatest relative difference: 6.899285817775002e-05 at index (0, 0) (up to 1e-07 allowed)
    _check_trace(

exam/torch_group/jit._trace/tests/test_torch_jit_trace_g4.py::test_trace_module_with_edge_cases
  /Users/zzf1sh/Documents/Project/TestAgent-CLI-main/exam/torch_group/jit._trace/tests/test_torch_jit_trace_g4.py:409: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
    if x.shape[0] == 0:

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================================ tests coverage ================================
______________ coverage: platform darwin, python 3.10.19-final-0 _______________

Name                               Stmts   Miss Branch BrPart  Cover   Missing
------------------------------------------------------------------------------
run_tests.py                          35     35     10      0     0%   4-62
tests/test_torch_jit_trace_g1.py      86     15      2      1    82%   23-24, 28, 32, 36, 203-217
tests/test_torch_jit_trace_g2.py      95     12      8      2    86%   223->219, 234-261
tests/test_torch_jit_trace_g3.py     167     19     18      4    88%   121-123, 233, 257, 273, 285-287, 309->300, 348-351, 395-398, 447-449, 509-513
tests/test_torch_jit_trace_g4.py     177     19     22      5    86%   21, 164-167, 248->261, 258, 327, 410, 441-461
------------------------------------------------------------------------------
TOTAL                                560    100     60     12    80%
Coverage XML written to file coverage.xml
=========================== short test summary info ============================
FAILED tests/test_torch_jit_trace_g2.py::test_complex_module_structure_tracing
FAILED tests/test_torch_jit_trace_g4.py::test_invalid_input_handling - TypeEr...
2 failed, 12 passed, 5 warnings in 0.82s

Error: exit 1