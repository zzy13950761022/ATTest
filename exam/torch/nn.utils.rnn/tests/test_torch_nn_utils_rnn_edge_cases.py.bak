import math
import pytest
import torch
import torch.nn.utils.rnn as rnn_utils
from typing import List, Tuple

# ==== BLOCK:HEADER START ====
# Test file for torch.nn.utils.rnn edge cases and error handling
# Group: G3 - Boundary and exception handling
# ==== BLOCK:HEADER END ====

# ==== BLOCK:CASE_04 START ====
@pytest.mark.parametrize("dtype", [torch.float32])
@pytest.mark.parametrize("device", ["cpu"])
@pytest.mark.parametrize("batch_first", [False])
@pytest.mark.parametrize("enforce_sorted", [False])
def test_enforce_sorted_parameter_behavior(
    dtype: torch.dtype,
    device: str,
    batch_first: bool,
    enforce_sorted: bool
):
    """TC-04: enforce_sorted参数行为"""
    # Test parameters from param_matrix
    unsorted_lengths = True
    batch_size = 3
    max_len = 5
    feature_dim = 3
    
    # Generate UNSORTED lengths (not in descending order)
    if unsorted_lengths:
        # Create lengths that are not sorted
        lengths = torch.tensor([3, 5, 2], device=device)  # Not sorted: 3, 5, 2
    else:
        lengths = torch.tensor([5, 3, 2], device=device)  # Sorted: 5, 3, 2
    
    # Create padded sequence with unsorted lengths
    if batch_first:
        padded = torch.zeros(batch_size, max_len, feature_dim, dtype=dtype, device=device)
        for i, length in enumerate(lengths):
            padded[i, :length] = torch.randn(length, feature_dim, dtype=dtype, device=device)
    else:
        padded = torch.zeros(max_len, batch_size, feature_dim, dtype=dtype, device=device)
        for i, length in enumerate(lengths):
            padded[:length, i] = torch.randn(length, feature_dim, dtype=dtype, device=device)
    
    # Weak assertions (epoch 1)
    # Test with enforce_sorted=False (should work even with unsorted lengths)
    if not enforce_sorted:
        # 1. function_executes: Should execute without exception
        packed = rnn_utils.pack_padded_sequence(
            padded,
            lengths,
            batch_first=batch_first,
            enforce_sorted=enforce_sorted
        )
        
        # 2. no_exception: Already verified by execution
        # 3. output_type_correct: Should return PackedSequence
        assert isinstance(packed, rnn_utils.PackedSequence), \
            f"Expected PackedSequence, got {type(packed)}"
        
        # 4. sorted_indices_present: Should have sorted_indices attribute
        assert hasattr(packed, 'sorted_indices'), "PackedSequence should have sorted_indices"
        assert hasattr(packed, 'unsorted_indices'), "PackedSequence should have unsorted_indices"
        
        # Verify that sorted_indices reflects the sorting
        # When enforce_sorted=False, the function should sort internally
        # sorted_indices should show the sorting order
        assert packed.sorted_indices.shape == (batch_size,), \
            f"Expected sorted_indices shape ({batch_size},), got {packed.sorted_indices.shape}"
        
        # Verify that unsorted_indices can restore original order
        assert packed.unsorted_indices.shape == (batch_size,), \
            f"Expected unsorted_indices shape ({batch_size},), got {packed.unsorted_indices.shape}"
        
        # Basic consistency checks
        total_elements = lengths.sum().item()
        assert packed.data.shape[0] == total_elements, \
            f"Expected {total_elements} elements in data, got {packed.data.shape[0]}"
        
        # Device and dtype preservation
        assert packed.data.device.type == device, \
            f"Expected device {device}, got {packed.data.device.type}"
        assert packed.data.dtype == dtype, \
            f"Expected dtype {dtype}, got {packed.data.dtype}"
        
        # batch_sizes should be on CPU
        assert packed.batch_sizes.device.type == 'cpu', \
            f"batch_sizes should be on CPU, got {packed.batch_sizes.device.type}"
        
        # Test that we can pad back and recover data
        padded_back, lengths_back = rnn_utils.pad_packed_sequence(
            packed,
            batch_first=batch_first
        )
        
        # Verify lengths are recovered correctly
        # Note: when unpacking, lengths should be in the sorted order
        # We need to use unsorted_indices to get back to original order
        sorted_lengths = lengths[packed.sorted_indices]
        assert torch.equal(lengths_back, sorted_lengths), \
            f"Lengths mismatch: expected {sorted_lengths}, got {lengths_back}"
    
    # Test error case: enforce_sorted=True with unsorted lengths
    # This should raise an error according to documentation
    # Note: We'll test this in strong assertions phase (epoch > 1)
    
    # For weak assertions in epoch 1, we just verify the function works
    # with enforce_sorted=False and unsorted lengths
# ==== BLOCK:CASE_04 END ====

# ==== BLOCK:CASE_09 START ====
# DEFERRED CASE
# ==== BLOCK:CASE_09 END ====

# ==== BLOCK:CASE_10 START ====
# DEFERRED CASE
# ==== BLOCK:CASE_10 END ====

# ==== BLOCK:FOOTER START ====
# Footer block for cleanup and helper functions
# ==== BLOCK:FOOTER END ====