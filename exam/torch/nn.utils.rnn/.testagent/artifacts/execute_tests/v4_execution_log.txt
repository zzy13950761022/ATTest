=== Run Tests ===
..F....F...F                                                             [100%]
=================================== FAILURES ===================================
______________ test_pad_packed_sequence_inverse[False-cpu-dtype0] ______________

dtype = torch.float32, device = 'cpu', batch_first = False

    @pytest.mark.parametrize("dtype", [torch.float32])
    @pytest.mark.parametrize("device", ["cpu"])
    @pytest.mark.parametrize("batch_first", [False])
    def test_pad_packed_sequence_inverse(
        dtype: torch.dtype,
        device: str,
        batch_first: bool
    ):
        """TC-02: pad_packed_sequence逆操作"""
        # Test parameters from param_matrix
        padding_value = 0.0
        total_length = None
        batch_size = 3
        max_len = 5
        feature_dim = 3
    
        # Generate test data and pack it
        padded, lengths = generate_padded_sequence(
            batch_size=batch_size,
            max_len=max_len,
            feature_dim=feature_dim,
            dtype=dtype,
            device=device,
            batch_first=batch_first
        )
    
        # First pack the sequence
        packed = rnn_utils.pack_padded_sequence(
            padded,
            lengths,
            batch_first=batch_first,
            enforce_sorted=True
        )
    
        # Now pad it back
        padded_output, output_lengths = rnn_utils.pad_packed_sequence(
            packed,
            batch_first=batch_first,
            padding_value=padding_value,
            total_length=total_length
        )
    
        # Weak assertions (epoch 1)
        # 1. output_shape: Should match original shape
        if batch_first:
            expected_shape = (batch_size, max_len, feature_dim)
        else:
            expected_shape = (max_len, batch_size, feature_dim)
    
>       assert padded_output.shape == expected_shape, \
            f"Expected shape {expected_shape}, got {padded_output.shape}"
E       AssertionError: Expected shape (5, 3, 3), got torch.Size([4, 3, 3])
E       assert torch.Size([4, 3, 3]) == (5, 3, 3)
E         
E         At index 0 diff: 4 != 5
E         Use -v to get more diff

tests/test_torch_nn_utils_rnn_pack_unpack.py:234: AssertionError
__________________ test_pad_unpad_roundtrip[False-cpu-dtype0] __________________

dtype = torch.float32, device = 'cpu', batch_first = False

    @pytest.mark.parametrize("dtype", [torch.float32])
    @pytest.mark.parametrize("device", ["cpu"])
    @pytest.mark.parametrize("batch_first", [False, True])
    def test_pad_unpad_roundtrip(
        dtype: torch.dtype,
        device: str,
        batch_first: bool
    ):
        """TC-08: pad_sequence和unpad_sequence往返测试"""
        # Test parameters
        num_sequences = 4
        max_len = 6
        feature_dim = 2
        padding_value = -1.0
    
        # Generate test data
        sequences = generate_sequence_list(
            num_sequences=num_sequences,
            max_len=max_len,
            feature_dim=feature_dim,
            dtype=dtype,
            device=device
        )
    
        # Get lengths for verification
        lengths = torch.tensor([seq.size(0) for seq in sequences], dtype=torch.int64, device=device)
    
        # Step 1: Pad the sequences
        padded = rnn_utils.pad_sequence(
            sequences,
            batch_first=batch_first,
            padding_value=padding_value
        )
    
        # Step 2: Unpad them back
        unpadded_sequences = rnn_utils.unpad_sequence(
            padded,
            lengths,
            batch_first=batch_first
        )
    
        # Weak assertions (epoch 1)
        # 1. roundtrip_consistency: Unpadded sequences should match original
        assert len(unpadded_sequences) == len(sequences), \
            f"Expected {len(sequences)} sequences, got {len(unpadded_sequences)}"
    
        for i, (original, unpadded) in enumerate(zip(sequences, unpadded_sequences)):
            # Check shape
            assert unpadded.shape == original.shape, \
                f"Sequence {i}: Expected shape {original.shape}, got {unpadded.shape}"
    
            # Check data (within tolerance)
            assert torch.allclose(original, unpadded, rtol=1e-6, atol=1e-6), \
                f"Sequence {i}: Data mismatch after roundtrip"
    
        # 2. padding_correctness: Verify padding was applied correctly
        actual_max_len = max(lengths).item()
    
        # FIXED: Correct shape calculation based on batch_first parameter
        if batch_first:
            expected_shape = (num_sequences, actual_max_len, feature_dim)
        else:
            expected_shape = (actual_max_len, num_sequences, feature_dim)
    
>       assert padded.shape == expected_shape, \
            f"Expected padded shape {expected_shape}, got {padded.shape}"
E       AssertionError: Expected padded shape (6, 4, 2), got torch.Size([4, 6, 2])
E       assert torch.Size([4, 6, 2]) == (6, 4, 2)
E         
E         At index 0 diff: 4 != 6
E         Use -v to get more diff

tests/test_torch_nn_utils_rnn_pad_unpad.py:318: AssertionError
__________ TestPadUnpadFunctions.test_unpad_sequence_length_mismatch ___________

    @staticmethod
    def test_unpad_sequence_length_mismatch():
        """Test unpad_sequence with incorrect lengths."""
        # Create a padded tensor
        padded = torch.randn(10, 3, 5)  # max_len=10, batch_size=3, feature_dim=5
    
        # Create lengths that are too long
        lengths = torch.tensor([12, 8, 9])  # First length > max_len
    
        # FIXED: unpad_sequence doesn't raise an error when length > max_len
        # Instead, it just returns all elements up to max_len
        # Let's test the actual behavior
        unpadded_sequences = rnn_utils.unpad_sequence(padded, lengths, batch_first=False)
    
        # Verify we get the correct number of sequences
        assert len(unpadded_sequences) == 3
    
        # Verify each sequence has the correct shape
        # When length > max_len, unpad_sequence returns all max_len elements
        assert unpadded_sequences[0].shape == (10, 5)  # First sequence: length=12 but max_len=10
        assert unpadded_sequences[1].shape == (8, 5)   # Second sequence: length=8
        assert unpadded_sequences[2].shape == (9, 5)   # Third sequence: length=9
    
        # Verify the data matches the original padded tensor
        for i in range(3):
            # For batch_first=False, padded shape is (max_len, batch_size, feature_dim)
            # Each unpadded sequence should match the corresponding column
>           assert torch.allclose(unpadded_sequences[i], padded[:, i, :])
E           RuntimeError: The size of tensor a (10) must match the size of tensor b (3) at non-singleton dimension 0

tests/test_torch_nn_utils_rnn_pad_unpad.py:407: RuntimeError
================================ tests coverage ================================
______________ coverage: platform darwin, python 3.10.19-final-0 _______________

Name                                           Stmts   Miss Branch BrPart  Cover   Missing
------------------------------------------------------------------------------------------
tests/test_torch_nn_utils_rnn_edge_cases.py       41      4     10      3    82%   35, 39-41, 49->exit
tests/test_torch_nn_utils_rnn_pack_unpack.py     173     50     40      8    66%   31-33, 49-54, 60, 65, 140-144, 152-156, 178-179, 230, 239-282, 376-380, 388-392, 458-459
tests/test_torch_nn_utils_rnn_pad_unpad.py       161     22     46      6    84%   42-54, 60, 65, 111, 124-127, 150-151, 328-329, 404->exit, 412-413
------------------------------------------------------------------------------------------
TOTAL                                            375     76     96     17    76%
Coverage XML written to file coverage.xml
=========================== short test summary info ============================
FAILED tests/test_torch_nn_utils_rnn_pack_unpack.py::test_pad_packed_sequence_inverse[False-cpu-dtype0]
FAILED tests/test_torch_nn_utils_rnn_pad_unpad.py::test_pad_unpad_roundtrip[False-cpu-dtype0]
FAILED tests/test_torch_nn_utils_rnn_pad_unpad.py::TestPadUnpadFunctions::test_unpad_sequence_length_mismatch
3 failed, 9 passed in 0.86s

Error: exit 1