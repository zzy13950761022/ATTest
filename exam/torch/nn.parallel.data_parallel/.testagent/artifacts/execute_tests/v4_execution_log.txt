=== Run Tests ===
ssssssssssFFsFFssFFFF                                                    [100%]
=================================== FAILURES ===================================
_____________ test_parameter_validation_and_exceptions[test_case0] _____________

test_case = {'device_ids': [0], 'dim': 0, 'error_pattern': 'module.*Module|must be.*Module|argument.*module', 'expected_error': <class 'TypeError'>, ...}

    @pytest.mark.parametrize("test_case", [
        # 测试1: module参数类型错误
        {
            "name": "module非Module类型",
            "module": "not_a_module",  # 字符串而不是Module
            "inputs": torch.randn(2, 10),
            "device_ids": [0],
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_error": TypeError,
            "error_pattern": "module.*Module|must be.*Module|argument.*module"
        },
        # 测试2: inputs参数类型错误
        {
            "name": "inputs非Tensor类型",
            "module": nn.Linear(10, 5),
            "inputs": "not_a_tensor",  # 字符串而不是Tensor
            "device_ids": [0],
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_error": TypeError,
            "error_pattern": "inputs.*Tensor|must be.*Tensor|argument.*inputs"
        },
        # 测试3: device_ids包含无效GPU ID（仅在CUDA可用时测试）
        {
            "name": "device_ids包含无效GPU ID",
            "module": nn.Linear(10, 5),
            "inputs": torch.randn(2, 10),
            "device_ids": [999],  # 无效的GPU ID
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_error": RuntimeError,
            "error_pattern": "device|invalid|cuda|index",
            "skip_if_no_cuda": True
        },
        # 测试4: dim超出输入维度范围
        {
            "name": "dim超出输入维度范围",
            "module": nn.Linear(10, 5),
            "inputs": torch.randn(2, 10),  # 2维张量
            "device_ids": [0],
            "output_device": 0,
            "dim": 5,  # 超出有效范围(0-1)
            "module_kwargs": {},
            "expected_error": IndexError,
            "error_pattern": "dim|index|out of range|size"
        },
        # 测试5: module_kwargs非字典类型
        {
            "name": "module_kwargs非字典类型",
            "module": nn.Linear(10, 5),
            "inputs": torch.randn(2, 10),
            "device_ids": [0],
            "output_device": 0,
            "dim": 0,
            "module_kwargs": "not_a_dict",  # 字符串而不是字典
            "expected_error": TypeError,
            "error_pattern": "module_kwargs.*dict|must be.*dict|argument.*module_kwargs"
        }
    ])
    def test_parameter_validation_and_exceptions(test_case):
        """测试参数验证与异常场景"""
        # 检查是否需要跳过（如需要CUDA但不可用）
        if test_case.get("skip_if_no_cuda", False) and not torch.cuda.is_available():
            pytest.skip("需要CUDA设备来测试此场景")
    
        # 准备模块
        module = test_case["module"]
        if isinstance(module, nn.Module):
            # 如果是真实的Module，确保它在正确的设备上
            if torch.cuda.is_available() and test_case["device_ids"] and test_case["device_ids"][0] >= 0:
                device = torch.device(f"cuda:{test_case['device_ids'][0]}")
                module = module.to(device)
    
        # 准备输入
        inputs = test_case["inputs"]
        if isinstance(inputs, torch.Tensor):
            # 如果是真实的Tensor，确保它在正确的设备上
            if torch.cuda.is_available() and test_case["device_ids"] and test_case["device_ids"][0] >= 0:
                device = torch.device(f"cuda:{test_case['device_ids'][0]}")
                inputs = inputs.to(device)
    
        # 准备其他参数
        device_ids = test_case["device_ids"]
        output_device = test_case["output_device"]
        dim = test_case["dim"]
        module_kwargs = test_case["module_kwargs"]
    
        # 验证异常
        with pytest.raises(test_case["expected_error"]) as exc_info:
            torch.nn.parallel.data_parallel(
                module=module,
                inputs=inputs,
                device_ids=device_ids,
                output_device=output_device,
                dim=dim,
                module_kwargs=module_kwargs
            )
    
        # 检查错误消息是否包含预期模式
        if "error_pattern" in test_case:
            error_msg = str(exc_info.value).lower()
            patterns = test_case["error_pattern"].split("|")
            # 检查是否有任何一个模式匹配
            pattern_matched = any(pattern in error_msg for pattern in patterns)
>           assert pattern_matched, \
                f"错误消息中应包含模式之一'{patterns}'，但得到: {error_msg}"
E           AssertionError: 错误消息中应包含模式之一'['module.*Module', 'must be.*Module', 'argument.*module']'，但得到: device(): argument 'type' (position 1) must be str, not nonetype
E           assert False

tests/test_torch_nn_parallel_data_parallel_g2.py:557: AssertionError
_____________ test_parameter_validation_and_exceptions[test_case1] _____________

test_case = {'device_ids': [0], 'dim': 0, 'error_pattern': 'inputs.*Tensor|must be.*Tensor|argument.*inputs', 'expected_error': <class 'TypeError'>, ...}

    @pytest.mark.parametrize("test_case", [
        # 测试1: module参数类型错误
        {
            "name": "module非Module类型",
            "module": "not_a_module",  # 字符串而不是Module
            "inputs": torch.randn(2, 10),
            "device_ids": [0],
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_error": TypeError,
            "error_pattern": "module.*Module|must be.*Module|argument.*module"
        },
        # 测试2: inputs参数类型错误
        {
            "name": "inputs非Tensor类型",
            "module": nn.Linear(10, 5),
            "inputs": "not_a_tensor",  # 字符串而不是Tensor
            "device_ids": [0],
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_error": TypeError,
            "error_pattern": "inputs.*Tensor|must be.*Tensor|argument.*inputs"
        },
        # 测试3: device_ids包含无效GPU ID（仅在CUDA可用时测试）
        {
            "name": "device_ids包含无效GPU ID",
            "module": nn.Linear(10, 5),
            "inputs": torch.randn(2, 10),
            "device_ids": [999],  # 无效的GPU ID
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_error": RuntimeError,
            "error_pattern": "device|invalid|cuda|index",
            "skip_if_no_cuda": True
        },
        # 测试4: dim超出输入维度范围
        {
            "name": "dim超出输入维度范围",
            "module": nn.Linear(10, 5),
            "inputs": torch.randn(2, 10),  # 2维张量
            "device_ids": [0],
            "output_device": 0,
            "dim": 5,  # 超出有效范围(0-1)
            "module_kwargs": {},
            "expected_error": IndexError,
            "error_pattern": "dim|index|out of range|size"
        },
        # 测试5: module_kwargs非字典类型
        {
            "name": "module_kwargs非字典类型",
            "module": nn.Linear(10, 5),
            "inputs": torch.randn(2, 10),
            "device_ids": [0],
            "output_device": 0,
            "dim": 0,
            "module_kwargs": "not_a_dict",  # 字符串而不是字典
            "expected_error": TypeError,
            "error_pattern": "module_kwargs.*dict|must be.*dict|argument.*module_kwargs"
        }
    ])
    def test_parameter_validation_and_exceptions(test_case):
        """测试参数验证与异常场景"""
        # 检查是否需要跳过（如需要CUDA但不可用）
        if test_case.get("skip_if_no_cuda", False) and not torch.cuda.is_available():
            pytest.skip("需要CUDA设备来测试此场景")
    
        # 准备模块
        module = test_case["module"]
        if isinstance(module, nn.Module):
            # 如果是真实的Module，确保它在正确的设备上
            if torch.cuda.is_available() and test_case["device_ids"] and test_case["device_ids"][0] >= 0:
                device = torch.device(f"cuda:{test_case['device_ids'][0]}")
                module = module.to(device)
    
        # 准备输入
        inputs = test_case["inputs"]
        if isinstance(inputs, torch.Tensor):
            # 如果是真实的Tensor，确保它在正确的设备上
            if torch.cuda.is_available() and test_case["device_ids"] and test_case["device_ids"][0] >= 0:
                device = torch.device(f"cuda:{test_case['device_ids'][0]}")
                inputs = inputs.to(device)
    
        # 准备其他参数
        device_ids = test_case["device_ids"]
        output_device = test_case["output_device"]
        dim = test_case["dim"]
        module_kwargs = test_case["module_kwargs"]
    
        # 验证异常
        with pytest.raises(test_case["expected_error"]) as exc_info:
            torch.nn.parallel.data_parallel(
                module=module,
                inputs=inputs,
                device_ids=device_ids,
                output_device=output_device,
                dim=dim,
                module_kwargs=module_kwargs
            )
    
        # 检查错误消息是否包含预期模式
        if "error_pattern" in test_case:
            error_msg = str(exc_info.value).lower()
            patterns = test_case["error_pattern"].split("|")
            # 检查是否有任何一个模式匹配
            pattern_matched = any(pattern in error_msg for pattern in patterns)
>           assert pattern_matched, \
                f"错误消息中应包含模式之一'{patterns}'，但得到: {error_msg}"
E           AssertionError: 错误消息中应包含模式之一'['inputs.*Tensor', 'must be.*Tensor', 'argument.*inputs']'，但得到: device(): argument 'type' (position 1) must be str, not nonetype
E           assert False

tests/test_torch_nn_parallel_data_parallel_g2.py:557: AssertionError
_____________ test_parameter_validation_and_exceptions[test_case3] _____________

test_case = {'device_ids': [0], 'dim': 5, 'error_pattern': 'dim|index|out of range|size', 'expected_error': <class 'IndexError'>, ...}

    @pytest.mark.parametrize("test_case", [
        # 测试1: module参数类型错误
        {
            "name": "module非Module类型",
            "module": "not_a_module",  # 字符串而不是Module
            "inputs": torch.randn(2, 10),
            "device_ids": [0],
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_error": TypeError,
            "error_pattern": "module.*Module|must be.*Module|argument.*module"
        },
        # 测试2: inputs参数类型错误
        {
            "name": "inputs非Tensor类型",
            "module": nn.Linear(10, 5),
            "inputs": "not_a_tensor",  # 字符串而不是Tensor
            "device_ids": [0],
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_error": TypeError,
            "error_pattern": "inputs.*Tensor|must be.*Tensor|argument.*inputs"
        },
        # 测试3: device_ids包含无效GPU ID（仅在CUDA可用时测试）
        {
            "name": "device_ids包含无效GPU ID",
            "module": nn.Linear(10, 5),
            "inputs": torch.randn(2, 10),
            "device_ids": [999],  # 无效的GPU ID
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_error": RuntimeError,
            "error_pattern": "device|invalid|cuda|index",
            "skip_if_no_cuda": True
        },
        # 测试4: dim超出输入维度范围
        {
            "name": "dim超出输入维度范围",
            "module": nn.Linear(10, 5),
            "inputs": torch.randn(2, 10),  # 2维张量
            "device_ids": [0],
            "output_device": 0,
            "dim": 5,  # 超出有效范围(0-1)
            "module_kwargs": {},
            "expected_error": IndexError,
            "error_pattern": "dim|index|out of range|size"
        },
        # 测试5: module_kwargs非字典类型
        {
            "name": "module_kwargs非字典类型",
            "module": nn.Linear(10, 5),
            "inputs": torch.randn(2, 10),
            "device_ids": [0],
            "output_device": 0,
            "dim": 0,
            "module_kwargs": "not_a_dict",  # 字符串而不是字典
            "expected_error": TypeError,
            "error_pattern": "module_kwargs.*dict|must be.*dict|argument.*module_kwargs"
        }
    ])
    def test_parameter_validation_and_exceptions(test_case):
        """测试参数验证与异常场景"""
        # 检查是否需要跳过（如需要CUDA但不可用）
        if test_case.get("skip_if_no_cuda", False) and not torch.cuda.is_available():
            pytest.skip("需要CUDA设备来测试此场景")
    
        # 准备模块
        module = test_case["module"]
        if isinstance(module, nn.Module):
            # 如果是真实的Module，确保它在正确的设备上
            if torch.cuda.is_available() and test_case["device_ids"] and test_case["device_ids"][0] >= 0:
                device = torch.device(f"cuda:{test_case['device_ids'][0]}")
                module = module.to(device)
    
        # 准备输入
        inputs = test_case["inputs"]
        if isinstance(inputs, torch.Tensor):
            # 如果是真实的Tensor，确保它在正确的设备上
            if torch.cuda.is_available() and test_case["device_ids"] and test_case["device_ids"][0] >= 0:
                device = torch.device(f"cuda:{test_case['device_ids'][0]}")
                inputs = inputs.to(device)
    
        # 准备其他参数
        device_ids = test_case["device_ids"]
        output_device = test_case["output_device"]
        dim = test_case["dim"]
        module_kwargs = test_case["module_kwargs"]
    
        # 验证异常
        with pytest.raises(test_case["expected_error"]) as exc_info:
>           torch.nn.parallel.data_parallel(
                module=module,
                inputs=inputs,
                device_ids=device_ids,
                output_device=output_device,
                dim=dim,
                module_kwargs=module_kwargs
            )

tests/test_torch_nn_parallel_data_parallel_g2.py:542: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

module = Linear(in_features=10, out_features=5, bias=True)
inputs = (tensor([[ 0.9225,  0.7324, -1.3899, -0.1109, -0.9408,  1.2378,  0.1645, -1.0856,
         -0.5164, -0.5771],
        [-0.9472, -0.9922,  0.9014,  1.2193,  1.6542,  1.0266,  0.8727,  0.4845,
         -0.4819,  2.2021]]),)
device_ids = [0], output_device = 0, dim = 5, module_kwargs = {}

    def data_parallel(module, inputs, device_ids=None, output_device=None, dim=0, module_kwargs=None):
        r"""Evaluates module(input) in parallel across the GPUs given in device_ids.
    
        This is the functional version of the DataParallel module.
    
        Args:
            module (Module): the module to evaluate in parallel
            inputs (Tensor): inputs to the module
            device_ids (list of int or torch.device): GPU ids on which to replicate module
            output_device (list of int or torch.device): GPU location of the output  Use -1 to indicate the CPU.
                (default: device_ids[0])
        Returns:
            a Tensor containing the result of module(input) located on
            output_device
        """
        if not isinstance(inputs, tuple):
            inputs = (inputs,) if inputs is not None else ()
    
        device_type = _get_available_device_type()
    
        if device_ids is None:
            device_ids = _get_all_device_indices()
    
        if output_device is None:
            output_device = device_ids[0]
    
        device_ids = [_get_device_index(x, True) for x in device_ids]
        output_device = _get_device_index(output_device, True)
>       src_device_obj = torch.device(device_type, device_ids[0])
E       TypeError: Device(): argument 'type' (position 1) must be str, not NoneType

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:215: TypeError
_____________ test_parameter_validation_and_exceptions[test_case4] _____________

test_case = {'device_ids': [0], 'dim': 0, 'error_pattern': 'module_kwargs.*dict|must be.*dict|argument.*module_kwargs', 'expected_error': <class 'TypeError'>, ...}

    @pytest.mark.parametrize("test_case", [
        # 测试1: module参数类型错误
        {
            "name": "module非Module类型",
            "module": "not_a_module",  # 字符串而不是Module
            "inputs": torch.randn(2, 10),
            "device_ids": [0],
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_error": TypeError,
            "error_pattern": "module.*Module|must be.*Module|argument.*module"
        },
        # 测试2: inputs参数类型错误
        {
            "name": "inputs非Tensor类型",
            "module": nn.Linear(10, 5),
            "inputs": "not_a_tensor",  # 字符串而不是Tensor
            "device_ids": [0],
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_error": TypeError,
            "error_pattern": "inputs.*Tensor|must be.*Tensor|argument.*inputs"
        },
        # 测试3: device_ids包含无效GPU ID（仅在CUDA可用时测试）
        {
            "name": "device_ids包含无效GPU ID",
            "module": nn.Linear(10, 5),
            "inputs": torch.randn(2, 10),
            "device_ids": [999],  # 无效的GPU ID
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_error": RuntimeError,
            "error_pattern": "device|invalid|cuda|index",
            "skip_if_no_cuda": True
        },
        # 测试4: dim超出输入维度范围
        {
            "name": "dim超出输入维度范围",
            "module": nn.Linear(10, 5),
            "inputs": torch.randn(2, 10),  # 2维张量
            "device_ids": [0],
            "output_device": 0,
            "dim": 5,  # 超出有效范围(0-1)
            "module_kwargs": {},
            "expected_error": IndexError,
            "error_pattern": "dim|index|out of range|size"
        },
        # 测试5: module_kwargs非字典类型
        {
            "name": "module_kwargs非字典类型",
            "module": nn.Linear(10, 5),
            "inputs": torch.randn(2, 10),
            "device_ids": [0],
            "output_device": 0,
            "dim": 0,
            "module_kwargs": "not_a_dict",  # 字符串而不是字典
            "expected_error": TypeError,
            "error_pattern": "module_kwargs.*dict|must be.*dict|argument.*module_kwargs"
        }
    ])
    def test_parameter_validation_and_exceptions(test_case):
        """测试参数验证与异常场景"""
        # 检查是否需要跳过（如需要CUDA但不可用）
        if test_case.get("skip_if_no_cuda", False) and not torch.cuda.is_available():
            pytest.skip("需要CUDA设备来测试此场景")
    
        # 准备模块
        module = test_case["module"]
        if isinstance(module, nn.Module):
            # 如果是真实的Module，确保它在正确的设备上
            if torch.cuda.is_available() and test_case["device_ids"] and test_case["device_ids"][0] >= 0:
                device = torch.device(f"cuda:{test_case['device_ids'][0]}")
                module = module.to(device)
    
        # 准备输入
        inputs = test_case["inputs"]
        if isinstance(inputs, torch.Tensor):
            # 如果是真实的Tensor，确保它在正确的设备上
            if torch.cuda.is_available() and test_case["device_ids"] and test_case["device_ids"][0] >= 0:
                device = torch.device(f"cuda:{test_case['device_ids'][0]}")
                inputs = inputs.to(device)
    
        # 准备其他参数
        device_ids = test_case["device_ids"]
        output_device = test_case["output_device"]
        dim = test_case["dim"]
        module_kwargs = test_case["module_kwargs"]
    
        # 验证异常
        with pytest.raises(test_case["expected_error"]) as exc_info:
            torch.nn.parallel.data_parallel(
                module=module,
                inputs=inputs,
                device_ids=device_ids,
                output_device=output_device,
                dim=dim,
                module_kwargs=module_kwargs
            )
    
        # 检查错误消息是否包含预期模式
        if "error_pattern" in test_case:
            error_msg = str(exc_info.value).lower()
            patterns = test_case["error_pattern"].split("|")
            # 检查是否有任何一个模式匹配
            pattern_matched = any(pattern in error_msg for pattern in patterns)
>           assert pattern_matched, \
                f"错误消息中应包含模式之一'{patterns}'，但得到: {error_msg}"
E           AssertionError: 错误消息中应包含模式之一'['module_kwargs.*dict', 'must be.*dict', 'argument.*module_kwargs']'，但得到: device(): argument 'type' (position 1) must be str, not nonetype
E           assert False

tests/test_torch_nn_parallel_data_parallel_g2.py:557: AssertionError
_____________________ test_edge_case_handling[test_case2] ______________________

test_case = {'device_ids': [0], 'dim': 0, 'expected_behavior': 'handle_empty_input', 'input_shape': [0, 10], ...}

    @pytest.mark.parametrize("test_case", [
        # 测试1: 空device_ids列表（应该使用所有可用设备）
        {
            "name": "空device_ids列表",
            "module_type": "Linear",
            "input_shape": [4, 10],
            "device_ids": [],  # 空列表
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_behavior": "use_all_available",
            "skip_if_no_cuda": True  # 空列表在CPU环境下会出错，需要跳过
        },
        # 测试2: device_ids为None（应该使用所有可用设备）
        {
            "name": "device_ids为None",
            "module_type": "Linear",
            "input_shape": [4, 10],
            "device_ids": None,  # None值
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_behavior": "use_all_available",
            "skip_if_no_cuda": True  # None在CPU环境下会出错，需要跳过
        },
        # 测试3: 空输入张量
        {
            "name": "空输入张量",
            "module_type": "Linear",
            "input_shape": [0, 10],  # batch size为0
            "device_ids": [0],
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_behavior": "handle_empty_input"
        },
        # 测试4: 单元素batch size
        {
            "name": "单元素batch size",
            "module_type": "Linear",
            "input_shape": [1, 10],  # batch size为1
            "device_ids": [0],
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_behavior": "handle_single_batch"
        },
        # 测试5: 极端大形状输入（内存允许的情况下）
        {
            "name": "中等大形状输入",
            "module_type": "Linear",
            "input_shape": [100, 50],  # 中等大小，避免内存问题
            "device_ids": [0],
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_behavior": "handle_large_input"
        },
        # 测试6: 不同dim值
        {
            "name": "dim=1的分散维度",
            "module_type": "Linear",
            "input_shape": [8, 10],
            "device_ids": [0],
            "output_device": 0,
            "dim": 1,  # 在特征维度上分散
            "module_kwargs": {},
            "expected_behavior": "scatter_along_dim"
        }
    ])
    def test_edge_case_handling(test_case):
        """测试边界条件处理"""
        # 解包测试配置
        name = test_case["name"]
        module_type = test_case["module_type"]
        input_shape = test_case["input_shape"]
        device_ids = test_case["device_ids"]
        output_device = test_case["output_device"]
        dim = test_case["dim"]
        module_kwargs = test_case["module_kwargs"]
        expected_behavior = test_case["expected_behavior"]
    
        # 检查是否需要跳过（如需要CUDA但不可用）
        if test_case.get("skip_if_no_cuda", False) and not torch.cuda.is_available():
            pytest.skip("需要CUDA设备来测试此场景")
    
        # 检查CUDA可用性
        cuda_available = torch.cuda.is_available()
    
        # 对于需要CUDA的测试，如果CUDA不可用则跳过
        if device_ids and device_ids != [] and device_ids != [0] and not cuda_available:
            pytest.skip("需要CUDA设备来测试此场景")
    
        # 调整device_ids：如果CUDA不可用，使用CPU
        if not cuda_available:
            if device_ids is not None and device_ids != []:
                # 对于CPU环境，device_ids应该为空列表
                # 但根据源码，空列表在CPU环境下会导致索引错误
                # 所以我们需要跳过这些测试
                if device_ids == [] or device_ids is None:
                    pytest.skip("空device_ids在CPU环境下会导致错误")
                else:
                    device_ids = []
    
        # 创建模块
        module = create_module(module_type, input_shape, device_id=0 if cuda_available else -1)
    
        # 创建输入张量
        inputs = create_input_tensor(input_shape, device_id=0 if cuda_available else -1)
    
        # 计算参考输出（单设备执行）
        with torch.no_grad():
            if cuda_available:
                expected_output = module(inputs, **module_kwargs)
            else:
                expected_output = module(inputs, **module_kwargs)
    
        # 使用data_parallel执行
        with torch.no_grad():
>           actual_output = torch.nn.parallel.data_parallel(
                module=module,
                inputs=inputs,
                device_ids=device_ids,
                output_device=output_device,
                dim=dim,
                module_kwargs=module_kwargs
            )

tests/test_torch_nn_parallel_data_parallel_g2.py:681: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

module = Linear(in_features=10, out_features=5, bias=True)
inputs = (tensor([], size=(0, 10)),), device_ids = [], output_device = 0
dim = 0, module_kwargs = {}

    def data_parallel(module, inputs, device_ids=None, output_device=None, dim=0, module_kwargs=None):
        r"""Evaluates module(input) in parallel across the GPUs given in device_ids.
    
        This is the functional version of the DataParallel module.
    
        Args:
            module (Module): the module to evaluate in parallel
            inputs (Tensor): inputs to the module
            device_ids (list of int or torch.device): GPU ids on which to replicate module
            output_device (list of int or torch.device): GPU location of the output  Use -1 to indicate the CPU.
                (default: device_ids[0])
        Returns:
            a Tensor containing the result of module(input) located on
            output_device
        """
        if not isinstance(inputs, tuple):
            inputs = (inputs,) if inputs is not None else ()
    
        device_type = _get_available_device_type()
    
        if device_ids is None:
            device_ids = _get_all_device_indices()
    
        if output_device is None:
            output_device = device_ids[0]
    
        device_ids = [_get_device_index(x, True) for x in device_ids]
        output_device = _get_device_index(output_device, True)
>       src_device_obj = torch.device(device_type, device_ids[0])
E       IndexError: list index out of range

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:215: IndexError
_____________________ test_edge_case_handling[test_case3] ______________________

test_case = {'device_ids': [0], 'dim': 0, 'expected_behavior': 'handle_single_batch', 'input_shape': [1, 10], ...}

    @pytest.mark.parametrize("test_case", [
        # 测试1: 空device_ids列表（应该使用所有可用设备）
        {
            "name": "空device_ids列表",
            "module_type": "Linear",
            "input_shape": [4, 10],
            "device_ids": [],  # 空列表
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_behavior": "use_all_available",
            "skip_if_no_cuda": True  # 空列表在CPU环境下会出错，需要跳过
        },
        # 测试2: device_ids为None（应该使用所有可用设备）
        {
            "name": "device_ids为None",
            "module_type": "Linear",
            "input_shape": [4, 10],
            "device_ids": None,  # None值
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_behavior": "use_all_available",
            "skip_if_no_cuda": True  # None在CPU环境下会出错，需要跳过
        },
        # 测试3: 空输入张量
        {
            "name": "空输入张量",
            "module_type": "Linear",
            "input_shape": [0, 10],  # batch size为0
            "device_ids": [0],
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_behavior": "handle_empty_input"
        },
        # 测试4: 单元素batch size
        {
            "name": "单元素batch size",
            "module_type": "Linear",
            "input_shape": [1, 10],  # batch size为1
            "device_ids": [0],
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_behavior": "handle_single_batch"
        },
        # 测试5: 极端大形状输入（内存允许的情况下）
        {
            "name": "中等大形状输入",
            "module_type": "Linear",
            "input_shape": [100, 50],  # 中等大小，避免内存问题
            "device_ids": [0],
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_behavior": "handle_large_input"
        },
        # 测试6: 不同dim值
        {
            "name": "dim=1的分散维度",
            "module_type": "Linear",
            "input_shape": [8, 10],
            "device_ids": [0],
            "output_device": 0,
            "dim": 1,  # 在特征维度上分散
            "module_kwargs": {},
            "expected_behavior": "scatter_along_dim"
        }
    ])
    def test_edge_case_handling(test_case):
        """测试边界条件处理"""
        # 解包测试配置
        name = test_case["name"]
        module_type = test_case["module_type"]
        input_shape = test_case["input_shape"]
        device_ids = test_case["device_ids"]
        output_device = test_case["output_device"]
        dim = test_case["dim"]
        module_kwargs = test_case["module_kwargs"]
        expected_behavior = test_case["expected_behavior"]
    
        # 检查是否需要跳过（如需要CUDA但不可用）
        if test_case.get("skip_if_no_cuda", False) and not torch.cuda.is_available():
            pytest.skip("需要CUDA设备来测试此场景")
    
        # 检查CUDA可用性
        cuda_available = torch.cuda.is_available()
    
        # 对于需要CUDA的测试，如果CUDA不可用则跳过
        if device_ids and device_ids != [] and device_ids != [0] and not cuda_available:
            pytest.skip("需要CUDA设备来测试此场景")
    
        # 调整device_ids：如果CUDA不可用，使用CPU
        if not cuda_available:
            if device_ids is not None and device_ids != []:
                # 对于CPU环境，device_ids应该为空列表
                # 但根据源码，空列表在CPU环境下会导致索引错误
                # 所以我们需要跳过这些测试
                if device_ids == [] or device_ids is None:
                    pytest.skip("空device_ids在CPU环境下会导致错误")
                else:
                    device_ids = []
    
        # 创建模块
        module = create_module(module_type, input_shape, device_id=0 if cuda_available else -1)
    
        # 创建输入张量
        inputs = create_input_tensor(input_shape, device_id=0 if cuda_available else -1)
    
        # 计算参考输出（单设备执行）
        with torch.no_grad():
            if cuda_available:
                expected_output = module(inputs, **module_kwargs)
            else:
                expected_output = module(inputs, **module_kwargs)
    
        # 使用data_parallel执行
        with torch.no_grad():
>           actual_output = torch.nn.parallel.data_parallel(
                module=module,
                inputs=inputs,
                device_ids=device_ids,
                output_device=output_device,
                dim=dim,
                module_kwargs=module_kwargs
            )

tests/test_torch_nn_parallel_data_parallel_g2.py:681: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

module = Linear(in_features=10, out_features=5, bias=True)
inputs = (tensor([[-0.1115,  0.1204, -0.3696, -0.2404, -1.1969,  0.2093, -0.9724, -0.7550,
          0.3239, -0.1085]]),)
device_ids = [], output_device = 0, dim = 0, module_kwargs = {}

    def data_parallel(module, inputs, device_ids=None, output_device=None, dim=0, module_kwargs=None):
        r"""Evaluates module(input) in parallel across the GPUs given in device_ids.
    
        This is the functional version of the DataParallel module.
    
        Args:
            module (Module): the module to evaluate in parallel
            inputs (Tensor): inputs to the module
            device_ids (list of int or torch.device): GPU ids on which to replicate module
            output_device (list of int or torch.device): GPU location of the output  Use -1 to indicate the CPU.
                (default: device_ids[0])
        Returns:
            a Tensor containing the result of module(input) located on
            output_device
        """
        if not isinstance(inputs, tuple):
            inputs = (inputs,) if inputs is not None else ()
    
        device_type = _get_available_device_type()
    
        if device_ids is None:
            device_ids = _get_all_device_indices()
    
        if output_device is None:
            output_device = device_ids[0]
    
        device_ids = [_get_device_index(x, True) for x in device_ids]
        output_device = _get_device_index(output_device, True)
>       src_device_obj = torch.device(device_type, device_ids[0])
E       IndexError: list index out of range

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:215: IndexError
_____________________ test_edge_case_handling[test_case4] ______________________

test_case = {'device_ids': [0], 'dim': 0, 'expected_behavior': 'handle_large_input', 'input_shape': [100, 50], ...}

    @pytest.mark.parametrize("test_case", [
        # 测试1: 空device_ids列表（应该使用所有可用设备）
        {
            "name": "空device_ids列表",
            "module_type": "Linear",
            "input_shape": [4, 10],
            "device_ids": [],  # 空列表
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_behavior": "use_all_available",
            "skip_if_no_cuda": True  # 空列表在CPU环境下会出错，需要跳过
        },
        # 测试2: device_ids为None（应该使用所有可用设备）
        {
            "name": "device_ids为None",
            "module_type": "Linear",
            "input_shape": [4, 10],
            "device_ids": None,  # None值
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_behavior": "use_all_available",
            "skip_if_no_cuda": True  # None在CPU环境下会出错，需要跳过
        },
        # 测试3: 空输入张量
        {
            "name": "空输入张量",
            "module_type": "Linear",
            "input_shape": [0, 10],  # batch size为0
            "device_ids": [0],
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_behavior": "handle_empty_input"
        },
        # 测试4: 单元素batch size
        {
            "name": "单元素batch size",
            "module_type": "Linear",
            "input_shape": [1, 10],  # batch size为1
            "device_ids": [0],
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_behavior": "handle_single_batch"
        },
        # 测试5: 极端大形状输入（内存允许的情况下）
        {
            "name": "中等大形状输入",
            "module_type": "Linear",
            "input_shape": [100, 50],  # 中等大小，避免内存问题
            "device_ids": [0],
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_behavior": "handle_large_input"
        },
        # 测试6: 不同dim值
        {
            "name": "dim=1的分散维度",
            "module_type": "Linear",
            "input_shape": [8, 10],
            "device_ids": [0],
            "output_device": 0,
            "dim": 1,  # 在特征维度上分散
            "module_kwargs": {},
            "expected_behavior": "scatter_along_dim"
        }
    ])
    def test_edge_case_handling(test_case):
        """测试边界条件处理"""
        # 解包测试配置
        name = test_case["name"]
        module_type = test_case["module_type"]
        input_shape = test_case["input_shape"]
        device_ids = test_case["device_ids"]
        output_device = test_case["output_device"]
        dim = test_case["dim"]
        module_kwargs = test_case["module_kwargs"]
        expected_behavior = test_case["expected_behavior"]
    
        # 检查是否需要跳过（如需要CUDA但不可用）
        if test_case.get("skip_if_no_cuda", False) and not torch.cuda.is_available():
            pytest.skip("需要CUDA设备来测试此场景")
    
        # 检查CUDA可用性
        cuda_available = torch.cuda.is_available()
    
        # 对于需要CUDA的测试，如果CUDA不可用则跳过
        if device_ids and device_ids != [] and device_ids != [0] and not cuda_available:
            pytest.skip("需要CUDA设备来测试此场景")
    
        # 调整device_ids：如果CUDA不可用，使用CPU
        if not cuda_available:
            if device_ids is not None and device_ids != []:
                # 对于CPU环境，device_ids应该为空列表
                # 但根据源码，空列表在CPU环境下会导致索引错误
                # 所以我们需要跳过这些测试
                if device_ids == [] or device_ids is None:
                    pytest.skip("空device_ids在CPU环境下会导致错误")
                else:
                    device_ids = []
    
        # 创建模块
        module = create_module(module_type, input_shape, device_id=0 if cuda_available else -1)
    
        # 创建输入张量
        inputs = create_input_tensor(input_shape, device_id=0 if cuda_available else -1)
    
        # 计算参考输出（单设备执行）
        with torch.no_grad():
            if cuda_available:
                expected_output = module(inputs, **module_kwargs)
            else:
                expected_output = module(inputs, **module_kwargs)
    
        # 使用data_parallel执行
        with torch.no_grad():
>           actual_output = torch.nn.parallel.data_parallel(
                module=module,
                inputs=inputs,
                device_ids=device_ids,
                output_device=output_device,
                dim=dim,
                module_kwargs=module_kwargs
            )

tests/test_torch_nn_parallel_data_parallel_g2.py:681: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

module = Linear(in_features=50, out_features=5, bias=True)
inputs = (tensor([[ 0.3374, -0.1778, -0.3035,  ..., -0.5850,  0.8768,  1.6221],
        [-1.4779,  1.1331, -1.2203,  ..., -1.31...74, -0.3299,  ...,  0.9435,  1.0918,  1.0149],
        [-1.0725, -0.1296, -0.3116,  ..., -1.7791,  0.9917,  0.0354]]),)
device_ids = [], output_device = 0, dim = 0, module_kwargs = {}

    def data_parallel(module, inputs, device_ids=None, output_device=None, dim=0, module_kwargs=None):
        r"""Evaluates module(input) in parallel across the GPUs given in device_ids.
    
        This is the functional version of the DataParallel module.
    
        Args:
            module (Module): the module to evaluate in parallel
            inputs (Tensor): inputs to the module
            device_ids (list of int or torch.device): GPU ids on which to replicate module
            output_device (list of int or torch.device): GPU location of the output  Use -1 to indicate the CPU.
                (default: device_ids[0])
        Returns:
            a Tensor containing the result of module(input) located on
            output_device
        """
        if not isinstance(inputs, tuple):
            inputs = (inputs,) if inputs is not None else ()
    
        device_type = _get_available_device_type()
    
        if device_ids is None:
            device_ids = _get_all_device_indices()
    
        if output_device is None:
            output_device = device_ids[0]
    
        device_ids = [_get_device_index(x, True) for x in device_ids]
        output_device = _get_device_index(output_device, True)
>       src_device_obj = torch.device(device_type, device_ids[0])
E       IndexError: list index out of range

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:215: IndexError
_____________________ test_edge_case_handling[test_case5] ______________________

test_case = {'device_ids': [0], 'dim': 1, 'expected_behavior': 'scatter_along_dim', 'input_shape': [8, 10], ...}

    @pytest.mark.parametrize("test_case", [
        # 测试1: 空device_ids列表（应该使用所有可用设备）
        {
            "name": "空device_ids列表",
            "module_type": "Linear",
            "input_shape": [4, 10],
            "device_ids": [],  # 空列表
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_behavior": "use_all_available",
            "skip_if_no_cuda": True  # 空列表在CPU环境下会出错，需要跳过
        },
        # 测试2: device_ids为None（应该使用所有可用设备）
        {
            "name": "device_ids为None",
            "module_type": "Linear",
            "input_shape": [4, 10],
            "device_ids": None,  # None值
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_behavior": "use_all_available",
            "skip_if_no_cuda": True  # None在CPU环境下会出错，需要跳过
        },
        # 测试3: 空输入张量
        {
            "name": "空输入张量",
            "module_type": "Linear",
            "input_shape": [0, 10],  # batch size为0
            "device_ids": [0],
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_behavior": "handle_empty_input"
        },
        # 测试4: 单元素batch size
        {
            "name": "单元素batch size",
            "module_type": "Linear",
            "input_shape": [1, 10],  # batch size为1
            "device_ids": [0],
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_behavior": "handle_single_batch"
        },
        # 测试5: 极端大形状输入（内存允许的情况下）
        {
            "name": "中等大形状输入",
            "module_type": "Linear",
            "input_shape": [100, 50],  # 中等大小，避免内存问题
            "device_ids": [0],
            "output_device": 0,
            "dim": 0,
            "module_kwargs": {},
            "expected_behavior": "handle_large_input"
        },
        # 测试6: 不同dim值
        {
            "name": "dim=1的分散维度",
            "module_type": "Linear",
            "input_shape": [8, 10],
            "device_ids": [0],
            "output_device": 0,
            "dim": 1,  # 在特征维度上分散
            "module_kwargs": {},
            "expected_behavior": "scatter_along_dim"
        }
    ])
    def test_edge_case_handling(test_case):
        """测试边界条件处理"""
        # 解包测试配置
        name = test_case["name"]
        module_type = test_case["module_type"]
        input_shape = test_case["input_shape"]
        device_ids = test_case["device_ids"]
        output_device = test_case["output_device"]
        dim = test_case["dim"]
        module_kwargs = test_case["module_kwargs"]
        expected_behavior = test_case["expected_behavior"]
    
        # 检查是否需要跳过（如需要CUDA但不可用）
        if test_case.get("skip_if_no_cuda", False) and not torch.cuda.is_available():
            pytest.skip("需要CUDA设备来测试此场景")
    
        # 检查CUDA可用性
        cuda_available = torch.cuda.is_available()
    
        # 对于需要CUDA的测试，如果CUDA不可用则跳过
        if device_ids and device_ids != [] and device_ids != [0] and not cuda_available:
            pytest.skip("需要CUDA设备来测试此场景")
    
        # 调整device_ids：如果CUDA不可用，使用CPU
        if not cuda_available:
            if device_ids is not None and device_ids != []:
                # 对于CPU环境，device_ids应该为空列表
                # 但根据源码，空列表在CPU环境下会导致索引错误
                # 所以我们需要跳过这些测试
                if device_ids == [] or device_ids is None:
                    pytest.skip("空device_ids在CPU环境下会导致错误")
                else:
                    device_ids = []
    
        # 创建模块
        module = create_module(module_type, input_shape, device_id=0 if cuda_available else -1)
    
        # 创建输入张量
        inputs = create_input_tensor(input_shape, device_id=0 if cuda_available else -1)
    
        # 计算参考输出（单设备执行）
        with torch.no_grad():
            if cuda_available:
                expected_output = module(inputs, **module_kwargs)
            else:
                expected_output = module(inputs, **module_kwargs)
    
        # 使用data_parallel执行
        with torch.no_grad():
>           actual_output = torch.nn.parallel.data_parallel(
                module=module,
                inputs=inputs,
                device_ids=device_ids,
                output_device=output_device,
                dim=dim,
                module_kwargs=module_kwargs
            )

tests/test_torch_nn_parallel_data_parallel_g2.py:681: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

module = Linear(in_features=10, out_features=5, bias=True)
inputs = (tensor([[ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603, -0.2196, -0.3792,
          0.7671, -1.1925],
        ....6236],
        [-2.3229,  1.0878,  0.6716,  0.6933, -0.9487, -0.0765, -0.1526,  0.1167,
          0.4403, -1.4465]]),)
device_ids = [], output_device = 0, dim = 1, module_kwargs = {}

    def data_parallel(module, inputs, device_ids=None, output_device=None, dim=0, module_kwargs=None):
        r"""Evaluates module(input) in parallel across the GPUs given in device_ids.
    
        This is the functional version of the DataParallel module.
    
        Args:
            module (Module): the module to evaluate in parallel
            inputs (Tensor): inputs to the module
            device_ids (list of int or torch.device): GPU ids on which to replicate module
            output_device (list of int or torch.device): GPU location of the output  Use -1 to indicate the CPU.
                (default: device_ids[0])
        Returns:
            a Tensor containing the result of module(input) located on
            output_device
        """
        if not isinstance(inputs, tuple):
            inputs = (inputs,) if inputs is not None else ()
    
        device_type = _get_available_device_type()
    
        if device_ids is None:
            device_ids = _get_all_device_indices()
    
        if output_device is None:
            output_device = device_ids[0]
    
        device_ids = [_get_device_index(x, True) for x in device_ids]
        output_device = _get_device_index(output_device, True)
>       src_device_obj = torch.device(device_type, device_ids[0])
E       IndexError: list index out of range

/opt/anaconda3/envs/testagent-experiment/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:215: IndexError
================================ tests coverage ================================
______________ coverage: platform darwin, python 3.10.19-final-0 _______________

Name                                               Stmts   Miss Branch BrPart  Cover   Missing
----------------------------------------------------------------------------------------------
tests/test_torch_nn_parallel_data_parallel_g1.py     150    127     32      1    13%   13-15, 20-45, 51-66, 71-72, 77-80, 117-162, 201-289, 300-374, 384, 395
tests/test_torch_nn_parallel_data_parallel_g2.py     226    140     94     15    34%   15, 25-38, 42-43, 55-59, 63-64, 71-72, 77-80, 132-170, 245-287, 369-445, 523-524, 531-532, 552->exit, 653, 656->667, 657->667, 662, 675, 691-735, 740
----------------------------------------------------------------------------------------------
TOTAL                                                376    267    126     16    26%
Coverage XML written to file coverage.xml
=========================== short test summary info ============================
FAILED tests/test_torch_nn_parallel_data_parallel_g2.py::test_parameter_validation_and_exceptions[test_case0]
FAILED tests/test_torch_nn_parallel_data_parallel_g2.py::test_parameter_validation_and_exceptions[test_case1]
FAILED tests/test_torch_nn_parallel_data_parallel_g2.py::test_parameter_validation_and_exceptions[test_case3]
FAILED tests/test_torch_nn_parallel_data_parallel_g2.py::test_parameter_validation_and_exceptions[test_case4]
FAILED tests/test_torch_nn_parallel_data_parallel_g2.py::test_edge_case_handling[test_case2]
FAILED tests/test_torch_nn_parallel_data_parallel_g2.py::test_edge_case_handling[test_case3]
FAILED tests/test_torch_nn_parallel_data_parallel_g2.py::test_edge_case_handling[test_case4]
FAILED tests/test_torch_nn_parallel_data_parallel_g2.py::test_edge_case_handling[test_case5]
8 failed, 13 skipped in 0.65s

Error: exit 1