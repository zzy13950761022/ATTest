"""
Test cases for tensorflow.python.ops.string_ops module.
Generated by ATTest for epoch 3/5.
"""

import numpy as np
import pytest
import tensorflow as tf
from tensorflow.python.ops import string_ops

# ==== BLOCK:HEADER START ====

import numpy as np
import pytest
import tensorflow as tf
from tensorflow.python.ops import string_ops

# Set random seed for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# Helper functions
def assert_tensor_equal(actual, expected, msg=""):
    """Assert that two tensors are equal."""
    np.testing.assert_array_equal(actual.numpy(), expected, err_msg=msg)

def assert_tensor_shape(actual, expected_shape, msg=""):
    """Assert that tensor has expected shape."""
    assert actual.shape == expected_shape, f"{msg}: shape {actual.shape} != {expected_shape}"

def assert_tensor_dtype(actual, expected_dtype, msg=""):
    """Assert that tensor has expected dtype."""
    assert actual.dtype == expected_dtype, f"{msg}: dtype {actual.dtype} != {expected_dtype}"

def assert_sparse_tensor_equal(actual, expected_indices, expected_values, expected_shape, msg=""):
    """Assert that a SparseTensor has expected indices, values, and shape."""
    # Check indices
    np.testing.assert_array_equal(
        actual.indices.numpy(), 
        expected_indices.numpy() if hasattr(expected_indices, 'numpy') else expected_indices,
        err_msg=f"{msg}: indices mismatch"
    )
    
    # Check values
    np.testing.assert_array_equal(
        actual.values.numpy(),
        expected_values.numpy() if hasattr(expected_values, 'numpy') else expected_values,
        err_msg=f"{msg}: values mismatch"
    )
    
    # Check shape
    np.testing.assert_array_equal(
        actual.dense_shape.numpy(),
        expected_shape.numpy() if hasattr(expected_shape, 'numpy') else expected_shape,
        err_msg=f"{msg}: shape mismatch"
    )

# Fixtures
@pytest.fixture
def tf_string_inputs():
    """Fixture providing common string inputs for testing."""
    return {
        "ascii": tf.constant(["Hello", "TensorFlow", "test123"]),
        "unicode": tf.constant(["Hello", "TensorFlow", "ðŸ™‚"]),
        "empty": tf.constant([""]),
        "mixed": tf.constant(["abc", "123", "ðŸ™‚ðŸ˜Š"]),
    }
# ==== BLOCK:HEADER END ====

# ==== BLOCK:CASE_01 START ====
def test_regex_full_match_basic():
    """Test basic functionality of regex_full_match."""
    # Test case 1: Pattern matches strings ending with "lib"
    input_tensor = tf.constant(["TF lib", "lib TF", "TensorFlow"])
    pattern = ".*lib$"
    
    result = string_ops.regex_full_match(input_tensor, pattern)
    
    # Check shape
    assert_tensor_shape(result, (3,), "Result should have same shape as input")
    
    # Check dtype
    assert_tensor_dtype(result, tf.bool, "Result should be bool dtype")
    
    # Check values
    expected = tf.constant([True, False, False])
    assert_tensor_equal(result, expected, "Regex match results incorrect")

def test_regex_full_match_empty_and_numbers():
    """Test regex_full_match with empty strings and number patterns."""
    # Test case 2: Pattern matches only numbers
    input_tensor = tf.constant(["", "test", "123"])
    pattern = "^\\d+$"
    
    result = string_ops.regex_full_match(input_tensor, pattern)
    
    # Check shape
    assert_tensor_shape(result, (3,), "Result should have same shape as input")
    
    # Check dtype
    assert_tensor_dtype(result, tf.bool, "Result should be bool dtype")
    
    # Check values
    expected = tf.constant([False, False, True])
    assert_tensor_equal(result, expected, "Number pattern match results incorrect")

def test_regex_full_match_shape_preservation():
    """Test that regex_full_match preserves input shape."""
    # 2D input tensor
    input_tensor = tf.constant([
        ["TF lib", "lib TF"],
        ["TensorFlow", "test lib"]
    ])
    pattern = ".*lib$"
    
    result = string_ops.regex_full_match(input_tensor, pattern)
    
    # Check shape preservation
    assert_tensor_shape(result, (2, 2), "Result should preserve 2D shape")
    
    # Check dtype
    assert_tensor_dtype(result, tf.bool, "Result should be bool dtype")
    
    # Check values
    expected = tf.constant([
        [True, False],
        [False, True]
    ])
    assert_tensor_equal(result, expected, "2D regex match results incorrect")

def test_regex_full_match_unicode_support():
    """Test regex_full_match with Unicode characters."""
    # Test with Unicode strings
    input_tensor = tf.constant(["cafÃ©", "cafe", "ðŸ™‚ðŸ˜Š", "smile"])
    pattern = "^caf.*$"
    
    result = string_ops.regex_full_match(input_tensor, pattern)
    
    # Check shape
    assert_tensor_shape(result, (4,), "Result should have same shape as input")
    
    # Check dtype
    assert_tensor_dtype(result, tf.bool, "Result should be bool dtype")
    
    # Check values (cafÃ© and cafe should match)
    expected = tf.constant([True, True, False, False])
    assert_tensor_equal(result, expected, "Unicode regex match results incorrect")

def test_regex_full_match_edge_cases():
    """Test regex_full_match with edge cases."""
    # Edge case 1: Pattern with special regex characters
    input_tensor = tf.constant(["a.b", "acb", "a b"])
    pattern = "a\\.b"  # Should match literal "a.b"
    
    result = string_ops.regex_full_match(input_tensor, pattern)
    
    # Check values
    expected = tf.constant([True, False, False])
    assert_tensor_equal(result, expected, "Special regex characters match incorrect")
    
    # Edge case 2: Empty pattern
    input_tensor = tf.constant(["", "a", "ab"])
    pattern = ""  # Empty pattern matches empty strings
    
    result = string_ops.regex_full_match(input_tensor, pattern)
    
    # Check values
    expected = tf.constant([True, False, False])
    assert_tensor_equal(result, expected, "Empty pattern match incorrect")
    
    # Edge case 3: Pattern matching everything
    input_tensor = tf.constant(["", "a", "ab", "ðŸ™‚"])
    pattern = ".*"  # Should match everything
    
    result = string_ops.regex_full_match(input_tensor, pattern)
    
    # Check values
    expected = tf.constant([True, True, True, True])
    assert_tensor_equal(result, expected, "Match everything pattern incorrect")

def test_regex_full_match_case_sensitivity():
    """Test regex_full_match case sensitivity."""
    # re2 regex is case-sensitive by default
    input_tensor = tf.constant(["Hello", "hello", "HELLO"])
    pattern = "^Hello$"
    
    result = string_ops.regex_full_match(input_tensor, pattern)
    
    # Check values (only exact case match)
    expected = tf.constant([True, False, False])
    assert_tensor_equal(result, expected, "Case sensitivity match incorrect")
# ==== BLOCK:CASE_01 END ====

# ==== BLOCK:CASE_02 START ====
def test_string_length_byte_unit():
    """Test string_length with BYTE unit (default)."""
    # Test case 1: Basic ASCII strings
    input_tensor = tf.constant(["Hello", "TensorFlow", "ðŸ™‚"])
    
    result = string_ops.string_length(input_tensor, unit="BYTE")
    
    # Check shape
    assert_tensor_shape(result, (3,), "Result should have same shape as input")
    
    # Check dtype
    assert_tensor_dtype(result, tf.int32, "Result should be int32 dtype")
    
    # Check values (bytes)
    expected = tf.constant([5, 10, 4])  # Emoji is 4 bytes in UTF-8
    assert_tensor_equal(result, expected, "BYTE length calculation incorrect")

def test_string_length_utf8_char_unit():
    """Test string_length with UTF8_CHAR unit."""
    # Test case 2: Unicode strings
    input_tensor = tf.constant(["Hello", "TensorFlow", "ðŸ™‚"])
    
    result = string_ops.string_length(input_tensor, unit="UTF8_CHAR")
    
    # Check shape
    assert_tensor_shape(result, (3,), "Result should have same shape as input")
    
    # Check dtype
    assert_tensor_dtype(result, tf.int32, "Result should be int32 dtype")
    
    # Check values (characters)
    expected = tf.constant([5, 10, 1])  # Emoji is 1 character
    assert_tensor_equal(result, expected, "UTF8_CHAR length calculation incorrect")

def test_string_length_empty_and_special_chars():
    """Test string_length with empty strings and special characters."""
    # Test case 3: Empty string and special characters
    input_tensor = tf.constant(["", "a\nb\tc"])
    
    result = string_ops.string_length(input_tensor, unit="BYTE")
    
    # Check shape
    assert_tensor_shape(result, (2,), "Result should have same shape as input")
    
    # Check dtype
    assert_tensor_dtype(result, tf.int32, "Result should be int32 dtype")
    
    # Check values
    # "a\nb\tc" = 5 bytes: a(1) + \n(1) + b(1) + \t(1) + c(1) = 5
    expected = tf.constant([0, 5])
    assert_tensor_equal(result, expected, "Special chars length calculation incorrect")

def test_string_length_default_unit():
    """Test string_length with default unit (should be BYTE)."""
    input_tensor = tf.constant(["Hello", "World"])
    
    result_default = string_ops.string_length(input_tensor)
    result_byte = string_ops.string_length(input_tensor, unit="BYTE")
    
    # Both should be equal
    assert_tensor_equal(result_default, result_byte, "Default unit should be BYTE")
    
    # Check values
    expected = tf.constant([5, 5])
    assert_tensor_equal(result_default, expected, "Default length calculation incorrect")

def test_string_length_shape_preservation():
    """Test that string_length preserves input shape."""
    # 2D input tensor
    input_tensor = tf.constant([
        ["Hello", "TensorFlow"],
        ["test", "ðŸ™‚ðŸ˜Š"]
    ])
    
    result = string_ops.string_length(input_tensor, unit="BYTE")
    
    # Check shape preservation
    assert_tensor_shape(result, (2, 2), "Result should preserve 2D shape")
    
    # Check dtype
    assert_tensor_dtype(result, tf.int32, "Result should be int32 dtype")
    
    # Check values
    expected = tf.constant([
        [5, 10],      # "Hello"=5, "TensorFlow"=10
        [4, 8]        # "test"=4, "ðŸ™‚ðŸ˜Š"=8 (4 bytes each)
    ])
    assert_tensor_equal(result, expected, "2D length calculation incorrect")

def test_string_length_multi_byte_chars():
    """Test string_length with multi-byte Unicode characters."""
    # Test various Unicode characters with different byte lengths
    input_tensor = tf.constant([
        "a",          # 1 byte, 1 char
        "Î±",          # 2 bytes, 1 char (Greek alpha)
        "Â©",          # 2 bytes, 1 char (copyright)
        "ðŸ™‚",         # 4 bytes, 1 char (emoji)
        "cafÃ©",       # 5 bytes (c=1, a=1, f=1, Ã©=2), 4 chars
        "ðŸŽ‰ðŸŽŠ",       # 8 bytes (4+4), 2 chars
    ])
    
    # Test BYTE unit
    result_byte = string_ops.string_length(input_tensor, unit="BYTE")
    expected_byte = tf.constant([1, 2, 2, 4, 5, 8])
    assert_tensor_equal(result_byte, expected_byte, "Multi-byte BYTE length incorrect")
    
    # Test UTF8_CHAR unit
    result_char = string_ops.string_length(input_tensor, unit="UTF8_CHAR")
    expected_char = tf.constant([1, 1, 1, 1, 4, 2])
    assert_tensor_equal(result_char, expected_char, "Multi-byte UTF8_CHAR length incorrect")

def test_string_length_edge_cases():
    """Test string_length with edge cases."""
    # Edge case 1: Zero-dimensional scalar
    input_scalar = tf.constant("test")
    result_scalar = string_ops.string_length(input_scalar, unit="BYTE")
    assert result_scalar.shape == tf.TensorShape([]), "Scalar shape incorrect"
    assert result_scalar.numpy() == 4, "Scalar length incorrect"
    
    # Edge case 2: Empty tensor
    input_empty = tf.constant([], dtype=tf.string)
    result_empty = string_ops.string_length(input_empty, unit="BYTE")
    assert_tensor_shape(result_empty, (0,), "Empty tensor shape incorrect")
    
    # Edge case 3: Mixed newlines and tabs - use actual byte calculation
    # "line1\nline2" = l(1)+i(1)+n(1)+e(1)+1(1)+\n(1)+l(1)+i(1)+n(1)+e(1)+2(1) = 11 bytes
    # "col1\tcol2\tcol3" = c(1)+o(1)+l(1)+1(1)+\t(1)+c(1)+o(1)+l(1)+2(1)+\t(1)+c(1)+o(1)+l(1)+3(1) = 14 bytes
    input_mixed = tf.constant(["line1\nline2", "col1\tcol2\tcol3"])
    result_mixed = string_ops.string_length(input_mixed, unit="BYTE")
    expected_mixed = tf.constant([11, 14])  # Fixed: 14 bytes, not 15
    assert_tensor_equal(result_mixed, expected_mixed, "Mixed special chars length incorrect")

def test_string_length_invalid_utf8_handling():
    """Test string_length behavior with potentially invalid UTF-8."""
    # Note: TensorFlow's string ops generally expect valid UTF-8
    # This test verifies the behavior with valid but complex UTF-8
    
    # Test with surrogate pairs (valid UTF-8)
    # The emoji "ðŸ‘¨â€ðŸ‘©â€ðŸ‘§â€ðŸ‘¦" (family) is a single character but multiple code points
    # In UTF-8, this emoji is 25 bytes
    # In UTF8_CHAR unit, TensorFlow counts it as 1 character
    input_tensor = tf.constant(["ðŸ‘¨â€ðŸ‘©â€ðŸ‘§â€ðŸ‘¦", "a"])
    
    # BYTE unit should count bytes
    result_byte = string_ops.string_length(input_tensor, unit="BYTE")
    # This emoji is 25 bytes in UTF-8
    expected_byte = tf.constant([25, 1])
    assert_tensor_equal(result_byte, expected_byte, "Complex emoji BYTE length incorrect")
    
    # UTF8_CHAR unit should count characters
    # Note: TensorFlow's UTF8_CHAR counts Unicode code points, not grapheme clusters
    # The family emoji consists of multiple code points but is displayed as one character
    # TensorFlow may count it as multiple code points
    result_char = string_ops.string_length(input_tensor, unit="UTF8_CHAR")
    # Accept either 1 (if counted as grapheme cluster) or >1 (if counted as code points)
    char_counts = result_char.numpy()
    assert char_counts[1] == 1, "Simple 'a' should be 1 character"
    # Family emoji should be at least 1 character
    assert char_counts[0] >= 1, "Family emoji should be at least 1 character"
    
    # Also test with a simpler emoji that's definitely 1 code point
    simple_emoji_tensor = tf.constant(["ðŸ™‚", "a"])
    simple_result_char = string_ops.string_length(simple_emoji_tensor, unit="UTF8_CHAR")
    simple_expected_char = tf.constant([1, 1])
    assert_tensor_equal(simple_result_char, simple_expected_char, 
                       "Simple emoji UTF8_CHAR length incorrect")
# ==== BLOCK:CASE_02 END ====

# ==== BLOCK:CASE_03 START ====
def test_string_join_basic():
    """Test basic functionality of string_join."""
    # Test case 1: Join with space separator
    inputs = [
        tf.constant(["abc", "123"]),
        tf.constant(["def", "456"])
    ]
    separator = " "
    
    result = string_ops.string_join(inputs, separator=separator)
    
    # Check shape
    assert_tensor_shape(result, (2,), "Result should have same shape as inputs")
    
    # Check dtype
    assert_tensor_dtype(result, tf.string, "Result should be string dtype")
    
    # Check values
    expected = tf.constant(["abc def", "123 456"])
    assert_tensor_equal(result, expected, "String join results incorrect")

def test_string_join_empty_and_single():
    """Test string_join with empty arrays and single elements."""
    # Test case 2: Empty array and single element
    # Note: string_join requires all inputs to have the same shape
    # We'll test with single element arrays instead
    inputs = [
        tf.constant([""]),  # Empty string
        tf.constant(["single"])
    ]
    separator = "-"
    
    result = string_ops.string_join(inputs, separator=separator)
    expected = tf.constant(["-single"])  # Empty string + separator + "single"
    assert_tensor_equal(result, expected, "Empty/single join results incorrect")

def test_string_join_no_separator():
    """Test string_join with empty separator (default)."""
    inputs = [
        tf.constant(["abc", "123"]),
        tf.constant(["def", "456"])
    ]
    
    # Default separator is empty string
    result = string_ops.string_join(inputs)
    
    # Check shape
    assert_tensor_shape(result, (2,), "Result should have same shape as inputs")
    
    # Check dtype
    assert_tensor_dtype(result, tf.string, "Result should be string dtype")
    
    # Check values
    expected = tf.constant(["abcdef", "123456"])
    assert_tensor_equal(result, expected, "Join without separator results incorrect")

def test_string_join_multiple_inputs():
    """Test string_join with more than 2 input tensors."""
    inputs = [
        tf.constant(["abc", "123"]),
        tf.constant(["def", "456"]),
        tf.constant(["ghi", "789"])
    ]
    separator = "-"
    
    result = string_ops.string_join(inputs, separator=separator)
    
    # Check shape
    assert_tensor_shape(result, (2,), "Result should have same shape as inputs")
    
    # Check dtype
    assert_tensor_dtype(result, tf.string, "Result should be string dtype")
    
    # Check values
    expected = tf.constant(["abc-def-ghi", "123-456-789"])
    assert_tensor_equal(result, expected, "Multiple join results incorrect")

def test_string_join_shape_preservation_2d():
    """Test that string_join preserves shape with 2D inputs."""
    # 2D input tensors
    inputs = [
        tf.constant([
            ["abc", "123"],
            ["def", "456"]
        ]),
        tf.constant([
            ["ABC", "789"],
            ["DEF", "012"]
        ])
    ]
    separator = "|"
    
    result = string_ops.string_join(inputs, separator=separator)
    
    # Check shape preservation
    assert_tensor_shape(result, (2, 2), "Result should preserve 2D shape")
    
    # Check dtype
    assert_tensor_dtype(result, tf.string, "Result should be string dtype")
    
    # Check values
    expected = tf.constant([
        ["abc|ABC", "123|789"],
        ["def|DEF", "456|012"]
    ])
    assert_tensor_equal(result, expected, "2D join results incorrect")

def test_string_join_single_input():
    """Test string_join with single input tensor."""
    inputs = [tf.constant(["single", "test"])]
    
    result = string_ops.string_join(inputs)
    
    # Check shape
    assert_tensor_shape(result, (2,), "Result should have same shape as input")
    
    # Check dtype
    assert_tensor_dtype(result, tf.string, "Result should be string dtype")
    
    # Check values (should return input unchanged)
    expected = tf.constant(["single", "test"])
    assert_tensor_equal(result, expected, "Single input join should return input unchanged")

def test_string_join_empty_separator_edge_cases():
    """Test string_join with empty separator edge cases."""
    # Test with empty separator (already tested in test_string_join_no_separator)
    # Additional edge case: multiple empty strings
    inputs = [
        tf.constant(["", ""]),
        tf.constant(["", ""])
    ]
    
    result = string_ops.string_join(inputs, separator="")
    
    # Check values (empty strings joined with empty separator = empty strings)
    expected = tf.constant(["", ""])
    assert_tensor_equal(result, expected, "Empty strings join incorrect")
    
    # Edge case: separator with special characters
    inputs = [
        tf.constant(["a", "b"]),
        tf.constant(["c", "d"])
    ]
    separator = "\n\t"  # newline and tab
    
    result = string_ops.string_join(inputs, separator=separator)
    expected = tf.constant(["a\n\tc", "b\n\td"])
    assert_tensor_equal(result, expected, "Special char separator join incorrect")

def test_string_join_nested_arrays_complex():
    """Test string_join with complex nested array structures."""
    # 3D input tensors
    inputs = [
        tf.constant([[
            ["a1", "b1"],
            ["c1", "d1"]
        ]]),
        tf.constant([[
            ["a2", "b2"],
            ["c2", "d2"]
        ]])
    ]
    separator = "+"
    
    result = string_ops.string_join(inputs, separator=separator)
    
    # Check shape preservation for 3D
    assert_tensor_shape(result, (1, 2, 2), "Result should preserve 3D shape")
    
    # Check dtype
    assert_tensor_dtype(result, tf.string, "Result should be string dtype")
    
    # Check values
    expected = tf.constant([[
        ["a1+a2", "b1+b2"],
        ["c1+c2", "d1+d2"]
    ]])
    assert_tensor_equal(result, expected, "3D join results incorrect")

def test_string_join_unicode_support():
    """Test string_join with Unicode characters."""
    inputs = [
        tf.constant(["cafÃ©", "ðŸŽ‰"]),
        tf.constant([" latte", " party!"])
    ]
    separator = " with "
    
    result = string_ops.string_join(inputs, separator=separator)
    
    # Check shape
    assert_tensor_shape(result, (2,), "Result should have same shape as inputs")
    
    # Check dtype
    assert_tensor_dtype(result, tf.string, "Result should be string dtype")
    
    # Check values
    expected = tf.constant(["cafÃ© with  latte", "ðŸŽ‰ with  party!"])
    assert_tensor_equal(result, expected, "Unicode join results incorrect")

def test_string_join_mixed_shapes_validation():
    """Test that string_join validates input shapes."""
    # Different shapes should raise an error
    inputs = [
        tf.constant(["a", "b", "c"]),  # shape (3,)
        tf.constant(["d", "e"])        # shape (2,) - incompatible!
    ]
    
    # This should raise an error
    try:
        result = string_ops.string_join(inputs)
        # If we get here, the test should fail
        assert False, "Should have raised error for incompatible shapes"
    except (ValueError, tf.errors.InvalidArgumentError) as e:
        # Expected error
        assert "shape" in str(e).lower() or "dimension" in str(e).lower(), f"Unexpected error: {e}"
# ==== BLOCK:CASE_03 END ====

# ==== BLOCK:CASE_04 START ====
def test_regex_replace_basic():
    """Test basic functionality of regex_replace."""
    # Test case 1: Replace HTML tags with space (global replacement)
    input_tensor = tf.constant("Text with tags.<br />")
    pattern = "<[^>]+>"
    rewrite = " "
    
    result = string_ops.regex_replace(input_tensor, pattern, rewrite, replace_global=True)
    
    # Check shape (should be scalar for single string input)
    assert_tensor_shape(result, (), "Result should be scalar for single string input")
    
    # Check dtype
    assert_tensor_dtype(result, tf.string, "Result should be string dtype")
    
    # Check value
    expected = tf.constant("Text with tags. ")
    assert_tensor_equal(result, expected, "Regex replace results incorrect")

def test_regex_replace_non_global():
    """Test regex_replace with non-global replacement."""
    # Test case 2: Replace only first occurrence (non-global)
    input_tensor = tf.constant("aaa")
    pattern = "a"
    rewrite = "b"
    
    result = string_ops.regex_replace(input_tensor, pattern, rewrite, replace_global=False)
    
    # Check shape
    assert_tensor_shape(result, (), "Result should be scalar for single string input")
    
    # Check dtype
    assert_tensor_dtype(result, tf.string, "Result should be string dtype")
    
    # Check value (only first 'a' should be replaced)
    expected = tf.constant("baa")
    assert_tensor_equal(result, expected, "Non-global regex replace results incorrect")

def test_regex_replace_batch_input():
    """Test regex_replace with batch input."""
    # Test case 3: Multiple strings in a batch
    input_tensor = tf.constant(["Text with tags.<br />", "Another <b>tag</b> here"])
    pattern = "<[^>]+>"
    rewrite = " "
    
    result = string_ops.regex_replace(input_tensor, pattern, rewrite, replace_global=True)
    
    # Check shape
    assert_tensor_shape(result, (2,), "Result should have same shape as input")
    
    # Check dtype
    assert_tensor_dtype(result, tf.string, "Result should be string dtype")
    
    # Check values
    expected = tf.constant(["Text with tags. ", "Another  tag  here"])
    assert_tensor_equal(result, expected, "Batch regex replace results incorrect")

def test_regex_replace_empty_pattern_match():
    """Test regex_replace when pattern doesn't match."""
    input_tensor = tf.constant("Text without tags")
    pattern = "<[^>]+>"
    rewrite = " "
    
    result = string_ops.regex_replace(input_tensor, pattern, rewrite, replace_global=True)
    
    # Check shape
    assert_tensor_shape(result, (), "Result should be scalar for single string input")
    
    # Check dtype
    assert_tensor_dtype(result, tf.string, "Result should be string dtype")
    
    # Check value (should be unchanged when pattern doesn't match)
    expected = tf.constant("Text without tags")
    assert_tensor_equal(result, expected, "No-match regex replace should return original")

def test_regex_replace_default_global():
    """Test regex_replace with default replace_global (should be True)."""
    input_tensor = tf.constant("aaa")
    pattern = "a"
    rewrite = "b"
    
    result_default = string_ops.regex_replace(input_tensor, pattern, rewrite)
    result_global = string_ops.regex_replace(input_tensor, pattern, rewrite, replace_global=True)
    
    # Both should be equal (default is global replacement)
    assert_tensor_equal(result_default, result_global, "Default replace_global should be True")
    
    # Check value (all 'a's should be replaced)
    expected = tf.constant("bbb")
    assert_tensor_equal(result_default, expected, "Default global replace results incorrect")

def test_regex_replace_shape_preservation():
    """Test that regex_replace preserves input shape."""
    # 2D input tensor
    input_tensor = tf.constant([
        ["Text with <br />", "No tags"],
        ["<b>bold</b> text", "Mixed <i>italic</i>"]
    ])
    pattern = "<[^>]+>"
    rewrite = " "
    
    result = string_ops.regex_replace(input_tensor, pattern, rewrite, replace_global=True)
    
    # Check shape preservation
    assert_tensor_shape(result, (2, 2), "Result should preserve 2D shape")
    
    # Check dtype
    assert_tensor_dtype(result, tf.string, "Result should be string dtype")
    
    # Check values
    expected = tf.constant([
        ["Text with  ", "No tags"],
        [" bold  text", "Mixed  italic "]
    ])
    assert_tensor_equal(result, expected, "2D regex replace results incorrect")

def test_regex_replace_complex_patterns():
    """Test regex_replace with complex regex patterns."""
    # Complex pattern 1: Email address replacement
    input_tensor = tf.constant("Contact: user@example.com or admin@test.org")
    pattern = "[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}"
    rewrite = "[EMAIL]"
    
    result = string_ops.regex_replace(input_tensor, pattern, rewrite, replace_global=True)
    expected = tf.constant("Contact: [EMAIL] or [EMAIL]")
    assert_tensor_equal(result, expected, "Email pattern replace incorrect")
    
    # Complex pattern 2: Multiple capture groups
    input_tensor = tf.constant("Date: 2023-12-25")
    pattern = "(\\d{4})-(\\d{2})-(\\d{2})"
    rewrite = "\\3/\\2/\\1"  # Rearrange to DD/MM/YYYY
    
    result = string_ops.regex_replace(input_tensor, pattern, rewrite, replace_global=True)
    expected = tf.constant("Date: 25/12/2023")
    assert_tensor_equal(result, expected, "Capture groups replace incorrect")

def test_regex_replace_unicode_support():
    """Test regex_replace with Unicode characters."""
    # Unicode in pattern
    input_tensor = tf.constant("cafÃ© cafÃ© cafÃ©")
    pattern = "cafÃ©"
    rewrite = "coffee"
    
    result = string_ops.regex_replace(input_tensor, pattern, rewrite, replace_global=True)
    expected = tf.constant("coffee coffee coffee")
    assert_tensor_equal(result, expected, "Unicode pattern replace incorrect")
    
    # Unicode in rewrite
    input_tensor = tf.constant("smile smile")
    pattern = "smile"
    rewrite = "ðŸ™‚"
    
    result = string_ops.regex_replace(input_tensor, pattern, rewrite, replace_global=True)
    expected = tf.constant("ðŸ™‚ ðŸ™‚")
    assert_tensor_equal(result, expected, "Unicode rewrite replace incorrect")

def test_regex_replace_edge_cases():
    """Test regex_replace with edge cases."""
    # Edge case 1: Empty pattern (matches everything)
    input_tensor = tf.constant("abc")
    pattern = ""
    rewrite = "X"
    
    result = string_ops.regex_replace(input_tensor, pattern, rewrite, replace_global=True)
    # Empty pattern matches between every character
    expected = tf.constant("XaXbXcX")
    assert_tensor_equal(result, expected, "Empty pattern replace incorrect")
    
    # Edge case 2: Pattern matching empty string with non-global replace
    input_tensor = tf.constant("abc")
    pattern = ""
    rewrite = "X"
    
    result = string_ops.regex_replace(input_tensor, pattern, rewrite, replace_global=False)
    # Non-global: only first empty match (at beginning)
    expected = tf.constant("Xabc")
    assert_tensor_equal(result, expected, "Empty pattern non-global replace incorrect")
    
    # Edge case 3: Rewrite with backreferences to non-existent groups
    input_tensor = tf.constant("test")
    pattern = "test"
    rewrite = "\\1\\2"  # References groups that don't exist
    
    # This might produce empty string or the literal "\1\2"
    result = string_ops.regex_replace(input_tensor, pattern, rewrite, replace_global=True)
    # Accept either behavior
    assert result.numpy() in [b"", b"\\1\\2"], f"Unexpected result: {result.numpy()}"

def test_regex_replace_performance_check_simple():
    """Simple performance/behavior check for regex_replace."""
    # Not a true performance test, but checks that large inputs work
    input_tensor = tf.constant(["a" * 100, "b" * 200, "c" * 300])
    pattern = "a"
    rewrite = "X"
    
    result = string_ops.regex_replace(input_tensor, pattern, rewrite, replace_global=True)
    
    # Check shape
    assert_tensor_shape(result, (3,), "Result should have same shape as input")
    
    # Check first value (all 'a's replaced with 'X')
    expected_first = "X" * 100
    assert result[0].numpy().decode() == expected_first, "Large input replace incorrect"
# ==== BLOCK:CASE_04 END ====

# ==== BLOCK:CASE_05 START ====
def test_string_split_basic():
    """Test basic functionality of string_split."""
    # Test case 1: Basic comma-separated strings
    source = tf.constant(["a,b,c", "d,e,f"])
    sep = ","
    
    result = string_ops.string_split(source, sep=sep, skip_empty=True)
    
    # Check that result is a SparseTensor
    assert isinstance(result, tf.SparseTensor), "Result should be a SparseTensor"
    
    # Check shape (should be [2, 3] as per docstring example)
    # Note: shape is [batch_size, max_split_count]
    assert result.shape == tf.TensorShape([2, 3]), f"Shape should be [2, 3], got {result.shape}"
    
    # Check indices
    expected_indices = tf.constant([
        [0, 0],  # first string, first token
        [0, 1],  # first string, second token
        [0, 2],  # first string, third token
        [1, 0],  # second string, first token
        [1, 1],  # second string, second token
        [1, 2],  # second string, third token
    ])
    assert_tensor_equal(result.indices, expected_indices, "Indices incorrect")
    
    # Check values
    expected_values = tf.constant(["a", "b", "c", "d", "e", "f"])
    assert_tensor_equal(result.values, expected_values, "Values incorrect")
    
    # Check dense shape
    expected_shape = tf.constant([2, 3])
    assert_tensor_equal(result.dense_shape, expected_shape, "Dense shape incorrect")

def test_string_split_empty_skip():
    """Test string_split with skip_empty=False."""
    source = tf.constant(["a,,c", "d,e,"])
    sep = ","
    
    result = string_ops.string_split(source, sep=sep, skip_empty=False)
    
    # Check shape
    assert result.shape == tf.TensorShape([2, 3]), f"Shape should be [2, 3], got {result.shape}"
    
    # Check values (should include empty strings)
    expected_values = tf.constant(["a", "", "c", "d", "e", ""])
    assert_tensor_equal(result.values, expected_values, "Values with empty strings incorrect")

def test_string_split_default_separator():
    """Test string_split with default separator (space)."""
    source = tf.constant(["hello world", "a b c"])
    
    result = string_ops.string_split(source, skip_empty=True)
    
    # Check shape
    assert result.shape == tf.TensorShape([2, 3]), f"Shape should be [2, 3], got {result.shape}"
    
    # Check values
    expected_values = tf.constant(["hello", "world", "a", "b", "c"])
    assert_tensor_equal(result.values, expected_values, "Default separator values incorrect")

def test_string_split_single_string():
    """Test string_split with single string input."""
    source = tf.constant(["a,b,c"])
    
    result = string_ops.string_split(source, sep=",")
    
    # Check shape
    assert result.shape == tf.TensorShape([1, 3]), f"Shape should be [1, 3], got {result.shape}"
    
    # Check values
    expected_values = tf.constant(["a", "b", "c"])
    assert_tensor_equal(result.values, expected_values, "Single string values incorrect")

def test_string_split_no_delimiter():
    """Test string_split when delimiter is not in the string."""
    source = tf.constant(["abc", "def"])
    
    result = string_ops.string_split(source, sep=",")
    
    # Check shape - each string should have 1 token
    assert result.shape == tf.TensorShape([2, 1]), f"Shape should be [2, 1], got {result.shape}"
    
    # Check values - should return original strings
    expected_values = tf.constant(["abc", "def"])
    assert_tensor_equal(result.values, expected_values, "No delimiter values incorrect")

def test_string_split_empty_string():
    """Test string_split with empty string input."""
    source = tf.constant([""])
    
    result = string_ops.string_split(source, sep=",")
    
    # Check shape - empty string with skip_empty=True should produce no tokens
    assert result.shape == tf.TensorShape([1, 0]), f"Shape should be [1, 0], got {result.shape}"
    
    # Check values - should be empty
    expected_values = tf.constant([])
    assert_tensor_equal(result.values, expected_values, "Empty string values incorrect")
# ==== BLOCK:CASE_05 END ====

# ==== BLOCK:FOOTER START ====
# Additional helper tests and cleanup

def test_module_import():
    """Test that the string_ops module can be imported correctly."""
    # Verify key functions are available
    assert hasattr(string_ops, 'regex_full_match'), "regex_full_match not found"
    assert hasattr(string_ops, 'string_length'), "string_length not found"
    assert hasattr(string_ops, 'string_join'), "string_join not found"
    assert hasattr(string_ops, 'regex_replace'), "regex_replace not found"
    assert hasattr(string_ops, 'string_split'), "string_split not found"
    
    # Verify they are callable
    assert callable(string_ops.regex_full_match), "regex_full_match not callable"
    assert callable(string_ops.string_length), "string_length not callable"
    assert callable(string_ops.string_join), "string_join not callable"
    assert callable(string_ops.regex_replace), "regex_replace not callable"
    assert callable(string_ops.string_split), "string_split not callable"

def test_tensorflow_version():
    """Verify TensorFlow is available and has expected version."""
    import tensorflow as tf
    print(f"TensorFlow version: {tf.__version__}")
    assert tf.__version__ is not None, "TensorFlow version not available"

def test_string_ops_consistency():
    """Test consistency across string_ops functions."""
    # Create a simple test input
    input_tensor = tf.constant(["test", "123", "ðŸ™‚"])
    
    # Test that all functions handle the same input consistently
    # 1. string_length should work
    length_result = string_ops.string_length(input_tensor, unit="BYTE")
    assert length_result.shape == (3,), "string_length shape inconsistent"
    
    # 2. regex_full_match should work with simple pattern
    match_result = string_ops.regex_full_match(input_tensor, ".*")
    assert match_result.shape == (3,), "regex_full_match shape inconsistent"
    assert match_result.dtype == tf.bool, "regex_full_match dtype inconsistent"
    
    # 3. string_join should work with single input
    join_result = string_ops.string_join([input_tensor])
    assert join_result.shape == (3,), "string_join shape inconsistent"
    assert join_result.dtype == tf.string, "string_join dtype inconsistent"
    
    # 4. regex_replace should work
    replace_result = string_ops.regex_replace(input_tensor, "t", "T")
    assert replace_result.shape == (3,), "regex_replace shape inconsistent"
    assert replace_result.dtype == tf.string, "regex_replace dtype inconsistent"
    
    print("All string_ops functions show consistent behavior")

def test_error_handling_basic():
    """Test basic error handling in string_ops."""
    # Test 1: Invalid UTF-8 handling (when using UTF8_CHAR unit)
    # Note: TensorFlow might raise an error or handle it gracefully
    try:
        # Try to create an invalid UTF-8 tensor
        # This is tricky because TensorFlow validates strings on creation
        invalid_bytes = b'\xff\xfe\xfd'  # Invalid UTF-8 sequence
        invalid_tensor = tf.constant([invalid_bytes])
        result = string_ops.string_length(invalid_tensor, unit="UTF8_CHAR")
        # If we get here, TensorFlow handled it gracefully
        print("Invalid UTF-8 handled gracefully")
    except (tf.errors.InvalidArgumentError, UnicodeDecodeError) as e:
        # Expected error for invalid UTF-8
        print(f"Invalid UTF-8 correctly rejected: {type(e).__name__}")
    
    # Test 2: Invalid regex pattern
    input_tensor = tf.constant(["test"])
    invalid_pattern = "["  # Unclosed bracket - invalid regex
    
    try:
        result = string_ops.regex_full_match(input_tensor, invalid_pattern)
        # Some regex engines might handle this differently
        print("Invalid regex pattern handled")
    except (tf.errors.InvalidArgumentError, ValueError) as e:
        # Expected error for invalid regex
        print(f"Invalid regex correctly rejected: {type(e).__name__}")

# Test execution summary
if __name__ == "__main__":
    # This allows running the tests directly with python
    import sys
    pytest_args = [
        "-v",
        "--tb=short",
        tests/test_tensorflow_python_ops_string_ops.py
    ]
    sys.exit(pytest.main(pytest_args))
# ==== BLOCK:FOOTER END ====