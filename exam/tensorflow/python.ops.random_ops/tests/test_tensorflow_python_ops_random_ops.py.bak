# ==== BLOCK:HEADER START ====
"""
Test cases for tensorflow.python.ops.random_ops module.
Generated by TestAgent for random number generation functions.
"""

import math
import numpy as np
import pytest
import tensorflow as tf
from tensorflow.python.ops import random_ops

# Helper functions for statistical tests
def check_shape_and_dtype(tensor, expected_shape, expected_dtype):
    """Check tensor shape and dtype."""
    assert tensor.shape.as_list() == expected_shape
    assert tensor.dtype == expected_dtype

def check_finite_values(tensor):
    """Check that all values are finite (not NaN or Inf)."""
    tensor_np = tensor.numpy()
    assert np.all(np.isfinite(tensor_np))

def check_range(tensor, min_val, max_val, inclusive_min=True, inclusive_max=False):
    """Check that tensor values are within specified range."""
    tensor_np = tensor.numpy()
    if inclusive_min:
        assert np.all(tensor_np >= min_val)
    else:
        assert np.all(tensor_np > min_val)
    
    if inclusive_max:
        assert np.all(tensor_np <= max_val)
    else:
        assert np.all(tensor_np < max_val)

def check_positive_values(tensor):
    """Check that all values are positive."""
    tensor_np = tensor.numpy()
    assert np.all(tensor_np > 0)

def check_integer_values(tensor):
    """Check that all values are integers."""
    tensor_np = tensor.numpy()
    assert np.all(np.equal(np.mod(tensor_np, 1), 0))

# Statistical test helpers (weak assertions for round 1)
def basic_normal_property_check(tensor, mean=0.0, stddev=1.0, tolerance=1e-6):
    """Basic property check for normal distribution."""
    tensor_np = tensor.numpy()
    # Check that values are within reasonable bounds (99.7% within 3 sigma)
    assert np.all(np.abs(tensor_np - mean) < 10 * stddev)

def basic_uniform_property_check(tensor, minval=0.0, maxval=1.0, tolerance=1e-6):
    """Basic property check for uniform distribution."""
    tensor_np = tensor.numpy()
    # Check range
    assert np.all(tensor_np >= minval - tolerance)
    assert np.all(tensor_np < maxval + tolerance)

def basic_truncated_normal_check(tensor, mean=0.0, stddev=1.0, tolerance=1e-6):
    """Basic check for truncated normal distribution."""
    tensor_np = tensor.numpy()
    # Truncated normal should be within 2 standard deviations
    assert np.all(np.abs(tensor_np - mean) < 2 * stddev + tolerance)

# Strong assertion helpers for epoch 4/5
def statistical_normal_test(tensor, mean=0.0, stddev=1.0, alpha=0.05):
    """Strong statistical test for normal distribution."""
    tensor_np = tensor.numpy()
    n_samples = tensor_np.size
    
    # Check sample mean
    sample_mean = np.mean(tensor_np)
    mean_se = stddev / np.sqrt(n_samples)
    z_score_mean = abs(sample_mean - mean) / mean_se
    
    # For large n, z-score should follow standard normal
    # Using 3 sigma rule for test (corresponds to ~0.0027 p-value)
    assert z_score_mean < 3, f"Mean test failed: z={z_score_mean}, sample_mean={sample_mean}"
    
    # Check sample variance
    sample_var = np.var(tensor_np, ddof=1)  # Unbiased estimator
    # For normal distribution, (n-1)*s^2/σ^2 ~ χ^2(n-1)
    chi2_stat = (n_samples - 1) * sample_var / (stddev ** 2)
    # Check within reasonable bounds (0.1 to 10 for chi^2 with n-1 df)
    assert 0.1 * (n_samples - 1) < chi2_stat < 10 * (n_samples - 1), \
        f"Variance test failed: chi2={chi2_stat}, sample_var={sample_var}"

def statistical_uniform_test(tensor, minval=0.0, maxval=1.0, n_bins=10):
    """Strong statistical test for uniform distribution."""
    tensor_np = tensor.numpy()
    n_samples = tensor_np.size
    
    # Chi-square test for uniformity
    bins = np.linspace(minval, maxval, n_bins + 1)
    observed, _ = np.histogram(tensor_np, bins=bins)
    expected = n_samples / n_bins
    
    # Chi-square statistic
    chi2 = np.sum((observed - expected) ** 2 / expected)
    
    # For n_bins=10, critical value at alpha=0.05 is ~16.92
    # Using more lenient threshold for testing
    assert chi2 < 30, f"Uniformity test failed: chi2={chi2}"

def check_distribution_properties(tensor, dist_type="normal", **params):
    """Check distribution-specific properties."""
    tensor_np = tensor.numpy()
    
    if dist_type == "normal":
        mean = params.get("mean", 0.0)
        stddev = params.get("stddev", 1.0)
        
        # Check symmetry (for normal distribution)
        median = np.median(tensor_np)
        assert abs(median - mean) < 0.5 * stddev, \
            f"Median {median} not close to mean {mean} for normal distribution"
        
    elif dist_type == "uniform":
        minval = params.get("minval", 0.0)
        maxval = params.get("maxval", 1.0)
        
        # Check that values are evenly distributed
        # Simple test: check that quartiles are approximately at 25%, 50%, 75%
        q25, q50, q75 = np.percentile(tensor_np, [25, 50, 75])
        expected_q25 = minval + 0.25 * (maxval - minval)
        expected_q50 = minval + 0.5 * (maxval - minval)
        expected_q75 = minval + 0.75 * (maxval - minval)
        
        tolerance = 0.1 * (maxval - minval)
        assert abs(q25 - expected_q25) < tolerance, \
            f"25th percentile {q25} not close to expected {expected_q25}"
        assert abs(q50 - expected_q50) < tolerance, \
            f"50th percentile {q50} not close to expected {expected_q50}"
        assert abs(q75 - expected_q75) < tolerance, \
            f"75th percentile {q75} not close to expected {expected_q75}"

# Seed reproducibility helper
def check_seed_reproducibility(func, *args, seed=None, **kwargs):
    """Check that same seed produces same results."""
    if seed is None:
        return  # Skip if no seed
    
    # Reset global seed for reproducibility
    tf.random.set_seed(42)
    result1 = func(*args, seed=seed, **kwargs)
    
    tf.random.set_seed(42)
    result2 = func(*args, seed=seed, **kwargs)
    
    # Check equality
    assert np.allclose(result1.numpy(), result2.numpy(), rtol=1e-6)
# ==== BLOCK:HEADER END ====

# ==== BLOCK:CASE_01 START ====
def test_random_normal_basic():
    """Test basic functionality of random_normal function."""
    # Test 1: Basic case with default parameters
    shape = [10]
    mean = 0.0
    stddev = 1.0
    dtype = tf.float32
    seed = 42
    
    result = random_ops.random_normal(
        shape=shape,
        mean=mean,
        stddev=stddev,
        dtype=dtype,
        seed=seed
    )
    
    # Weak assertions (round 1)
    check_shape_and_dtype(result, shape, dtype)
    check_finite_values(result)
    basic_normal_property_check(result, mean, stddev)
    check_seed_reproducibility(
        random_ops.random_normal,
        shape=shape,
        mean=mean,
        stddev=stddev,
        dtype=dtype,
        seed=seed
    )
    
    # Strong assertions for epoch 4/5
    # Statistical test: check mean and variance
    result_np = result.numpy()
    sample_mean = np.mean(result_np)
    sample_std = np.std(result_np)
    
    # For 10 samples, allow reasonable tolerance
    assert abs(sample_mean - mean) < 0.5, f"Sample mean {sample_mean} not close to expected mean {mean}"
    assert abs(sample_std - stddev) < 0.3, f"Sample std {sample_std} not close to expected std {stddev}"
    
    # Distribution properties: check that values follow normal distribution pattern
    # Using simple statistical tests without scipy
    # Check skewness and kurtosis (approximate for normal distribution)
    n_samples = len(result_np)
    if n_samples >= 20:  # Only for reasonable sample sizes
        # Calculate skewness manually
        centered = result_np - sample_mean
        skewness = np.mean(centered ** 3) / (sample_std ** 3)
        # Normal distribution should have skewness close to 0
        assert abs(skewness) < 1.0, f"Distribution appears skewed: skewness={skewness}"
        
        # Calculate kurtosis manually
        kurtosis = np.mean(centered ** 4) / (sample_std ** 4) - 3
        # Normal distribution has kurtosis = 0 (excess kurtosis)
        assert abs(kurtosis) < 2.0, f"Distribution has unusual kurtosis: kurtosis={kurtosis}"

@pytest.mark.parametrize("test_case", [
    {
        "shape": [2, 3, 4],
        "mean": 5.0,
        "stddev": 2.0,
        "dtype": tf.float64,
        "seed": 123,
        "note": "Multi-dimensional shape and different parameters"
    },
    {
        "shape": [0],
        "mean": 0.0,
        "stddev": 1.0,
        "dtype": tf.float32,
        "seed": 42,
        "note": "Empty tensor edge case"
    }
])
def test_random_normal_param_extensions(test_case):
    """Parameter extensions for random_normal."""
    shape = test_case["shape"]
    mean = test_case["mean"]
    stddev = test_case["stddev"]
    dtype = test_case["dtype"]
    seed = test_case["seed"]
    
    result = random_ops.random_normal(
        shape=shape,
        mean=mean,
        stddev=stddev,
        dtype=dtype,
        seed=seed
    )
    
    # Weak assertions
    check_shape_and_dtype(result, shape, dtype)
    check_finite_values(result)
    
    # For empty tensor, just check shape and dtype
    if shape == [0]:
        assert result.shape.as_list() == [0]
        assert result.dtype == dtype
    else:
        basic_normal_property_check(result, mean, stddev)
        
        # Strong assertions for epoch 4/5
        result_np = result.numpy()
        sample_mean = np.mean(result_np)
        sample_std = np.std(result_np)
        
        # Calculate expected tolerance based on sample size
        n_samples = np.prod(shape)
        mean_tolerance = 3 * stddev / np.sqrt(n_samples)  # 3 sigma rule for mean
        std_tolerance = 0.5 * stddev  # Allow 50% variation for std
        
        assert abs(sample_mean - mean) < mean_tolerance, \
            f"Sample mean {sample_mean} not close to expected mean {mean} for shape {shape}"
        assert abs(sample_std - stddev) < std_tolerance, \
            f"Sample std {sample_std} not close to expected std {stddev} for shape {shape}"
    
    # Check seed reproducibility if seed is provided
    if seed is not None:
        check_seed_reproducibility(
            random_ops.random_normal,
            shape=shape,
            mean=mean,
            stddev=stddev,
            dtype=dtype,
            seed=seed
        )
# ==== BLOCK:CASE_01 END ====

# ==== BLOCK:CASE_02 START ====
def test_random_uniform_basic():
    """Test basic functionality of random_uniform function."""
    # Test 1: Basic case with default parameters
    shape = [5, 5]
    minval = 0.0
    maxval = 1.0
    dtype = tf.float32
    seed = 42
    
    result = random_ops.random_uniform(
        shape=shape,
        minval=minval,
        maxval=maxval,
        dtype=dtype,
        seed=seed
    )
    
    # Weak assertions (round 1)
    check_shape_and_dtype(result, shape, dtype)
    check_range(result, minval, maxval, inclusive_min=True, inclusive_max=False)
    basic_uniform_property_check(result, minval, maxval)
    check_seed_reproducibility(
        random_ops.random_uniform,
        shape=shape,
        minval=minval,
        maxval=maxval,
        dtype=dtype,
        seed=seed
    )
    
    # Strong assertions for epoch 4/5
    result_np = result.numpy()
    
    # Uniformity test: check mean is approximately (minval + maxval) / 2
    expected_mean = (minval + maxval) / 2
    sample_mean = np.mean(result_np)
    n_samples = np.prod(shape)
    
    # For uniform distribution, standard deviation is (maxval - minval) / sqrt(12)
    std_uniform = (maxval - minval) / np.sqrt(12)
    mean_tolerance = 3 * std_uniform / np.sqrt(n_samples)  # 3 sigma rule
    
    assert abs(sample_mean - expected_mean) < mean_tolerance, \
        f"Sample mean {sample_mean} not close to expected mean {expected_mean}"
    
    # Boundary check: ensure no values exactly at maxval (exclusive)
    assert np.all(result_np < maxval), "Found values at or above maxval (should be exclusive)"
    assert np.all(result_np >= minval), "Found values below minval (should be inclusive)"

@pytest.mark.parametrize("test_case", [
    {
        "shape": [10],
        "minval": -10.0,
        "maxval": 10.0,
        "dtype": tf.float64,
        "seed": 456,
        "note": "Negative range uniform distribution"
    }
])
def test_random_uniform_param_extensions(test_case):
    """Parameter extensions for random_uniform."""
    shape = test_case["shape"]
    minval = test_case["minval"]
    maxval = test_case["maxval"]
    dtype = test_case["dtype"]
    seed = test_case["seed"]
    
    result = random_ops.random_uniform(
        shape=shape,
        minval=minval,
        maxval=maxval,
        dtype=dtype,
        seed=seed
    )
    
    # Weak assertions
    check_shape_and_dtype(result, shape, dtype)
    check_range(result, minval, maxval, inclusive_min=True, inclusive_max=False)
    basic_uniform_property_check(result, minval, maxval)
    
    # Strong assertions for epoch 4/5
    result_np = result.numpy()
    
    # Check uniformity more rigorously
    expected_mean = (minval + maxval) / 2
    sample_mean = np.mean(result_np)
    n_samples = np.prod(shape)
    
    std_uniform = (maxval - minval) / np.sqrt(12)
    mean_tolerance = 3 * std_uniform / np.sqrt(n_samples)
    
    assert abs(sample_mean - expected_mean) < mean_tolerance, \
        f"Sample mean {sample_mean} not close to expected mean {expected_mean} for range [{minval}, {maxval})"
    
    # Check that values are properly distributed across the range
    # Divide range into 4 bins and check each has reasonable number of samples
    if n_samples >= 40:  # Only for reasonable sample sizes
        bins = np.linspace(minval, maxval, 5)  # 4 bins
        hist, _ = np.histogram(result_np, bins=bins)
        expected_per_bin = n_samples / 4
        # Chi-square like check: each bin should have at least 20% of expected
        for count in hist:
            assert count > 0.2 * expected_per_bin, \
                f"Bin has too few samples: {count} < 0.2 * {expected_per_bin}"
    
    # Check seed reproducibility if seed is provided
    if seed is not None:
        check_seed_reproducibility(
            random_ops.random_uniform,
            shape=shape,
            minval=minval,
            maxval=maxval,
            dtype=dtype,
            seed=seed
        )
# ==== BLOCK:CASE_02 END ====

# ==== BLOCK:CASE_03 START ====
def test_truncated_normal_basic():
    """Test basic functionality of truncated_normal function."""
    # Test 1: Basic case with default parameters
    shape = [100]
    mean = 0.0
    stddev = 1.0
    dtype = tf.float32
    seed = 42
    
    result = random_ops.truncated_normal(
        shape=shape,
        mean=mean,
        stddev=stddev,
        dtype=dtype,
        seed=seed
    )
    
    # Weak assertions (round 1)
    check_shape_and_dtype(result, shape, dtype)
    check_finite_values(result)
    basic_truncated_normal_check(result, mean, stddev)
    check_seed_reproducibility(
        random_ops.truncated_normal,
        shape=shape,
        mean=mean,
        stddev=stddev,
        dtype=dtype,
        seed=seed
    )
    
    # Strong assertions for epoch 4/5
    result_np = result.numpy()
    
    # Truncation verification: check all values are within 2 standard deviations
    assert np.all(np.abs(result_np - mean) < 2 * stddev), \
        "Found values outside 2 standard deviations for truncated normal"
    
    # Statistical test: check mean and variance
    sample_mean = np.mean(result_np)
    sample_std = np.std(result_np)
    
    # For truncated normal with truncation at ±2 sigma:
    # Theoretical mean is approximately 0.0 (slightly biased toward 0)
    # Theoretical std is approximately 0.88 (reduced from 1.0 due to truncation)
    expected_std_truncated = 0.88  # Approximate for truncation at ±2 sigma
    
    n_samples = np.prod(shape)
    mean_tolerance = 3 * expected_std_truncated / np.sqrt(n_samples)
    
    assert abs(sample_mean - mean) < mean_tolerance, \
        f"Sample mean {sample_mean} not close to expected mean {mean}"
    assert 0.7 < sample_std < 0.95, \
        f"Sample std {sample_std} not in expected range for truncated normal"
    
    # Distribution properties: check skewness (should be approximately 0 for symmetric truncation)
    # Calculate skewness manually without scipy
    centered = result_np - sample_mean
    skewness = np.mean(centered ** 3) / (sample_std ** 3)
    # Truncated normal should be symmetric (skewness close to 0)
    assert abs(skewness) < 0.3, f"Distribution appears skewed: skewness={skewness}"

@pytest.mark.parametrize("test_case", [
    {
        "shape": [1000],
        "mean": 10.0,
        "stddev": 0.5,
        "dtype": tf.float32,
        "seed": 789,
        "note": "Different mean and standard deviation"
    }
])
def test_truncated_normal_param_extensions(test_case):
    """Parameter extensions for truncated_normal."""
    shape = test_case["shape"]
    mean = test_case["mean"]
    stddev = test_case["stddev"]
    dtype = test_case["dtype"]
    seed = test_case["seed"]
    
    result = random_ops.truncated_normal(
        shape=shape,
        mean=mean,
        stddev=stddev,
        dtype=dtype,
        seed=seed
    )
    
    # Weak assertions
    check_shape_and_dtype(result, shape, dtype)
    check_finite_values(result)
    basic_truncated_normal_check(result, mean, stddev)
    
    # Strong assertions for epoch 4/5
    result_np = result.numpy()
    
    # Verify truncation at ±2 standard deviations
    assert np.all(np.abs(result_np - mean) < 2 * stddev), \
        f"Found values outside 2 standard deviations for mean={mean}, stddev={stddev}"
    
    # Check that distribution is properly centered
    sample_mean = np.mean(result_np)
    n_samples = np.prod(shape)
    
    # For truncated normal, standard deviation is reduced
    expected_std_truncated = stddev * 0.88  # Approximate reduction factor
    mean_tolerance = 3 * expected_std_truncated / np.sqrt(n_samples)
    
    assert abs(sample_mean - mean) < mean_tolerance, \
        f"Sample mean {sample_mean} not close to expected mean {mean} for truncated normal"
    
    # Check that values are not too clustered (should have reasonable spread)
    sample_std = np.std(result_np)
    assert sample_std > 0.3 * stddev, \
        f"Sample std {sample_std} too small for truncated normal with stddev={stddev}"
    assert sample_std < 0.95 * stddev, \
        f"Sample std {sample_std} too large for truncated normal with stddev={stddev}"
    
    # Check symmetry
    centered = result_np - sample_mean
    skewness = np.mean(centered ** 3) / (sample_std ** 3)
    assert abs(skewness) < 0.3, f"Distribution appears skewed: skewness={skewness}"
    
    # Check seed reproducibility if seed is provided
    if seed is not None:
        check_seed_reproducibility(
            random_ops.truncated_normal,
            shape=shape,
            mean=mean,
            stddev=stddev,
            dtype=dtype,
            seed=seed
        )
# ==== BLOCK:CASE_03 END ====

# ==== BLOCK:CASE_04 START ====
# Test case for random_gamma distribution verification

def test_random_gamma_basic():
    """Test basic functionality of random_gamma."""
    # Test with basic parameters from test plan
    shape = [50]
    alpha = 2.0
    beta = 1.0
    dtype = tf.float32
    seed = 42
    
    result = random_ops.random_gamma(
        shape=shape,
        alpha=alpha,
        beta=beta,
        dtype=dtype,
        seed=seed
    )
    
    # Weak assertions: shape, dtype, positive_check, basic_property
    assert result.shape == tuple(shape)
    assert result.dtype == dtype
    
    # Check that all values are positive (gamma distribution produces positive values)
    assert tf.reduce_all(result > 0.0)
    
    # Check that values are finite
    assert tf.reduce_all(tf.math.is_finite(result))
    
    # Basic property: mean should be approximately alpha/beta = 2.0
    # For weak assertions, just check it's a reasonable positive number
    mean_val = tf.reduce_mean(result).numpy()
    assert mean_val > 0.0
    # Gamma distribution mean = alpha/beta = 2.0, allow wide tolerance for weak assertion
    assert 0.5 < mean_val < 10.0

@pytest.mark.parametrize("test_case", [
    {
        "shape": [100],
        "alpha": 0.5,
        "beta": 2.0,
        "dtype": tf.float32,
        "seed": 42,
        "note": "Small alpha parameter gamma distribution"
    }
])
def test_random_gamma_param_extensions(test_case):
    """Parameter extensions for random_gamma."""
    result = random_ops.random_gamma(
        shape=test_case["shape"],
        alpha=test_case["alpha"],
        beta=test_case["beta"],
        dtype=test_case["dtype"],
        seed=test_case["seed"]
    )
    
    # Weak assertions
    assert result.shape == tuple(test_case["shape"])
    assert result.dtype == test_case["dtype"]
    
    # Gamma distribution produces positive values
    assert tf.reduce_all(result > 0.0)
    
    # Check finite values
    assert tf.reduce_all(tf.math.is_finite(result))
    
    # For small alpha (0.5), values should still be positive
    # Mean should be alpha/beta = 0.5/2.0 = 0.25
    mean_val = tf.reduce_mean(result).numpy()
    assert mean_val > 0.0
    # Allow wide tolerance for weak assertion
    assert 0.05 < mean_val < 2.0
# ==== BLOCK:CASE_04 END ====

# ==== BLOCK:CASE_05 START ====
# Test case for random_poisson_v2 Poisson distribution

def test_random_poisson_v2_basic():
    """Test basic functionality of random_poisson_v2."""
    # Test with basic parameters from test plan
    shape = [30]
    lam = 5.0
    dtype = tf.float32
    seed = 42
    
    result = random_ops.random_poisson_v2(
        shape=shape,
        lam=lam,
        dtype=dtype,
        seed=seed
    )
    
    # Weak assertions: shape, dtype, integer_check, basic_property
    assert result.shape == tuple(shape)
    assert result.dtype == dtype
    
    # Check that all values are non-negative (Poisson distribution produces non-negative values)
    assert tf.reduce_all(result >= 0.0)
    
    # Check that values are finite
    assert tf.reduce_all(tf.math.is_finite(result))
    
    # Basic property: mean should be approximately lam = 5.0
    # For weak assertions, just check it's a reasonable non-negative number
    mean_val = tf.reduce_mean(result).numpy()
    assert mean_val >= 0.0
    # Poisson distribution mean = lam = 5.0, allow wide tolerance for weak assertion
    assert 1.0 < mean_val < 15.0
    
    # Check that values are integers (Poisson produces integer counts)
    # Since we're using float32 dtype, values should be integers but represented as floats
    # We can check that values are close to integers
    values = result.numpy()
    # Check that values are close to their integer representations
    integer_diff = np.abs(values - np.round(values))
    assert np.all(integer_diff < 1e-6)
# ==== BLOCK:CASE_05 END ====

# ==== BLOCK:FOOTER START ====
# Additional test cases for error handling and edge cases

def test_random_normal_invalid_stddev():
    """Test random_normal with invalid stddev parameter."""
    # TensorFlow does not validate stddev > 0, so we test the actual behavior
    # stddev = 0 should produce all values equal to mean
    result = random_ops.random_normal(shape=[10], stddev=0.0, seed=42)
    assert result.shape == (10,)
    assert result.dtype == tf.float32
    # All values should be 0.0 (mean) when stddev=0
    tf.debugging.assert_near(result, 0.0, atol=1e-6)
    
    # stddev = -1.0 should produce normally distributed values with negative scaling
    result = random_ops.random_normal(shape=[100], stddev=-1.0, seed=42)
    assert result.shape == (100,)
    assert result.dtype == tf.float32
    # Values should be finite
    assert tf.reduce_all(tf.math.is_finite(result))
    
    # Test with very small stddev
    result = random_ops.random_normal(shape=[50], stddev=1e-10, seed=42)
    assert result.shape == (50,)
    assert result.dtype == tf.float32
    # Values should be very close to 0
    assert tf.reduce_max(tf.abs(result)) < 1e-8

def test_random_uniform_invalid_range():
    """Test random_uniform with invalid range parameters."""
    # TensorFlow does not validate minval < maxval, so we test the actual behavior
    # minval > maxval produces values in the range [maxval, minval) which is mathematically valid
    result = random_ops.random_uniform(shape=[10], minval=1.0, maxval=0.0, seed=42)
    assert result.shape == (10,)
    assert result.dtype == tf.float32
    # Values should be in [0.0, 1.0) due to swapping
    tf.debugging.assert_greater_equal(result, 0.0)
    tf.debugging.assert_less(result, 1.0)
    
    # minval = maxval produces all values equal to minval
    result = random_ops.random_uniform(shape=[10], minval=1.0, maxval=1.0, seed=42)
    assert result.shape == (10,)
    assert result.dtype == tf.float32
    # All values should be 1.0
    tf.debugging.assert_near(result, 1.0, atol=1e-6)
    
    # Test with very small range
    result = random_ops.random_uniform(shape=[20], minval=0.0, maxval=1e-10, seed=42)
    assert result.shape == (20,)
    assert result.dtype == tf.float32
    # All values should be between 0 and 1e-10
    tf.debugging.assert_greater_equal(result, 0.0)
    tf.debugging.assert_less(result, 1e-10)

def test_random_uniform_integer_no_maxval():
    """Test random_uniform with integer dtype but no maxval."""
    with pytest.raises(ValueError):
        random_ops.random_uniform(shape=[10], dtype=tf.int32)
    
    # Test with integer dtype and valid range
    result = random_ops.random_uniform(shape=[10], minval=0, maxval=100, dtype=tf.int32, seed=42)
    assert result.shape == (10,)
    assert result.dtype == tf.int32
    # Values should be integers in [0, 100)
    tf.debugging.assert_greater_equal(result, 0)
    tf.debugging.assert_less(result, 100)
    
    # Check that values are integers
    result_np = result.numpy()
    assert np.all(np.equal(np.mod(result_np, 1), 0))

def test_truncated_normal_invalid_stddev():
    """Test truncated_normal with invalid stddev parameter."""
    # TensorFlow does not validate stddev > 0, so we test the actual behavior
    # stddev = 0 should produce all values equal to mean
    result = random_ops.truncated_normal(shape=[10], stddev=0.0, seed=42)
    assert result.shape == (10,)
    assert result.dtype == tf.float32
    # All values should be 0.0 (mean) when stddev=0
    tf.debugging.assert_near(result, 0.0, atol=1e-6)
    
    # stddev = -1.0 should produce truncated normally distributed values with negative scaling
    result = random_ops.truncated_normal(shape=[100], stddev=-1.0, seed=42)
    assert result.shape == (100,)
    assert result.dtype == tf.float32
    # Values should be finite and within [-2, 2] range (truncated at 2 stddevs)
    assert tf.reduce_all(tf.math.is_finite(result))
    tf.debugging.assert_greater_equal(result, -2.0)
    tf.debugging.assert_less_equal(result, 2.0)
    
    # Test with very small stddev
    result = random_ops.truncated_normal(shape=[50], stddev=1e-10, seed=42)
    assert result.shape == (50,)
    assert result.dtype == tf.float32
    # Values should be very close to 0 and within ±2e-10
    assert tf.reduce_max(tf.abs(result)) < 2.1e-10

def test_invalid_shape():
    """Test with invalid shape parameter."""
    # TensorFlow should validate shape parameters
    with pytest.raises((ValueError, tf.errors.InvalidArgumentError)):
        random_ops.random_normal(shape=[-1])
    
    with pytest.raises((ValueError, tf.errors.InvalidArgumentError)):
        random_ops.random_normal(shape=[1, -2, 3])
    
    # Test with zero dimensions (should work)
    result = random_ops.random_normal(shape=[0], seed=42)
    assert result.shape == (0,)
    assert result.dtype == tf.float32
    
    # Test with large but valid shape
    result = random_ops.random_normal(shape=[1000000], seed=42)
    assert result.shape == (1000000,)
    assert result.dtype == tf.float32
    # Just check it doesn't crash and produces finite values
    assert tf.reduce_all(tf.math.is_finite(result))

def test_large_shape():
    """Test with large shape (memory permitting)."""
    # Use small shape for basic test, can be adjusted based on available memory
    shape = [1000]
    result = random_ops.random_normal(shape=shape, seed=42)
    check_shape_and_dtype(result, shape, tf.float32)
    check_finite_values(result)
    
    # Test statistical properties for large sample
    result_np = result.numpy()
    sample_mean = np.mean(result_np)
    sample_std = np.std(result_np)
    
    # For 1000 samples, mean should be within 0.1 of 0
    assert abs(sample_mean) < 0.1, f"Mean {sample_mean} not close to 0 for large sample"
    # Std should be close to 1
    assert 0.9 < sample_std < 1.1, f"Std {sample_std} not close to 1 for large sample"

def test_different_dtypes():
    """Test random functions with different dtypes."""
    # Test random_normal with float64
    result = random_ops.random_normal(shape=[10], dtype=tf.float64, seed=42)
    assert result.shape == (10,)
    assert result.dtype == tf.float64
    check_finite_values(result)
    
    # Test random_uniform with float64
    result = random_ops.random_uniform(shape=[10], dtype=tf.float64, seed=42)
    assert result.shape == (10,)
    assert result.dtype == tf.float64
    tf.debugging.assert_greater_equal(result, 0.0)
    tf.debugging.assert_less(result, 1.0)
    
    # Test truncated_normal with float64
    result = random_ops.truncated_normal(shape=[10], dtype=tf.float64, seed=42)
    assert result.shape == (10,)
    assert result.dtype == tf.float64
    check_finite_values(result)
    tf.debugging.assert_greater_equal(result, -2.0)
    tf.debugging.assert_less_equal(result, 2.0)

def test_no_seed_variability():
    """Test that different calls without seed produce different results."""
    # Without seed, results should be different (with very high probability)
    result1 = random_ops.random_normal(shape=[100])
    result2 = random_ops.random_normal(shape=[100])
    
    # Check that they are not identical (very unlikely for 100 samples)
    assert not np.allclose(result1.numpy(), result2.numpy(), rtol=1e-10)
    
    # Same for random_uniform
    result1 = random_ops.random_uniform(shape=[100])
    result2 = random_ops.random_uniform(shape=[100])
    assert not np.allclose(result1.numpy(), result2.numpy(), rtol=1e-10)
    
    # Same for truncated_normal
    result1 = random_ops.truncated_normal(shape=[100])
    result2 = random_ops.truncated_normal(shape=[100])
    assert not np.allclose(result1.numpy(), result2.numpy(), rtol=1e-10)

# Cleanup and teardown if needed
def teardown_module():
    """Cleanup after all tests."""
    # Reset any global state if needed
    tf.random.set_seed(None)
# ==== BLOCK:FOOTER END ====