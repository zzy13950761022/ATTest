"""Tests for tensorflow.python.ops.gen_audio_ops module."""

import math
import numpy as np
import pytest
import tensorflow as tf
from tensorflow.python.ops import gen_audio_ops

# Set random seed for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# ==== BLOCK:HEADER START ====
# Test class and helper functions
class TestGenAudioOps:
    """Test class for gen_audio_ops module."""
    
    @staticmethod
    def generate_sine_wave(frequency, sample_rate, duration, channels=1):
        """Generate a sine wave audio signal."""
        t = np.linspace(0, duration, int(sample_rate * duration), endpoint=False)
        signal = np.sin(2 * np.pi * frequency * t)
        if channels > 1:
            signal = np.stack([signal] * channels, axis=-1)
        return signal.astype(np.float32)
    
    @staticmethod
    def generate_random_audio(shape, min_val=-1.0, max_val=1.0):
        """Generate random audio data within valid range."""
        audio = np.random.uniform(min_val, max_val, shape).astype(np.float32)
        return audio
    
    @staticmethod
    def compute_spectrogram_manual(audio, window_size, stride, magnitude_squared=False):
        """Manual computation of spectrogram for validation."""
        # Simplified manual computation for basic validation
        # In practice, this would use proper FFT
        num_samples = audio.shape[0]
        num_channels = audio.shape[1] if len(audio.shape) > 1 else 1
        
        if num_channels > 1:
            audio = audio.reshape(num_samples, num_channels)
        
        # Calculate number of windows
        num_windows = max(0, (num_samples - window_size) // stride + 1)
        
        # For basic validation, return a simple shape
        if magnitude_squared:
            return np.ones((num_channels, num_windows, window_size // 2 + 1), dtype=np.float32)
        else:
            return np.ones((num_channels, num_windows, window_size // 2 + 1), dtype=np.float32)
    
    @staticmethod
    def create_wav_data(audio, sample_rate):
        """Create WAV encoded data from audio."""
        # Use TensorFlow's encode_wav function
        audio_tensor = tf.constant(audio, dtype=tf.float32)
        sample_rate_tensor = tf.constant(sample_rate, dtype=tf.int32)
        wav_data = gen_audio_ops.encode_wav(audio_tensor, sample_rate_tensor)
        return wav_data.numpy()
    
    @staticmethod
    def generate_edge_case_audio(case_type, shape):
        """Generate audio data for edge case testing."""
        num_samples, num_channels = shape
        
        if case_type == "all_zeros":
            # All zeros audio
            return np.zeros(shape, dtype=np.float32)
        elif case_type == "all_ones":
            # All ones audio (clipped to valid range)
            return np.ones(shape, dtype=np.float32)
        elif case_type == "alternating":
            # Alternating +1/-1 pattern
            audio = np.ones(shape, dtype=np.float32)
            for i in range(num_samples):
                if i % 2 == 0:
                    audio[i] = 1.0
                else:
                    audio[i] = -1.0
            return audio
        elif case_type == "single_sample":
            # Single sample audio
            if num_samples > 0:
                return np.ones((1, num_channels), dtype=np.float32)
            else:
                return np.zeros((0, num_channels), dtype=np.float32)
        elif case_type == "extreme_values":
            # Values at the extreme of valid range
            audio = np.zeros(shape, dtype=np.float32)
            audio[::2] = 1.0  # Every other sample at +1
            audio[1::2] = -1.0  # Every other sample at -1
            return audio
        else:
            # Default: random audio
            return np.random.uniform(-0.5, 0.5, shape).astype(np.float32)
    
    @staticmethod
    def validate_audio_range(audio, min_val=-1.0, max_val=1.0, tolerance=1e-6):
        """Validate that audio values are within specified range."""
        audio_np = audio.numpy() if hasattr(audio, 'numpy') else audio
        return np.all(audio_np >= min_val - tolerance) and np.all(audio_np <= max_val + tolerance)
    
    @staticmethod
    def validate_spectrogram_properties(spectrogram, expected_channels, expected_windows, expected_freq_bins):
        """Validate basic properties of a spectrogram."""
        spec_np = spectrogram.numpy() if hasattr(spectrogram, 'numpy') else spectrogram
        
        # Check shape
        assert spec_np.shape == (expected_channels, expected_windows, expected_freq_bins), \
            f"Shape mismatch: expected ({expected_channels}, {expected_windows}, {expected_freq_bins}), got {spec_np.shape}"
        
        # Check non-negative values (spectrogram magnitudes are non-negative)
        assert np.all(spec_np >= 0), "Spectrogram contains negative values"
        
        # Check finite values
        assert np.all(np.isfinite(spec_np)), "Spectrogram contains non-finite values"
        
        return True
# ==== BLOCK:HEADER END ====

# ==== BLOCK:CASE_01 START ====
    @pytest.mark.parametrize("input_shape,window_size,stride,magnitude_squared,dtype", [
        ([16000, 1], 512, 256, False, "float32"),
        ([32000, 2], 1024, 512, True, "float32"),  # param_extension: 多通道音频和平方幅度测试
        ([8000, 1], 256, 128, False, "float32"),   # param_extension: 非2的幂窗口大小测试
    ])
    def test_audio_spectrogram_basic(self, input_shape, window_size, stride, magnitude_squared, dtype):
        """Test basic functionality of audio_spectrogram."""
        # Generate test audio data - audio_spectrogram expects 2D input [samples, channels]
        num_samples, num_channels = input_shape
        audio = self.generate_sine_wave(
            frequency=440.0,  # A4 note
            sample_rate=16000,
            duration=num_samples / 16000,
            channels=num_channels
        )
        
        # Ensure audio is 2D: [samples, channels]
        if len(audio.shape) == 1:
            audio = audio.reshape(-1, 1)
        elif len(audio.shape) == 2 and audio.shape[1] != num_channels:
            # Reshape if needed
            audio = audio.reshape(-1, num_channels)
        
        # Convert to tensor
        audio_tensor = tf.constant(audio, dtype=getattr(tf, dtype))
        
        # Call the function
        spectrogram = gen_audio_ops.audio_spectrogram(
            input=audio_tensor,
            window_size=window_size,
            stride=stride,
            magnitude_squared=magnitude_squared
        )
        
        # Weak assertions (round 1)
        # 1. Shape assertion
        num_windows = max(0, (num_samples - window_size) // stride + 1)
        expected_channels = num_channels
        expected_freq_bins = window_size // 2 + 1
        
        # audio_spectrogram returns 3D tensor: [channels, time, frequency]
        assert spectrogram.shape == (expected_channels, num_windows, expected_freq_bins), \
            f"Expected shape ({expected_channels}, {num_windows}, {expected_freq_bins}), got {spectrogram.shape}"
        
        # 2. Dtype assertion
        assert spectrogram.dtype == tf.float32, \
            f"Expected dtype float32, got {spectrogram.dtype}"
        
        # 3. Finite values assertion
        spectrogram_np = spectrogram.numpy()
        assert np.all(np.isfinite(spectrogram_np)), \
            "Spectrogram contains non-finite values"
        
        # 4. Basic property assertions
        assert np.all(spectrogram_np >= 0), \
            "Spectrogram values should be non-negative"
        
        # For magnitude_squared=True, values should be squared
        if magnitude_squared:
            # Values should be positive (squared magnitudes)
            assert np.all(spectrogram_np >= 0), \
                "Squared magnitude spectrogram should have non-negative values"
        else:
            # Regular magnitude - still non-negative
            assert np.all(spectrogram_np >= 0), \
                "Magnitude spectrogram should have non-negative values"
        
        # Additional basic checks
        assert spectrogram_np.size > 0, "Spectrogram should not be empty"
        
        # Check that output has reasonable values (not all zeros unless input is zero)
        if np.any(audio != 0):
            assert np.any(spectrogram_np > 0), \
                "Spectrogram should have positive values for non-zero input"
        
        # Check shape consistency
        assert spectrogram_np.shape[0] == expected_channels, \
            f"Channel dimension mismatch: expected {expected_channels}, got {spectrogram_np.shape[0]}"
        
        assert spectrogram_np.shape[1] == num_windows, \
            f"Time dimension mismatch: expected {num_windows}, got {spectrogram_np.shape[1]}"
        
        assert spectrogram_np.shape[2] == expected_freq_bins, \
            f"Frequency dimension mismatch: expected {expected_freq_bins}, got {spectrogram_np.shape[2]}"
# ==== BLOCK:CASE_01 END ====

# ==== BLOCK:CASE_02 START ====
    @pytest.mark.parametrize("audio_shape,sample_rate,desired_channels,desired_samples,dtype", [
        ([44100, 2], 44100, -1, -1, "float32"),
        ([22050, 1], 22050, 2, 11025, "float32"),  # param_extension: 指定通道数和样本数测试
    ])
    def test_wav_encode_decode_roundtrip(self, audio_shape, sample_rate, desired_channels, desired_samples, dtype):
        """Test roundtrip consistency of encode_wav and decode_wav."""
        # Generate test audio data
        num_samples, num_channels = audio_shape
        audio = self.generate_random_audio(audio_shape)
        
        # Encode to WAV
        audio_tensor = tf.constant(audio, dtype=getattr(tf, dtype))
        sample_rate_tensor = tf.constant(sample_rate, dtype=tf.int32)
        
        wav_data = gen_audio_ops.encode_wav(audio_tensor, sample_rate_tensor)
        
        # Decode from WAV
        decoded = gen_audio_ops.decode_wav(
            contents=wav_data,
            desired_channels=desired_channels,
            desired_samples=desired_samples
        )
        
        decoded_audio, decoded_sample_rate = decoded
        
        # Weak assertions (round 1)
        # 1. Shape assertion
        if desired_samples == -1:
            expected_samples = num_samples
        else:
            expected_samples = min(desired_samples, num_samples)
        
        if desired_channels == -1:
            expected_channels = num_channels
        else:
            expected_channels = desired_channels
        
        assert decoded_audio.shape == (expected_samples, expected_channels), \
            f"Expected shape ({expected_samples}, {expected_channels}), got {decoded_audio.shape}"
        
        # 2. Dtype assertion
        assert decoded_audio.dtype == tf.float32, \
            f"Expected dtype float32, got {decoded_audio.dtype}"
        
        # 3. Sample rate assertion
        assert decoded_sample_rate == sample_rate, \
            f"Expected sample rate {sample_rate}, got {decoded_sample_rate}"
        
        # 4. Finite values assertion
        decoded_audio_np = decoded_audio.numpy()
        assert np.all(np.isfinite(decoded_audio_np)), \
            "Decoded audio contains non-finite values"
        
        # 5. Basic property assertions
        # Audio values should be in valid range [-1, 1] after decode
        assert np.all(decoded_audio_np >= -1.0) and np.all(decoded_audio_np <= 1.0), \
            f"Decoded audio values out of range [-1, 1]. Min: {np.min(decoded_audio_np)}, Max: {np.max(decoded_audio_np)}"
        
        # Check that we didn't lose all information
        assert decoded_audio_np.size > 0, "Decoded audio should not be empty"
        
        # For the case where desired_channels/desired_samples don't truncate,
        # we can check basic consistency
        if desired_channels == -1 and desired_samples == -1:
            # The audio should be similar (allowing for WAV encoding/decoding precision loss)
            # We'll do a weak check here - just ensure it's not completely different
            original_flat = audio.flatten()
            decoded_flat = decoded_audio_np.flatten()
            
            # Simple correlation check (weak)
            if len(original_flat) == len(decoded_flat):
                # Check that they're not completely uncorrelated
                correlation = np.corrcoef(original_flat, decoded_flat)[0, 1]
                assert not np.isnan(correlation), "Correlation is NaN"
                # Weak assertion: correlation should not be exactly 0 for non-zero input
                if np.any(original_flat != 0):
                    assert abs(correlation) > 0.01, \
                        f"Audio lost too much information in roundtrip. Correlation: {correlation}"
# ==== BLOCK:CASE_02 END ====

# ==== BLOCK:CASE_03 START ====
    @pytest.mark.parametrize("spectrogram_shape,sample_rate,upper_frequency_limit,lower_frequency_limit,filterbank_channel_count,dct_coefficient_count,dtype", [
        ([100, 257], 16000, 4000.0, 20.0, 40, 13, "float32"),
        ([50, 129], 8000, 2000.0, 100.0, 20, 20, "float32"),  # param_extension: 不同MFCC参数配置测试
    ])
    def test_mfcc_feature_extraction(self, spectrogram_shape, sample_rate, upper_frequency_limit, 
                                    lower_frequency_limit, filterbank_channel_count, 
                                    dct_coefficient_count, dtype):
        """Test MFCC feature extraction correctness."""
        # Generate random spectrogram data (magnitude squared as required)
        # mfcc expects 3D input: [channels, time, frequency]
        # We'll create a single channel spectrogram
        num_frames, num_freq_bins = spectrogram_shape
        num_channels = 1  # Single channel for simplicity
        
        # Create 3D spectrogram: [channels, time, frequency]
        spectrogram_3d = np.random.uniform(0.1, 10.0, (num_channels, num_frames, num_freq_bins)).astype(np.float32)
        
        # Convert to tensor
        spectrogram_tensor = tf.constant(spectrogram_3d, dtype=getattr(tf, dtype))
        sample_rate_tensor = tf.constant(sample_rate, dtype=tf.int32)
        
        # Call the MFCC function
        mfcc_features = gen_audio_ops.mfcc(
            spectrogram=spectrogram_tensor,
            sample_rate=sample_rate_tensor,
            upper_frequency_limit=upper_frequency_limit,
            lower_frequency_limit=lower_frequency_limit,
            filterbank_channel_count=filterbank_channel_count,
            dct_coefficient_count=dct_coefficient_count
        )
        
        # Weak assertions (round 1)
        # 1. Shape assertion
        # Based on execution logs, MFCC returns 3D tensor: [channels, time, dct_coefficients]
        # where channels dimension is preserved from input
        expected_shape = (num_channels, num_frames, dct_coefficient_count)
        assert mfcc_features.shape == expected_shape, \
            f"Expected shape {expected_shape}, got {mfcc_features.shape}"
        
        # 2. Dtype assertion
        assert mfcc_features.dtype == tf.float32, \
            f"Expected dtype float32, got {mfcc_features.dtype}"
        
        # 3. Finite values assertion
        mfcc_np = mfcc_features.numpy()
        assert np.all(np.isfinite(mfcc_np)), \
            "MFCC features contain non-finite values"
        
        # 4. Basic property assertions
        # MFCC features should have reasonable range
        # They can be positive or negative, but shouldn't be extreme
        mfcc_abs = np.abs(mfcc_np)
        assert np.all(mfcc_abs < 1e6), \
            f"MFCC values too large. Max absolute value: {np.max(mfcc_abs)}"
        
        # Check that output is not all zeros (unless input is pathological)
        assert np.any(mfcc_np != 0), \
            "MFCC features should not be all zeros for non-zero input"
        
        # Check that dimensions match expectations
        assert mfcc_np.shape[0] == num_channels, \
            f"Channel dimension mismatch: expected {num_channels}, got {mfcc_np.shape[0]}"
        
        assert mfcc_np.shape[1] == num_frames, \
            f"Time dimension mismatch: expected {num_frames}, got {mfcc_np.shape[1]}"
        
        assert mfcc_np.shape[2] == dct_coefficient_count, \
            f"DCT coefficient count mismatch: expected {dct_coefficient_count}, got {mfcc_np.shape[2]}"
        
        # Basic statistical properties
        mfcc_mean = np.mean(mfcc_np)
        mfcc_std = np.std(mfcc_np)
        
        # MFCC features often have mean around 0 (after mean normalization in some implementations)
        # This is a weak check - just ensure they're not extremely biased
        assert abs(mfcc_mean) < 100.0, \
            f"MFCC mean too large: {mfcc_mean}"
        
        # Standard deviation should be reasonable
        assert 0.1 < mfcc_std < 100.0, \
            f"MFCC standard deviation out of reasonable range: {mfcc_std}"
        
        # Check that different frames produce different features (not all identical)
        if num_frames > 1:
            first_frame = mfcc_np[0, 0, :]  # First channel, first frame
            second_frame = mfcc_np[0, 1, :]  # First channel, second frame
            frames_different = not np.allclose(first_frame, second_frame, rtol=1e-5, atol=1e-5)
            # This is a weak assertion - just log if they're identical
            if not frames_different:
                print(f"Warning: First two MFCC frames are identical for shape {spectrogram_shape}")
        
        # Parameter validation checks
        assert upper_frequency_limit > lower_frequency_limit, \
            f"Upper frequency limit ({upper_frequency_limit}) should be greater than lower limit ({lower_frequency_limit})"
        
        assert upper_frequency_limit <= sample_rate / 2, \
            f"Upper frequency limit ({upper_frequency_limit}) should be <= Nyquist frequency ({sample_rate / 2})"
        
        assert filterbank_channel_count > 0, \
            f"Filterbank channel count should be positive, got {filterbank_channel_count}"
        
        assert dct_coefficient_count > 0, \
            f"DCT coefficient count should be positive, got {dct_coefficient_count}"
        
        assert dct_coefficient_count <= filterbank_channel_count, \
            f"DCT coefficient count ({dct_coefficient_count}) should be <= filterbank channels ({filterbank_channel_count})"
        
        # Additional shape consistency checks
        assert mfcc_np.ndim == 3, f"MFCC should be 3D, got {mfcc_np.ndim}D"
        
        # Check that all values are finite (already done, but double-check)
        assert not np.any(np.isnan(mfcc_np)), "MFCC contains NaN values"
        assert not np.any(np.isinf(mfcc_np)), "MFCC contains infinite values"
# ==== BLOCK:CASE_03 END ====

# ==== BLOCK:CASE_04 START ====
    @pytest.mark.parametrize("input_shape,window_size,stride,magnitude_squared,dtype,test_type", [
        ([0, 1], 256, 128, False, "float32", "empty_input"),
        ([1, 1], 256, 128, False, "float32", "single_sample"),
        ([100, 2], 512, 512, True, "float32", "stride_equal_window"),
        ([1000, 1], 1024, 1000, False, "float32", "stride_larger_than_window"),
        ([500, 2], 63, 32, False, "float32", "non_power_of_two_window"),
    ])
    def test_audio_boundary_values(self, input_shape, window_size, stride, magnitude_squared, dtype, test_type):
        """Test boundary value handling for audio data."""
        num_samples, num_channels = input_shape
        
        if test_type == "empty_input":
            # Test empty audio input
            # Create empty 2D audio tensor: [0, channels]
            audio = np.zeros((num_samples, num_channels), dtype=np.float32)
            
            # Convert to tensor
            audio_tensor = tf.constant(audio, dtype=getattr(tf, dtype))
            
            # Call the function - empty input should be handled gracefully
            spectrogram = gen_audio_ops.audio_spectrogram(
                input=audio_tensor,
                window_size=window_size,
                stride=stride,
                magnitude_squared=magnitude_squared
            )
            
            # Weak assertions for empty input
            # 1. Shape assertion
            num_windows = max(0, (num_samples - window_size) // stride + 1)
            expected_channels = num_channels
            expected_freq_bins = window_size // 2 + 1
            
            assert spectrogram.shape == (expected_channels, num_windows, expected_freq_bins), \
                f"Expected shape ({expected_channels}, {num_windows}, {expected_freq_bins}), got {spectrogram.shape}"
            
            # 2. Dtype assertion
            assert spectrogram.dtype == tf.float32, \
                f"Expected dtype float32, got {spectrogram.dtype}"
            
            # 3. Check that output is empty (zero windows)
            spectrogram_np = spectrogram.numpy()
            assert spectrogram_np.size == 0, \
                f"Empty input should produce empty output, got size {spectrogram_np.size}"
            
            # 4. Basic property - empty tensor should be handled without error
            assert True, "Empty input handled without exception"
            
        elif test_type == "single_sample":
            # Test single sample audio
            audio = self.generate_edge_case_audio("single_sample", input_shape)
            
            # Convert to tensor
            audio_tensor = tf.constant(audio, dtype=getattr(tf, dtype))
            
            # Call the function
            spectrogram = gen_audio_ops.audio_spectrogram(
                input=audio_tensor,
                window_size=window_size,
                stride=stride,
                magnitude_squared=magnitude_squared
            )
            
            # Weak assertions
            # 1. Shape assertion
            num_windows = max(0, (num_samples - window_size) // stride + 1)
            expected_channels = num_channels
            expected_freq_bins = window_size // 2 + 1
            
            assert spectrogram.shape == (expected_channels, num_windows, expected_freq_bins), \
                f"Expected shape ({expected_channels}, {num_windows}, {expected_freq_bins}), got {spectrogram.shape}"
            
            # 2. Dtype assertion
            assert spectrogram.dtype == tf.float32, \
                f"Expected dtype float32, got {spectrogram.dtype}"
            
            # 3. Finite values assertion
            spectrogram_np = spectrogram.numpy()
            assert np.all(np.isfinite(spectrogram_np)), \
                "Spectrogram contains non-finite values"
            
            # 4. Basic property - single sample should produce valid output
            # For single sample with window_size > 1, num_windows should be 0
            if window_size > num_samples:
                assert spectrogram_np.size == 0, \
                    f"Window larger than input should produce empty output, got size {spectrogram_np.size}"
            else:
                assert spectrogram_np.size > 0, \
                    "Valid input should produce non-empty output"
            
        elif test_type == "stride_equal_window":
            # Test stride equal to window size
            audio = self.generate_random_audio(input_shape)
            
            # Convert to tensor
            audio_tensor = tf.constant(audio, dtype=getattr(tf, dtype))
            
            # Call the function
            spectrogram = gen_audio_ops.audio_spectrogram(
                input=audio_tensor,
                window_size=window_size,
                stride=stride,
                magnitude_squared=magnitude_squared
            )
            
            # Weak assertions
            # 1. Shape assertion
            num_windows = max(0, (num_samples - window_size) // stride + 1)
            expected_channels = num_channels
            expected_freq_bins = window_size // 2 + 1
            
            assert spectrogram.shape == (expected_channels, num_windows, expected_freq_bins), \
                f"Expected shape ({expected_channels}, {num_windows}, {expected_freq_bins}), got {spectrogram.shape}"
            
            # 2. Dtype assertion
            assert spectrogram.dtype == tf.float32, \
                f"Expected dtype float32, got {spectrogram.dtype}"
            
            # 3. Finite values assertion
            spectrogram_np = spectrogram.numpy()
            assert np.all(np.isfinite(spectrogram_np)), \
                "Spectrogram contains non-finite values"
            
            # 4. Basic property - non-negative values
            assert np.all(spectrogram_np >= 0), \
                "Spectrogram values should be non-negative"
            
            # Check that we have the expected number of windows
            # When stride == window_size, windows don't overlap
            expected_non_overlap_windows = num_samples // window_size
            assert spectrogram_np.shape[1] == expected_non_overlap_windows, \
                f"Expected {expected_non_overlap_windows} non-overlapping windows, got {spectrogram_np.shape[1]}"
            
        elif test_type == "stride_larger_than_window":
            # Test stride larger than window size
            audio = self.generate_random_audio(input_shape)
            
            # Convert to tensor
            audio_tensor = tf.constant(audio, dtype=getattr(tf, dtype))
            
            # Call the function
            spectrogram = gen_audio_ops.audio_spectrogram(
                input=audio_tensor,
                window_size=window_size,
                stride=stride,
                magnitude_squared=magnitude_squared
            )
            
            # Weak assertions
            # 1. Shape assertion
            num_windows = max(0, (num_samples - window_size) // stride + 1)
            expected_channels = num_channels
            expected_freq_bins = window_size // 2 + 1
            
            assert spectrogram.shape == (expected_channels, num_windows, expected_freq_bins), \
                f"Expected shape ({expected_channels}, {num_windows}, {expected_freq_bins}), got {spectrogram.shape}"
            
            # 2. Dtype assertion
            assert spectrogram.dtype == tf.float32, \
                f"Expected dtype float32, got {spectrogram.dtype}"
            
            # 3. Finite values assertion
            spectrogram_np = spectrogram.numpy()
            assert np.all(np.isfinite(spectrogram_np)), \
                "Spectrogram contains non-finite values"
            
            # 4. Basic property - when stride > window_size, windows have gaps
            # This is valid, just ensure output is valid
            assert True, "Stride larger than window size handled correctly"
            
        elif test_type == "non_power_of_two_window":
            # Test non-power-of-two window size
            audio = self.generate_random_audio(input_shape)
            
            # Convert to tensor
            audio_tensor = tf.constant(audio, dtype=getattr(tf, dtype))
            
            # Call the function - non-power-of-two should still work
            spectrogram = gen_audio_ops.audio_spectrogram(
                input=audio_tensor,
                window_size=window_size,
                stride=stride,
                magnitude_squared=magnitude_squared
            )
            
            # Weak assertions
            # 1. Shape assertion
            num_windows = max(0, (num_samples - window_size) // stride + 1)
            expected_channels = num_channels
            expected_freq_bins = window_size // 2 + 1
            
            assert spectrogram.shape == (expected_channels, num_windows, expected_freq_bins), \
                f"Expected shape ({expected_channels}, {num_windows}, {expected_freq_bins}), got {spectrogram.shape}"
            
            # 2. Dtype assertion
            assert spectrogram.dtype == tf.float32, \
                f"Expected dtype float32, got {spectrogram.dtype}"
            
            # 3. Finite values assertion
            spectrogram_np = spectrogram.numpy()
            assert np.all(np.isfinite(spectrogram_np)), \
                "Spectrogram contains non-finite values"
            
            # 4. Basic property - non-power-of-two window should still produce valid output
            assert spectrogram_np.size > 0, \
                "Non-power-of-two window should produce non-empty output"
            
            # Check frequency bins calculation
            # For window_size=63, expected_freq_bins should be 32 (63//2 + 1 = 31 + 1 = 32)
            assert spectrogram_np.shape[2] == expected_freq_bins, \
                f"Expected {expected_freq_bins} frequency bins for window_size={window_size}, got {spectrogram_np.shape[2]}"
            
        else:
            # For future test types
            pytest.skip(f"Test type {test_type} not implemented yet")
# ==== BLOCK:CASE_04 END ====

# ==== BLOCK:CASE_05 START ====
    @pytest.mark.parametrize("input_shape,window_size,stride,magnitude_squared,dtype,test_type", [
        ([16000, 1], 512, 256, False, "float64", "wrong_dtype"),
    ])
    def test_data_type_and_shape_error_handling(self, input_shape, window_size, stride, magnitude_squared, dtype, test_type):
        """Test error handling for data type and shape issues."""
        num_samples, num_channels = input_shape
        
        if test_type == "wrong_dtype":
            # Test with wrong dtype (float64 instead of float32)
            # audio_spectrogram expects float32 input
            audio = np.random.uniform(-1.0, 1.0, input_shape).astype(np.float64)
            
            # Convert to tensor with wrong dtype
            audio_tensor = tf.constant(audio, dtype=getattr(tf, dtype))
            
            # Weak assertions: exception handling
            # audio_spectrogram should raise an error for non-float32 input
            # Note: TensorFlow ops often have type checking, but the exact error
            # might vary. We'll check that some error is raised.
            with pytest.raises(Exception) as exc_info:
                gen_audio_ops.audio_spectrogram(
                    input=audio_tensor,
                    window_size=window_size,
                    stride=stride,
                    magnitude_squared=magnitude_squared
                )
            
            # Check that an error was raised
            assert exc_info.value is not None, \
                "Expected exception for wrong dtype input"
            
            # Check error type - could be TypeError, ValueError, or tf.errors.InvalidArgumentError
            error_msg = str(exc_info.value).lower()
            
            # Common error messages for dtype mismatch in TensorFlow
            # Based on actual error: "cannot compute audiospectrogram as input #0(zero-based) was expected to be a float tensor but is a double tensor"
            # We need to be more flexible in checking error messages
            dtype_error_keywords = [
                "dtype", "type", "float", "double", "tensor", 
                "expected", "but is", "invalid", "unsupported", 
                "not supported", "must be", "cannot compute"
            ]
            
            # Check if error message contains any dtype-related keywords
            # Use a more lenient check - at least one keyword should match
            has_dtype_error = any(keyword in error_msg for keyword in dtype_error_keywords)
            
            # Also check for specific patterns seen in actual error
            has_float_double_pattern = "float" in error_msg and "double" in error_msg
            has_expected_but_pattern = "expected" in error_msg and "but" in error_msg
            
            # Accept if any of these conditions is true
            assert has_dtype_error or has_float_double_pattern or has_expected_but_pattern, \
                f"Error message should mention dtype/tensor type issue. Got: {error_msg}"
            
            # Additional weak assertions
            # 1. Exception handling - passed (we caught an exception)
            assert True, "Exception handling test passed"
            
            # 2. Error type - we verified it's some kind of exception
            assert True, "Error type verification passed"
            
        else:
            # For future test types
            pytest.skip(f"Test type {test_type} not implemented yet")
        
        # Additional test cases that could be added in future rounds:
        # - Test with invalid window_size (negative or zero)
        # - Test with invalid stride (negative or zero)
        # - Test with window_size > input length
        # - Test with non-2D input
        # - Test with wrong shape dimensions
# ==== BLOCK:CASE_05 END ====

# ==== BLOCK:FOOTER START ====
# Close the TestGenAudioOps class
# Additional test functions and cleanup
if __name__ == "__main__":
    pytest.main([__file__, "-v"])
# ==== BLOCK:FOOTER END ====