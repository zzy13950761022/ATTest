"""
Test cases for tensorflow.python.ops.image_ops_impl module.
Generated by ATTest-CLI.
"""

import math
import numpy as np
import pytest
import tensorflow as tf
from tensorflow.python.ops import image_ops_impl

# ==== BLOCK:HEADER START ====
# Test fixtures and helper functions
@pytest.fixture
def set_random_seed():
    """Set random seeds for reproducibility."""
    np.random.seed(42)
    tf.random.set_seed(42)
    return 42

def assert_tensor_shape(tensor, expected_shape):
    """Assert tensor shape matches expected shape."""
    assert tensor.shape == expected_shape, f"Expected shape {expected_shape}, got {tensor.shape}"

def assert_tensor_dtype(tensor, expected_dtype):
    """Assert tensor dtype matches expected dtype."""
    assert tensor.dtype == expected_dtype, f"Expected dtype {expected_dtype}, got {tensor.dtype}"

def assert_tensor_finite(tensor):
    """Assert tensor contains only finite values."""
    # For floating point types, check for finite values
    if tensor.dtype.is_floating:
        assert tf.reduce_all(tf.math.is_finite(tensor)), "Tensor contains non-finite values"
    # For integer types, just check that tensor is not None and has valid shape
    else:
        assert tensor is not None, "Tensor is None"
        assert len(tensor.shape) > 0, "Tensor has empty shape"

def assert_basic_property(tensor, original_tensor=None):
    """Basic property assertions for image operations."""
    # Check tensor is not None
    assert tensor is not None
    # Check shape is valid
    assert len(tensor.shape) >= 3, f"Tensor should have at least 3 dimensions, got {len(tensor.shape)}"
    # If original tensor provided, check shape compatibility
    if original_tensor is not None:
        assert len(tensor.shape) == len(original_tensor.shape), \
            f"Rank mismatch: {len(tensor.shape)} vs {len(original_tensor.shape)}"
# ==== BLOCK:HEADER END ====

# ==== BLOCK:CASE_01 START ====
# TC-01: adjust_brightness 基本亮度调整
# Priority: High
# Assertion level: strong (approx_equal, brightness_correctness, range_check)

@pytest.mark.parametrize("dtype,shape,delta", [
    (tf.float32, (32, 32, 3), 0.2),  # Base case from test plan
    (tf.uint8, (64, 64, 3), -0.1),   # Parameter extension: uint8 with negative delta
    (tf.float32, (1, 32, 32, 3), 0.5),  # Parameter extension: batch image
])
def test_adjust_brightness_basic(set_random_seed, dtype, shape, delta):
    """Test basic brightness adjustment functionality."""
    # Create test image
    if dtype == tf.uint8:
        # For uint8, create values in [0, 255] range
        image = tf.constant(np.random.randint(0, 256, size=shape, dtype=np.uint8), dtype=dtype)
    else:
        # For float32, create values in [0, 1] range
        image = tf.constant(np.random.uniform(0, 1, size=shape).astype(np.float32), dtype=dtype)
    
    # Apply brightness adjustment
    result = image_ops_impl.adjust_brightness(image, delta)
    
    # Weak assertions (still needed)
    assert_tensor_shape(result, shape)
    assert_tensor_dtype(result, dtype)
    assert_tensor_finite(result)
    assert_basic_property(result, image)
    
    # Additional basic property: result should have same rank as input
    assert len(result.shape) == len(image.shape), \
        f"Rank mismatch: {len(result.shape)} vs {len(image.shape)}"
    
    # STRONG ASSERTIONS
    
    # 1. approx_equal: For float32, check that result ≈ image + delta
    if dtype == tf.float32:
        # For float images, brightness adjustment should be: result = image + delta
        # But note: adjust_brightness clips values to [0, 1] range
        expected = image + delta
        # Clip to [0, 1] range as per TensorFlow implementation
        expected = tf.clip_by_value(expected, 0.0, 1.0)
        
        # Check approximate equality with tolerance
        diff = tf.abs(result - expected)
        max_diff = tf.reduce_max(diff).numpy()
        assert max_diff < 1e-6, f"Result not approximately equal to expected: max_diff={max_diff}"
    
    # 2. brightness_correctness: Check brightness adjustment logic
    # For uint8 images, brightness adjustment works differently
    if dtype == tf.uint8:
        # Convert to float for calculation
        image_float = tf.cast(image, tf.float32)
        result_float = tf.cast(result, tf.float32)
        
        # Expected: result_float = image_float + delta * 255.0 (clipped to [0, 255])
        # Then converted back to uint8
        expected_float = image_float + delta * 255.0
        expected_float = tf.clip_by_value(expected_float, 0.0, 255.0)
        
        # Check approximate equality
        diff = tf.abs(result_float - expected_float)
        max_diff = tf.reduce_max(diff).numpy()
        # Allow larger tolerance for uint8 conversion rounding
        assert max_diff < 1.0, f"Brightness adjustment incorrect for uint8: max_diff={max_diff}"
    
    # 3. range_check: Check values are in valid range
    if dtype == tf.float32:
        # For float images, values should be in [0, 1] after clipping
        min_val = tf.reduce_min(result).numpy()
        max_val = tf.reduce_max(result).numpy()
        assert min_val >= -1e-6 and max_val <= 1.0 + 1e-6, \
            f"float32 values out of range [0, 1]: min={min_val}, max={max_val}"
    elif dtype == tf.uint8:
        # For uint8 images, values should be in [0, 255] range
        min_val = tf.reduce_min(result).numpy()
        max_val = tf.reduce_max(result).numpy()
        assert min_val >= 0 and max_val <= 255, \
            f"uint8 values out of range: min={min_val}, max={max_val}"
    
    # Additional strong assertion: test with known values
    if dtype == tf.float32 and shape == (32, 32, 3):
        # Create a simple test case with known values
        test_image = tf.constant(0.5, shape=(1, 1, 3), dtype=tf.float32)
        test_delta = 0.3
        test_result = image_ops_impl.adjust_brightness(test_image, test_delta)
        
        # Expected: 0.5 + 0.3 = 0.8
        expected_value = 0.8
        actual_value = test_result[0, 0, 0].numpy()
        assert abs(actual_value - expected_value) < 1e-6, \
            f"Known value test failed: {actual_value} != {expected_value}"
        
        # Test negative delta
        test_delta_neg = -0.4
        test_result_neg = image_ops_impl.adjust_brightness(test_image, test_delta_neg)
        
        # Expected: 0.5 - 0.4 = 0.1
        expected_value_neg = 0.1
        actual_value_neg = test_result_neg[0, 0, 0].numpy()
        assert abs(actual_value_neg - expected_value_neg) < 1e-6, \
            f"Negative delta test failed: {actual_value_neg} != {expected_value_neg}"
# ==== BLOCK:CASE_01 END ====

# ==== BLOCK:CASE_02 START ====
# TC-02: random_flip_left_right 随机水平翻转
# Priority: High
# Assertion level: strong (flip_correctness, seed_consistency, randomness_check)

@pytest.mark.parametrize("dtype,shape,seed", [
    (tf.uint8, (4, 64, 64, 3), 42),  # Base case from test plan
    (tf.float32, (32, 32, 1), None),  # Parameter extension: grayscale with None seed
])
def test_random_flip_left_right_basic(set_random_seed, dtype, shape, seed):
    """Test random horizontal flip functionality."""
    # Create test image
    if dtype == tf.uint8:
        image = tf.constant(np.random.randint(0, 256, size=shape, dtype=np.uint8), dtype=dtype)
    else:
        image = tf.constant(np.random.uniform(0, 1, size=shape).astype(np.float32), dtype=dtype)
    
    # Apply random flip
    result = image_ops_impl.random_flip_left_right(image, seed=seed)
    
    # Weak assertions (still needed)
    assert_tensor_shape(result, shape)
    assert_tensor_dtype(result, dtype)
    assert_tensor_finite(result)
    assert_basic_property(result, image)
    
    # Additional basic property: result should have same dimensions as input
    for i in range(len(shape)):
        assert result.shape[i] == image.shape[i], \
            f"Dimension {i} mismatch: {result.shape[i]} vs {image.shape[i]}"
    
    # Basic property: check value ranges based on dtype
    if dtype == tf.uint8:
        # For uint8 images, values should be in [0, 255] range
        min_val = tf.reduce_min(result).numpy()
        max_val = tf.reduce_max(result).numpy()
        assert min_val >= 0 and max_val <= 255, \
            f"uint8 values out of range: min={min_val}, max={max_val}"
    
    # STRONG ASSERTIONS
    
    # 1. flip_correctness: Check that flip operation is correct when it happens
    # To test flip correctness, we need to know if the image was actually flipped
    # We can test by comparing with manual flip operation
    
    # Create a simple test pattern to detect flipping
    if shape == (4, 64, 64, 3) or shape == (32, 32, 1):
        # Create an asymmetric test image
        test_shape = (1, 5, 5, 3) if len(shape) == 4 else (5, 5, 1)
        test_image = tf.zeros(test_shape, dtype=dtype)
        
        # Put a distinctive pattern on the left side
        if len(test_shape) == 4:
            test_image = tf.tensor_scatter_nd_update(
                test_image, 
                [[0, 0, 0, 0], [0, 0, 1, 0], [0, 0, 2, 0]],
                [1.0, 1.0, 1.0] if dtype == tf.float32 else [255, 255, 255]
            )
        else:
            test_image = tf.tensor_scatter_nd_update(
                test_image,
                [[0, 0, 0], [0, 1, 0], [0, 2, 0]],
                [1.0] if dtype == tf.float32 else [255]
            )
        
        # Apply flip with fixed seed to get deterministic result
        test_result = image_ops_impl.random_flip_left_right(test_image, seed=123)
        
        # Manually flip the image for comparison
        manual_flip = tf.image.flip_left_right(test_image)
        
        # Check if result matches either original or flipped version
        # This tests that the flip operation is correct when applied
        diff_original = tf.reduce_sum(tf.abs(test_result - test_image)).numpy()
        diff_flipped = tf.reduce_sum(tf.abs(test_result - manual_flip)).numpy()
        
        # The result should be either the original or the flipped version
        assert diff_original < 1e-6 or diff_flipped < 1e-6, \
            f"Flip operation incorrect: diff_original={diff_original}, diff_flipped={diff_flipped}"
    
    # 2. seed_consistency: With same seed, same image should get same flip decision
    if seed is not None:
        # Reset seeds
        tf.random.set_seed(seed)
        np.random.seed(seed)
        
        # Create two identical images
        if dtype == tf.uint8:
            image1 = tf.constant(np.random.randint(0, 256, size=shape, dtype=np.uint8), dtype=dtype)
            image2 = tf.constant(np.random.randint(0, 256, size=shape, dtype=np.uint8), dtype=dtype)
        else:
            image1 = tf.constant(np.random.uniform(0, 1, size=shape).astype(np.float32), dtype=dtype)
            image2 = tf.constant(np.random.uniform(0, 1, size=shape).astype(np.float32), dtype=dtype)
        
        # Apply flip with same seed
        result1 = image_ops_impl.random_flip_left_right(image1, seed=seed)
        result2 = image_ops_impl.random_flip_left_right(image2, seed=seed)
        
        # Check if flip decision was the same by comparing patterns
        # We can't compare values directly since images are different,
        # but we can check if the relative differences are consistent
        
        # Create a simple metric: check if left-right asymmetry changed similarly
        if len(shape) >= 3:
            # Compare left half vs right half
            width = shape[-2] if len(shape) == 4 else shape[-3]
            mid = width // 2
            
            if len(shape) == 4:  # batch format
                left1 = image1[:, :, :mid, :]
                right1 = image1[:, :, -mid:, :]
                left2 = image2[:, :, :mid, :]
                right2 = image2[:, :, -mid:, :]
                
                left_r1 = result1[:, :, :mid, :]
                right_r1 = result1[:, :, -mid:, :]
                left_r2 = result2[:, :, :mid, :]
                right_r2 = result2[:, :, -mid:, :]
            else:  # non-batch format
                left1 = image1[:, :mid, :]
                right1 = image1[:, -mid:, :]
                left2 = image2[:, :mid, :]
                right2 = image2[:, -mid:, :]
                
                left_r1 = result1[:, :mid, :]
                right_r1 = result1[:, -mid:, :]
                left_r2 = result2[:, :mid, :]
                right_r2 = result2[:, -mid:, :]
            
            # Calculate asymmetry changes
            asym_change1 = tf.reduce_mean(tf.abs(left_r1 - right1) + tf.abs(right_r1 - left1)).numpy()
            asym_change2 = tf.reduce_mean(tf.abs(left_r2 - right2) + tf.abs(right_r2 - left2)).numpy()
            
            # With same seed, both should either flip or not flip
            # So asymmetry changes should be similar (both high if flipped, both low if not)
            assert abs(asym_change1 - asym_change2) < 0.1, \
                f"Seed consistency failed: asym_change1={asym_change1}, asym_change2={asym_change2}"
    
    # 3. randomness_check: With None seed or different seeds, results should vary
    # Test that with different seeds, we get different flip decisions over multiple trials
    if seed is None or shape == (32, 32, 1):  # Test with grayscale case
        # Create a simple test image
        test_shape = (1, 10, 10, 3) if len(shape) == 4 else (10, 10, 1)
        test_image = tf.zeros(test_shape, dtype=dtype)
        
        # Make it asymmetric
        if len(test_shape) == 4:
            test_image = tf.tensor_scatter_nd_update(
                test_image,
                [[0, 0, 0, 0], [0, 0, 9, 0]],
                [1.0, 0.5] if dtype == tf.float32 else [255, 128]
            )
        else:
            test_image = tf.tensor_scatter_nd_update(
                test_image,
                [[0, 0, 0], [0, 9, 0]],
                [1.0] if dtype == tf.float32 else [255]
            )
        
        # Test multiple times with different seeds
        results = []
        for i in range(5):
            result_i = image_ops_impl.random_flip_left_right(test_image, seed=1000 + i)
            results.append(result_i)
        
        # Check that not all results are identical (some randomness)
        all_same = True
        for i in range(1, len(results)):
            if tf.reduce_sum(tf.abs(results[i] - results[0])).numpy() > 1e-6:
                all_same = False
                break
        
        # With different seeds, we should see some variation
        # (Note: it's possible but unlikely that all 5 random decisions are the same)
        if not all_same:
            # Good, we have randomness
            pass
        else:
            # Check if this is the grayscale case with None seed
            # For None seed, TensorFlow uses random seed, so results should differ
            if seed is None:
                # Try a few more times
                more_results = []
                for i in range(10):
                    result_i = image_ops_impl.random_flip_left_right(test_image, seed=None)
                    more_results.append(result_i)
                
                # Check for variation
                varied = False
                for i in range(1, len(more_results)):
                    if tf.reduce_sum(tf.abs(more_results[i] - more_results[0])).numpy() > 1e-6:
                        varied = True
                        break
                
                # With None seed, we expect some variation
                # But it's not guaranteed in a small sample, so we just log
                if not varied:
                    print(f"Warning: No variation in random flips with None seed for shape {shape}")
    
    # Additional strong assertion: test with known seed
    if seed == 42:
        # Create a simple test to verify deterministic behavior
        simple_shape = (1, 3, 3, 1) if len(shape) == 4 else (3, 3, 1)
        simple_image = tf.constant([
            [[1], [2], [3]],
            [[4], [5], [6]],
            [[7], [8], [9]]
        ], dtype=dtype)
        
        if len(shape) == 4:
            simple_image = tf.expand_dims(simple_image, 0)
        
        # Apply with seed 42
        result_simple = image_ops_impl.random_flip_left_right(simple_image, seed=42)
        
        # Apply again with same seed
        result_simple2 = image_ops_impl.random_flip_left_right(simple_image, seed=42)
        
        # Results should be identical
        diff = tf.reduce_sum(tf.abs(result_simple - result_simple2)).numpy()
        assert diff < 1e-6, f"Deterministic seed failed: diff={diff}"
# ==== BLOCK:CASE_02 END ====

# ==== BLOCK:CASE_03 START ====
# TC-03: central_crop 中心裁剪
# Priority: High
# Assertion level: strong (crop_correctness, center_alignment, content_preservation)

@pytest.mark.parametrize("dtype,shape,central_fraction", [
    (tf.float32, (128, 128, 3), 0.5),  # Base case from test plan
    (tf.float32, (100, 150, 3), 0.8),  # Parameter extension: non-square image with large fraction
])
def test_central_crop_basic(set_random_seed, dtype, shape, central_fraction):
    """Test central crop functionality."""
    # Create test image
    image = tf.constant(np.random.uniform(0, 1, size=shape).astype(np.float32), dtype=dtype)
    
    # Apply central crop
    result = image_ops_impl.central_crop(image, central_fraction)
    
    # Calculate expected shape after crop
    height, width = shape[0], shape[1]
    expected_height = int(height * central_fraction)
    expected_width = int(width * central_fraction)
    expected_shape = (expected_height, expected_width) + shape[2:]
    
    # Weak assertions (still needed)
    assert_tensor_shape(result, expected_shape)
    assert_tensor_dtype(result, dtype)
    assert_tensor_finite(result)
    assert_basic_property(result)
    
    # Additional basic property: cropped dimensions should be smaller or equal
    assert result.shape[0] <= image.shape[0], \
        f"Cropped height {result.shape[0]} should be <= original {image.shape[0]}"
    assert result.shape[1] <= image.shape[1], \
        f"Cropped width {result.shape[1]} should be <= original {image.shape[1]}"
    
    # Basic property: depth/channels should remain unchanged
    if len(shape) == 3:
        assert result.shape[2] == image.shape[2], \
            f"Channels mismatch: {result.shape[2]} vs {image.shape[2]}"
    elif len(shape) == 4:
        assert result.shape[0] == image.shape[0], \
            f"Batch size mismatch: {result.shape[0]} vs {image.shape[0]}"
        assert result.shape[3] == image.shape[3], \
            f"Channels mismatch: {result.shape[3]} vs {image.shape[3]}"
    
    # STRONG ASSERTIONS
    
    # 1. crop_correctness: Verify the crop is taken from the correct region
    # For central crop, we should take the center region of the image
    
    # Calculate crop boundaries
    start_h = (height - expected_height) // 2
    start_w = (width - expected_width) // 2
    end_h = start_h + expected_height
    end_w = start_w + expected_width
    
    # Extract the expected center region manually
    if len(shape) == 3:
        expected_center = image[start_h:end_h, start_w:end_w, :]
    else:  # shape[0] is batch dimension
        expected_center = image[:, start_h:end_h, start_w:end_w, :]
    
    # Check that result matches the center region
    diff = tf.reduce_max(tf.abs(result - expected_center)).numpy()
    assert diff < 1e-6, f"Crop correctness failed: max_diff={diff}"
    
    # 2. center_alignment: Verify the crop is centered correctly
    # The crop should be symmetric around the center when possible
    
    # Check that start positions are as centered as possible
    # For even dimensions, there might be a 1-pixel offset, which is fine
    expected_start_h = (height - expected_height) // 2
    expected_start_w = (width - expected_width) // 2
    
    # The alternative start position would be one pixel different
    alt_start_h = (height - expected_height + 1) // 2
    alt_start_w = (width - expected_width + 1) // 2
    
    # Check that we're using one of the centered options
    assert start_h == expected_start_h or start_h == alt_start_h, \
        f"Height not centered: start_h={start_h}, expected={expected_start_h} or {alt_start_h}"
    assert start_w == expected_start_w or start_w == alt_start_w, \
        f"Width not centered: start_w={start_w}, expected={expected_start_w} or {alt_start_w}"
    
    # Additional check: the leftover pixels should be distributed as evenly as possible
    leftover_h = height - expected_height
    leftover_w = width - expected_width
    
    top_pixels = start_h
    bottom_pixels = height - end_h
    left_pixels = start_w
    right_pixels = width - end_w
    
    # The difference between top/bottom and left/right should be at most 1
    assert abs(top_pixels - bottom_pixels) <= 1, \
        f"Vertical centering uneven: top={top_pixels}, bottom={bottom_pixels}"
    assert abs(left_pixels - right_pixels) <= 1, \
        f"Horizontal centering uneven: left={left_pixels}, right={right_pixels}"
    
    # 3. content_preservation: Verify content is preserved in the crop
    # Create an image with distinctive patterns to verify content preservation
    
    if shape == (128, 128, 3) or shape == (100, 150, 3):
        # Create a test image with grid pattern
        test_shape = shape
        test_image = tf.zeros(test_shape, dtype=dtype)
        
        # Add distinctive markers at center and corners
        center_h, center_w = height // 2, width // 2
        
        if len(shape) == 3:
            # Mark center
            test_image = tf.tensor_scatter_nd_update(
                test_image,
                [[center_h, center_w, 0]],
                [1.0]
            )
            
            # Mark expected crop corners
            crop_h, crop_w = expected_height, expected_width
            crop_start_h, crop_start_w = start_h, start_w
            crop_end_h, crop_end_w = end_h - 1, end_w - 1
            
            # Mark crop corners (use different channels)
            test_image = tf.tensor_scatter_nd_update(
                test_image,
                [[crop_start_h, crop_start_w, 1],  # top-left
                 [crop_start_h, crop_end_w, 1],    # top-right
                 [crop_end_h, crop_start_w, 2],    # bottom-left
                 [crop_end_h, crop_end_w, 2]],     # bottom-right
                [1.0, 1.0, 1.0, 1.0]
            )
        else:  # batch format
            # Similar logic for batch format
            pass
        
        # Apply crop
        test_result = image_ops_impl.central_crop(test_image, central_fraction)
        
        # Check that center marker is in the cropped result
        # In the cropped image, the center should be at (crop_h//2, crop_w//2)
        crop_center_h, crop_center_w = expected_height // 2, expected_width // 2
        
        if len(shape) == 3:
            center_value = test_result[crop_center_h, crop_center_w, 0].numpy()
            assert center_value == 1.0, f"Center not preserved: {center_value}"
            
            # Check that crop corners are at the edges of the result
            # Top-left should be at (0, 0) in result
            tl_value = test_result[0, 0, 1].numpy()
            assert tl_value == 1.0, f"Top-left not preserved: {tl_value}"
            
            # Top-right should be at (0, crop_w-1)
            tr_value = test_result[0, expected_width - 1, 1].numpy()
            assert tr_value == 1.0, f"Top-right not preserved: {tr_value}"
            
            # Bottom-left should be at (crop_h-1, 0)
            bl_value = test_result[expected_height - 1, 0, 2].numpy()
            assert bl_value == 1.0, f"Bottom-left not preserved: {bl_value}"
            
            # Bottom-right should be at (crop_h-1, crop_w-1)
            br_value = test_result[expected_height - 1, expected_width - 1, 2].numpy()
            assert br_value == 1.0, f"Bottom-right not preserved: {br_value}"
    
    # Additional strong assertion: test with known values
    if shape == (128, 128, 3) and central_fraction == 0.5:
        # Create a simple test pattern
        simple_image = tf.ones((6, 6, 1), dtype=dtype)
        
        # Put distinctive values
        for i in range(6):
            for j in range(6):
                simple_image = tf.tensor_scatter_nd_update(
                    simple_image,
                    [[i, j, 0]],
                    [float(i * 6 + j)]
                )
        
        # Apply 0.5 crop (should get 3x3 center)
        simple_result = image_ops_impl.central_crop(simple_image, 0.5)
        
        # Expected center: rows 1-3, cols 1-3
        # Values: (1*6+1)=7, (1*6+2)=8, (1*6+3)=9
        #         (2*6+1)=13, (2*6+2)=14, (2*6+3)=15
        #         (3*6+1)=19, (3*6+2)=20, (3*6+3)=21
        expected_values = [[7.0, 8.0, 9.0],
                          [13.0, 14.0, 15.0],
                          [19.0, 20.0, 21.0]]
        
        # Check each value
        for i in range(3):
            for j in range(3):
                actual = simple_result[i, j, 0].numpy()
                expected = expected_values[i][j]
                assert abs(actual - expected) < 1e-6, \
                    f"Known value test failed at ({i},{j}): {actual} != {expected}"
# ==== BLOCK:CASE_03 END ====

# ==== BLOCK:CASE_04 START ====
# TC-04: rgb_to_yuv 颜色空间转换
# Priority: High
# Assertion level: strong (color_conversion_accuracy, roundtrip_consistency, range_check)

@pytest.mark.parametrize("dtype,shape", [
    (tf.float32, (16, 16, 3)),  # Base case from test plan
    (tf.uint8, (4, 48, 48, 3)),  # Parameter extension: batch uint8 images
])
def test_rgb_to_yuv_basic(set_random_seed, dtype, shape):
    """Test RGB to YUV color space conversion functionality."""
    # Create test RGB image
    if dtype == tf.uint8:
        # For uint8, create values in [0, 255] range
        # Note: rgb_to_yuv expects values in [0, 1] range, so we'll convert
        image = tf.constant(np.random.randint(0, 256, size=shape, dtype=np.uint8), dtype=dtype)
        # Convert to float32 in [0, 1] range as required by rgb_to_yuv
        image_float = tf.cast(image, tf.float32) / 255.0
    else:
        # For float32, create values in [0, 1] range as required
        image_float = tf.constant(np.random.uniform(0, 1, size=shape).astype(np.float32), dtype=dtype)
    
    # Apply RGB to YUV conversion
    result = image_ops_impl.rgb_to_yuv(image_float)
    
    # Weak assertions (still needed)
    assert_tensor_shape(result, shape)
    # rgb_to_yuv returns float32 regardless of input dtype
    assert_tensor_dtype(result, tf.float32)
    assert_tensor_finite(result)
    assert_basic_property(result, image_float)
    
    # Additional basic property: result should have same rank as input
    assert len(result.shape) == len(image_float.shape), \
        f"Rank mismatch: {len(result.shape)} vs {len(image_float.shape)}"
    
    # Basic property: check that last dimension is 3 (YUV channels)
    assert result.shape[-1] == 3, \
        f"Last dimension should be 3 for YUV, got {result.shape[-1]}"
    
    # STRONG ASSERTIONS
    
    # 1. color_conversion_accuracy: Test with known RGB values
    # Simple test case: pure red [1.0, 0.0, 0.0]
    if dtype == tf.float32 and shape == (16, 16, 3):
        # Create a simple test case
        red_image = tf.ones((1, 1, 3), dtype=tf.float32)
        red_image = red_image * tf.constant([1.0, 0.0, 0.0], dtype=tf.float32)
        
        red_yuv = image_ops_impl.rgb_to_yuv(red_image)
        
        # Standard conversion coefficients (ITU-R BT.601)
        # Y = 0.299*R + 0.587*G + 0.114*B = 0.299 for pure red
        expected_y = 0.299
        # U = -0.14713*R - 0.28886*G + 0.436*B = -0.14713 for pure red
        expected_u = -0.14713
        # V = 0.615*R - 0.51499*G - 0.10001*B = 0.615 for pure red
        expected_v = 0.615
        
        # Check with increased tolerance (1e-4) to handle TensorFlow implementation differences
        y_val = red_yuv[0, 0, 0].numpy()
        u_val = red_yuv[0, 0, 1].numpy()
        v_val = red_yuv[0, 0, 2].numpy()
        
        assert abs(y_val - expected_y) < 1e-4, \
            f"Y value incorrect: {y_val} vs {expected_y}"
        assert abs(u_val - expected_u) < 1e-4, \
            f"U value incorrect: {u_val} vs {expected_u}"
        assert abs(v_val - expected_v) < 1e-4, \
            f"V value incorrect: {v_val} vs {expected_v}"
        
        # Also test pure green [0.0, 1.0, 0.0]
        green_image = tf.ones((1, 1, 3), dtype=tf.float32)
        green_image = green_image * tf.constant([0.0, 1.0, 0.0], dtype=tf.float32)
        
        green_yuv = image_ops_impl.rgb_to_yuv(green_image)
        
        # Y = 0.299*R + 0.587*G + 0.114*B = 0.587 for pure green
        expected_y_green = 0.587
        # U = -0.14713*R - 0.28886*G + 0.436*B = -0.28886 for pure green
        expected_u_green = -0.28886
        # V = 0.615*R - 0.51499*G - 0.10001*B = -0.51499 for pure green
        expected_v_green = -0.51499
        
        y_val_g = green_yuv[0, 0, 0].numpy()
        u_val_g = green_yuv[0, 0, 1].numpy()
        v_val_g = green_yuv[0, 0, 2].numpy()
        
        assert abs(y_val_g - expected_y_green) < 1e-4, \
            f"Y value incorrect for green: {y_val_g} vs {expected_y_green}"
        assert abs(u_val_g - expected_u_green) < 1e-4, \
            f"U value incorrect for green: {u_val_g} vs {expected_u_green}"
        assert abs(v_val_g - expected_v_green) < 1e-4, \
            f"V value incorrect for green: {v_val_g} vs {expected_v_green}"
        
        # Test pure blue [0.0, 0.0, 1.0]
        blue_image = tf.ones((1, 1, 3), dtype=tf.float32)
        blue_image = blue_image * tf.constant([0.0, 0.0, 1.0], dtype=tf.float32)
        
        blue_yuv = image_ops_impl.rgb_to_yuv(blue_image)
        
        # Y = 0.299*R + 0.587*G + 0.114*B = 0.114 for pure blue
        expected_y_blue = 0.114
        # U = -0.14713*R - 0.28886*G + 0.436*B = 0.436 for pure blue
        expected_u_blue = 0.436
        # V = 0.615*R - 0.51499*G - 0.10001*B = -0.10001 for pure blue
        expected_v_blue = -0.10001
        
        y_val_b = blue_yuv[0, 0, 0].numpy()
        u_val_b = blue_yuv[0, 0, 1].numpy()
        v_val_b = blue_yuv[0, 0, 2].numpy()
        
        assert abs(y_val_b - expected_y_blue) < 1e-4, \
            f"Y value incorrect for blue: {y_val_b} vs {expected_y_blue}"
        assert abs(u_val_b - expected_u_blue) < 1e-4, \
            f"U value incorrect for blue: {u_val_b} vs {expected_u_blue}"
        assert abs(v_val_b - expected_v_blue) < 1e-4, \
            f"V value incorrect for blue: {v_val_b} vs {expected_v_blue}"
    
    # 2. roundtrip_consistency: RGB -> YUV -> RGB should preserve values (approximately)
    # Note: We need yuv_to_rgb function for roundtrip test
    # Check if yuv_to_rgb is available in the same module
    try:
        from tensorflow.python.ops.image_ops_impl import yuv_to_rgb
        
        # Convert RGB to YUV
        yuv_result = image_ops_impl.rgb_to_yuv(image_float)
        
        # Convert YUV back to RGB
        rgb_roundtrip = yuv_to_rgb(yuv_result)
        
        # Check that roundtrip preserves values (with some tolerance)
        # Color space conversion is not lossless, so we need reasonable tolerance
        diff = tf.reduce_max(tf.abs(image_float - rgb_roundtrip)).numpy()
        
        # For color conversion, allow larger tolerance due to floating point errors
        # and potential implementation differences
        assert diff < 1e-4, f"Roundtrip consistency failed: max_diff={diff}"
        
        # Also check that values are in valid range [0, 1]
        min_val = tf.reduce_min(rgb_roundtrip).numpy()
        max_val = tf.reduce_max(rgb_roundtrip).numpy()
        assert min_val >= -1e-5 and max_val <= 1.0 + 1e-5, \
            f"Roundtrip values out of range: min={min_val}, max={max_val}"
            
    except ImportError:
        # yuv_to_rgb might not be available or imported differently
        # Try alternative import
        try:
            yuv_to_rgb = image_ops_impl.yuv_to_rgb
            # Same test as above
            yuv_result = image_ops_impl.rgb_to_yuv(image_float)
            rgb_roundtrip = yuv_to_rgb(yuv_result)
            
            diff = tf.reduce_max(tf.abs(image_float - rgb_roundtrip)).numpy()
            assert diff < 1e-4, f"Roundtrip consistency failed: max_diff={diff}"
            
            min_val = tf.reduce_min(rgb_roundtrip).numpy()
            max_val = tf.reduce_max(rgb_roundtrip).numpy()
            assert min_val >= -1e-5 and max_val <= 1.0 + 1e-5, \
                f"Roundtrip values out of range: min={min_val}, max={max_val}"
                
        except AttributeError:
            # yuv_to_rgb not available, skip roundtrip test
            print("Warning: yuv_to_rgb not available, skipping roundtrip consistency test")
    
    # 3. range_check: Verify YUV values are in expected ranges
    # Y channel should be in [0, 1] for RGB inputs in [0, 1]
    y_channel = result[..., 0]
    min_y = tf.reduce_min(y_channel).numpy()
    max_y = tf.reduce_max(y_channel).numpy()
    
    # Y should be in [0, 1] (allow small tolerance for floating point errors)
    assert min_y >= -1e-5, f"Y channel minimum too low: {min_y}"
    assert max_y <= 1.0 + 1e-5, f"Y channel maximum too high: {max_y}"
    
    # U and V channels have different ranges in YUV color space
    # For standard YUV (BT.601), U and V are in [-0.436, 0.436] and [-0.615, 0.615] respectively
    # But implementations may scale differently
    
    u_channel = result[..., 1]
    v_channel = result[..., 2]
    
    min_u = tf.reduce_min(u_channel).numpy()
    max_u = tf.reduce_max(u_channel).numpy()
    min_v = tf.reduce_min(v_channel).numpy()
    max_v = tf.reduce_max(v_channel).numpy()
    
    # Check that U and V are within reasonable bounds
    # Based on standard YUV ranges and our test inputs
    assert min_u >= -0.5 and max_u <= 0.5, \
        f"U channel out of reasonable range: min={min_u}, max={max_u}"
    assert min_v >= -0.7 and max_v <= 0.7, \
        f"V channel out of reasonable range: min={min_v}, max={max_v}"
    
    # Additional check: test with extreme RGB values
    if dtype == tf.float32:
        # Test with black [0, 0, 0]
        black_image = tf.zeros((1, 1, 3), dtype=tf.float32)
        black_yuv = image_ops_impl.rgb_to_yuv(black_image)
        
        # Black should convert to YUV (0, 0, 0)
        black_y = black_yuv[0, 0, 0].numpy()
        black_u = black_yuv[0, 0, 1].numpy()
        black_v = black_yuv[0, 0, 2].numpy()
        
        assert abs(black_y) < 1e-6, f"Black Y not zero: {black_y}"
        assert abs(black_u) < 1e-6, f"Black U not zero: {black_u}"
        assert abs(black_v) < 1e-6, f"Black V not zero: {black_v}"
        
        # Test with white [1, 1, 1]
        white_image = tf.ones((1, 1, 3), dtype=tf.float32)
        white_yuv = image_ops_impl.rgb_to_yuv(white_image)
        
        # White: Y = 0.299 + 0.587 + 0.114 = 1.0
        # U = -0.14713 - 0.28886 + 0.436 = 0.00001 (approximately 0)
        # V = 0.615 - 0.51499 - 0.10001 = 0.0
        white_y = white_yuv[0, 0, 0].numpy()
        white_u = white_yuv[0, 0, 1].numpy()
        white_v = white_yuv[0, 0, 2].numpy()
        
        assert abs(white_y - 1.0) < 1e-5, f"White Y not 1.0: {white_y}"
        assert abs(white_u) < 1e-5, f"White U not zero: {white_u}"
        assert abs(white_v) < 1e-5, f"White V not zero: {white_v}"
    
    # Check all channels are finite
    for channel in range(3):
        channel_data = result[..., channel]
        assert tf.reduce_all(tf.math.is_finite(channel_data)), \
            f"Channel {channel} contains non-finite values"
# ==== BLOCK:CASE_04 END ====

# ==== BLOCK:CASE_05 START ====
# TC-05: non_max_suppression 边界框筛选
# Priority: High
# Assertion level: strong (nms_correctness, iou_threshold, score_ordering)

def test_non_max_suppression_basic(set_random_seed):
    """Test non-max suppression functionality."""
    # Create test boxes and scores
    # 10 boxes with format [y1, x1, y2, x2]
    boxes = tf.constant([
        [0.0, 0.0, 1.0, 1.0],    # Box 0 - score 0.9
        [0.1, 0.1, 0.9, 0.9],    # Box 1 - score 0.8 (overlaps with box 0, IoU ~0.64)
        [0.5, 0.5, 1.5, 1.5],    # Box 2 - score 0.7
        [0.6, 0.6, 1.4, 1.4],    # Box 3 - score 0.6 (overlaps with box 2, IoU ~0.64)
        [2.0, 2.0, 3.0, 3.0],    # Box 4 - score 0.5
        [2.1, 2.1, 2.9, 2.9],    # Box 5 - score 0.4 (overlaps with box 4, IoU ~0.64)
        [4.0, 4.0, 5.0, 5.0],    # Box 6 - score 0.3
        [4.1, 4.1, 4.9, 4.9],    # Box 7 - score 0.2 (overlaps with box 6, IoU ~0.64)
        [6.0, 6.0, 7.0, 7.0],    # Box 8 - score 0.1
        [6.1, 6.1, 6.9, 6.9],    # Box 9 - score 0.05 (overlaps with box 8, IoU ~0.64)
    ], dtype=tf.float32)
    
    # Create scores (higher scores should be selected first)
    scores = tf.constant([0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.05], dtype=tf.float32)
    
    # Apply non-max suppression with max_output_size = 5
    max_output_size = 5
    selected_indices = image_ops_impl.non_max_suppression(
        boxes, scores, max_output_size, iou_threshold=0.5
    )
    
    # Weak assertions (still needed)
    # Check output is a tensor
    assert isinstance(selected_indices, tf.Tensor), \
        f"Expected tf.Tensor, got {type(selected_indices)}"
    
    # Check dtype is int32
    assert selected_indices.dtype == tf.int32, \
        f"Expected dtype int32, got {selected_indices.dtype}"
    
    # Check shape is 1D
    assert len(selected_indices.shape) == 1, \
        f"Expected 1D tensor, got shape {selected_indices.shape}"
    
    # Check output size <= max_output_size
    output_size = selected_indices.shape[0]
    assert output_size <= max_output_size, \
        f"Output size {output_size} exceeds max_output_size {max_output_size}"
    
    # Check indices are within valid range
    indices_np = selected_indices.numpy()
    for idx in indices_np:
        assert 0 <= idx < boxes.shape[0], \
            f"Index {idx} out of range [0, {boxes.shape[0]})"
    
    # Check indices are unique
    unique_indices = set(indices_np)
    assert len(unique_indices) == len(indices_np), \
        f"Duplicate indices found: {indices_np}"
    
    # STRONG ASSERTIONS
    
    # 1. nms_correctness: Verify NMS algorithm correctness
    # With IoU threshold 0.5, overlapping boxes with IoU > 0.5 should be suppressed
    # Each pair (0,1), (2,3), (4,5), (6,7), (8,9) has IoU ~0.64 > 0.5
    # So only the highest scoring box from each pair should be selected
    
    # Expected: boxes 0, 2, 4, 6, 8 (highest score from each overlapping pair)
    # But limited to max_output_size = 5, so all 5 should be selected
    expected_indices = {0, 2, 4, 6, 8}
    selected_set = set(indices_np)
    
    # Check that selected indices match expected (order may vary)
    assert selected_set == expected_indices, \
        f"NMS correctness failed: selected {selected_set}, expected {expected_indices}"
    
    # 2. iou_threshold: Test with different IoU thresholds
    # With iou_threshold = 0.0, no boxes should overlap (all boxes have IoU > 0 with themselves)
    # But NMS compares boxes with higher scores, so only box 0 should be selected
    selected_indices_strict = image_ops_impl.non_max_suppression(
        boxes, scores, max_output_size, iou_threshold=0.0
    )
    
    # Check output is valid
    assert isinstance(selected_indices_strict, tf.Tensor)
    assert selected_indices_strict.dtype == tf.int32
    assert len(selected_indices_strict.shape) == 1
    
    # With iou_threshold = 0.0, only the highest scoring box should be selected
    # (or possibly more if max_output_size allows, but overlapping boxes have IoU > 0)
    strict_indices = selected_indices_strict.numpy()
    assert len(strict_indices) >= 1, "At least one box should be selected with iou_threshold=0.0"
    assert 0 in strict_indices, "Box 0 (highest score) should be selected with iou_threshold=0.0"
    
    # With iou_threshold = 1.0, all boxes should be allowed (but limited by max_output_size)
    selected_indices_lenient = image_ops_impl.non_max_suppression(
        boxes, scores, max_output_size, iou_threshold=1.0
    )
    
    # Check output is valid
    assert isinstance(selected_indices_lenient, tf.Tensor)
    assert selected_indices_lenient.dtype == tf.int32
    assert len(selected_indices_lenient.shape) == 1
    
    lenient_indices = selected_indices_lenient.numpy()
    # With iou_threshold=1.0, all boxes can be selected (up to max_output_size)
    # Should select boxes 0, 1, 2, 3, 4 (top 5 scores)
    expected_lenient = {0, 1, 2, 3, 4}
    lenient_set = set(lenient_indices)
    
    # Check that we got the top 5 scores
    assert lenient_set == expected_lenient, \
        f"With iou_threshold=1.0, expected top 5 scores: {expected_lenient}, got {lenient_set}"
    
    # Test with intermediate iou_threshold = 0.6
    # Box pairs have IoU ~0.64, so with threshold 0.6 they should still be suppressed
    selected_indices_06 = image_ops_impl.non_max_suppression(
        boxes, scores, max_output_size, iou_threshold=0.6
    )
    
    indices_06 = selected_indices_06.numpy()
    set_06 = set(indices_06)
    # Should still get boxes 0, 2, 4, 6, 8 (IoU ~0.64 > 0.6)
    assert set_06 == expected_indices, \
        f"With iou_threshold=0.6, expected {expected_indices}, got {set_06}"
    
    # Test with iou_threshold = 0.7
    # Box pairs have IoU ~0.64 < 0.7, so all boxes can be selected (up to max_output_size)
    selected_indices_07 = image_ops_impl.non_max_suppression(
        boxes, scores, max_output_size, iou_threshold=0.7
    )
    
    indices_07 = selected_indices_07.numpy()
    set_07 = set(indices_07)
    # Should get top 5 scores: 0, 1, 2, 3, 4
    assert set_07 == expected_lenient, \
        f"With iou_threshold=0.7, expected {expected_lenient}, got {set_07}"
    
    # 3. score_ordering: Verify selected indices are sorted by score (descending)
    # Get the scores of selected boxes
    selected_scores = tf.gather(scores, selected_indices).numpy()
    
    # Check scores are in strictly non-increasing order
    for i in range(len(selected_scores) - 1):
        assert selected_scores[i] >= selected_scores[i + 1], \
            f"Scores not in descending order: {selected_scores[i]} < {selected_scores[i + 1]}"
    
    # Verify the actual order matches score order
    # With our test data and iou_threshold=0.5, we should get boxes in order: 0, 2, 4, 6, 8
    expected_order = [0, 2, 4, 6, 8]
    
    # Check order matches (NMS should return indices in score-descending order)
    for i, idx in enumerate(indices_np):
        expected_idx = expected_order[i]
        assert idx == expected_idx, \
            f"Score ordering failed at position {i}: got {idx}, expected {expected_idx}"
    
    # Additional strong assertion: test with score_threshold
    selected_indices_threshold = image_ops_impl.non_max_suppression(
        boxes, scores, max_output_size, iou_threshold=0.5, score_threshold=0.5
    )
    
    # Check output is valid
    assert isinstance(selected_indices_threshold, tf.Tensor)
    assert selected_indices_threshold.dtype == tf.int32
    assert len(selected_indices_threshold.shape) == 1
    
    # All selected scores should be >= score_threshold
    if selected_indices_threshold.shape[0] > 0:
        threshold_scores = tf.gather(scores, selected_indices_threshold).numpy()
        for score in threshold_scores:
            assert score >= 0.5, f"Score {score} below threshold 0.5"
    
    # With score_threshold=0.5, boxes 0, 2, 4 should be selected (scores 0.9, 0.7, 0.5)
    # Boxes 6 and 8 have scores 0.3 and 0.1 < 0.5
    threshold_indices = selected_indices_threshold.numpy()
    threshold_set = set(threshold_indices)
    expected_threshold = {0, 2, 4}
    
    assert threshold_set == expected_threshold, \
        f"With score_threshold=0.5, expected {expected_threshold}, got {threshold_set}"
    
    # Test edge case: max_output_size = 0
    selected_indices_zero = image_ops_impl.non_max_suppression(
        boxes, scores, 0, iou_threshold=0.5
    )
    
    assert selected_indices_zero.shape[0] == 0, \
        f"Expected empty output for max_output_size=0, got {selected_indices_zero.shape[0]}"
    
    # Test edge case: max_output_size > number of boxes
    selected_indices_large = image_ops_impl.non_max_suppression(
        boxes, scores, boxes.shape[0] * 2, iou_threshold=0.5
    )
    
    assert selected_indices_large.shape[0] <= boxes.shape[0], \
        f"Output size {selected_indices_large.shape[0]} exceeds number of boxes {boxes.shape[0]}"
    
    # With large max_output_size and iou_threshold=0.5, should get 5 boxes (0, 2, 4, 6, 8)
    large_indices = selected_indices_large.numpy()
    large_set = set(large_indices)
    assert large_set == expected_indices, \
        f"With large max_output_size, expected {expected_indices}, got {large_set}"
    
    # Additional test: verify IoU calculations
    # Manually compute IoU for box 0 and box 1 to verify > 0.5
    box0 = boxes[0].numpy()
    box1 = boxes[1].numpy()
    
    # Compute intersection
    y1_i = max(box0[0], box1[0])
    x1_i = max(box0[1], box1[1])
    y2_i = min(box0[2], box1[2])
    x2_i = min(box0[3], box1[3])
    
    intersection = max(0, y2_i - y1_i) * max(0, x2_i - x1_i)
    
    # Compute union
    area0 = (box0[2] - box0[0]) * (box0[3] - box0[1])
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    union = area0 + area1 - intersection
    
    iou = intersection / union if union > 0 else 0
    
    # Verify IoU > 0.5 (should be ~0.64)
    assert iou > 0.5, f"IoU between box 0 and box 1 is {iou}, expected > 0.5"
    
    # Test with non-overlapping boxes
    non_overlap_boxes = tf.constant([
        [0.0, 0.0, 1.0, 1.0],
        [2.0, 2.0, 3.0, 3.0],
        [4.0, 4.0, 5.0, 5.0],
    ], dtype=tf.float32)
    
    non_overlap_scores = tf.constant([0.9, 0.8, 0.7], dtype=tf.float32)
    
    non_overlap_result = image_ops_impl.non_max_suppression(
        non_overlap_boxes, non_overlap_scores, 3, iou_threshold=0.5
    )
    
    # All boxes should be selected since they don't overlap
    non_overlap_indices = non_overlap_result.numpy()
    assert set(non_overlap_indices) == {0, 1, 2}, \
        f"All non-overlapping boxes should be selected: got {set(non_overlap_indices)}"
# ==== BLOCK:CASE_05 END ====

# ==== BLOCK:FOOTER START ====
# Additional test cases and edge cases

def test_adjust_brightness_edge_cases():
    """Test edge cases for brightness adjustment."""
    # Test with extreme delta values
    image = tf.constant([[1.0, 2.0], [3.0, 4.0]], dtype=tf.float32)
    
    # Large positive delta
    result = image_ops_impl.adjust_brightness(image, 10.0)
    assert_tensor_shape(result, (2, 2))
    assert_tensor_dtype(result, tf.float32)
    assert_tensor_finite(result)
    
    # Large negative delta
    result = image_ops_impl.adjust_brightness(image, -10.0)
    assert_tensor_shape(result, (2, 2))
    assert_tensor_dtype(result, tf.float32)
    assert_tensor_finite(result)
    
    # Zero delta (should return same values)
    result = image_ops_impl.adjust_brightness(image, 0.0)
    assert_tensor_shape(result, (2, 2))
    assert_tensor_dtype(result, tf.float32)

def test_central_crop_invalid_fraction():
    """Test central crop with invalid fraction values."""
    image = tf.constant(np.ones((32, 32, 3), dtype=np.float32), dtype=tf.float32)
    
    # Test with fraction = 0 (should raise ValueError)
    with pytest.raises(ValueError, match="central_fraction must be within"):
        image_ops_impl.central_crop(image, 0.0)
    
    # Test with fraction > 1 (should raise ValueError)
    with pytest.raises(ValueError, match="central_fraction must be within"):
        image_ops_impl.central_crop(image, 1.1)
    
    # Test with negative fraction (should raise ValueError)
    with pytest.raises(ValueError, match="central_fraction must be within"):
        image_ops_impl.central_crop(image, -0.1)

def test_random_flip_invalid_shape():
    """Test random flip with invalid image shapes."""
    # 2D image (should work but might not be valid for all operations)
    image_2d = tf.constant([[1.0, 2.0], [3.0, 4.0]], dtype=tf.float32)
    
    # random_flip_left_right expects at least 3D
    with pytest.raises(ValueError, match="shape"):
        image_ops_impl.random_flip_left_right(image_2d)
    
    # Valid 3D image
    image_3d = tf.constant([[[1.0], [2.0]], [[3.0], [4.0]]], dtype=tf.float32)
    result = image_ops_impl.random_flip_left_right(image_3d, seed=42)
    assert_tensor_shape(result, (2, 2, 1))
    assert_tensor_dtype(result, tf.float32)

def test_image_ops_with_different_dtypes():
    """Test image operations with various data types."""
    # Test adjust_brightness with different dtypes
    shapes = [(32, 32, 3), (1, 64, 64, 3)]
    dtypes = [tf.float16, tf.float32, tf.float64, tf.uint8, tf.uint16]
    
    for shape in shapes:
        for dtype in dtypes:
            if dtype in [tf.float16, tf.float32, tf.float64]:
                image = tf.constant(np.random.uniform(0, 1, size=shape).astype(np.float32), dtype=dtype)
            else:
                # For integer types, scale to appropriate range
                if dtype == tf.uint8:
                    image = tf.constant(np.random.randint(0, 256, size=shape, dtype=np.uint8), dtype=dtype)
                elif dtype == tf.uint16:
                    image = tf.constant(np.random.randint(0, 65536, size=shape, dtype=np.uint16), dtype=dtype)
            
            # Test adjust_brightness
            result = image_ops_impl.adjust_brightness(image, 0.1)
            assert_tensor_shape(result, shape)
            assert_tensor_dtype(result, dtype)
            assert_tensor_finite(result)
            
            # Test that operation doesn't crash with small delta
            result = image_ops_impl.adjust_brightness(image, 0.01)
            assert_tensor_shape(result, shape)
            assert_tensor_dtype(result, dtype)
            
            # Additional check for integer types
            if dtype in [tf.uint8, tf.uint16]:
                # Check values are within appropriate range
                min_val = tf.reduce_min(result).numpy()
                max_val = tf.reduce_max(result).numpy()
                if dtype == tf.uint8:
                    assert min_val >= 0 and max_val <= 255, \
                        f"uint8 values out of range: min={min_val}, max={max_val}"
                elif dtype == tf.uint16:
                    assert min_val >= 0 and max_val <= 65535, \
                        f"uint16 values out of range: min={min_val}, max={max_val}"
# ==== BLOCK:FOOTER END ====