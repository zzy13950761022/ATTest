=== Run Tests ===
...FFFFFF.F..sss..                                                       [100%]
================================== FAILURES ===================================
_ test_categorical_column_with_vocabulary_list_basic_creation[category-vocabulary_list1-dtype1-0-2] _

key = 'category', vocabulary_list = [1, 2, 3, 4, 5], dtype = tf.int64
default_value = 0, num_oov_buckets = 2

    @pytest.mark.parametrize(
        "key,vocabulary_list,dtype,default_value,num_oov_buckets",
        [
            # Base case from test plan
            ("department", ["math", "philosophy", "english"], None, -1, 0),
            # Parameter extension
            ("category", [1, 2, 3, 4, 5], tf.int64, 0, 2),
        ]
    )
    def test_categorical_column_with_vocabulary_list_basic_creation(
        key, vocabulary_list, dtype, default_value, num_oov_buckets
    ):
        """Test categorical_column_with_vocabulary_list basic creation (CASE_02)"""
        # Import the function
        from tensorflow.python.feature_column.feature_column_v2 import categorical_column_with_vocabulary_list
    
        # Create the column
>       column = categorical_column_with_vocabulary_list(
            key=key,
            vocabulary_list=vocabulary_list,
            dtype=dtype,
            default_value=default_value,
            num_oov_buckets=num_oov_buckets
        )

tests\test_tensorflow_python_feature_column_feature_column_v2.py:113: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'category', vocabulary_list = [1, 2, 3, 4, 5], dtype = tf.int64
default_value = 0, num_oov_buckets = 2

    @tf_export('feature_column.categorical_column_with_vocabulary_list')
    def categorical_column_with_vocabulary_list(key,
                                                vocabulary_list,
                                                dtype=None,
                                                default_value=-1,
                                                num_oov_buckets=0):
      """A `CategoricalColumn` with in-memory vocabulary.
    
      Use this when your inputs are in string or integer format, and you have an
      in-memory vocabulary mapping each value to an integer ID. By default,
      out-of-vocabulary values are ignored. Use either (but not both) of
      `num_oov_buckets` and `default_value` to specify how to include
      out-of-vocabulary values.
    
      For input dictionary `features`, `features[key]` is either `Tensor` or
      `SparseTensor`. If `Tensor`, missing values can be represented by `-1` for int
      and `''` for string, which will be dropped by this feature column.
    
      Example with `num_oov_buckets`:
      In the following example, each input in `vocabulary_list` is assigned an ID
      0-3 corresponding to its index (e.g., input 'B' produces output 2). All other
      inputs are hashed and assigned an ID 4-5.
    
      ```python
      colors = categorical_column_with_vocabulary_list(
          key='colors', vocabulary_list=('R', 'G', 'B', 'Y'),
          num_oov_buckets=2)
      columns = [colors, ...]
      features = tf.io.parse_example(..., features=make_parse_example_spec(columns))
      linear_prediction, _, _ = linear_model(features, columns)
      ```
    
      Example with `default_value`:
      In the following example, each input in `vocabulary_list` is assigned an ID
      0-4 corresponding to its index (e.g., input 'B' produces output 3). All other
      inputs are assigned `default_value` 0.
    
    
      ```python
      colors = categorical_column_with_vocabulary_list(
          key='colors', vocabulary_list=('X', 'R', 'G', 'B', 'Y'), default_value=0)
      columns = [colors, ...]
      features = tf.io.parse_example(..., features=make_parse_example_spec(columns))
      linear_prediction, _, _ = linear_model(features, columns)
      ```
    
      And to make an embedding with either:
    
      ```python
      columns = [embedding_column(colors, 3),...]
      features = tf.io.parse_example(..., features=make_parse_example_spec(columns))
      dense_tensor = input_layer(features, columns)
      ```
    
      Args:
        key: A unique string identifying the input feature. It is used as the column
          name and the dictionary key for feature parsing configs, feature `Tensor`
          objects, and feature columns.
        vocabulary_list: An ordered iterable defining the vocabulary. Each feature
          is mapped to the index of its value (if present) in `vocabulary_list`.
          Must be castable to `dtype`.
        dtype: The type of features. Only string and integer types are supported. If
          `None`, it will be inferred from `vocabulary_list`.
        default_value: The integer ID value to return for out-of-vocabulary feature
          values, defaults to `-1`. This can not be specified with a positive
          `num_oov_buckets`.
        num_oov_buckets: Non-negative integer, the number of out-of-vocabulary
          buckets. All out-of-vocabulary inputs will be assigned IDs in the range
          `[len(vocabulary_list), len(vocabulary_list)+num_oov_buckets)` based on a
          hash of the input value. A positive `num_oov_buckets` can not be specified
          with `default_value`.
    
      Returns:
        A `CategoricalColumn` with in-memory vocabulary.
    
      Raises:
        ValueError: if `vocabulary_list` is empty, or contains duplicate keys.
        ValueError: `num_oov_buckets` is a negative integer.
        ValueError: `num_oov_buckets` and `default_value` are both specified.
        ValueError: if `dtype` is not integer or string.
      """
      if (vocabulary_list is None) or (len(vocabulary_list) < 1):
        raise ValueError(
            'vocabulary_list {} must be non-empty, column_name: {}'.format(
                vocabulary_list, key))
      if len(set(vocabulary_list)) != len(vocabulary_list):
        raise ValueError(
            'Duplicate keys in vocabulary_list {}, column_name: {}'.format(
                vocabulary_list, key))
      vocabulary_dtype = dtypes.as_dtype(np.array(vocabulary_list).dtype)
      if num_oov_buckets:
        if default_value != -1:
>         raise ValueError(
              'Can\'t specify both num_oov_buckets and default_value in {}.'.format(
                  key))
E         ValueError: Can't specify both num_oov_buckets and default_value in category.

D:\Coding\Anaconda\envs\testagent-experiment\lib\site-packages\tensorflow\python\feature_column\feature_column_v2.py:1574: ValueError
_________ test_bucketized_column_boundary_bucketing[age-boundaries0] __________

source_column_key = 'age', boundaries = [18, 25, 30, 40, 50]

    @pytest.mark.parametrize(
        "source_column_key,boundaries",
        [
            # Base case from test plan
            ("age", [18, 25, 30, 40, 50]),
            # Parameter extension
            ("income", [1000, 5000, 10000, 50000, 100000]),
        ]
    )
    def test_bucketized_column_boundary_bucketing(source_column_key, boundaries):
        """Test bucketized_column boundary bucketing (CASE_03)"""
        # Import functions
        from tensorflow.python.feature_column.feature_column_v2 import (
            numeric_column, bucketized_column
        )
    
        # First create a source numeric column
        source_column = numeric_column(key=source_column_key, shape=(1,))
    
        # Create the bucketized column
        column = bucketized_column(
            source_column=source_column,
            boundaries=boundaries
        )
    
        # Assert basic properties (weak assertions)
        assert column is not None
>       assert hasattr(column, 'key')
E       AssertionError: assert False
E        +  where False = hasattr(BucketizedColumn(source_column=NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(18, 25, 30, 40, 50)), 'key')

tests\test_tensorflow_python_feature_column_feature_column_v2.py:176: AssertionError
________ test_bucketized_column_boundary_bucketing[income-boundaries1] ________

source_column_key = 'income', boundaries = [1000, 5000, 10000, 50000, 100000]

    @pytest.mark.parametrize(
        "source_column_key,boundaries",
        [
            # Base case from test plan
            ("age", [18, 25, 30, 40, 50]),
            # Parameter extension
            ("income", [1000, 5000, 10000, 50000, 100000]),
        ]
    )
    def test_bucketized_column_boundary_bucketing(source_column_key, boundaries):
        """Test bucketized_column boundary bucketing (CASE_03)"""
        # Import functions
        from tensorflow.python.feature_column.feature_column_v2 import (
            numeric_column, bucketized_column
        )
    
        # First create a source numeric column
        source_column = numeric_column(key=source_column_key, shape=(1,))
    
        # Create the bucketized column
        column = bucketized_column(
            source_column=source_column,
            boundaries=boundaries
        )
    
        # Assert basic properties (weak assertions)
        assert column is not None
>       assert hasattr(column, 'key')
E       AssertionError: assert False
E        +  where False = hasattr(BucketizedColumn(source_column=NumericColumn(key='income', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(1000, 5000, 10000, 50000, 100000)), 'key')

tests\test_tensorflow_python_feature_column_feature_column_v2.py:176: AssertionError
_____ test_embedding_column_dimension_validation[department-16-mean-True] _____

categorical_column_key = 'department', dimension = 16, combiner = 'mean'
trainable = True

    @pytest.mark.parametrize(
        "categorical_column_key,dimension,combiner,trainable",
        [
            # Base case from test plan
            ("department", 16, "mean", True),
            # Parameter extension
            ("product", 32, "sqrtn", False),
        ]
    )
    def test_embedding_column_dimension_validation(categorical_column_key, dimension, combiner, trainable):
        """Test embedding_column dimension validation (CASE_04)"""
        # Import functions
        from tensorflow.python.feature_column.feature_column_v2 import (
            categorical_column_with_vocabulary_list, embedding_column
        )
    
        # First create a categorical column
        categorical_column = categorical_column_with_vocabulary_list(
            key=categorical_column_key,
            vocabulary_list=["item1", "item2", "item3", "item4", "item5"]
        )
    
        # Create the embedding column
        column = embedding_column(
            categorical_column=categorical_column,
            dimension=dimension,
            combiner=combiner,
            trainable=trainable
        )
    
        # Assert basic properties (weak assertions)
        assert column is not None
>       assert hasattr(column, 'key')
E       AssertionError: assert False
E        +  where False = hasattr(EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='department', vocabulary_list=('item1', 'item2'...9AF0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True), 'key')

tests\test_tensorflow_python_feature_column_feature_column_v2.py:240: AssertionError
_____ test_embedding_column_dimension_validation[product-32-sqrtn-False] ______

categorical_column_key = 'product', dimension = 32, combiner = 'sqrtn'
trainable = False

    @pytest.mark.parametrize(
        "categorical_column_key,dimension,combiner,trainable",
        [
            # Base case from test plan
            ("department", 16, "mean", True),
            # Parameter extension
            ("product", 32, "sqrtn", False),
        ]
    )
    def test_embedding_column_dimension_validation(categorical_column_key, dimension, combiner, trainable):
        """Test embedding_column dimension validation (CASE_04)"""
        # Import functions
        from tensorflow.python.feature_column.feature_column_v2 import (
            categorical_column_with_vocabulary_list, embedding_column
        )
    
        # First create a categorical column
        categorical_column = categorical_column_with_vocabulary_list(
            key=categorical_column_key,
            vocabulary_list=["item1", "item2", "item3", "item4", "item5"]
        )
    
        # Create the embedding column
        column = embedding_column(
            categorical_column=categorical_column,
            dimension=dimension,
            combiner=combiner,
            trainable=trainable
        )
    
        # Assert basic properties (weak assertions)
        assert column is not None
>       assert hasattr(column, 'key')
E       AssertionError: assert False
E        +  where False = hasattr(EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='product', vocabulary_list=('item1', 'item2', '...880>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=False, use_safe_embedding_lookup=True), 'key')

tests\test_tensorflow_python_feature_column_feature_column_v2.py:240: AssertionError
_ test_numeric_column_error_handling[-shape0-dtype0-None-None-key cannot be empty-ValueError] _

key = '', shape = (1,), dtype = tf.float32, default_value = None
normalizer_fn = None, expected_exception = 'key cannot be empty'
expected_exception_type = <class 'ValueError'>

    @pytest.mark.parametrize(
        "key,shape,dtype,default_value,normalizer_fn,expected_exception,expected_exception_type",
        [
            # Empty key should raise ValueError
            ("", (1,), tf.float32, None, None, "key cannot be empty", ValueError),
            # Invalid shape (0) should raise ValueError
            ("test", (0,), tf.float32, None, None, "shape", ValueError),
            # Invalid dtype should raise TypeError
            ("test", (1,), "invalid", None, None, "dtype", TypeError),
            # Type mismatch for default_value should raise TypeError
            ("test", (1,), tf.float32, "wrong_type", None, "default_value", TypeError),
            # Non-callable normalizer_fn should raise TypeError
            ("test", (1,), tf.float32, None, "not_callable", "normalizer_fn", TypeError),
        ]
    )
    def test_numeric_column_error_handling(
        key, shape, dtype, default_value, normalizer_fn,
        expected_exception, expected_exception_type
    ):
        """Test numeric_column error handling (CASE_05)"""
        # Import the function
        from tensorflow.python.feature_column.feature_column_v2 import numeric_column
    
        # Test that the expected exception is raised
        with pytest.raises(expected_exception_type) as exc_info:
            if normalizer_fn is not None:
                column = numeric_column(
                    key=key,
                    shape=shape,
                    dtype=dtype,
                    default_value=default_value,
                    normalizer_fn=normalizer_fn
                )
            else:
>               column = numeric_column(
                    key=key,
                    shape=shape,
                    dtype=dtype,
                    default_value=default_value
                )
E               Failed: DID NOT RAISE <class 'ValueError'>

tests\test_tensorflow_python_feature_column_feature_column_v2.py:303: Failed
_ test_numeric_column_error_handling[test-shape2-invalid-None-None-dtype-TypeError] _

key = 'test', shape = (1,), dtype = 'invalid', default_value = None
normalizer_fn = None, expected_exception = 'dtype'
expected_exception_type = <class 'TypeError'>

    @pytest.mark.parametrize(
        "key,shape,dtype,default_value,normalizer_fn,expected_exception,expected_exception_type",
        [
            # Empty key should raise ValueError
            ("", (1,), tf.float32, None, None, "key cannot be empty", ValueError),
            # Invalid shape (0) should raise ValueError
            ("test", (0,), tf.float32, None, None, "shape", ValueError),
            # Invalid dtype should raise TypeError
            ("test", (1,), "invalid", None, None, "dtype", TypeError),
            # Type mismatch for default_value should raise TypeError
            ("test", (1,), tf.float32, "wrong_type", None, "default_value", TypeError),
            # Non-callable normalizer_fn should raise TypeError
            ("test", (1,), tf.float32, None, "not_callable", "normalizer_fn", TypeError),
        ]
    )
    def test_numeric_column_error_handling(
        key, shape, dtype, default_value, normalizer_fn,
        expected_exception, expected_exception_type
    ):
        """Test numeric_column error handling (CASE_05)"""
        # Import the function
        from tensorflow.python.feature_column.feature_column_v2 import numeric_column
    
        # Test that the expected exception is raised
        with pytest.raises(expected_exception_type) as exc_info:
            if normalizer_fn is not None:
                column = numeric_column(
                    key=key,
                    shape=shape,
                    dtype=dtype,
                    default_value=default_value,
                    normalizer_fn=normalizer_fn
                )
            else:
>               column = numeric_column(
                    key=key,
                    shape=shape,
                    dtype=dtype,
                    default_value=default_value
                )

tests\test_tensorflow_python_feature_column_feature_column_v2.py:303: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'test', shape = (1,), default_value = None, dtype = 'invalid'
normalizer_fn = None

    @tf_export('feature_column.numeric_column')
    def numeric_column(key,
                       shape=(1,),
                       default_value=None,
                       dtype=dtypes.float32,
                       normalizer_fn=None):
      """Represents real valued or numerical features.
    
      Example:
    
      Assume we have data with two features `a` and `b`.
    
      >>> data = {'a': [15, 9, 17, 19, 21, 18, 25, 30],
      ...    'b': [5.0, 6.4, 10.5, 13.6, 15.7, 19.9, 20.3 , 0.0]}
    
      Let us represent the features `a` and `b` as numerical features.
    
      >>> a = tf.feature_column.numeric_column('a')
      >>> b = tf.feature_column.numeric_column('b')
    
      Feature column describe a set of transformations to the inputs.
    
      For example, to "bucketize" feature `a`, wrap the `a` column in a
      `feature_column.bucketized_column`.
      Providing `5` bucket boundaries, the bucketized_column api
      will bucket this feature in total of `6` buckets.
    
      >>> a_buckets = tf.feature_column.bucketized_column(a,
      ...    boundaries=[10, 15, 20, 25, 30])
    
      Create a `DenseFeatures` layer which will apply the transformations
      described by the set of `tf.feature_column` objects:
    
      >>> feature_layer = tf.keras.layers.DenseFeatures([a_buckets, b])
      >>> print(feature_layer(data))
      tf.Tensor(
      [[ 0.   0.   1.   0.   0.   0.   5. ]
       [ 1.   0.   0.   0.   0.   0.   6.4]
       [ 0.   0.   1.   0.   0.   0.  10.5]
       [ 0.   0.   1.   0.   0.   0.  13.6]
       [ 0.   0.   0.   1.   0.   0.  15.7]
       [ 0.   0.   1.   0.   0.   0.  19.9]
       [ 0.   0.   0.   0.   1.   0.  20.3]
       [ 0.   0.   0.   0.   0.   1.   0. ]], shape=(8, 7), dtype=float32)
    
      Args:
        key: A unique string identifying the input feature. It is used as the
          column name and the dictionary key for feature parsing configs, feature
          `Tensor` objects, and feature columns.
        shape: An iterable of integers specifies the shape of the `Tensor`. An
          integer can be given which means a single dimension `Tensor` with given
          width. The `Tensor` representing the column will have the shape of
          [batch_size] + `shape`.
        default_value: A single value compatible with `dtype` or an iterable of
          values compatible with `dtype` which the column takes on during
          `tf.Example` parsing if data is missing. A default value of `None` will
          cause `tf.io.parse_example` to fail if an example does not contain this
          column. If a single value is provided, the same value will be applied as
          the default value for every item. If an iterable of values is provided,
          the shape of the `default_value` should be equal to the given `shape`.
        dtype: defines the type of values. Default value is `tf.float32`. Must be a
          non-quantized, real integer or floating point type.
        normalizer_fn: If not `None`, a function that can be used to normalize the
          value of the tensor after `default_value` is applied for parsing.
          Normalizer function takes the input `Tensor` as its argument, and returns
          the output `Tensor`. (e.g. lambda x: (x - 3.0) / 4.2). Please note that
          even though the most common use case of this function is normalization, it
          can be used for any kind of Tensorflow transformations.
    
      Returns:
        A `NumericColumn`.
    
      Raises:
        TypeError: if any dimension in shape is not an int
        ValueError: if any dimension in shape is not a positive integer
        TypeError: if `default_value` is an iterable but not compatible with `shape`
        TypeError: if `default_value` is not compatible with `dtype`.
        ValueError: if `dtype` is not convertible to `tf.float32`.
      """
      shape = _check_shape(shape, key)
>     if not (dtype.is_integer or dtype.is_floating):
E     AttributeError: 'str' object has no attribute 'is_integer'

D:\Coding\Anaconda\envs\testagent-experiment\lib\site-packages\tensorflow\python\feature_column\feature_column_v2.py:1067: AttributeError

---------- coverage: platform win32, python 3.9.25-final-0 -----------
Name                                                               Stmts   Miss Branch BrPart  Cover   Missing
--------------------------------------------------------------------------------------------------------------
tests\test_tensorflow_python_feature_column_feature_column_v2.py     119     26     12      1    79%   29-32, 180-195, 244-261, 388-389, 394-395, 424
--------------------------------------------------------------------------------------------------------------
TOTAL                                                                119     26     12      1    79%
Coverage XML written to file coverage.xml

=========================== short test summary info ===========================
FAILED tests\test_tensorflow_python_feature_column_feature_column_v2.py::test_categorical_column_with_vocabulary_list_basic_creation[category-vocabulary_list1-dtype1-0-2]
FAILED tests\test_tensorflow_python_feature_column_feature_column_v2.py::test_bucketized_column_boundary_bucketing[age-boundaries0]
FAILED tests\test_tensorflow_python_feature_column_feature_column_v2.py::test_bucketized_column_boundary_bucketing[income-boundaries1]
FAILED tests\test_tensorflow_python_feature_column_feature_column_v2.py::test_embedding_column_dimension_validation[department-16-mean-True]
FAILED tests\test_tensorflow_python_feature_column_feature_column_v2.py::test_embedding_column_dimension_validation[product-32-sqrtn-False]
FAILED tests\test_tensorflow_python_feature_column_feature_column_v2.py::test_numeric_column_error_handling[-shape0-dtype0-None-None-key cannot be empty-ValueError]
FAILED tests\test_tensorflow_python_feature_column_feature_column_v2.py::test_numeric_column_error_handling[test-shape2-invalid-None-None-dtype-TypeError]
7 failed, 8 passed, 3 skipped in 1.66s

Error: exit 1