=== Run Tests ===
..FF.FFFF.FFFFsss..                                                      [100%]
================================== FAILURES ===================================
_ test_categorical_column_with_vocabulary_list_basic_creation[department-vocabulary_list0-None--1-0-False] _

key = 'department', vocabulary_list = ['math', 'philosophy', 'english']
dtype = None, default_value = -1, num_oov_buckets = 0, expect_error = False

    @pytest.mark.parametrize(
        "key,vocabulary_list,dtype,default_value,num_oov_buckets,expect_error",
        [
            # Base case from test plan - default_value only
            ("department", ["math", "philosophy", "english"], None, -1, 0, False),
            # Parameter extension - num_oov_buckets only (cannot have both default_value and num_oov_buckets)
            ("category", [1, 2, 3, 4, 5], tf.int64, None, 2, False),
            # Test case with both default_value and num_oov_buckets - should raise ValueError
            ("invalid", ["a", "b", "c"], None, 0, 2, True),
        ]
    )
    def test_categorical_column_with_vocabulary_list_basic_creation(
        key, vocabulary_list, dtype, default_value, num_oov_buckets, expect_error
    ):
        """Test categorical_column_with_vocabulary_list basic creation (CASE_02)"""
        # Import the function
        from tensorflow.python.feature_column.feature_column_v2 import categorical_column_with_vocabulary_list
    
        if expect_error:
            # Test that ValueError is raised when both default_value and num_oov_buckets are specified
            with pytest.raises(ValueError) as exc_info:
                column = categorical_column_with_vocabulary_list(
                    key=key,
                    vocabulary_list=vocabulary_list,
                    dtype=dtype,
                    default_value=default_value,
                    num_oov_buckets=num_oov_buckets
                )
            # Check error message mentions the conflict
            error_msg = str(exc_info.value).lower()
            assert "default_value" in error_msg or "num_oov_buckets" in error_msg
            return
    
        # Create the column
        # Note: TensorFlow's categorical_column_with_vocabulary_list has special handling:
        # - If default_value is None and num_oov_buckets > 0, default_value is set to -1 internally
        # - If default_value is provided, num_oov_buckets must be 0
        column = categorical_column_with_vocabulary_list(
            key=key,
            vocabulary_list=vocabulary_list,
            dtype=dtype,
            default_value=default_value,
            num_oov_buckets=num_oov_buckets
        )
    
        # Assert basic properties (weak assertions)
        assert column is not None
        assert hasattr(column, 'key')
        assert column.key == key
    
        # Check vocabulary_list - it might be stored as a list or tensor
        assert hasattr(column, 'vocabulary_list')
        # We can check that vocabulary_list is accessible
    
        # Check default_value - TensorFlow may set default_value to -1 internally when num_oov_buckets > 0
        if default_value is not None:
            assert hasattr(column, 'default_value')
            # Note: default_value might be -1 by default
        elif num_oov_buckets > 0:
            # When num_oov_buckets > 0 and default_value is None, TensorFlow sets default_value to -1
            assert hasattr(column, 'default_value')
            # The default_value should be -1 in this case
            assert column.default_value == -1
    
        # Check num_oov_buckets
        assert hasattr(column, 'num_oov_buckets')
        assert column.num_oov_buckets == num_oov_buckets
    
        # Check if it's a CategoricalColumn
        # Note: The actual class name might be different in TensorFlow
        # We'll check for common attributes instead of specific class
        assert hasattr(column, 'name')
        assert hasattr(column, 'parse_example_spec')
    
        # Additional test: verify vocabulary size
        vocab_size = len(vocabulary_list)
        if num_oov_buckets > 0:
            # With num_oov_buckets, the total vocabulary size should be vocab_size + num_oov_buckets
            assert hasattr(column, 'num_buckets')
            assert column.num_buckets == vocab_size + num_oov_buckets
        elif default_value is not None:
            # With default_value, the vocabulary size should be vocab_size
            assert hasattr(column, 'num_buckets')
            assert column.num_buckets == vocab_size
    
        # Test parse_example_spec returns a dictionary
        parse_spec = column.parse_example_spec
        assert isinstance(parse_spec, dict)
        assert key in parse_spec
        # The value should be a FixedLenFeature or VarLenFeature
        spec_value = parse_spec[key]
        assert hasattr(spec_value, 'dtype')
>       assert hasattr(spec_value, 'shape')
E       AssertionError: assert False
E        +  where False = hasattr(VarLenFeature(dtype=tf.string), 'shape')

tests\test_tensorflow_python_feature_column_feature_column_v2.py:176: AssertionError
_ test_categorical_column_with_vocabulary_list_basic_creation[category-vocabulary_list1-dtype1-None-2-False] _

key = 'category', vocabulary_list = [1, 2, 3, 4, 5], dtype = tf.int64
default_value = None, num_oov_buckets = 2, expect_error = False

    @pytest.mark.parametrize(
        "key,vocabulary_list,dtype,default_value,num_oov_buckets,expect_error",
        [
            # Base case from test plan - default_value only
            ("department", ["math", "philosophy", "english"], None, -1, 0, False),
            # Parameter extension - num_oov_buckets only (cannot have both default_value and num_oov_buckets)
            ("category", [1, 2, 3, 4, 5], tf.int64, None, 2, False),
            # Test case with both default_value and num_oov_buckets - should raise ValueError
            ("invalid", ["a", "b", "c"], None, 0, 2, True),
        ]
    )
    def test_categorical_column_with_vocabulary_list_basic_creation(
        key, vocabulary_list, dtype, default_value, num_oov_buckets, expect_error
    ):
        """Test categorical_column_with_vocabulary_list basic creation (CASE_02)"""
        # Import the function
        from tensorflow.python.feature_column.feature_column_v2 import categorical_column_with_vocabulary_list
    
        if expect_error:
            # Test that ValueError is raised when both default_value and num_oov_buckets are specified
            with pytest.raises(ValueError) as exc_info:
                column = categorical_column_with_vocabulary_list(
                    key=key,
                    vocabulary_list=vocabulary_list,
                    dtype=dtype,
                    default_value=default_value,
                    num_oov_buckets=num_oov_buckets
                )
            # Check error message mentions the conflict
            error_msg = str(exc_info.value).lower()
            assert "default_value" in error_msg or "num_oov_buckets" in error_msg
            return
    
        # Create the column
        # Note: TensorFlow's categorical_column_with_vocabulary_list has special handling:
        # - If default_value is None and num_oov_buckets > 0, default_value is set to -1 internally
        # - If default_value is provided, num_oov_buckets must be 0
>       column = categorical_column_with_vocabulary_list(
            key=key,
            vocabulary_list=vocabulary_list,
            dtype=dtype,
            default_value=default_value,
            num_oov_buckets=num_oov_buckets
        )

tests\test_tensorflow_python_feature_column_feature_column_v2.py:121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'category', vocabulary_list = [1, 2, 3, 4, 5], dtype = tf.int64
default_value = None, num_oov_buckets = 2

    @tf_export('feature_column.categorical_column_with_vocabulary_list')
    def categorical_column_with_vocabulary_list(key,
                                                vocabulary_list,
                                                dtype=None,
                                                default_value=-1,
                                                num_oov_buckets=0):
      """A `CategoricalColumn` with in-memory vocabulary.
    
      Use this when your inputs are in string or integer format, and you have an
      in-memory vocabulary mapping each value to an integer ID. By default,
      out-of-vocabulary values are ignored. Use either (but not both) of
      `num_oov_buckets` and `default_value` to specify how to include
      out-of-vocabulary values.
    
      For input dictionary `features`, `features[key]` is either `Tensor` or
      `SparseTensor`. If `Tensor`, missing values can be represented by `-1` for int
      and `''` for string, which will be dropped by this feature column.
    
      Example with `num_oov_buckets`:
      In the following example, each input in `vocabulary_list` is assigned an ID
      0-3 corresponding to its index (e.g., input 'B' produces output 2). All other
      inputs are hashed and assigned an ID 4-5.
    
      ```python
      colors = categorical_column_with_vocabulary_list(
          key='colors', vocabulary_list=('R', 'G', 'B', 'Y'),
          num_oov_buckets=2)
      columns = [colors, ...]
      features = tf.io.parse_example(..., features=make_parse_example_spec(columns))
      linear_prediction, _, _ = linear_model(features, columns)
      ```
    
      Example with `default_value`:
      In the following example, each input in `vocabulary_list` is assigned an ID
      0-4 corresponding to its index (e.g., input 'B' produces output 3). All other
      inputs are assigned `default_value` 0.
    
    
      ```python
      colors = categorical_column_with_vocabulary_list(
          key='colors', vocabulary_list=('X', 'R', 'G', 'B', 'Y'), default_value=0)
      columns = [colors, ...]
      features = tf.io.parse_example(..., features=make_parse_example_spec(columns))
      linear_prediction, _, _ = linear_model(features, columns)
      ```
    
      And to make an embedding with either:
    
      ```python
      columns = [embedding_column(colors, 3),...]
      features = tf.io.parse_example(..., features=make_parse_example_spec(columns))
      dense_tensor = input_layer(features, columns)
      ```
    
      Args:
        key: A unique string identifying the input feature. It is used as the column
          name and the dictionary key for feature parsing configs, feature `Tensor`
          objects, and feature columns.
        vocabulary_list: An ordered iterable defining the vocabulary. Each feature
          is mapped to the index of its value (if present) in `vocabulary_list`.
          Must be castable to `dtype`.
        dtype: The type of features. Only string and integer types are supported. If
          `None`, it will be inferred from `vocabulary_list`.
        default_value: The integer ID value to return for out-of-vocabulary feature
          values, defaults to `-1`. This can not be specified with a positive
          `num_oov_buckets`.
        num_oov_buckets: Non-negative integer, the number of out-of-vocabulary
          buckets. All out-of-vocabulary inputs will be assigned IDs in the range
          `[len(vocabulary_list), len(vocabulary_list)+num_oov_buckets)` based on a
          hash of the input value. A positive `num_oov_buckets` can not be specified
          with `default_value`.
    
      Returns:
        A `CategoricalColumn` with in-memory vocabulary.
    
      Raises:
        ValueError: if `vocabulary_list` is empty, or contains duplicate keys.
        ValueError: `num_oov_buckets` is a negative integer.
        ValueError: `num_oov_buckets` and `default_value` are both specified.
        ValueError: if `dtype` is not integer or string.
      """
      if (vocabulary_list is None) or (len(vocabulary_list) < 1):
        raise ValueError(
            'vocabulary_list {} must be non-empty, column_name: {}'.format(
                vocabulary_list, key))
      if len(set(vocabulary_list)) != len(vocabulary_list):
        raise ValueError(
            'Duplicate keys in vocabulary_list {}, column_name: {}'.format(
                vocabulary_list, key))
      vocabulary_dtype = dtypes.as_dtype(np.array(vocabulary_list).dtype)
      if num_oov_buckets:
        if default_value != -1:
>         raise ValueError(
              'Can\'t specify both num_oov_buckets and default_value in {}.'.format(
                  key))
E         ValueError: Can't specify both num_oov_buckets and default_value in category.

D:\Coding\Anaconda\envs\testagent-experiment\lib\site-packages\tensorflow\python\feature_column\feature_column_v2.py:1574: ValueError
_________ test_bucketized_column_boundary_bucketing[age-boundaries0] __________

source_column_key = 'age', boundaries = [18, 25, 30, 40, 50]

    @pytest.mark.parametrize(
        "source_column_key,boundaries",
        [
            # Base case from test plan
            ("age", [18, 25, 30, 40, 50]),
            # Parameter extension
            ("income", [1000, 5000, 10000, 50000, 100000]),
        ]
    )
    def test_bucketized_column_boundary_bucketing(source_column_key, boundaries):
        """Test bucketized_column boundary bucketing (CASE_03)"""
        # Import functions
        from tensorflow.python.feature_column.feature_column_v2 import (
            numeric_column, bucketized_column
        )
    
        # First create a source numeric column
        source_column = numeric_column(key=source_column_key, shape=(1,))
    
        # Create the bucketized column
        column = bucketized_column(
            source_column=source_column,
            boundaries=boundaries
        )
    
        # Assert basic properties (weak assertions)
        assert column is not None
    
        # Check source_column - bucketized column should have reference to source
        assert hasattr(column, 'source_column')
        assert column.source_column is source_column
    
        # Check boundaries
        assert hasattr(column, 'boundaries')
        # Boundaries might be stored as a tuple
        assert len(column.boundaries) == len(boundaries)
    
        # Check if it's a BucketizedColumn by checking for specific attributes
        # Bucketized columns should have num_buckets attribute
        assert hasattr(column, 'num_buckets')
        # Number of buckets should be len(boundaries) + 1
        assert column.num_buckets == len(boundaries) + 1
    
        # Check that column has a name (derived from source column)
        assert hasattr(column, 'name')
        # The name should contain the source column key
        assert source_column_key in column.name
    
        # Check that column has parse_example_spec method
        assert hasattr(column, 'parse_example_spec')
>       assert callable(column.parse_example_spec)
E       AssertionError: assert False
E        +  where False = callable({'age': FixedLenFeature(shape=(1,), dtype=tf.float32, default_value=None)})
E        +    where {'age': FixedLenFeature(shape=(1,), dtype=tf.float32, default_value=None)} = BucketizedColumn(source_column=NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(18, 25, 30, 40, 50)).parse_example_spec

tests\test_tensorflow_python_feature_column_feature_column_v2.py:230: AssertionError
________ test_bucketized_column_boundary_bucketing[income-boundaries1] ________

source_column_key = 'income', boundaries = [1000, 5000, 10000, 50000, 100000]

    @pytest.mark.parametrize(
        "source_column_key,boundaries",
        [
            # Base case from test plan
            ("age", [18, 25, 30, 40, 50]),
            # Parameter extension
            ("income", [1000, 5000, 10000, 50000, 100000]),
        ]
    )
    def test_bucketized_column_boundary_bucketing(source_column_key, boundaries):
        """Test bucketized_column boundary bucketing (CASE_03)"""
        # Import functions
        from tensorflow.python.feature_column.feature_column_v2 import (
            numeric_column, bucketized_column
        )
    
        # First create a source numeric column
        source_column = numeric_column(key=source_column_key, shape=(1,))
    
        # Create the bucketized column
        column = bucketized_column(
            source_column=source_column,
            boundaries=boundaries
        )
    
        # Assert basic properties (weak assertions)
        assert column is not None
    
        # Check source_column - bucketized column should have reference to source
        assert hasattr(column, 'source_column')
        assert column.source_column is source_column
    
        # Check boundaries
        assert hasattr(column, 'boundaries')
        # Boundaries might be stored as a tuple
        assert len(column.boundaries) == len(boundaries)
    
        # Check if it's a BucketizedColumn by checking for specific attributes
        # Bucketized columns should have num_buckets attribute
        assert hasattr(column, 'num_buckets')
        # Number of buckets should be len(boundaries) + 1
        assert column.num_buckets == len(boundaries) + 1
    
        # Check that column has a name (derived from source column)
        assert hasattr(column, 'name')
        # The name should contain the source column key
        assert source_column_key in column.name
    
        # Check that column has parse_example_spec method
        assert hasattr(column, 'parse_example_spec')
>       assert callable(column.parse_example_spec)
E       AssertionError: assert False
E        +  where False = callable({'income': FixedLenFeature(shape=(1,), dtype=tf.float32, default_value=None)})
E        +    where {'income': FixedLenFeature(shape=(1,), dtype=tf.float32, default_value=None)} = BucketizedColumn(source_column=NumericColumn(key='income', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(1000, 5000, 10000, 50000, 100000)).parse_example_spec

tests\test_tensorflow_python_feature_column_feature_column_v2.py:230: AssertionError
_____ test_embedding_column_dimension_validation[department-16-mean-True] _____

categorical_column_key = 'department', dimension = 16, combiner = 'mean'
trainable = True

    @pytest.mark.parametrize(
        "categorical_column_key,dimension,combiner,trainable",
        [
            # Base case from test plan
            ("department", 16, "mean", True),
            # Parameter extension
            ("product", 32, "sqrtn", False),
        ]
    )
    def test_embedding_column_dimension_validation(categorical_column_key, dimension, combiner, trainable):
        """Test embedding_column dimension validation (CASE_04)"""
        # Import functions
        from tensorflow.python.feature_column.feature_column_v2 import (
            categorical_column_with_vocabulary_list, embedding_column
        )
    
        # First create a categorical column
        categorical_column = categorical_column_with_vocabulary_list(
            key=categorical_column_key,
            vocabulary_list=["item1", "item2", "item3", "item4", "item5"]
        )
    
        # Create the embedding column
        column = embedding_column(
            categorical_column=categorical_column,
            dimension=dimension,
            combiner=combiner,
            trainable=trainable
        )
    
        # Assert basic properties (weak assertions)
        assert column is not None
    
        # Check categorical_column - embedding column should have reference to categorical column
        assert hasattr(column, 'categorical_column')
        assert column.categorical_column is categorical_column
    
        # Check dimension
        assert hasattr(column, 'dimension')
        assert column.dimension == dimension
    
        # Check combiner
        assert hasattr(column, 'combiner')
        assert column.combiner == combiner
    
        # Check trainable
        assert hasattr(column, 'trainable')
        assert column.trainable == trainable
    
        # Check if it's an EmbeddingColumn by checking for specific attributes
        # Embedding columns should have initializer attribute
        assert hasattr(column, 'initializer')
    
        # Check that column has a name (derived from categorical column)
        assert hasattr(column, 'name')
        # The name should contain the categorical column key
        assert categorical_column_key in column.name
    
        # Check that column has parse_example_spec method
        assert hasattr(column, 'parse_example_spec')
>       assert callable(column.parse_example_spec)
E       AssertionError: assert False
E        +  where False = callable({'department': VarLenFeature(dtype=tf.string)})
E        +    where {'department': VarLenFeature(dtype=tf.string)} = EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='department', vocabulary_list=('item1', 'item2'...9A00>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True).parse_example_spec

tests\test_tensorflow_python_feature_column_feature_column_v2.py:324: AssertionError
_____ test_embedding_column_dimension_validation[product-32-sqrtn-False] ______

categorical_column_key = 'product', dimension = 32, combiner = 'sqrtn'
trainable = False

    @pytest.mark.parametrize(
        "categorical_column_key,dimension,combiner,trainable",
        [
            # Base case from test plan
            ("department", 16, "mean", True),
            # Parameter extension
            ("product", 32, "sqrtn", False),
        ]
    )
    def test_embedding_column_dimension_validation(categorical_column_key, dimension, combiner, trainable):
        """Test embedding_column dimension validation (CASE_04)"""
        # Import functions
        from tensorflow.python.feature_column.feature_column_v2 import (
            categorical_column_with_vocabulary_list, embedding_column
        )
    
        # First create a categorical column
        categorical_column = categorical_column_with_vocabulary_list(
            key=categorical_column_key,
            vocabulary_list=["item1", "item2", "item3", "item4", "item5"]
        )
    
        # Create the embedding column
        column = embedding_column(
            categorical_column=categorical_column,
            dimension=dimension,
            combiner=combiner,
            trainable=trainable
        )
    
        # Assert basic properties (weak assertions)
        assert column is not None
    
        # Check categorical_column - embedding column should have reference to categorical column
        assert hasattr(column, 'categorical_column')
        assert column.categorical_column is categorical_column
    
        # Check dimension
        assert hasattr(column, 'dimension')
        assert column.dimension == dimension
    
        # Check combiner
        assert hasattr(column, 'combiner')
        assert column.combiner == combiner
    
        # Check trainable
        assert hasattr(column, 'trainable')
        assert column.trainable == trainable
    
        # Check if it's an EmbeddingColumn by checking for specific attributes
        # Embedding columns should have initializer attribute
        assert hasattr(column, 'initializer')
    
        # Check that column has a name (derived from categorical column)
        assert hasattr(column, 'name')
        # The name should contain the categorical column key
        assert categorical_column_key in column.name
    
        # Check that column has parse_example_spec method
        assert hasattr(column, 'parse_example_spec')
>       assert callable(column.parse_example_spec)
E       AssertionError: assert False
E        +  where False = callable({'product': VarLenFeature(dtype=tf.string)})
E        +    where {'product': VarLenFeature(dtype=tf.string)} = EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='product', vocabulary_list=('item1', 'item2', '...AC0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=False, use_safe_embedding_lookup=True).parse_example_spec

tests\test_tensorflow_python_feature_column_feature_column_v2.py:324: AssertionError
_ test_numeric_column_error_handling[test-shape1-dtype1-None-None-shape-ValueError] _

key = 'test', shape = (0,), dtype = tf.float32, default_value = None
normalizer_fn = None, expected_exception = 'shape'
expected_exception_type = <class 'ValueError'>

    @pytest.mark.parametrize(
        "key,shape,dtype,default_value,normalizer_fn,expected_exception,expected_exception_type",
        [
            # Empty key - TensorFlow might not raise error for empty string
            # Let's test what actually happens
            ("", (1,), tf.float32, None, None, None, None),
            # Invalid shape (0) should raise ValueError
            ("test", (0,), tf.float32, None, None, "shape", ValueError),
            # Invalid dtype string should raise TypeError or ValueError
            ("test", (1,), "invalid", None, None, "dtype", (TypeError, ValueError)),
            # Type mismatch for default_value should raise TypeError
            ("test", (1,), tf.float32, "wrong_type", None, "default_value", TypeError),
            # Non-callable normalizer_fn should raise TypeError
            ("test", (1,), tf.float32, None, "not_callable", "normalizer_fn", TypeError),
        ]
    )
    def test_numeric_column_error_handling(
        key, shape, dtype, default_value, normalizer_fn,
        expected_exception, expected_exception_type
    ):
        """Test numeric_column error handling (CASE_05)"""
        # Import the function
        from tensorflow.python.feature_column.feature_column_v2 import numeric_column
    
        # Special case: empty key
        if key == "":
            # Test what happens with empty key
            try:
                column = numeric_column(key=key, shape=shape, dtype=dtype)
                # If no exception is raised, that's OK - just verify the column
                assert column is not None
                assert hasattr(column, 'key')
                assert column.key == key
                return
            except Exception as e:
                # If exception is raised, verify it's the expected type
                assert isinstance(e, (ValueError, TypeError))
                return
    
        # Special case: invalid dtype string
        if dtype == "invalid":
            # TensorFlow expects a tf.DType object, not a string
            # We need to test with actual invalid dtype
            with pytest.raises((TypeError, ValueError)) as exc_info:
                # Try to create column with invalid dtype
                # Note: TensorFlow might accept string dtype like "float32" in some versions
                # Let's test with truly invalid value
                try:
                    # First try with string "invalid"
                    column = numeric_column(
                        key=key,
                        shape=shape,
                        dtype=dtype,
                        default_value=default_value
                    )
                except (TypeError, ValueError) as e:
                    # Re-raise to be caught by pytest.raises
                    raise e
                except Exception as e:
                    # If it's a different exception, convert to TypeError/ValueError
                    raise TypeError(f"Unexpected error: {e}")
    
            # Check that error message mentions dtype
            error_msg = str(exc_info.value).lower()
            # The error might mention "dtype", "float", or "type"
            assert any(word in error_msg for word in ["dtype", "float", "type", "invalid"])
            return
    
        # For other test cases
        if expected_exception_type is not None:
            # Handle case where expected_exception_type could be a tuple
            if isinstance(expected_exception_type, tuple):
                with pytest.raises(expected_exception_type) as exc_info:
                    if normalizer_fn is not None:
                        column = numeric_column(
                            key=key,
                            shape=shape,
                            dtype=dtype,
                            default_value=default_value,
                            normalizer_fn=normalizer_fn
                        )
                    else:
                        column = numeric_column(
                            key=key,
                            shape=shape,
                            dtype=dtype,
                            default_value=default_value
                        )
            else:
                with pytest.raises(expected_exception_type) as exc_info:
                    if normalizer_fn is not None:
                        column = numeric_column(
                            key=key,
                            shape=shape,
                            dtype=dtype,
                            default_value=default_value,
                            normalizer_fn=normalizer_fn
                        )
                    else:
                        column = numeric_column(
                            key=key,
                            shape=shape,
                            dtype=dtype,
                            default_value=default_value
                        )
    
            # Check that the exception message contains expected text if provided
            if expected_exception:
                error_msg = str(exc_info.value).lower()
                assert expected_exception.lower() in error_msg
    
        # Additional test for invalid shape with negative values
        if shape == (0,):
            # Test negative shape
            with pytest.raises(ValueError) as exc_info:
                numeric_column(key="test", shape=(-1,))
            error_msg = str(exc_info.value).lower()
            assert "shape" in error_msg or "positive" in error_msg
    
        # Test for None key - should raise TypeError or ValueError
        with pytest.raises((TypeError, ValueError)) as exc_info:
            numeric_column(key=None, shape=(1,))
        error_msg = str(exc_info.value).lower()
        assert "key" in error_msg or "none" in error_msg
    
        # Test for non-integer shape
        with pytest.raises(TypeError) as exc_info:
            numeric_column(key="test", shape=("invalid",))
        error_msg = str(exc_info.value).lower()
        assert "int" in error_msg or "integer" in error_msg
    
        # Test for invalid dtype object (not a tf.DType)
        with pytest.raises((TypeError, ValueError)) as exc_info:
>           numeric_column(key="test", shape=(1,), dtype=object)

tests\test_tensorflow_python_feature_column_feature_column_v2.py:502: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'test', shape = (1,), default_value = None, dtype = <class 'object'>
normalizer_fn = None

    @tf_export('feature_column.numeric_column')
    def numeric_column(key,
                       shape=(1,),
                       default_value=None,
                       dtype=dtypes.float32,
                       normalizer_fn=None):
      """Represents real valued or numerical features.
    
      Example:
    
      Assume we have data with two features `a` and `b`.
    
      >>> data = {'a': [15, 9, 17, 19, 21, 18, 25, 30],
      ...    'b': [5.0, 6.4, 10.5, 13.6, 15.7, 19.9, 20.3 , 0.0]}
    
      Let us represent the features `a` and `b` as numerical features.
    
      >>> a = tf.feature_column.numeric_column('a')
      >>> b = tf.feature_column.numeric_column('b')
    
      Feature column describe a set of transformations to the inputs.
    
      For example, to "bucketize" feature `a`, wrap the `a` column in a
      `feature_column.bucketized_column`.
      Providing `5` bucket boundaries, the bucketized_column api
      will bucket this feature in total of `6` buckets.
    
      >>> a_buckets = tf.feature_column.bucketized_column(a,
      ...    boundaries=[10, 15, 20, 25, 30])
    
      Create a `DenseFeatures` layer which will apply the transformations
      described by the set of `tf.feature_column` objects:
    
      >>> feature_layer = tf.keras.layers.DenseFeatures([a_buckets, b])
      >>> print(feature_layer(data))
      tf.Tensor(
      [[ 0.   0.   1.   0.   0.   0.   5. ]
       [ 1.   0.   0.   0.   0.   0.   6.4]
       [ 0.   0.   1.   0.   0.   0.  10.5]
       [ 0.   0.   1.   0.   0.   0.  13.6]
       [ 0.   0.   0.   1.   0.   0.  15.7]
       [ 0.   0.   1.   0.   0.   0.  19.9]
       [ 0.   0.   0.   0.   1.   0.  20.3]
       [ 0.   0.   0.   0.   0.   1.   0. ]], shape=(8, 7), dtype=float32)
    
      Args:
        key: A unique string identifying the input feature. It is used as the
          column name and the dictionary key for feature parsing configs, feature
          `Tensor` objects, and feature columns.
        shape: An iterable of integers specifies the shape of the `Tensor`. An
          integer can be given which means a single dimension `Tensor` with given
          width. The `Tensor` representing the column will have the shape of
          [batch_size] + `shape`.
        default_value: A single value compatible with `dtype` or an iterable of
          values compatible with `dtype` which the column takes on during
          `tf.Example` parsing if data is missing. A default value of `None` will
          cause `tf.io.parse_example` to fail if an example does not contain this
          column. If a single value is provided, the same value will be applied as
          the default value for every item. If an iterable of values is provided,
          the shape of the `default_value` should be equal to the given `shape`.
        dtype: defines the type of values. Default value is `tf.float32`. Must be a
          non-quantized, real integer or floating point type.
        normalizer_fn: If not `None`, a function that can be used to normalize the
          value of the tensor after `default_value` is applied for parsing.
          Normalizer function takes the input `Tensor` as its argument, and returns
          the output `Tensor`. (e.g. lambda x: (x - 3.0) / 4.2). Please note that
          even though the most common use case of this function is normalization, it
          can be used for any kind of Tensorflow transformations.
    
      Returns:
        A `NumericColumn`.
    
      Raises:
        TypeError: if any dimension in shape is not an int
        ValueError: if any dimension in shape is not a positive integer
        TypeError: if `default_value` is an iterable but not compatible with `shape`
        TypeError: if `default_value` is not compatible with `dtype`.
        ValueError: if `dtype` is not convertible to `tf.float32`.
      """
      shape = _check_shape(shape, key)
>     if not (dtype.is_integer or dtype.is_floating):
E     AttributeError: type object 'object' has no attribute 'is_integer'

D:\Coding\Anaconda\envs\testagent-experiment\lib\site-packages\tensorflow\python\feature_column\feature_column_v2.py:1067: AttributeError
_ test_numeric_column_error_handling[test-shape2-invalid-None-None-dtype-expected_exception_type2] _

key = 'test', shape = (1,), dtype = 'invalid', default_value = None
normalizer_fn = None, expected_exception = 'dtype'
expected_exception_type = (<class 'TypeError'>, <class 'ValueError'>)

    @pytest.mark.parametrize(
        "key,shape,dtype,default_value,normalizer_fn,expected_exception,expected_exception_type",
        [
            # Empty key - TensorFlow might not raise error for empty string
            # Let's test what actually happens
            ("", (1,), tf.float32, None, None, None, None),
            # Invalid shape (0) should raise ValueError
            ("test", (0,), tf.float32, None, None, "shape", ValueError),
            # Invalid dtype string should raise TypeError or ValueError
            ("test", (1,), "invalid", None, None, "dtype", (TypeError, ValueError)),
            # Type mismatch for default_value should raise TypeError
            ("test", (1,), tf.float32, "wrong_type", None, "default_value", TypeError),
            # Non-callable normalizer_fn should raise TypeError
            ("test", (1,), tf.float32, None, "not_callable", "normalizer_fn", TypeError),
        ]
    )
    def test_numeric_column_error_handling(
        key, shape, dtype, default_value, normalizer_fn,
        expected_exception, expected_exception_type
    ):
        """Test numeric_column error handling (CASE_05)"""
        # Import the function
        from tensorflow.python.feature_column.feature_column_v2 import numeric_column
    
        # Special case: empty key
        if key == "":
            # Test what happens with empty key
            try:
                column = numeric_column(key=key, shape=shape, dtype=dtype)
                # If no exception is raised, that's OK - just verify the column
                assert column is not None
                assert hasattr(column, 'key')
                assert column.key == key
                return
            except Exception as e:
                # If exception is raised, verify it's the expected type
                assert isinstance(e, (ValueError, TypeError))
                return
    
        # Special case: invalid dtype string
        if dtype == "invalid":
            # TensorFlow expects a tf.DType object, not a string
            # We need to test with actual invalid dtype
            with pytest.raises((TypeError, ValueError)) as exc_info:
                # Try to create column with invalid dtype
                # Note: TensorFlow might accept string dtype like "float32" in some versions
                # Let's test with truly invalid value
                try:
                    # First try with string "invalid"
                    column = numeric_column(
                        key=key,
                        shape=shape,
                        dtype=dtype,
                        default_value=default_value
                    )
                except (TypeError, ValueError) as e:
                    # Re-raise to be caught by pytest.raises
                    raise e
                except Exception as e:
                    # If it's a different exception, convert to TypeError/ValueError
                    raise TypeError(f"Unexpected error: {e}")
    
            # Check that error message mentions dtype
            error_msg = str(exc_info.value).lower()
            # The error might mention "dtype", "float", or "type"
>           assert any(word in error_msg for word in ["dtype", "float", "type", "invalid"])
E           assert False
E            +  where False = any(<generator object test_numeric_column_error_handling.<locals>.<genexpr> at 0x000001F4DAE07510>)

tests\test_tensorflow_python_feature_column_feature_column_v2.py:434: AssertionError
_ test_numeric_column_error_handling[test-shape3-dtype3-wrong_type-None-default_value-TypeError] _

key = 'test', shape = (1,), dtype = tf.float32, default_value = 'wrong_type'
normalizer_fn = None, expected_exception = 'default_value'
expected_exception_type = <class 'TypeError'>

    @pytest.mark.parametrize(
        "key,shape,dtype,default_value,normalizer_fn,expected_exception,expected_exception_type",
        [
            # Empty key - TensorFlow might not raise error for empty string
            # Let's test what actually happens
            ("", (1,), tf.float32, None, None, None, None),
            # Invalid shape (0) should raise ValueError
            ("test", (0,), tf.float32, None, None, "shape", ValueError),
            # Invalid dtype string should raise TypeError or ValueError
            ("test", (1,), "invalid", None, None, "dtype", (TypeError, ValueError)),
            # Type mismatch for default_value should raise TypeError
            ("test", (1,), tf.float32, "wrong_type", None, "default_value", TypeError),
            # Non-callable normalizer_fn should raise TypeError
            ("test", (1,), tf.float32, None, "not_callable", "normalizer_fn", TypeError),
        ]
    )
    def test_numeric_column_error_handling(
        key, shape, dtype, default_value, normalizer_fn,
        expected_exception, expected_exception_type
    ):
        """Test numeric_column error handling (CASE_05)"""
        # Import the function
        from tensorflow.python.feature_column.feature_column_v2 import numeric_column
    
        # Special case: empty key
        if key == "":
            # Test what happens with empty key
            try:
                column = numeric_column(key=key, shape=shape, dtype=dtype)
                # If no exception is raised, that's OK - just verify the column
                assert column is not None
                assert hasattr(column, 'key')
                assert column.key == key
                return
            except Exception as e:
                # If exception is raised, verify it's the expected type
                assert isinstance(e, (ValueError, TypeError))
                return
    
        # Special case: invalid dtype string
        if dtype == "invalid":
            # TensorFlow expects a tf.DType object, not a string
            # We need to test with actual invalid dtype
            with pytest.raises((TypeError, ValueError)) as exc_info:
                # Try to create column with invalid dtype
                # Note: TensorFlow might accept string dtype like "float32" in some versions
                # Let's test with truly invalid value
                try:
                    # First try with string "invalid"
                    column = numeric_column(
                        key=key,
                        shape=shape,
                        dtype=dtype,
                        default_value=default_value
                    )
                except (TypeError, ValueError) as e:
                    # Re-raise to be caught by pytest.raises
                    raise e
                except Exception as e:
                    # If it's a different exception, convert to TypeError/ValueError
                    raise TypeError(f"Unexpected error: {e}")
    
            # Check that error message mentions dtype
            error_msg = str(exc_info.value).lower()
            # The error might mention "dtype", "float", or "type"
            assert any(word in error_msg for word in ["dtype", "float", "type", "invalid"])
            return
    
        # For other test cases
        if expected_exception_type is not None:
            # Handle case where expected_exception_type could be a tuple
            if isinstance(expected_exception_type, tuple):
                with pytest.raises(expected_exception_type) as exc_info:
                    if normalizer_fn is not None:
                        column = numeric_column(
                            key=key,
                            shape=shape,
                            dtype=dtype,
                            default_value=default_value,
                            normalizer_fn=normalizer_fn
                        )
                    else:
                        column = numeric_column(
                            key=key,
                            shape=shape,
                            dtype=dtype,
                            default_value=default_value
                        )
            else:
                with pytest.raises(expected_exception_type) as exc_info:
                    if normalizer_fn is not None:
                        column = numeric_column(
                            key=key,
                            shape=shape,
                            dtype=dtype,
                            default_value=default_value,
                            normalizer_fn=normalizer_fn
                        )
                    else:
                        column = numeric_column(
                            key=key,
                            shape=shape,
                            dtype=dtype,
                            default_value=default_value
                        )
    
            # Check that the exception message contains expected text if provided
            if expected_exception:
                error_msg = str(exc_info.value).lower()
                assert expected_exception.lower() in error_msg
    
        # Additional test for invalid shape with negative values
        if shape == (0,):
            # Test negative shape
            with pytest.raises(ValueError) as exc_info:
                numeric_column(key="test", shape=(-1,))
            error_msg = str(exc_info.value).lower()
            assert "shape" in error_msg or "positive" in error_msg
    
        # Test for None key - should raise TypeError or ValueError
        with pytest.raises((TypeError, ValueError)) as exc_info:
            numeric_column(key=None, shape=(1,))
        error_msg = str(exc_info.value).lower()
        assert "key" in error_msg or "none" in error_msg
    
        # Test for non-integer shape
        with pytest.raises(TypeError) as exc_info:
            numeric_column(key="test", shape=("invalid",))
        error_msg = str(exc_info.value).lower()
        assert "int" in error_msg or "integer" in error_msg
    
        # Test for invalid dtype object (not a tf.DType)
        with pytest.raises((TypeError, ValueError)) as exc_info:
>           numeric_column(key="test", shape=(1,), dtype=object)

tests\test_tensorflow_python_feature_column_feature_column_v2.py:502: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'test', shape = (1,), default_value = None, dtype = <class 'object'>
normalizer_fn = None

    @tf_export('feature_column.numeric_column')
    def numeric_column(key,
                       shape=(1,),
                       default_value=None,
                       dtype=dtypes.float32,
                       normalizer_fn=None):
      """Represents real valued or numerical features.
    
      Example:
    
      Assume we have data with two features `a` and `b`.
    
      >>> data = {'a': [15, 9, 17, 19, 21, 18, 25, 30],
      ...    'b': [5.0, 6.4, 10.5, 13.6, 15.7, 19.9, 20.3 , 0.0]}
    
      Let us represent the features `a` and `b` as numerical features.
    
      >>> a = tf.feature_column.numeric_column('a')
      >>> b = tf.feature_column.numeric_column('b')
    
      Feature column describe a set of transformations to the inputs.
    
      For example, to "bucketize" feature `a`, wrap the `a` column in a
      `feature_column.bucketized_column`.
      Providing `5` bucket boundaries, the bucketized_column api
      will bucket this feature in total of `6` buckets.
    
      >>> a_buckets = tf.feature_column.bucketized_column(a,
      ...    boundaries=[10, 15, 20, 25, 30])
    
      Create a `DenseFeatures` layer which will apply the transformations
      described by the set of `tf.feature_column` objects:
    
      >>> feature_layer = tf.keras.layers.DenseFeatures([a_buckets, b])
      >>> print(feature_layer(data))
      tf.Tensor(
      [[ 0.   0.   1.   0.   0.   0.   5. ]
       [ 1.   0.   0.   0.   0.   0.   6.4]
       [ 0.   0.   1.   0.   0.   0.  10.5]
       [ 0.   0.   1.   0.   0.   0.  13.6]
       [ 0.   0.   0.   1.   0.   0.  15.7]
       [ 0.   0.   1.   0.   0.   0.  19.9]
       [ 0.   0.   0.   0.   1.   0.  20.3]
       [ 0.   0.   0.   0.   0.   1.   0. ]], shape=(8, 7), dtype=float32)
    
      Args:
        key: A unique string identifying the input feature. It is used as the
          column name and the dictionary key for feature parsing configs, feature
          `Tensor` objects, and feature columns.
        shape: An iterable of integers specifies the shape of the `Tensor`. An
          integer can be given which means a single dimension `Tensor` with given
          width. The `Tensor` representing the column will have the shape of
          [batch_size] + `shape`.
        default_value: A single value compatible with `dtype` or an iterable of
          values compatible with `dtype` which the column takes on during
          `tf.Example` parsing if data is missing. A default value of `None` will
          cause `tf.io.parse_example` to fail if an example does not contain this
          column. If a single value is provided, the same value will be applied as
          the default value for every item. If an iterable of values is provided,
          the shape of the `default_value` should be equal to the given `shape`.
        dtype: defines the type of values. Default value is `tf.float32`. Must be a
          non-quantized, real integer or floating point type.
        normalizer_fn: If not `None`, a function that can be used to normalize the
          value of the tensor after `default_value` is applied for parsing.
          Normalizer function takes the input `Tensor` as its argument, and returns
          the output `Tensor`. (e.g. lambda x: (x - 3.0) / 4.2). Please note that
          even though the most common use case of this function is normalization, it
          can be used for any kind of Tensorflow transformations.
    
      Returns:
        A `NumericColumn`.
    
      Raises:
        TypeError: if any dimension in shape is not an int
        ValueError: if any dimension in shape is not a positive integer
        TypeError: if `default_value` is an iterable but not compatible with `shape`
        TypeError: if `default_value` is not compatible with `dtype`.
        ValueError: if `dtype` is not convertible to `tf.float32`.
      """
      shape = _check_shape(shape, key)
>     if not (dtype.is_integer or dtype.is_floating):
E     AttributeError: type object 'object' has no attribute 'is_integer'

D:\Coding\Anaconda\envs\testagent-experiment\lib\site-packages\tensorflow\python\feature_column\feature_column_v2.py:1067: AttributeError
_ test_numeric_column_error_handling[test-shape4-dtype4-None-not_callable-normalizer_fn-TypeError] _

key = 'test', shape = (1,), dtype = tf.float32, default_value = None
normalizer_fn = 'not_callable', expected_exception = 'normalizer_fn'
expected_exception_type = <class 'TypeError'>

    @pytest.mark.parametrize(
        "key,shape,dtype,default_value,normalizer_fn,expected_exception,expected_exception_type",
        [
            # Empty key - TensorFlow might not raise error for empty string
            # Let's test what actually happens
            ("", (1,), tf.float32, None, None, None, None),
            # Invalid shape (0) should raise ValueError
            ("test", (0,), tf.float32, None, None, "shape", ValueError),
            # Invalid dtype string should raise TypeError or ValueError
            ("test", (1,), "invalid", None, None, "dtype", (TypeError, ValueError)),
            # Type mismatch for default_value should raise TypeError
            ("test", (1,), tf.float32, "wrong_type", None, "default_value", TypeError),
            # Non-callable normalizer_fn should raise TypeError
            ("test", (1,), tf.float32, None, "not_callable", "normalizer_fn", TypeError),
        ]
    )
    def test_numeric_column_error_handling(
        key, shape, dtype, default_value, normalizer_fn,
        expected_exception, expected_exception_type
    ):
        """Test numeric_column error handling (CASE_05)"""
        # Import the function
        from tensorflow.python.feature_column.feature_column_v2 import numeric_column
    
        # Special case: empty key
        if key == "":
            # Test what happens with empty key
            try:
                column = numeric_column(key=key, shape=shape, dtype=dtype)
                # If no exception is raised, that's OK - just verify the column
                assert column is not None
                assert hasattr(column, 'key')
                assert column.key == key
                return
            except Exception as e:
                # If exception is raised, verify it's the expected type
                assert isinstance(e, (ValueError, TypeError))
                return
    
        # Special case: invalid dtype string
        if dtype == "invalid":
            # TensorFlow expects a tf.DType object, not a string
            # We need to test with actual invalid dtype
            with pytest.raises((TypeError, ValueError)) as exc_info:
                # Try to create column with invalid dtype
                # Note: TensorFlow might accept string dtype like "float32" in some versions
                # Let's test with truly invalid value
                try:
                    # First try with string "invalid"
                    column = numeric_column(
                        key=key,
                        shape=shape,
                        dtype=dtype,
                        default_value=default_value
                    )
                except (TypeError, ValueError) as e:
                    # Re-raise to be caught by pytest.raises
                    raise e
                except Exception as e:
                    # If it's a different exception, convert to TypeError/ValueError
                    raise TypeError(f"Unexpected error: {e}")
    
            # Check that error message mentions dtype
            error_msg = str(exc_info.value).lower()
            # The error might mention "dtype", "float", or "type"
            assert any(word in error_msg for word in ["dtype", "float", "type", "invalid"])
            return
    
        # For other test cases
        if expected_exception_type is not None:
            # Handle case where expected_exception_type could be a tuple
            if isinstance(expected_exception_type, tuple):
                with pytest.raises(expected_exception_type) as exc_info:
                    if normalizer_fn is not None:
                        column = numeric_column(
                            key=key,
                            shape=shape,
                            dtype=dtype,
                            default_value=default_value,
                            normalizer_fn=normalizer_fn
                        )
                    else:
                        column = numeric_column(
                            key=key,
                            shape=shape,
                            dtype=dtype,
                            default_value=default_value
                        )
            else:
                with pytest.raises(expected_exception_type) as exc_info:
                    if normalizer_fn is not None:
                        column = numeric_column(
                            key=key,
                            shape=shape,
                            dtype=dtype,
                            default_value=default_value,
                            normalizer_fn=normalizer_fn
                        )
                    else:
                        column = numeric_column(
                            key=key,
                            shape=shape,
                            dtype=dtype,
                            default_value=default_value
                        )
    
            # Check that the exception message contains expected text if provided
            if expected_exception:
                error_msg = str(exc_info.value).lower()
                assert expected_exception.lower() in error_msg
    
        # Additional test for invalid shape with negative values
        if shape == (0,):
            # Test negative shape
            with pytest.raises(ValueError) as exc_info:
                numeric_column(key="test", shape=(-1,))
            error_msg = str(exc_info.value).lower()
            assert "shape" in error_msg or "positive" in error_msg
    
        # Test for None key - should raise TypeError or ValueError
        with pytest.raises((TypeError, ValueError)) as exc_info:
            numeric_column(key=None, shape=(1,))
        error_msg = str(exc_info.value).lower()
        assert "key" in error_msg or "none" in error_msg
    
        # Test for non-integer shape
        with pytest.raises(TypeError) as exc_info:
            numeric_column(key="test", shape=("invalid",))
        error_msg = str(exc_info.value).lower()
        assert "int" in error_msg or "integer" in error_msg
    
        # Test for invalid dtype object (not a tf.DType)
        with pytest.raises((TypeError, ValueError)) as exc_info:
>           numeric_column(key="test", shape=(1,), dtype=object)

tests\test_tensorflow_python_feature_column_feature_column_v2.py:502: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'test', shape = (1,), default_value = None, dtype = <class 'object'>
normalizer_fn = None

    @tf_export('feature_column.numeric_column')
    def numeric_column(key,
                       shape=(1,),
                       default_value=None,
                       dtype=dtypes.float32,
                       normalizer_fn=None):
      """Represents real valued or numerical features.
    
      Example:
    
      Assume we have data with two features `a` and `b`.
    
      >>> data = {'a': [15, 9, 17, 19, 21, 18, 25, 30],
      ...    'b': [5.0, 6.4, 10.5, 13.6, 15.7, 19.9, 20.3 , 0.0]}
    
      Let us represent the features `a` and `b` as numerical features.
    
      >>> a = tf.feature_column.numeric_column('a')
      >>> b = tf.feature_column.numeric_column('b')
    
      Feature column describe a set of transformations to the inputs.
    
      For example, to "bucketize" feature `a`, wrap the `a` column in a
      `feature_column.bucketized_column`.
      Providing `5` bucket boundaries, the bucketized_column api
      will bucket this feature in total of `6` buckets.
    
      >>> a_buckets = tf.feature_column.bucketized_column(a,
      ...    boundaries=[10, 15, 20, 25, 30])
    
      Create a `DenseFeatures` layer which will apply the transformations
      described by the set of `tf.feature_column` objects:
    
      >>> feature_layer = tf.keras.layers.DenseFeatures([a_buckets, b])
      >>> print(feature_layer(data))
      tf.Tensor(
      [[ 0.   0.   1.   0.   0.   0.   5. ]
       [ 1.   0.   0.   0.   0.   0.   6.4]
       [ 0.   0.   1.   0.   0.   0.  10.5]
       [ 0.   0.   1.   0.   0.   0.  13.6]
       [ 0.   0.   0.   1.   0.   0.  15.7]
       [ 0.   0.   1.   0.   0.   0.  19.9]
       [ 0.   0.   0.   0.   1.   0.  20.3]
       [ 0.   0.   0.   0.   0.   1.   0. ]], shape=(8, 7), dtype=float32)
    
      Args:
        key: A unique string identifying the input feature. It is used as the
          column name and the dictionary key for feature parsing configs, feature
          `Tensor` objects, and feature columns.
        shape: An iterable of integers specifies the shape of the `Tensor`. An
          integer can be given which means a single dimension `Tensor` with given
          width. The `Tensor` representing the column will have the shape of
          [batch_size] + `shape`.
        default_value: A single value compatible with `dtype` or an iterable of
          values compatible with `dtype` which the column takes on during
          `tf.Example` parsing if data is missing. A default value of `None` will
          cause `tf.io.parse_example` to fail if an example does not contain this
          column. If a single value is provided, the same value will be applied as
          the default value for every item. If an iterable of values is provided,
          the shape of the `default_value` should be equal to the given `shape`.
        dtype: defines the type of values. Default value is `tf.float32`. Must be a
          non-quantized, real integer or floating point type.
        normalizer_fn: If not `None`, a function that can be used to normalize the
          value of the tensor after `default_value` is applied for parsing.
          Normalizer function takes the input `Tensor` as its argument, and returns
          the output `Tensor`. (e.g. lambda x: (x - 3.0) / 4.2). Please note that
          even though the most common use case of this function is normalization, it
          can be used for any kind of Tensorflow transformations.
    
      Returns:
        A `NumericColumn`.
    
      Raises:
        TypeError: if any dimension in shape is not an int
        ValueError: if any dimension in shape is not a positive integer
        TypeError: if `default_value` is an iterable but not compatible with `shape`
        TypeError: if `default_value` is not compatible with `dtype`.
        ValueError: if `dtype` is not convertible to `tf.float32`.
      """
      shape = _check_shape(shape, key)
>     if not (dtype.is_integer or dtype.is_floating):
E     AttributeError: type object 'object' has no attribute 'is_integer'

D:\Coding\Anaconda\envs\testagent-experiment\lib\site-packages\tensorflow\python\feature_column\feature_column_v2.py:1067: AttributeError

---------- coverage: platform win32, python 3.9.25-final-0 -----------
Name                                                               Stmts   Miss Branch BrPart  Cover   Missing
--------------------------------------------------------------------------------------------------------------
tests\test_tensorflow_python_feature_column_feature_column_v2.py     211     56     34      7    73%   17-20, 142-146, 162-163, 164->170, 233-260, 327-365, 403-406, 426, 435, 438->481, 441-451, 476->481, 503-504, 567-568, 573-574, 603
--------------------------------------------------------------------------------------------------------------
TOTAL                                                                211     56     34      7    73%
Coverage XML written to file coverage.xml

=========================== short test summary info ===========================
FAILED tests\test_tensorflow_python_feature_column_feature_column_v2.py::test_categorical_column_with_vocabulary_list_basic_creation[department-vocabulary_list0-None--1-0-False]
FAILED tests\test_tensorflow_python_feature_column_feature_column_v2.py::test_categorical_column_with_vocabulary_list_basic_creation[category-vocabulary_list1-dtype1-None-2-False]
FAILED tests\test_tensorflow_python_feature_column_feature_column_v2.py::test_bucketized_column_boundary_bucketing[age-boundaries0]
FAILED tests\test_tensorflow_python_feature_column_feature_column_v2.py::test_bucketized_column_boundary_bucketing[income-boundaries1]
FAILED tests\test_tensorflow_python_feature_column_feature_column_v2.py::test_embedding_column_dimension_validation[department-16-mean-True]
FAILED tests\test_tensorflow_python_feature_column_feature_column_v2.py::test_embedding_column_dimension_validation[product-32-sqrtn-False]
FAILED tests\test_tensorflow_python_feature_column_feature_column_v2.py::test_numeric_column_error_handling[test-shape1-dtype1-None-None-shape-ValueError]
FAILED tests\test_tensorflow_python_feature_column_feature_column_v2.py::test_numeric_column_error_handling[test-shape2-invalid-None-None-dtype-expected_exception_type2]
FAILED tests\test_tensorflow_python_feature_column_feature_column_v2.py::test_numeric_column_error_handling[test-shape3-dtype3-wrong_type-None-default_value-TypeError]
FAILED tests\test_tensorflow_python_feature_column_feature_column_v2.py::test_numeric_column_error_handling[test-shape4-dtype4-None-not_callable-normalizer_fn-TypeError]
10 failed, 6 passed, 3 skipped in 1.80s

Error: exit 1