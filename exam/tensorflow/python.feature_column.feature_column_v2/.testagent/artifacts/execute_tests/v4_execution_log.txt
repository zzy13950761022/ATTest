=== Run Tests ===
...F.FFFF..F..sss..                                                      [100%]
================================== FAILURES ===================================
_ test_categorical_column_with_vocabulary_list_basic_creation[category-vocabulary_list1-dtype1-None-2-False] _

key = 'category', vocabulary_list = [1, 2, 3, 4, 5], dtype = tf.int64
default_value = None, num_oov_buckets = 2, expect_error = False

    @pytest.mark.parametrize(
        "key,vocabulary_list,dtype,default_value,num_oov_buckets,expect_error",
        [
            # Base case from test plan - default_value only
            ("department", ["math", "philosophy", "english"], None, -1, 0, False),
            # Parameter extension - num_oov_buckets only (cannot have both default_value and num_oov_buckets)
            ("category", [1, 2, 3, 4, 5], tf.int64, None, 2, False),
            # Test case with both default_value and num_oov_buckets - should raise ValueError
            ("invalid", ["a", "b", "c"], None, 0, 2, True),
        ]
    )
    def test_categorical_column_with_vocabulary_list_basic_creation(
        key, vocabulary_list, dtype, default_value, num_oov_buckets, expect_error
    ):
        """Test categorical_column_with_vocabulary_list basic creation (CASE_02)"""
        # Import the function
        from tensorflow.python.feature_column.feature_column_v2 import categorical_column_with_vocabulary_list
    
        if expect_error:
            # Test that ValueError is raised when both default_value and num_oov_buckets are specified
            with pytest.raises(ValueError) as exc_info:
                column = categorical_column_with_vocabulary_list(
                    key=key,
                    vocabulary_list=vocabulary_list,
                    dtype=dtype,
                    default_value=default_value,
                    num_oov_buckets=num_oov_buckets
                )
            # Check error message mentions the conflict
            error_msg = str(exc_info.value).lower()
            assert "default_value" in error_msg or "num_oov_buckets" in error_msg
            return
    
        # Create the column
        # Note: TensorFlow's categorical_column_with_vocabulary_list has special handling:
        # - If default_value is None and num_oov_buckets > 0, default_value is set to -1 internally
        # - If default_value is provided, num_oov_buckets must be 0
>       column = categorical_column_with_vocabulary_list(
            key=key,
            vocabulary_list=vocabulary_list,
            dtype=dtype,
            default_value=default_value,
            num_oov_buckets=num_oov_buckets
        )

tests\test_tensorflow_python_feature_column_feature_column_v2.py:121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

key = 'category', vocabulary_list = [1, 2, 3, 4, 5], dtype = tf.int64
default_value = None, num_oov_buckets = 2

    @tf_export('feature_column.categorical_column_with_vocabulary_list')
    def categorical_column_with_vocabulary_list(key,
                                                vocabulary_list,
                                                dtype=None,
                                                default_value=-1,
                                                num_oov_buckets=0):
      """A `CategoricalColumn` with in-memory vocabulary.
    
      Use this when your inputs are in string or integer format, and you have an
      in-memory vocabulary mapping each value to an integer ID. By default,
      out-of-vocabulary values are ignored. Use either (but not both) of
      `num_oov_buckets` and `default_value` to specify how to include
      out-of-vocabulary values.
    
      For input dictionary `features`, `features[key]` is either `Tensor` or
      `SparseTensor`. If `Tensor`, missing values can be represented by `-1` for int
      and `''` for string, which will be dropped by this feature column.
    
      Example with `num_oov_buckets`:
      In the following example, each input in `vocabulary_list` is assigned an ID
      0-3 corresponding to its index (e.g., input 'B' produces output 2). All other
      inputs are hashed and assigned an ID 4-5.
    
      ```python
      colors = categorical_column_with_vocabulary_list(
          key='colors', vocabulary_list=('R', 'G', 'B', 'Y'),
          num_oov_buckets=2)
      columns = [colors, ...]
      features = tf.io.parse_example(..., features=make_parse_example_spec(columns))
      linear_prediction, _, _ = linear_model(features, columns)
      ```
    
      Example with `default_value`:
      In the following example, each input in `vocabulary_list` is assigned an ID
      0-4 corresponding to its index (e.g., input 'B' produces output 3). All other
      inputs are assigned `default_value` 0.
    
    
      ```python
      colors = categorical_column_with_vocabulary_list(
          key='colors', vocabulary_list=('X', 'R', 'G', 'B', 'Y'), default_value=0)
      columns = [colors, ...]
      features = tf.io.parse_example(..., features=make_parse_example_spec(columns))
      linear_prediction, _, _ = linear_model(features, columns)
      ```
    
      And to make an embedding with either:
    
      ```python
      columns = [embedding_column(colors, 3),...]
      features = tf.io.parse_example(..., features=make_parse_example_spec(columns))
      dense_tensor = input_layer(features, columns)
      ```
    
      Args:
        key: A unique string identifying the input feature. It is used as the column
          name and the dictionary key for feature parsing configs, feature `Tensor`
          objects, and feature columns.
        vocabulary_list: An ordered iterable defining the vocabulary. Each feature
          is mapped to the index of its value (if present) in `vocabulary_list`.
          Must be castable to `dtype`.
        dtype: The type of features. Only string and integer types are supported. If
          `None`, it will be inferred from `vocabulary_list`.
        default_value: The integer ID value to return for out-of-vocabulary feature
          values, defaults to `-1`. This can not be specified with a positive
          `num_oov_buckets`.
        num_oov_buckets: Non-negative integer, the number of out-of-vocabulary
          buckets. All out-of-vocabulary inputs will be assigned IDs in the range
          `[len(vocabulary_list), len(vocabulary_list)+num_oov_buckets)` based on a
          hash of the input value. A positive `num_oov_buckets` can not be specified
          with `default_value`.
    
      Returns:
        A `CategoricalColumn` with in-memory vocabulary.
    
      Raises:
        ValueError: if `vocabulary_list` is empty, or contains duplicate keys.
        ValueError: `num_oov_buckets` is a negative integer.
        ValueError: `num_oov_buckets` and `default_value` are both specified.
        ValueError: if `dtype` is not integer or string.
      """
      if (vocabulary_list is None) or (len(vocabulary_list) < 1):
        raise ValueError(
            'vocabulary_list {} must be non-empty, column_name: {}'.format(
                vocabulary_list, key))
      if len(set(vocabulary_list)) != len(vocabulary_list):
        raise ValueError(
            'Duplicate keys in vocabulary_list {}, column_name: {}'.format(
                vocabulary_list, key))
      vocabulary_dtype = dtypes.as_dtype(np.array(vocabulary_list).dtype)
      if num_oov_buckets:
        if default_value != -1:
>         raise ValueError(
              'Can\'t specify both num_oov_buckets and default_value in {}.'.format(
                  key))
E         ValueError: Can't specify both num_oov_buckets and default_value in category.

D:\Coding\Anaconda\envs\testagent-experiment\lib\site-packages\tensorflow\python\feature_column\feature_column_v2.py:1574: ValueError
_________ test_bucketized_column_boundary_bucketing[age-boundaries0] __________

source_column_key = 'age', boundaries = [18, 25, 30, 40, 50]

    @pytest.mark.parametrize(
        "source_column_key,boundaries",
        [
            # Base case from test plan
            ("age", [18, 25, 30, 40, 50]),
            # Parameter extension
            ("income", [1000, 5000, 10000, 50000, 100000]),
        ]
    )
    def test_bucketized_column_boundary_bucketing(source_column_key, boundaries):
        """Test bucketized_column boundary bucketing (CASE_03)"""
        # Import functions
        from tensorflow.python.feature_column.feature_column_v2 import (
            numeric_column, bucketized_column
        )
    
        # First create a source numeric column
        source_column = numeric_column(key=source_column_key, shape=(1,))
    
        # Create the bucketized column
        column = bucketized_column(
            source_column=source_column,
            boundaries=boundaries
        )
    
        # Assert basic properties (weak assertions)
        assert column is not None
    
        # Check source_column - bucketized column should have reference to source
        assert hasattr(column, 'source_column')
        assert column.source_column is source_column
    
        # Check boundaries
        assert hasattr(column, 'boundaries')
        # Boundaries might be stored as a tuple
        assert len(column.boundaries) == len(boundaries)
    
        # Check if it's a BucketizedColumn by checking for specific attributes
        # Bucketized columns should have num_buckets attribute
        assert hasattr(column, 'num_buckets')
        # Number of buckets should be len(boundaries) + 1
        assert column.num_buckets == len(boundaries) + 1
    
        # Check that column has a name (derived from source column)
        assert hasattr(column, 'name')
        # The name should contain the source column key
        assert source_column_key in column.name
    
        # Check that column has parse_example_spec attribute (not method)
        assert hasattr(column, 'parse_example_spec')
        # parse_example_spec is a property, not a callable method
        # It should return a dictionary
        parse_spec = column.parse_example_spec
        assert isinstance(parse_spec, dict)
        # The key should be the column's name
>       assert column.name in parse_spec
E       AssertionError: assert 'age_bucketized' in {'age': FixedLenFeature(shape=(1,), dtype=tf.float32, default_value=None)}
E        +  where 'age_bucketized' = BucketizedColumn(source_column=NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(18, 25, 30, 40, 50)).name

tests\test_tensorflow_python_feature_column_feature_column_v2.py:244: AssertionError
________ test_bucketized_column_boundary_bucketing[income-boundaries1] ________

source_column_key = 'income', boundaries = [1000, 5000, 10000, 50000, 100000]

    @pytest.mark.parametrize(
        "source_column_key,boundaries",
        [
            # Base case from test plan
            ("age", [18, 25, 30, 40, 50]),
            # Parameter extension
            ("income", [1000, 5000, 10000, 50000, 100000]),
        ]
    )
    def test_bucketized_column_boundary_bucketing(source_column_key, boundaries):
        """Test bucketized_column boundary bucketing (CASE_03)"""
        # Import functions
        from tensorflow.python.feature_column.feature_column_v2 import (
            numeric_column, bucketized_column
        )
    
        # First create a source numeric column
        source_column = numeric_column(key=source_column_key, shape=(1,))
    
        # Create the bucketized column
        column = bucketized_column(
            source_column=source_column,
            boundaries=boundaries
        )
    
        # Assert basic properties (weak assertions)
        assert column is not None
    
        # Check source_column - bucketized column should have reference to source
        assert hasattr(column, 'source_column')
        assert column.source_column is source_column
    
        # Check boundaries
        assert hasattr(column, 'boundaries')
        # Boundaries might be stored as a tuple
        assert len(column.boundaries) == len(boundaries)
    
        # Check if it's a BucketizedColumn by checking for specific attributes
        # Bucketized columns should have num_buckets attribute
        assert hasattr(column, 'num_buckets')
        # Number of buckets should be len(boundaries) + 1
        assert column.num_buckets == len(boundaries) + 1
    
        # Check that column has a name (derived from source column)
        assert hasattr(column, 'name')
        # The name should contain the source column key
        assert source_column_key in column.name
    
        # Check that column has parse_example_spec attribute (not method)
        assert hasattr(column, 'parse_example_spec')
        # parse_example_spec is a property, not a callable method
        # It should return a dictionary
        parse_spec = column.parse_example_spec
        assert isinstance(parse_spec, dict)
        # The key should be the column's name
>       assert column.name in parse_spec
E       AssertionError: assert 'income_bucketized' in {'income': FixedLenFeature(shape=(1,), dtype=tf.float32, default_value=None)}
E        +  where 'income_bucketized' = BucketizedColumn(source_column=NumericColumn(key='income', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(1000, 5000, 10000, 50000, 100000)).name

tests\test_tensorflow_python_feature_column_feature_column_v2.py:244: AssertionError
_____ test_embedding_column_dimension_validation[department-16-mean-True] _____

categorical_column_key = 'department', dimension = 16, combiner = 'mean'
trainable = True

    @pytest.mark.parametrize(
        "categorical_column_key,dimension,combiner,trainable",
        [
            # Base case from test plan
            ("department", 16, "mean", True),
            # Parameter extension
            ("product", 32, "sqrtn", False),
        ]
    )
    def test_embedding_column_dimension_validation(categorical_column_key, dimension, combiner, trainable):
        """Test embedding_column dimension validation (CASE_04)"""
        # Import functions
        from tensorflow.python.feature_column.feature_column_v2 import (
            categorical_column_with_vocabulary_list, embedding_column
        )
    
        # First create a categorical column
        categorical_column = categorical_column_with_vocabulary_list(
            key=categorical_column_key,
            vocabulary_list=["item1", "item2", "item3", "item4", "item5"]
        )
    
        # Create the embedding column
        column = embedding_column(
            categorical_column=categorical_column,
            dimension=dimension,
            combiner=combiner,
            trainable=trainable
        )
    
        # Assert basic properties (weak assertions)
        assert column is not None
    
        # Check categorical_column - embedding column should have reference to categorical column
        assert hasattr(column, 'categorical_column')
        assert column.categorical_column is categorical_column
    
        # Check dimension
        assert hasattr(column, 'dimension')
        assert column.dimension == dimension
    
        # Check combiner
        assert hasattr(column, 'combiner')
        assert column.combiner == combiner
    
        # Check trainable
        assert hasattr(column, 'trainable')
        assert column.trainable == trainable
    
        # Check if it's an EmbeddingColumn by checking for specific attributes
        # Embedding columns should have initializer attribute
        assert hasattr(column, 'initializer')
    
        # Check that column has a name (derived from categorical column)
        assert hasattr(column, 'name')
        # The name should contain the categorical column key
        assert categorical_column_key in column.name
    
        # Check that column has parse_example_spec attribute (not method)
        assert hasattr(column, 'parse_example_spec')
        # parse_example_spec is a property, not a callable method
        # It should return a dictionary
        parse_spec = column.parse_example_spec
        assert isinstance(parse_spec, dict)
        # The key should be the column's name
>       assert column.name in parse_spec
E       AssertionError: assert 'department_embedding' in {'department': VarLenFeature(dtype=tf.string)}
E        +  where 'department_embedding' = EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='department', vocabulary_list=('item1', 'item2'...E490>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True).name

tests\test_tensorflow_python_feature_column_feature_column_v2.py:337: AssertionError
_____ test_embedding_column_dimension_validation[product-32-sqrtn-False] ______

categorical_column_key = 'product', dimension = 32, combiner = 'sqrtn'
trainable = False

    @pytest.mark.parametrize(
        "categorical_column_key,dimension,combiner,trainable",
        [
            # Base case from test plan
            ("department", 16, "mean", True),
            # Parameter extension
            ("product", 32, "sqrtn", False),
        ]
    )
    def test_embedding_column_dimension_validation(categorical_column_key, dimension, combiner, trainable):
        """Test embedding_column dimension validation (CASE_04)"""
        # Import functions
        from tensorflow.python.feature_column.feature_column_v2 import (
            categorical_column_with_vocabulary_list, embedding_column
        )
    
        # First create a categorical column
        categorical_column = categorical_column_with_vocabulary_list(
            key=categorical_column_key,
            vocabulary_list=["item1", "item2", "item3", "item4", "item5"]
        )
    
        # Create the embedding column
        column = embedding_column(
            categorical_column=categorical_column,
            dimension=dimension,
            combiner=combiner,
            trainable=trainable
        )
    
        # Assert basic properties (weak assertions)
        assert column is not None
    
        # Check categorical_column - embedding column should have reference to categorical column
        assert hasattr(column, 'categorical_column')
        assert column.categorical_column is categorical_column
    
        # Check dimension
        assert hasattr(column, 'dimension')
        assert column.dimension == dimension
    
        # Check combiner
        assert hasattr(column, 'combiner')
        assert column.combiner == combiner
    
        # Check trainable
        assert hasattr(column, 'trainable')
        assert column.trainable == trainable
    
        # Check if it's an EmbeddingColumn by checking for specific attributes
        # Embedding columns should have initializer attribute
        assert hasattr(column, 'initializer')
    
        # Check that column has a name (derived from categorical column)
        assert hasattr(column, 'name')
        # The name should contain the categorical column key
        assert categorical_column_key in column.name
    
        # Check that column has parse_example_spec attribute (not method)
        assert hasattr(column, 'parse_example_spec')
        # parse_example_spec is a property, not a callable method
        # It should return a dictionary
        parse_spec = column.parse_example_spec
        assert isinstance(parse_spec, dict)
        # The key should be the column's name
>       assert column.name in parse_spec
E       AssertionError: assert 'product_embedding' in {'product': VarLenFeature(dtype=tf.string)}
E        +  where 'product_embedding' = EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='product', vocabulary_list=('item1', 'item2', '...490>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=False, use_safe_embedding_lookup=True).name

tests\test_tensorflow_python_feature_column_feature_column_v2.py:337: AssertionError
_ test_numeric_column_error_handling[test-shape2-invalid-None-None-dtype-expected_exception_type2] _

key = 'test', shape = (1,), dtype = 'invalid', default_value = None
normalizer_fn = None, expected_exception = 'dtype'
expected_exception_type = (<class 'TypeError'>, <class 'ValueError'>)

    @pytest.mark.parametrize(
        "key,shape,dtype,default_value,normalizer_fn,expected_exception,expected_exception_type",
        [
            # Empty key - TensorFlow might not raise error for empty string
            # Let's test what actually happens
            ("", (1,), tf.float32, None, None, None, None),
            # Invalid shape (0) should raise ValueError
            ("test", (0,), tf.float32, None, None, "shape", ValueError),
            # Invalid dtype string should raise TypeError or ValueError
            ("test", (1,), "invalid", None, None, "dtype", (TypeError, ValueError)),
            # Type mismatch for default_value should raise TypeError
            ("test", (1,), tf.float32, "wrong_type", None, "default_value", TypeError),
            # Non-callable normalizer_fn should raise TypeError
            ("test", (1,), tf.float32, None, "not_callable", "normalizer_fn", TypeError),
        ]
    )
    def test_numeric_column_error_handling(
        key, shape, dtype, default_value, normalizer_fn,
        expected_exception, expected_exception_type
    ):
        """Test numeric_column error handling (CASE_05)"""
        # Import the function
        from tensorflow.python.feature_column.feature_column_v2 import numeric_column
    
        # Special case: empty key
        if key == "":
            # Test what happens with empty key
            try:
                column = numeric_column(key=key, shape=shape, dtype=dtype)
                # If no exception is raised, that's OK - just verify the column
                assert column is not None
                assert hasattr(column, 'key')
                assert column.key == key
                return
            except Exception as e:
                # If exception is raised, verify it's the expected type
                assert isinstance(e, (ValueError, TypeError))
                return
    
        # Special case: invalid dtype string
        if dtype == "invalid":
            # TensorFlow expects a tf.DType object, not a string
            # We need to test with actual invalid dtype
            with pytest.raises((TypeError, ValueError)) as exc_info:
                # Try to create column with invalid dtype
                # Note: TensorFlow might accept string dtype like "float32" in some versions
                # Let's test with truly invalid value
                try:
                    # First try with string "invalid"
                    column = numeric_column(
                        key=key,
                        shape=shape,
                        dtype=dtype,
                        default_value=default_value
                    )
                except (TypeError, ValueError) as e:
                    # Re-raise to be caught by pytest.raises
                    raise e
                except Exception as e:
                    # If it's a different exception, convert to TypeError/ValueError
                    raise TypeError(f"Unexpected error: {e}")
    
            # Check that error message mentions dtype
            error_msg = str(exc_info.value).lower()
            # The error might mention "dtype", "float", or "type"
            # Note: TensorFlow might raise different errors for invalid dtype strings
            # We'll be more flexible in our assertion
>           assert any(word in error_msg for word in ["dtype", "float", "type", "invalid", "string", "value"])
E           assert False
E            +  where False = any(<generator object test_numeric_column_error_handling.<locals>.<genexpr> at 0x000001DAC16280B0>)

tests\test_tensorflow_python_feature_column_feature_column_v2.py:443: AssertionError

---------- coverage: platform win32, python 3.9.25-final-0 -----------
Name                                                               Stmts   Miss Branch BrPart  Cover   Missing
--------------------------------------------------------------------------------------------------------------
tests\test_tensorflow_python_feature_column_feature_column_v2.py     211     48     42      9    76%   17-20, 142-146, 162-163, 164->170, 180, 246-268, 339-372, 410-413, 433, 444, 447->496, 450-460, 485->496, 492->496, 580-581, 586-587, 616
--------------------------------------------------------------------------------------------------------------
TOTAL                                                                211     48     42      9    76%
Coverage XML written to file coverage.xml

=========================== short test summary info ===========================
FAILED tests\test_tensorflow_python_feature_column_feature_column_v2.py::test_categorical_column_with_vocabulary_list_basic_creation[category-vocabulary_list1-dtype1-None-2-False]
FAILED tests\test_tensorflow_python_feature_column_feature_column_v2.py::test_bucketized_column_boundary_bucketing[age-boundaries0]
FAILED tests\test_tensorflow_python_feature_column_feature_column_v2.py::test_bucketized_column_boundary_bucketing[income-boundaries1]
FAILED tests\test_tensorflow_python_feature_column_feature_column_v2.py::test_embedding_column_dimension_validation[department-16-mean-True]
FAILED tests\test_tensorflow_python_feature_column_feature_column_v2.py::test_embedding_column_dimension_validation[product-32-sqrtn-False]
FAILED tests\test_tensorflow_python_feature_column_feature_column_v2.py::test_numeric_column_error_handling[test-shape2-invalid-None-None-dtype-expected_exception_type2]
6 failed, 10 passed, 3 skipped in 1.67s

Error: exit 1