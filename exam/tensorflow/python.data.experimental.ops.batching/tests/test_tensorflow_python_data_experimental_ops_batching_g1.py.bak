"""
Test cases for tensorflow.python.data.experimental.ops.batching module - Group G1.
Generated by ATTest.
"""
import numpy as np
import pytest
import tensorflow as tf
from tensorflow.python.data.experimental.ops import batching

# Set random seed for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# ==== BLOCK:HEADER START ====
# Test class for dense_to_ragged_batch operations
class TestDenseToRaggedBatch:
    """Test cases for dense_to_ragged_batch operation."""
    
    def setup_method(self):
        """Setup method for each test."""
        pass
    
    def teardown_method(self):
        """Teardown method for each test."""
        pass
# ==== BLOCK:HEADER END ====

# ==== BLOCK:CASE_01 START ====
    @pytest.mark.parametrize("batch_size,drop_remainder,row_splits_dtype,input_shape,data_type", [
        (2, False, tf.int64, "varying", tf.float32),
        (1, False, tf.int64, "single_element", tf.float32),  # param extension
        (5, False, tf.int32, "large_variation", tf.int32),   # param extension
    ])
    def test_dense_to_ragged_batch_basic(self, batch_size, drop_remainder, 
                                        row_splits_dtype, input_shape, data_type,
                                        random_tensor_generator):
        """Test basic functionality of dense_to_ragged_batch (CASE_01)."""
        # Generate test data
        tensors = random_tensor_generator(shape_type=input_shape, dtype=data_type)
        
        # Create dataset using from_generator to handle varying shapes
        def tensor_generator():
            for tensor in tensors:
                yield tensor
        
        # Get output signature based on data type
        if data_type == tf.float32:
            output_signature = tf.TensorSpec(shape=None, dtype=tf.float32)
        elif data_type == tf.int32:
            output_signature = tf.TensorSpec(shape=None, dtype=tf.int32)
        elif data_type == tf.int64:
            output_signature = tf.TensorSpec(shape=None, dtype=tf.int64)
        elif data_type == tf.float64:
            output_signature = tf.TensorSpec(shape=None, dtype=tf.float64)
        else:
            output_signature = tf.TensorSpec(shape=None, dtype=tf.float32)
        
        dataset = tf.data.Dataset.from_generator(
            tensor_generator,
            output_signature=output_signature
        )
        
        # Apply dense_to_ragged_batch transformation
        batch_transform = batching.dense_to_ragged_batch(
            batch_size=batch_size,
            drop_remainder=drop_remainder,
            row_splits_dtype=row_splits_dtype
        )
        batched_dataset = dataset.apply(batch_transform)
        
        # Collect batches
        batches = list(batched_dataset.as_numpy_iterator())
        
        # Weak assertions
        assert len(batches) > 0, "Should produce at least one batch"
        
        # Check each batch
        for batch in batches:
            # Output type assertion
            assert isinstance(batch, (np.ndarray, tf.RaggedTensor)), \
                f"Batch should be ndarray or RaggedTensor, got {type(batch)}"
            
            # Batch size assertion (for full batches)
            if isinstance(batch, tf.RaggedTensor):
                batch_dim = batch.shape[0]
                if batch_dim is not None:
                    # For the last batch with drop_remainder=False, size may be smaller
                    if not drop_remainder and batch is batches[-1]:
                        # Last batch can be smaller
                        assert batch_dim <= batch_size, \
                            f"Last batch size {batch_dim} should be ≤ {batch_size}"
                    else:
                        assert batch_dim == batch_size, \
                            f"Batch size {batch_dim} should equal {batch_size}"
                
                # Row splits dtype assertion
                if hasattr(batch, 'row_splits'):
                    assert batch.row_splits.dtype == row_splits_dtype, \
                        f"Row splits dtype {batch.row_splits.dtype} should be {row_splits_dtype}"
            
            # Element shape consistency
            if isinstance(batch, tf.RaggedTensor) and batch.flat_values is not None:
                # All values should have same dtype as input
                assert batch.flat_values.dtype == data_type, \
                    f"Values dtype {batch.flat_values.dtype} should match input {data_type}"
        
        # Additional validation: total elements should be preserved
        total_input_elements = sum(tf.size(t).numpy() for t in tensors)
        total_batched_elements = 0
        for batch in batches:
            if isinstance(batch, tf.RaggedTensor):
                total_batched_elements += tf.size(batch.flat_values).numpy()
            else:
                total_batched_elements += tf.size(batch).numpy()
        
        assert total_batched_elements == total_input_elements, \
            f"Total elements mismatch: {total_batched_elements} != {total_input_elements}"
# ==== BLOCK:CASE_01 END ====

# ==== BLOCK:CASE_02 START ====
    def test_dense_to_ragged_batch_drop_remainder(self, random_tensor_generator):
        """Test drop_remainder parameter behavior (CASE_02)."""
        # Test parameters from test_plan
        batch_size = 3
        drop_remainder = True
        row_splits_dtype = tf.int32
        input_shape = "fixed"
        data_type = tf.int32
        
        # Generate test data with 7 elements (2 full batches + 1 remainder)
        tensors = random_tensor_generator(shape_type=input_shape, dtype=data_type)
        # Ensure we have exactly 7 elements for testing
        while len(tensors) < 7:
            tensors.append(tensors[0])
        tensors = tensors[:7]
        
        dataset = tf.data.Dataset.from_tensor_slices(tensors)
        
        # Apply dense_to_ragged_batch with drop_remainder=True
        batch_transform = batching.dense_to_ragged_batch(
            batch_size=batch_size,
            drop_remainder=drop_remainder,
            row_splits_dtype=row_splits_dtype
        )
        batched_dataset = dataset.apply(batch_transform)
        
        # Collect batches
        batches = list(batched_dataset.as_numpy_iterator())
        
        # Weak assertions
        # Batch count assertion: with 7 elements and batch_size=3, drop_remainder=True
        # should produce 2 batches (drops the 1 remaining element)
        expected_batch_count = len(tensors) // batch_size  # 7 // 3 = 2
        assert len(batches) == expected_batch_count, \
            f"With drop_remainder=True, expected {expected_batch_count} batches, got {len(batches)}"
        
        # Remainder handling assertion: all batches should have exact batch_size
        for i, batch in enumerate(batches):
            if isinstance(batch, tf.RaggedTensor):
                batch_dim = batch.shape[0]
                assert batch_dim == batch_size, \
                    f"Batch {i} size {batch_dim} should equal {batch_size} with drop_remainder=True"
                
                # Row splits dtype assertion
                assert batch.row_splits.dtype == row_splits_dtype, \
                    f"Row splits dtype {batch.row_splits.dtype} should be {row_splits_dtype}"
        
        # Output shape consistency
        if len(batches) > 0:
            first_batch = batches[0]
            for batch in batches[1:]:
                # All batches should have same rank
                if isinstance(first_batch, tf.RaggedTensor) and isinstance(batch, tf.RaggedTensor):
                    assert len(first_batch.shape) == len(batch.shape), \
                        "All batches should have same rank"
        
        # Test with drop_remainder=False for comparison
        batch_transform_no_drop = batching.dense_to_ragged_batch(
            batch_size=batch_size,
            drop_remainder=False,
            row_splits_dtype=row_splits_dtype
        )
        batched_dataset_no_drop = dataset.apply(batch_transform_no_drop)
        batches_no_drop = list(batched_dataset_no_drop.as_numpy_iterator())
        
        # With drop_remainder=False, should have 3 batches (2 full + 1 partial)
        assert len(batches_no_drop) == expected_batch_count + 1, \
            f"With drop_remainder=False, expected {expected_batch_count + 1} batches, got {len(batches_no_drop)}"
        
        # Last batch should be smaller
        if len(batches_no_drop) > 0:
            last_batch = batches_no_drop[-1]
            if isinstance(last_batch, tf.RaggedTensor):
                last_batch_size = last_batch.shape[0]
                expected_last_size = len(tensors) % batch_size  # 7 % 3 = 1
                if last_batch_size is not None:
                    assert last_batch_size == expected_last_size, \
                        f"Last batch size {last_batch_size} should be {expected_last_size}"
# ==== BLOCK:CASE_02 END ====

# ==== BLOCK:CASE_05 START ====
# Placeholder for CASE_05: DEFERRED SET - dense_to_ragged_batch 边界情况
# ==== BLOCK:CASE_05 END ====

# ==== BLOCK:FOOTER START ====
# Additional helper functions and fixtures

@pytest.fixture
def random_tensor_generator():
    """Generate random tensors with varying shapes."""
    def _generator(shape_type="varying", dtype=tf.float32):
        if shape_type == "varying":
            # Generate tensors with varying shapes
            shapes = [
                (2,),      # 1D vector
                (3, 4),    # 2D matrix
                (1, 5, 2), # 3D tensor
                (4,),      # Another 1D vector
                (2, 3),    # Another 2D matrix
            ]
        elif shape_type == "fixed":
            # All tensors have same shape
            shapes = [(3, 4)] * 5
        elif shape_type == "single_element":
            # Single element tensors
            shapes = [(1,)] * 5
        elif shape_type == "large_variation":
            # Large variation in shapes
            shapes = [
                (1,), (10,), (2, 5), (3, 3, 3), (1, 2, 3, 4)
            ]
        else:
            shapes = [(2, 3)] * 5
            
        tensors = []
        for shape in shapes:
            if dtype == tf.float32:
                data = np.random.randn(*shape).astype(np.float32)
            elif dtype == tf.int32:
                data = np.random.randint(0, 10, shape, dtype=np.int32)
            elif dtype == tf.int64:
                data = np.random.randint(0, 10, shape, dtype=np.int64)
            elif dtype == tf.float64:
                data = np.random.randn(*shape).astype(np.float64)
            else:
                data = np.random.randn(*shape).astype(np.float32)
            tensors.append(tf.constant(data, dtype=dtype))
        return tensors
    return _generator

def assert_ragged_tensor_properties(rt, expected_batch_size=None, 
                                   expected_row_splits_dtype=tf.int64):
    """Assert basic properties of a RaggedTensor."""
    assert isinstance(rt, tf.RaggedTensor), "Output should be a RaggedTensor"
    if expected_batch_size is not None:
        assert rt.shape[0] == expected_batch_size, f"Batch size mismatch: {rt.shape[0]} != {expected_batch_size}"
    assert rt.row_splits.dtype == expected_row_splits_dtype, f"Row splits dtype mismatch: {rt.row_splits.dtype} != {expected_row_splits_dtype}"
    return True
# ==== BLOCK:FOOTER END ====