"""
Test cases for tensorflow.python.data.experimental.ops.prefetching_ops
Group G1: prefetch_to_device核心功能
"""
import math
import pytest
import tensorflow as tf
from tensorflow.python.data.experimental.ops.prefetching_ops import prefetch_to_device, copy_to_device

# ==== BLOCK:HEADER START ====
# Test fixtures and helper functions
@pytest.fixture
def tf_seed():
    """Set TensorFlow random seed for reproducibility."""
    tf.random.set_seed(42)
    return 42

def create_tensor_slices_dataset(data_shape, dtype, num_elements=None):
    """Create a tf.data.Dataset from tensor slices."""
    if num_elements is None:
        num_elements = data_shape[0] if data_shape else 1
    
    if dtype == "int32":
        data = tf.range(num_elements, dtype=tf.int32)
    elif dtype == "float32":
        data = tf.range(num_elements, dtype=tf.float32)
    elif dtype == "float64":
        data = tf.range(num_elements, dtype=tf.float64)
    elif dtype == "int64":
        data = tf.range(num_elements, dtype=tf.int64)
    else:
        raise ValueError(f"Unsupported dtype: {dtype}")
    
    # Reshape if needed
    if len(data_shape) > 1:
        total_elements = 1
        for dim in data_shape:
            total_elements *= dim
        data = tf.reshape(tf.range(total_elements, dtype=getattr(tf, dtype)), data_shape)
    
    return tf.data.Dataset.from_tensor_slices(data)

def create_empty_dataset(dtype="int32"):
    """Create an empty dataset."""
    if dtype == "int32":
        data = tf.constant([], dtype=tf.int32)
    else:
        data = tf.constant([], dtype=getattr(tf, dtype))
    return tf.data.Dataset.from_tensor_slices(data)

# Test cases for helper functions to improve coverage
def test_create_tensor_slices_dataset_basic():
    """Test basic functionality of create_tensor_slices_dataset."""
    # Test with int32
    dataset = create_tensor_slices_dataset([5], "int32")
    iterator = iter(dataset)
    elements = list(iterator)
    assert len(elements) == 5
    assert all(elem.dtype == tf.int32 for elem in elements)
    
    # Test with float32
    dataset = create_tensor_slices_dataset([3], "float32")
    iterator = iter(dataset)
    elements = list(iterator)
    assert len(elements) == 3
    assert all(elem.dtype == tf.float32 for elem in elements)
    
    # Test with custom num_elements
    dataset = create_tensor_slices_dataset([10], "int64", num_elements=3)
    iterator = iter(dataset)
    elements = list(iterator)
    assert len(elements) == 3
    assert all(elem.dtype == tf.int64 for elem in elements)

def test_create_tensor_slices_dataset_multidimensional():
    """Test create_tensor_slices_dataset with multidimensional data."""
    # Test 2D data
    dataset = create_tensor_slices_dataset([2, 3], "int32")
    iterator = iter(dataset)
    elements = list(iterator)
    assert len(elements) == 2
    assert all(elem.shape == (3,) for elem in elements)
    
    # Test 3D data
    dataset = create_tensor_slices_dataset([2, 3, 4], "float32")
    iterator = iter(dataset)
    elements = list(iterator)
    assert len(elements) == 2
    assert all(elem.shape == (3, 4) for elem in elements)

def test_create_tensor_slices_dataset_edge_cases():
    """Test edge cases for create_tensor_slices_dataset."""
    # Test empty data_shape
    dataset = create_tensor_slices_dataset([], "int32", num_elements=5)
    iterator = iter(dataset)
    elements = list(iterator)
    assert len(elements) == 5
    assert all(elem.shape == () for elem in elements)
    
    # Test with zero elements
    dataset = create_tensor_slices_dataset([0], "float32")
    iterator = iter(dataset)
    elements = list(iterator)
    assert len(elements) == 0

def test_create_tensor_slices_dataset_unsupported_dtype():
    """Test create_tensor_slices_dataset with unsupported dtype."""
    with pytest.raises(ValueError) as exc_info:
        create_tensor_slices_dataset([5], "unsupported_dtype")
    
    assert "Unsupported dtype" in str(exc_info.value)

def test_create_empty_dataset():
    """Test create_empty_dataset function."""
    # Test with default int32
    dataset = create_empty_dataset()
    iterator = iter(dataset)
    elements = list(iterator)
    assert len(elements) == 0
    
    # Test with float64
    dataset = create_empty_dataset("float64")
    iterator = iter(dataset)
    elements = list(iterator)
    assert len(elements) == 0
    # Verify dataset structure
    assert isinstance(dataset, tf.data.Dataset)
# ==== BLOCK:HEADER END ====

# ==== BLOCK:CASE_01 START ====
# TC-01: prefetch_to_device基本功能验证
# Priority: High, Group: G1
# Parameters: device=/cpu:0, buffer_size=1, dataset_type=tensor_slices, data_shape=[10], dtype=int32
# Weak asserts: returns_callable, dataset_apply_compatible, output_shape_match, output_dtype_match
@pytest.mark.parametrize("device,buffer_size,data_shape,dtype", [
    ("/cpu:0", 1, [10], "int32"),
])
def test_prefetch_to_device_basic_functionality(tf_seed, device, buffer_size, data_shape, dtype):
    """Test basic functionality of prefetch_to_device."""
    # Create dataset
    dataset = create_tensor_slices_dataset(data_shape, dtype)
    
    # Get transformation function
    transform_fn = prefetch_to_device(device=device, buffer_size=buffer_size)
    
    # Assert 1: returns_callable - transformation function should be callable
    assert callable(transform_fn), "prefetch_to_device should return a callable function"
    
    # Apply transformation
    transformed_dataset = dataset.apply(transform_fn)
    
    # Assert 2: dataset_apply_compatible - should work with Dataset.apply
    assert isinstance(transformed_dataset, tf.data.Dataset), \
        "Transformed result should be a tf.data.Dataset"
    
    # Create iterator and get first element
    iterator = iter(transformed_dataset)
    first_element = next(iterator)
    
    # Assert 3: output_shape_match - shape should match input
    expected_shape = data_shape[1:] if len(data_shape) > 1 else ()
    assert first_element.shape == expected_shape, \
        f"Output shape {first_element.shape} should match expected {expected_shape}"
    
    # Assert 4: output_dtype_match - dtype should match input
    expected_dtype = getattr(tf, dtype)
    assert first_element.dtype == expected_dtype, \
        f"Output dtype {first_element.dtype} should match expected {expected_dtype}"
    
    # Verify we can iterate through all elements
    count = 1
    for _ in iterator:
        count += 1
    
    expected_count = data_shape[0] if data_shape else 1
    assert count == expected_count, \
        f"Should iterate through {expected_count} elements, got {count}"
# ==== BLOCK:CASE_01 END ====

# ==== BLOCK:CASE_02 START ====
# TC-02: prefetch_to_device buffer_size参数验证
# Priority: High, Group: G1
# Parameters: device=/cpu:0, buffer_size=None, dataset_type=tensor_slices, data_shape=[5], dtype=float32
# Weak asserts: returns_callable, dataset_apply_compatible, auto_buffer_size_works, no_crash
@pytest.mark.parametrize("device,buffer_size,data_shape,dtype", [
    ("/cpu:0", None, [5], "float32"),
])
def test_prefetch_to_device_buffer_size_parameter(tf_seed, device, buffer_size, data_shape, dtype):
    """Test prefetch_to_device with auto buffer_size selection."""
    # Create dataset
    dataset = create_tensor_slices_dataset(data_shape, dtype)
    
    # Get transformation function with auto buffer_size
    transform_fn = prefetch_to_device(device=device, buffer_size=buffer_size)
    
    # Assert 1: returns_callable - transformation function should be callable
    assert callable(transform_fn), "prefetch_to_device should return a callable function"
    
    # Apply transformation
    transformed_dataset = dataset.apply(transform_fn)
    
    # Assert 2: dataset_apply_compatible - should work with Dataset.apply
    assert isinstance(transformed_dataset, tf.data.Dataset), \
        "Transformed result should be a tf.data.Dataset"
    
    # Assert 3: auto_buffer_size_works - should work without explicit buffer_size
    # Create iterator and get elements
    iterator = iter(transformed_dataset)
    
    # Get all elements to verify no crash
    elements = []
    for element in iterator:
        elements.append(element)
    
    # Assert 4: no_crash - should complete without errors
    assert len(elements) == data_shape[0], \
        f"Should get {data_shape[0]} elements, got {len(elements)}"
    
    # Verify dtype matches
    expected_dtype = getattr(tf, dtype)
    assert all(elem.dtype == expected_dtype for elem in elements), \
        "All elements should have correct dtype"
# ==== BLOCK:CASE_02 END ====

# ==== BLOCK:CASE_03 START ====
# TC-03: prefetch_to_device无效参数处理
# Priority: Medium, Group: G1
# Parameters: device=invalid_device, buffer_size=1, dataset_type=tensor_slices, data_shape=[3], dtype=int32
# Weak asserts: raises_exception, exception_type_correct, error_message_contains
@pytest.mark.parametrize("device,buffer_size,data_shape,dtype,test_phase", [
    ("invalid_device", 1, [3], "int32", "creation"),  # Test during function creation
    ("invalid_device", 1, [3], "int32", "application"),  # Test during dataset application
    ("invalid_device", 1, [3], "int32", "iteration"),  # Test during iteration
])
def test_prefetch_to_device_invalid_parameters(tf_seed, device, buffer_size, data_shape, dtype, test_phase):
    """Test prefetch_to_device with invalid parameters at different phases."""
    # Create dataset
    dataset = create_tensor_slices_dataset(data_shape, dtype)
    
    try:
        # Phase 1: Function creation
        transform_fn = prefetch_to_device(device=device, buffer_size=buffer_size)
        
        # Assert 1: returns_callable - should still return a callable even with invalid device
        assert callable(transform_fn), "prefetch_to_device should return a callable function even with invalid device"
        
        if test_phase == "creation":
            # Test passes if we get here without exception
            return
        
        # Phase 2: Dataset application
        transformed_dataset = dataset.apply(transform_fn)
        
        if test_phase == "application":
            # Test passes if we get here without exception
            # Verify dataset was created
            assert isinstance(transformed_dataset, tf.data.Dataset), \
                "Should create dataset even with invalid device (error may be deferred)"
            return
        
        # Phase 3: Iteration (where error is most likely to occur)
        iterator = iter(transformed_dataset)
        _ = next(iterator)
        
        # If we get here without exception, the test fails
        pytest.fail(f"Expected exception for invalid device {device} but none was raised")
        
    except Exception as exc_info:
        # Assert 2: raises_exception - should raise exception for invalid device
        exception = exc_info
        exception_type = type(exception).__name__
        
        # Assert 3: exception_type_correct - should raise appropriate exception
        # TensorFlow may raise various exceptions for invalid devices
        acceptable_exceptions = [
            'InvalidArgumentError',
            'NotFoundError',
            'FailedPreconditionError',
            'ValueError',
            'RuntimeError',
            'TypeError'
        ]
        
        assert any(acceptable in exception_type for acceptable in acceptable_exceptions), \
            f"Expected one of {acceptable_exceptions}, got {exception_type} with message: {str(exception)}"
        
        # Assert 4: error_message_contains - error message should contain relevant info
        error_message = str(exception).lower()
        
        # Check for device-related keywords in error message
        device_keywords = ['device', 'invalid', 'not found', 'not exist', 'unknown', 'unavailable']
        
        # For some TensorFlow versions, the error might be generic
        # We'll accept any exception with device in message, or if it's a known TensorFlow error type
        has_device_keyword = any(keyword in error_message for keyword in device_keywords)
        is_tf_error = any(tf_error in exception_type for tf_error in ['Error', 'Exception'])
        
        assert has_device_keyword or is_tf_error, \
            f"Error message should contain device-related info or be a TensorFlow error. " \
            f"Message: {error_message}, Type: {exception_type}"
        
        # Additional validation: Check that the exception provides useful context
        if test_phase == "iteration":
            # During iteration, we expect more specific errors
            assert len(error_message) > 10, "Error message should provide meaningful context"
        
        # Log the actual error for debugging
        print(f"Test phase '{test_phase}' caught expected exception: {exception_type}: {error_message}")
# ==== BLOCK:CASE_03 END ====

# ==== BLOCK:CASE_04 START ====
# TC-04: prefetch_to_device空数据集处理
# Priority: Medium, Group: G1
# Parameters: device=/cpu:0, buffer_size=1, dataset_type=empty, data_shape=[0], dtype=int32
# Weak asserts: returns_callable, dataset_apply_compatible, no_crash, empty_dataset_handled
@pytest.mark.parametrize("device,buffer_size,data_shape,dtype", [
    ("/cpu:0", 1, [0], "int32"),
])
def test_prefetch_to_device_empty_dataset(tf_seed, device, buffer_size, data_shape, dtype):
    """Test prefetch_to_device with empty dataset."""
    # Create empty dataset
    dataset = create_empty_dataset(dtype)
    
    # Get transformation function
    transform_fn = prefetch_to_device(device=device, buffer_size=buffer_size)
    
    # Assert 1: returns_callable - transformation function should be callable
    assert callable(transform_fn), "prefetch_to_device should return a callable function"
    
    # Apply transformation
    transformed_dataset = dataset.apply(transform_fn)
    
    # Assert 2: dataset_apply_compatible - should work with Dataset.apply
    assert isinstance(transformed_dataset, tf.data.Dataset), \
        "Transformed result should be a tf.data.Dataset"
    
    # Assert 3: no_crash - should handle empty dataset without crashing
    iterator = iter(transformed_dataset)
    
    # Assert 4: empty_dataset_handled - should handle empty dataset correctly
    with pytest.raises(StopIteration):
        # Empty dataset should raise StopIteration immediately
        _ = next(iterator)
    
    # Verify dataset properties
    # For empty dataset, we can check the element_spec
    element_spec = transformed_dataset.element_spec
    expected_dtype = getattr(tf, dtype)
    assert element_spec.dtype == expected_dtype, \
        f"Element spec dtype {element_spec.dtype} should match expected {expected_dtype}"
# ==== BLOCK:CASE_04 END ====

# ==== BLOCK:CASE_05 START ====
# TC-05: copy_to_device基本功能验证 (DEFERRED - G2 test, placeholder for reference)
# Priority: High, Group: G2
# This test case belongs to group G2 and will be implemented in its own file.
# ==== BLOCK:CASE_05 END ====

# ==== BLOCK:FOOTER START ====
# Additional test utilities and cleanup
if __name__ == "__main__":
    pytest.main([__file__, "-v"])
# ==== BLOCK:FOOTER END ====