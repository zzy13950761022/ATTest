"""
Test cases for tensorflow.python.ops.ragged.ragged_array_ops
Generated by ATTest
"""

import math
import numpy as np
import pytest
import tensorflow as tf
from tensorflow.python.ops.ragged import ragged_array_ops
from tensorflow.python.ops.ragged import ragged_tensor
from unittest import mock

# Set random seed for reproducibility
tf.random.set_seed(42)

# ==== BLOCK:HEADER START ====
# Test class and helper functions
class TestRaggedArrayOps:
    """Test suite for ragged_array_ops module."""
    
    @pytest.fixture(autouse=True)
    def setup(self):
        """Setup test fixture."""
        tf.random.set_seed(42)
        yield
    
    def _create_ragged_tensor(self, nested_list):
        """Helper to create RaggedTensor from nested list."""
        return tf.ragged.constant(nested_list)
    
    def _assert_ragged_structure_equal(self, rt1, rt2):
        """Assert that two RaggedTensors have the same structure and values."""
        # Convert to lists for comparison
        list1 = rt1.to_list()
        list2 = rt2.to_list()
        
        # Compare structure recursively
        def compare_lists(l1, l2, path=""):
            if isinstance(l1, list) and isinstance(l2, list):
                assert len(l1) == len(l2), \
                    f"Length mismatch at {path}: {len(l1)} != {len(l2)}"
                for i, (item1, item2) in enumerate(zip(l1, l2)):
                    compare_lists(item1, item2, f"{path}[{i}]")
            else:
                assert l1 == l2, f"Value mismatch at {path}: {l1} != {l2}"
        
        compare_lists(list1, list2)
    
    def _assert_dtype_preserved(self, input_tensor, output_tensor):
        """Assert that dtype is preserved."""
        assert output_tensor.dtype == input_tensor.dtype, \
            f"Dtype not preserved: {input_tensor.dtype} -> {output_tensor.dtype}"
# ==== BLOCK:HEADER END ====

# ==== BLOCK:CASE_01 START ====
    @pytest.mark.parametrize(
        "data_shape,mask_shape,expected_shape",
        [
            # Test case from specification
            (
                [[1, 2, 3], [4, 5, 6], [7, 8, 9]],
                [[True, False, True], [False, False, False], [True, False, False]],
                [[1, 3], [], [7]]
            ),
            # Additional test cases for coverage
            (
                [[1, 2, 3], [4], [5, 6]],
                [[False, False, True], [False], [True, True]],
                [[3], [], [5, 6]]
            ),
            (
                [[1, 2, 3], [4], [5, 6]],
                [True, False, True],
                [[1, 2, 3], [5, 6]]
            ),
        ]
    )
    def test_boolean_mask_basic(self, data_shape, mask_shape, expected_shape):
        """Test basic functionality of boolean_mask with RaggedTensor inputs."""
        # Create RaggedTensor data using tf.ragged.constant
        data = tf.ragged.constant(data_shape)
        
        # Create mask (could be RaggedTensor or regular Tensor)
        if isinstance(mask_shape[0], list):
            mask = tf.ragged.constant(mask_shape, dtype=tf.bool)
        else:
            mask = tf.constant(mask_shape, dtype=tf.bool)
        
        # Apply boolean_mask
        result = ragged_array_ops.boolean_mask(data, mask)
        
        # Weak assertions
        # 1. No exception
        assert result is not None
        
        # 2. Shape match (check ragged structure)
        result_list = result.to_list()
        assert len(result_list) == len(expected_shape), \
            f"Expected {len(expected_shape)} rows, got {len(result_list)}"
        
        # 3. Values correct
        for i, (res_row, exp_row) in enumerate(zip(result_list, expected_shape)):
            assert len(res_row) == len(exp_row), \
                f"Row {i}: expected {len(exp_row)} elements, got {len(res_row)}"
            for j, (res_val, exp_val) in enumerate(zip(res_row, exp_row)):
                assert res_val == exp_val, \
                    f"Row {i}, element {j}: expected {exp_val}, got {res_val}"
        
        # 4. Dtype preserved
        assert result.dtype == data.dtype, \
            f"Expected dtype {data.dtype}, got {result.dtype}"
        
        # 5. Rank preserved
        assert result.shape.rank == data.shape.rank, \
            f"Expected rank {data.shape.rank}, got {result.shape.rank}"
# ==== BLOCK:CASE_01 END ====

# ==== BLOCK:CASE_02 START ====
    @pytest.mark.parametrize(
        "input_shape,multiples,expected_shape",
        [
            # Test case from specification - corrected based on TensorFlow documentation
            (
                [[1, 2], [3]],
                [3, 2],
                [[1, 2, 1, 2], [3, 3], [1, 2, 1, 2], [3, 3], [1, 2, 1, 2], [3, 3]]
            ),
            # Additional test cases for coverage
            (
                [[1, 2, 3], [4, 5], [6]],
                [2, 1],
                [[1, 2, 3], [4, 5], [6], [1, 2, 3], [4, 5], [6]]
            ),
            (
                [[1], [2, 3], [4, 5, 6]],
                [1, 3],
                [[1, 1, 1], [2, 3, 2, 3, 2, 3], [4, 5, 6, 4, 5, 6, 4, 5, 6]]
            ),
        ]
    )
    def test_tile_replication(self, input_shape, multiples, expected_shape):
        """Test tile function for replicating RaggedTensor."""
        # Create RaggedTensor input using tf.ragged.constant
        input_tensor = tf.ragged.constant(input_shape)
        
        # Apply tile
        result = ragged_array_ops.tile(input_tensor, multiples)
        
        # Weak assertions
        # 1. No exception
        assert result is not None
        
        # 2. Shape match (check ragged structure)
        result_list = result.to_list()
        assert len(result_list) == len(expected_shape), \
            f"Expected {len(expected_shape)} rows, got {len(result_list)}"
        
        # 3. Repetition correct
        for i, (res_row, exp_row) in enumerate(zip(result_list, expected_shape)):
            assert len(res_row) == len(exp_row), \
                f"Row {i}: expected {len(exp_row)} elements, got {len(res_row)}"
            for j, (res_val, exp_val) in enumerate(zip(res_row, exp_row)):
                assert res_val == exp_val, \
                    f"Row {i}, element {j}: expected {exp_val}, got {res_val}"
        
        # 4. Dtype preserved
        assert result.dtype == input_tensor.dtype, \
            f"Expected dtype {input_tensor.dtype}, got {result.dtype}"
        
        # 5. Ragged rank preserved
        assert result.ragged_rank == input_tensor.ragged_rank, \
            f"Expected ragged_rank {input_tensor.ragged_rank}, got {result.ragged_rank}"
        
        # 6. Check total size multiplication
        input_size = sum(len(row) for row in input_shape)
        result_size = sum(len(row) for row in result_list)
        expected_size = input_size * multiples[0] * multiples[1]
        assert result_size == expected_size, \
            f"Expected total size {expected_size}, got {result_size}"
# ==== BLOCK:CASE_02 END ====

# ==== BLOCK:CASE_03 START ====
    @pytest.mark.parametrize(
        "input_shape,axis,expected_rank_increase",
        [
            # Test case from specification
            (
                [[1, 2], [3]],
                0,
                1  # Rank increases by 1
            ),
            # Additional test cases for coverage
            (
                [[1, 2, 3], [4, 5], [6]],
                -1,
                1  # Add dimension at the end
            ),
            (
                [[1], [2, 3], [4, 5, 6]],
                1,
                1  # Add dimension in the middle
            ),
            (
                [[1, 2], [3]],
                -2,
                1  # Add dimension at second last position
            ),
        ]
    )
    def test_expand_dims_dimension_expansion(self, input_shape, axis, expected_rank_increase):
        """Test expand_dims for adding dimensions to RaggedTensor."""
        # Create RaggedTensor input using tf.ragged.constant
        input_tensor = tf.ragged.constant(input_shape)
        original_rank = input_tensor.shape.rank
        
        # Apply expand_dims
        result = ragged_array_ops.expand_dims(input_tensor, axis)
        
        # Weak assertions
        # 1. No exception
        assert result is not None
        
        # 2. Rank increased
        new_rank = result.shape.rank
        assert new_rank == original_rank + expected_rank_increase, \
            f"Expected rank {original_rank + expected_rank_increase}, got {new_rank}"
        
        # 3. Values preserved (flatten and compare)
        # For axis=-1, flat_values becomes nested lists, so we need to flatten them
        input_values = input_tensor.flat_values.numpy().tolist()
        result_values = result.flat_values.numpy().tolist()
        
        # Flatten result values if they are nested (for axis=-1 case)
        def flatten_list(lst):
            flat = []
            for item in lst:
                if isinstance(item, list):
                    flat.extend(flatten_list(item))
                else:
                    flat.append(item)
            return flat
        
        flat_result_values = flatten_list(result_values)
        assert input_values == flat_result_values, \
            f"Values not preserved. Input: {input_values}, Flattened Result: {flat_result_values}"
        
        # 4. Dtype preserved
        assert result.dtype == input_tensor.dtype, \
            f"Expected dtype {input_tensor.dtype}, got {result.dtype}"
        
        # 5. Ragged structure preserved
        input_nested = input_tensor.to_list()
        result_nested = result.to_list()
        
        # For axis=0, we expect an extra outer list
        if axis == 0 or axis == -new_rank:
            assert len(result_nested) == 1, \
                f"Expected single outer list for axis=0, got {len(result_nested)}"
            assert result_nested[0] == input_nested, \
                f"Expected {input_nested} inside outer list, got {result_nested[0]}"
        # For axis=-1, we expect each row to become a list of single-element lists
        elif axis == -1 or axis == new_rank - 1:
            for i, (input_row, result_row) in enumerate(zip(input_nested, result_nested)):
                assert len(result_row) == len(input_row), \
                    f"Row {i}: expected {len(input_row)} inner lists, got {len(result_row)}"
                for j, (input_val, result_inner) in enumerate(zip(input_row, result_row)):
                    assert isinstance(result_inner, list) and len(result_inner) == 1, \
                        f"Row {i}, element {j}: expected single-element list, got {result_inner}"
                    assert result_inner[0] == input_val, \
                        f"Row {i}, element {j}: expected {input_val}, got {result_inner[0]}"
        # For axis=1 (middle dimension), we expect each row to become a list containing the original row
        elif axis == 1:
            for i, (input_row, result_row) in enumerate(zip(input_nested, result_nested)):
                assert len(result_row) == 1, \
                    f"Row {i}: expected single inner list for axis=1, got {len(result_row)}"
                assert result_row[0] == input_row, \
                    f"Row {i}: expected {input_row} inside inner list, got {result_row[0]}"
        
        # 6. Check that new dimension has size 1
        # The shape should have a 1 at the axis position
        result_shape = result.shape.as_list()
        if axis >= 0:
            axis_pos = axis
        else:
            axis_pos = new_rank + axis
        
        # For ragged tensors, some dimensions might be None (unknown)
        if result_shape[axis_pos] is not None:
            assert result_shape[axis_pos] == 1, \
                f"Expected dimension size 1 at position {axis_pos}, got {result_shape[axis_pos]}"
# ==== BLOCK:CASE_03 END ====

# ==== BLOCK:CASE_04 START ====
    @pytest.mark.parametrize(
        "input_shape, expected_size, expected_rank, test_type",
        [
            # Test case from test_plan.json: size function
            (
                [[1, 2, 3], [4, 5], [6]],  # input_shape
                6,  # expected_size: 3 + 2 + 1 = 6
                2,  # expected_rank: 2D ragged tensor
                "size"
            ),
            # Param extension: rank function with empty RaggedTensor
            (
                [],  # empty RaggedTensor
                0,  # expected_size: 0 elements
                1,  # expected_rank: 1D empty ragged tensor
                "rank"
            ),
            # Additional test: 1D ragged tensor
            (
                [[1, 2, 3, 4, 5]],  # single row with 5 elements
                5,  # expected_size
                2,  # expected_rank: 2D (1 row, variable columns)
                "both"
            ),
            # Additional test: 3D ragged tensor
            (
                [[[1, 2], [3]], [[4, 5, 6]]],  # 3D ragged tensor
                6,  # expected_size: 2 + 1 + 3 = 6
                3,  # expected_rank: 3D ragged tensor
                "both"
            ),
            # Additional test: scalar-like ragged tensor (1 element)
            (
                [[[42]]],  # single element
                1,  # expected_size
                3,  # expected_rank: 3D ragged tensor
                "both"
            ),
        ]
    )
    def test_size_and_rank_calculation(self, input_shape, expected_size, expected_rank, test_type):
        """Test size and rank calculations for RaggedTensors."""
        # Create RaggedTensor from input_shape
        if input_shape == []:
            # Special case: empty RaggedTensor
            rt = tf.ragged.constant([], ragged_rank=1, dtype=tf.int32)
        else:
            rt = tf.ragged.constant(input_shape, dtype=tf.int32)
        
        # Test size function
        if test_type in ["size", "both"]:
            # Test with default out_type (tf.int32)
            size_result = tf.size(rt)
            assert size_result.dtype == tf.int32, f"Expected dtype tf.int32, got {size_result.dtype}"
            assert size_result.shape == (), "size() should return a scalar"
            assert size_result.numpy() == expected_size, \
                f"Expected size {expected_size}, got {size_result.numpy()}"
            
            # Test with tf.int64 out_type
            size_result_int64 = tf.size(rt, out_type=tf.int64)
            assert size_result_int64.dtype == tf.int64, f"Expected dtype tf.int64, got {size_result_int64.dtype}"
            assert size_result_int64.numpy() == expected_size, \
                f"Expected size {expected_size} with tf.int64, got {size_result_int64.numpy()}"
        
        # Test rank function
        if test_type in ["rank", "both"]:
            rank_result = tf.rank(rt)
            assert rank_result.dtype == tf.int32, f"Expected dtype tf.int32, got {rank_result.dtype}"
            assert rank_result.shape == (), "rank() should return a scalar"
            assert rank_result.numpy() == expected_rank, \
                f"Expected rank {expected_rank}, got {rank_result.numpy()}"
            
            # Verify rank calculation matches expected structure
            if input_shape != []:
                # For non-empty tensors, verify ragged_rank + flat_values_rank
                if tf.ragged.is_ragged(rt):
                    flat_values_rank = tf.rank(rt.flat_values).numpy()
                    ragged_rank = rt.ragged_rank
                    calculated_rank = ragged_rank + flat_values_rank
                    assert calculated_rank == expected_rank, \
                        f"Rank calculation mismatch: {ragged_rank} + {flat_values_rank} != {expected_rank}"
        
        # Test that operations don't modify the original tensor
        original_values = rt.flat_values.numpy().copy() if hasattr(rt.flat_values, 'numpy') else None
        if original_values is not None and len(original_values) > 0:
            # Perform operations again
            _ = tf.size(rt)
            _ = tf.rank(rt)
            # Verify original tensor unchanged
            assert np.array_equal(rt.flat_values.numpy(), original_values), \
                "Original tensor was modified by size() or rank() operations"
# ==== BLOCK:CASE_04 END ====

# ==== BLOCK:CASE_05 START ====
# Placeholder for 混合类型操作 (DEFERRED_SET)
# This block will be replaced in later rounds
# ==== BLOCK:CASE_05 END ====

# ==== BLOCK:FOOTER START ====
    # Additional test cases for error scenarios
    def test_boolean_mask_invalid_mask_shape(self):
        """Test boolean_mask with invalid mask shape."""
        data = self._create_ragged_tensor([[1, 2, 3], [4, 5, 6]])
        # Mask shape is not a prefix of data shape
        mask = tf.constant([[True, False], [False, True]], dtype=tf.bool)
        
        with pytest.raises((ValueError, tf.errors.InvalidArgumentError)):
            ragged_array_ops.boolean_mask(data, mask)
    
    def test_tile_invalid_multiples_length(self):
        """Test tile with invalid multiples length."""
        data = self._create_ragged_tensor([[1, 2], [3]])
        # multiples length doesn't match input rank
        multiples = [2, 2, 2]  # Input has rank 2, multiples has length 3
        
        with pytest.raises((ValueError, tf.errors.InvalidArgumentError)):
            ragged_array_ops.tile(data, multiples)
    
    def test_expand_dims_invalid_axis(self):
        """Test expand_dims with invalid axis value."""
        data = self._create_ragged_tensor([[1, 2], [3]])
        original_rank = data.shape.rank
        
        # Axis out of range
        invalid_axis = original_rank + 1
        
        with pytest.raises((ValueError, tf.errors.InvalidArgumentError)):
            ragged_array_ops.expand_dims(data, invalid_axis)

# Additional test functions outside the class
def test_module_import():
    """Test that the module can be imported correctly."""
    assert hasattr(ragged_array_ops, 'boolean_mask')
    assert hasattr(ragged_array_ops, 'tile')
    assert hasattr(ragged_array_ops, 'expand_dims')
    assert hasattr(ragged_array_ops, 'size')
    assert hasattr(ragged_array_ops, 'rank')

if __name__ == '__main__':
    pytest.main([__file__, '-v'])
# ==== BLOCK:FOOTER END ====