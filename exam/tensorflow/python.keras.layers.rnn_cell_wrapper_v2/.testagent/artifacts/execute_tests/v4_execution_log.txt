=== Run Tests ===
.sss.s.sF.F..                                                            [100%]
================================== FAILURES ===================================
_ test_dropoutwrapper_serialization[BasicRNNCell-0.7-0.8-0.9-True-float32-5] __

cell_type = 'BasicRNNCell', input_keep_prob = 0.7, output_keep_prob = 0.8
state_keep_prob = 0.9, variational_recurrent = True, dtype = 'float32'
units = 5

    @pytest.mark.parametrize(
        "cell_type,input_keep_prob,output_keep_prob,state_keep_prob,variational_recurrent,dtype,units",
        [
            (
                "BasicRNNCell",
                0.7,
                0.8,
                0.9,
                True,
                "float32",
                5
            )
        ]
    )
    def test_dropoutwrapper_serialization(
        cell_type,
        input_keep_prob,
        output_keep_prob,
        state_keep_prob,
        variational_recurrent,
        dtype,
        units
    ):
        """Test DropoutWrapper serialization with various parameters."""
        # Create the base RNN cell
        if cell_type == "BasicRNNCell":
            cell = BasicRNNCell(num_units=units, dtype=getattr(tf, dtype))
            # Build the cell with a dummy input shape
            cell.build((None, units))
        else:
            raise ValueError(f"Unsupported cell type: {cell_type}")
    
        # Create the original DropoutWrapper
>       original_wrapper = DropoutWrapper(
            cell=cell,
            input_keep_prob=input_keep_prob,
            output_keep_prob=output_keep_prob,
            state_keep_prob=state_keep_prob,
            variational_recurrent=variational_recurrent,
            dtype=getattr(tf, dtype),
            seed=123
        )

tests\test_tensorflow_python_keras_layers_rnn_cell_wrapper_v2.py:588: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
D:\Coding\Anaconda\envs\testagent-experiment\lib\site-packages\tensorflow\python\keras\layers\rnn_cell_wrapper_v2.py:99: in __init__
    super(DropoutWrapper, self).__init__(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <tensorflow.python.keras.layers.rnn_cell_wrapper_v2.DropoutWrapper object at 0x000001E0456FE7C0>
cell = <tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.BasicRNNCell object at 0x000001E0456FEA30>
input_keep_prob = 0.7, output_keep_prob = 0.8, state_keep_prob = 0.9
variational_recurrent = True, input_size = None, dtype = tf.float32, seed = 123
dropout_state_filter_visitor = None, kwargs = {}
tensor_and_const_value = <function DropoutWrapperBase.__init__.<locals>.tensor_and_const_value at 0x000001E0456835E0>
prob = 0.8, attr = 'output_keep_prob'
tensor_prob = <tf.Tensor: shape=(), dtype=float32, numpy=0.8>, const_prob = 0.8

    def __init__(self,
                 cell,
                 input_keep_prob=1.0,
                 output_keep_prob=1.0,
                 state_keep_prob=1.0,
                 variational_recurrent=False,
                 input_size=None,
                 dtype=None,
                 seed=None,
                 dropout_state_filter_visitor=None,
                 **kwargs):
      """Create a cell with added input, state, and/or output dropout.
    
      If `variational_recurrent` is set to `True` (**NOT** the default behavior),
      then the same dropout mask is applied at every step, as described in:
      [A Theoretically Grounded Application of Dropout in Recurrent
      Neural Networks. Y. Gal, Z. Ghahramani](https://arxiv.org/abs/1512.05287).
    
      Otherwise a different dropout mask is applied at every time step.
    
      Note, by default (unless a custom `dropout_state_filter` is provided),
      the memory state (`c` component of any `LSTMStateTuple`) passing through
      a `DropoutWrapper` is never modified.  This behavior is described in the
      above article.
    
      Args:
        cell: an RNNCell, a projection to output_size is added to it.
        input_keep_prob: unit Tensor or float between 0 and 1, input keep
          probability; if it is constant and 1, no input dropout will be added.
        output_keep_prob: unit Tensor or float between 0 and 1, output keep
          probability; if it is constant and 1, no output dropout will be added.
        state_keep_prob: unit Tensor or float between 0 and 1, output keep
          probability; if it is constant and 1, no output dropout will be added.
          State dropout is performed on the outgoing states of the cell. **Note**
          the state components to which dropout is applied when `state_keep_prob`
          is in `(0, 1)` are also determined by the argument
          `dropout_state_filter_visitor` (e.g. by default dropout is never applied
          to the `c` component of an `LSTMStateTuple`).
        variational_recurrent: Python bool.  If `True`, then the same dropout
          pattern is applied across all time steps per run call. If this parameter
          is set, `input_size` **must** be provided.
        input_size: (optional) (possibly nested tuple of) `TensorShape` objects
          containing the depth(s) of the input tensors expected to be passed in to
          the `DropoutWrapper`.  Required and used **iff** `variational_recurrent
          = True` and `input_keep_prob < 1`.
        dtype: (optional) The `dtype` of the input, state, and output tensors.
          Required and used **iff** `variational_recurrent = True`.
        seed: (optional) integer, the randomness seed.
        dropout_state_filter_visitor: (optional), default: (see below).  Function
          that takes any hierarchical level of the state and returns a scalar or
          depth=1 structure of Python booleans describing which terms in the state
          should be dropped out.  In addition, if the function returns `True`,
          dropout is applied across this sublevel.  If the function returns
          `False`, dropout is not applied across this entire sublevel.
          Default behavior: perform dropout on all terms except the memory (`c`)
            state of `LSTMCellState` objects, and don't try to apply dropout to
          `TensorArray` objects: ```
          def dropout_state_filter_visitor(s):
            if isinstance(s, LSTMCellState): # Never perform dropout on the c
              state. return LSTMCellState(c=False, h=True)
            elif isinstance(s, TensorArray): return False return True ```
        **kwargs: dict of keyword arguments for base layer.
    
      Raises:
        TypeError: if `cell` is not an `RNNCell`, or `keep_state_fn` is provided
          but not `callable`.
        ValueError: if any of the keep_probs are not between 0 and 1.
      """
      super(DropoutWrapperBase, self).__init__(cell, dtype=dtype, **kwargs)
    
      if (dropout_state_filter_visitor is not None and
          not callable(dropout_state_filter_visitor)):
        raise TypeError("dropout_state_filter_visitor must be callable")
      self._dropout_state_filter = (
          dropout_state_filter_visitor or _default_dropout_state_filter_visitor)
      with ops.name_scope_v2("DropoutWrapperInit"):
    
        def tensor_and_const_value(v):
          tensor_value = ops.convert_to_tensor_v2_with_dispatch(v)
          const_value = tensor_util.constant_value(tensor_value)
          return (tensor_value, const_value)
    
        for prob, attr in [(input_keep_prob, "input_keep_prob"),
                           (state_keep_prob, "state_keep_prob"),
                           (output_keep_prob, "output_keep_prob")]:
          tensor_prob, const_prob = tensor_and_const_value(prob)
          if const_prob is not None:
            if const_prob < 0 or const_prob > 1:
              raise ValueError("Parameter %s must be between 0 and 1: %d" %
                               (attr, const_prob))
            setattr(self, "_%s" % attr, float(const_prob))
          else:
            setattr(self, "_%s" % attr, tensor_prob)
    
      # Set variational_recurrent, seed before running the code below
      self._variational_recurrent = variational_recurrent
      self._input_size = input_size
      self._seed = seed
    
      self._recurrent_input_noise = None
      self._recurrent_state_noise = None
      self._recurrent_output_noise = None
    
      if variational_recurrent:
        if dtype is None:
          raise ValueError(
              "When variational_recurrent=True, dtype must be provided")
    
        def convert_to_batch_shape(s):
          # Prepend a 1 for the batch dimension; for recurrent
          # variational dropout we use the same dropout mask for all
          # batch elements.
          return array_ops.concat(([1], tensor_shape.TensorShape(s).as_list()), 0)
    
        def batch_noise(s, inner_seed):
          shape = convert_to_batch_shape(s)
          return random_ops.random_uniform(shape, seed=inner_seed, dtype=dtype)
    
        if (not isinstance(self._input_keep_prob, numbers.Real) or
            self._input_keep_prob < 1.0):
          if input_size is None:
>           raise ValueError(
                "When variational_recurrent=True and input_keep_prob < 1.0 or "
                "is unknown, input_size must be provided")
E           ValueError: When variational_recurrent=True and input_keep_prob < 1.0 or is unknown, input_size must be provided

D:\Coding\Anaconda\envs\testagent-experiment\lib\site-packages\tensorflow\python\keras\layers\legacy_rnn\rnn_cell_wrapper_impl.py:158: ValueError
_ test_wrapper_serialization_cycle[DropoutWrapper-BasicRNNCell-0.6-0.7-float32-4] _

wrapper_type = 'DropoutWrapper', cell_type = 'BasicRNNCell'
input_keep_prob = 0.6, output_keep_prob = 0.7, dtype = 'float32', units = 4

    @pytest.mark.parametrize(
        "wrapper_type,cell_type,input_keep_prob,output_keep_prob,dtype,units",
        [
            (
                "DropoutWrapper",
                "BasicRNNCell",
                0.6,
                0.7,
                "float32",
                4
            )
        ]
    )
    def test_wrapper_serialization_cycle(
        wrapper_type,
        cell_type,
        input_keep_prob,
        output_keep_prob,
        dtype,
        units
    ):
        """Test serialization/deserialization cycle for wrappers."""
        # Create the base RNN cell
        if cell_type == "BasicRNNCell":
            cell = BasicRNNCell(num_units=units, dtype=getattr(tf, dtype))
            # Need to build with a dummy shape for serialization
            cell.build((None, units))  # Using units as input_dim for simplicity
        else:
            raise ValueError(f"Unsupported cell type: {cell_type}")
    
        # Create the wrapper
        if wrapper_type == "DropoutWrapper":
            original_wrapper = DropoutWrapper(
                cell=cell,
                input_keep_prob=input_keep_prob,
                output_keep_prob=output_keep_prob,
                dtype=getattr(tf, dtype),
                seed=42
            )
        else:
            raise ValueError(f"Unsupported wrapper type: {wrapper_type}")
    
        # Weak assertion 1: config_serializable
        config = original_wrapper.get_config()
        assert isinstance(config, dict)
    
        # Weak assertion 2: config_keys_present
        expected_keys = ['cell', 'name']
        for key in expected_keys:
            assert key in config, f"Missing key in config: {key}"
    
        # Check cell config is present
        assert 'cell' in config
        cell_config = config['cell']
        assert isinstance(cell_config, dict)
        assert 'class_name' in cell_config
        assert 'config' in cell_config
    
        # Weak assertion 3: deserialization_works
        # Recreate wrapper from config with custom_objects for BasicRNNCell
        custom_objects = {'BasicRNNCell': BasicRNNCell}
        reconstructed_wrapper = original_wrapper.__class__.from_config(
            config, custom_objects=custom_objects
        )
    
        # Weak assertion 4: reconstructed_callable
        assert isinstance(reconstructed_wrapper, original_wrapper.__class__)
        assert hasattr(reconstructed_wrapper, 'call')
        assert callable(reconstructed_wrapper.call)
    
        # Test that reconstructed wrapper works
        batch_size = 2
        input_dim = units
        inputs = tf.random.normal((batch_size, input_dim), dtype=getattr(tf, dtype))
        initial_state = tf.random.normal((batch_size, units), dtype=getattr(tf, dtype))
    
        # Call both wrappers
        original_output, original_state = original_wrapper.call(inputs, initial_state)
>       reconstructed_output, reconstructed_state = reconstructed_wrapper.call(inputs, initial_state)

tests\test_tensorflow_python_keras_layers_rnn_cell_wrapper_v2.py:863: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
D:\Coding\Anaconda\envs\testagent-experiment\lib\site-packages\tensorflow\python\keras\layers\rnn_cell_wrapper_v2.py:67: in call
    return self._call_wrapped_cell(
D:\Coding\Anaconda\envs\testagent-experiment\lib\site-packages\tensorflow\python\keras\layers\legacy_rnn\rnn_cell_wrapper_impl.py:273: in _call_wrapped_cell
    output, new_state = cell_call_fn(inputs, state, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl.BasicRNNCell object at 0x000001E0459B8100>
inputs = <tf.Tensor: shape=(2, 4), dtype=float32, numpy=
array([[ 0.        ,  2.2477493 ,  0.        ,  0.21509008],
       [-0.6021775 ,  0.        ,  1.5837847 ,  1.3188518 ]],
      dtype=float32)>
state = <tf.Tensor: shape=(2, 4), dtype=float32, numpy=
array([[ 0.22416219,  0.2207689 ,  1.6594125 , -1.8664807 ],
       [-0.20188189,  0.14063662,  2.0256739 ,  0.46836543]],
      dtype=float32)>

    def call(self, inputs, state):
      """Most basic RNN: output = new_state = act(W * input + U * state + B)."""
      _check_rnn_cell_input_dtypes([inputs, state])
      gate_inputs = math_ops.matmul(
>         array_ops.concat([inputs, state], 1), self._kernel)
E     AttributeError: 'BasicRNNCell' object has no attribute '_kernel'

D:\Coding\Anaconda\envs\testagent-experiment\lib\site-packages\tensorflow\python\keras\layers\legacy_rnn\rnn_cell_impl.py:479: AttributeError
============================== warnings summary ===============================
exam/tensorflow/python.keras.layers.rnn_cell_wrapper_v2/tests/test_tensorflow_python_keras_layers_rnn_cell_wrapper_v2.py::test_dropout_wrapper_basic_functionality[BasicRNNCell-1.0-1.0-1.0-False-float32-2-3-4-5]
exam/tensorflow/python.keras.layers.rnn_cell_wrapper_v2/tests/test_tensorflow_python_keras_layers_rnn_cell_wrapper_v2.py::test_dropout_wrapper_probability_boundaries[BasicRNNCell-0.0-0.5-1.0-False-float32-1-2-3-4]
exam/tensorflow/python.keras.layers.rnn_cell_wrapper_v2/tests/test_tensorflow_python_keras_layers_rnn_cell_wrapper_v2.py::test_dropout_wrapper_probability_boundaries[BasicRNNCell-1.0-0.0-0.0-False-float32-3-1-5-5]
exam/tensorflow/python.keras.layers.rnn_cell_wrapper_v2/tests/test_tensorflow_python_keras_layers_rnn_cell_wrapper_v2.py::test_residual_wrapper_dimension_matching[BasicRNNCell-6-6-float32-2-3]
exam/tensorflow/python.keras.layers.rnn_cell_wrapper_v2/tests/test_tensorflow_python_keras_layers_rnn_cell_wrapper_v2.py::test_device_wrapper_device_placement[BasicRNNCell-/cpu:0-float32-1-2-3-4]
exam/tensorflow/python.keras.layers.rnn_cell_wrapper_v2/tests/test_tensorflow_python_keras_layers_rnn_cell_wrapper_v2.py::test_dropoutwrapper_serialization[BasicRNNCell-0.7-0.8-0.9-True-float32-5]
exam/tensorflow/python.keras.layers.rnn_cell_wrapper_v2/tests/test_tensorflow_python_keras_layers_rnn_cell_wrapper_v2.py::test_dropoutwrapper_invalid_parameters[input_keep_prob-1.5-ValueError]
exam/tensorflow/python.keras.layers.rnn_cell_wrapper_v2/tests/test_tensorflow_python_keras_layers_rnn_cell_wrapper_v2.py::test_wrapper_serialization_cycle[DropoutWrapper-BasicRNNCell-0.6-0.7-float32-4]
  D:\Coding\Anaconda\envs\testagent-experiment\lib\site-packages\tensorflow\python\keras\layers\legacy_rnn\rnn_cell_impl.py:427: UserWarning: `tf.nn.rnn_cell.BasicRNNCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.SimpleRNNCell`, and will be replaced by that in Tensorflow 2.0.
    warnings.warn("`tf.nn.rnn_cell.BasicRNNCell` is deprecated and will be "

exam/tensorflow/python.keras.layers.rnn_cell_wrapper_v2/tests/test_tensorflow_python_keras_layers_rnn_cell_wrapper_v2.py::test_dropout_wrapper_basic_functionality[BasicRNNCell-1.0-1.0-1.0-False-float32-2-3-4-5]
exam/tensorflow/python.keras.layers.rnn_cell_wrapper_v2/tests/test_tensorflow_python_keras_layers_rnn_cell_wrapper_v2.py::test_dropout_wrapper_probability_boundaries[BasicRNNCell-0.0-0.5-1.0-False-float32-1-2-3-4]
exam/tensorflow/python.keras.layers.rnn_cell_wrapper_v2/tests/test_tensorflow_python_keras_layers_rnn_cell_wrapper_v2.py::test_dropout_wrapper_probability_boundaries[BasicRNNCell-1.0-0.0-0.0-False-float32-3-1-5-5]
exam/tensorflow/python.keras.layers.rnn_cell_wrapper_v2/tests/test_tensorflow_python_keras_layers_rnn_cell_wrapper_v2.py::test_residual_wrapper_dimension_matching[BasicRNNCell-6-6-float32-2-3]
exam/tensorflow/python.keras.layers.rnn_cell_wrapper_v2/tests/test_tensorflow_python_keras_layers_rnn_cell_wrapper_v2.py::test_device_wrapper_device_placement[BasicRNNCell-/cpu:0-float32-1-2-3-4]
exam/tensorflow/python.keras.layers.rnn_cell_wrapper_v2/tests/test_tensorflow_python_keras_layers_rnn_cell_wrapper_v2.py::test_dropoutwrapper_serialization[BasicRNNCell-0.7-0.8-0.9-True-float32-5]
exam/tensorflow/python.keras.layers.rnn_cell_wrapper_v2/tests/test_tensorflow_python_keras_layers_rnn_cell_wrapper_v2.py::test_dropoutwrapper_invalid_parameters[input_keep_prob-1.5-ValueError]
exam/tensorflow/python.keras.layers.rnn_cell_wrapper_v2/tests/test_tensorflow_python_keras_layers_rnn_cell_wrapper_v2.py::test_wrapper_serialization_cycle[DropoutWrapper-BasicRNNCell-0.6-0.7-float32-4]
  D:\Coding\Anaconda\envs\testagent-experiment\lib\site-packages\tensorflow\python\keras\engine\base_layer.py:2220: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.
    warnings.warn('`layer.add_variable` is deprecated and '

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html

---------- coverage: platform win32, python 3.9.25-final-0 -----------
Name                                                               Stmts   Miss Branch BrPart  Cover   Missing
--------------------------------------------------------------------------------------------------------------
tests\test_tensorflow_python_keras_layers_rnn_cell_wrapper_v2.py     324    123     72     15    58%   25-28, 33-36, 41-43, 55, 113, 149->159, 162-171, 225, 235-319, 364, 474, 513->526, 585, 599-680, 727->735, 759->exit, 813, 825, 867-902, 940-948, 952-953
--------------------------------------------------------------------------------------------------------------
TOTAL                                                                324    123     72     15    58%
Coverage XML written to file coverage.xml

=========================== short test summary info ===========================
FAILED tests\test_tensorflow_python_keras_layers_rnn_cell_wrapper_v2.py::test_dropoutwrapper_serialization[BasicRNNCell-0.7-0.8-0.9-True-float32-5]
FAILED tests\test_tensorflow_python_keras_layers_rnn_cell_wrapper_v2.py::test_wrapper_serialization_cycle[DropoutWrapper-BasicRNNCell-0.6-0.7-float32-4]
2 failed, 6 passed, 5 skipped, 16 warnings in 1.69s

Error: exit 1